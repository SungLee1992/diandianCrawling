2019-06-06 21:24:20 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-06 21:24:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/list-18535-3.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-06 21:24:30 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/show-16806.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-07 09:58:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/> (referer: None)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 27, in parse
    for key in self.zcfg_dict:
AttributeError: 'Zcfg_Article_Spider' object has no attribute 'zcfg_dict'
2019-06-07 10:07:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 49, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170427_5584803.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170630_5731919.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170424_5580935.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201705/t20170509_5600742.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201705/t20170509_5600743.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170613_5672363.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170608_5665309.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170721_5757375.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170906_5808198.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824248.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828755.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820159.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820168.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170724_5757925.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824165.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201805/t20180504_6141419.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201804/t20180420_6140709.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170419_5575066.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170419_5575074.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556140.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556143.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828817.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200809/t20080902_1124882.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949614.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912433.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912443.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200709/t20070903_883555.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949600.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200802/t20080229_981783.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141455.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201409/t20140911_4051177.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200812/t20081229_1197918.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300220.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300211.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200903/t20090302_1227396.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200903/t20090302_1227410.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200905/t20090504_1266032.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201506/t20150608_4651843.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201506/t20150608_4651770.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201507/t20150728_4766139.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201803/t20180330_6139431.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201803/t20180330_6139436.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201605/t20160506_5120615.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201603/t20160317_5057599.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170208_5470371.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170228_5498311.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170321_5532577.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170331_5546446.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170331_5546458.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170323_5535890.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5547976.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180408_6139692.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/t20180330_6139379.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180408_6139693.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180408_6139694.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 102, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180410_6139835.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 102, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180423_6140826.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180425_6140983.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180425_6140987.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180417_6140387.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180427_6141158.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180427_6141159.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141451.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141446.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141452.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201203/t20120327_2546951.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201303/t20130320_3354001.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201411/t20141121_4246421.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201404/t20140425_3884555.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201403/t20140311_3809883.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201504/t20150413_4524372.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201701/t20170124_5465008.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201409/t20140925_4065626.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201409/t20140917_4057743.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201401/t20140121_3743917.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201502/t20150203_4393992.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201504/t20150430_4570011.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201507/t20150709_4737906.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201505/t20150506_4581636.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201603/t20160307_5042888.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201505/t20150528_4622065.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201603/t20160307_5042908.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201601/t20160128_5000588.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141453.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824248.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820168.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170424_5580935.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828755.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170419_5575074.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824165.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828817.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201705/t20170509_5600742.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170630_5731919.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201705/t20170509_5600743.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170608_5665309.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170613_5672363.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170721_5757375.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170427_5584803.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170906_5808198.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200709/t20070903_883555.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912433.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201406/t20140603_3923826.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912443.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201406/t20140625_3950058.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212819.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212820.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220185.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212821.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212822.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180213_6137159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180214_6137218.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180222_6137268.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220187.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220188.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220192.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220193.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220190.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6249229.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6248325.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6249232.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6248327.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6248540.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201905/t20190531_6315980.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6248870.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541839.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541981.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541976.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201905/t20190531_6315983.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541980.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541840.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201902/t20190228_6172938.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541977.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201903/t20190328_6177382.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201903/t20190315_6176655.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201903/t20190315_6176656.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201902/t20190213_6171371.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201903/t20190318_6176742.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180112_6134888.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134904.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134916.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134902.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134917.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134899.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134914.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134900.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180129_6135857.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135983.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135970.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135971.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180201_6136265.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136662.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136666.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_540019.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_540018.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_540017.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540367.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540364.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540369.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540361.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540370.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540368.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540366.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540365.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171016_5840580.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171102_5858927.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171109_5865569.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171116_5902881.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540510.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171025_5850040.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171123_5917824.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171129_5923414.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123893.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123903.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171127_5920159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123904.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123891.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539834.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126064.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539851.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539493.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539482.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539848.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539850.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539490.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539492.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539489.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539488.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539622.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539623.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539621.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539625.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539624.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539620.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539849.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539847.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170414_5560889.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_539852.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170414_5560977.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170421_5579066.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5649116.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5648983.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201705/t20170505_5596785.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5649037.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170621_5718044.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170614_5677826.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170614_5677619.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170615_5688787.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201708/t20170823_5791602.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201708/t20170829_5797329.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170904_5802578.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170906_5808192.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170918_5818317.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170921_5821885.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170930_5833945.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171011_5837024.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_540016.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123885.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126067.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123892.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126057.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180102_6133588.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180110_6134472.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180105_6134191.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540512.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540659.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540511.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541058.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541060.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136668.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541059.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541188.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136812.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136737.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136818.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180213_6136943.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201903/t20190328_6177383.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201903/t20190328_6177384.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201903/t20190328_6177385.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190416_6179327.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201903/t20190328_6177386.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190403_6177891.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190402_6177761.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190416_6179328.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190416_6179329.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190416_6179330.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190416_6179331.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212817.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/t20180330_6139379.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 102, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 102, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180408_6139692.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180408_6139693.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180408_6139694.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180410_6139835.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180417_6140387.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180425_6140983.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180423_6140826.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180425_6140987.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180427_6141158.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180427_6141159.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141446.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541978.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141451.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141452.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141453.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541979.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541975.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541973.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541974.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060124_542162.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060124_542161.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060124_542448.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060124_542730.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200604/t20060430_604147.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060119_539110.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200611/t20061101_712436.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200707/t20070702_845239.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201905/t20190531_6315984.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200707/t20070702_845225.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201906/t20190606_6316285.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201605/t20160509_5122205.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201605/t20160527_5153573.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201607/t20160722_5215101.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201605/t20160506_5120615.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201703/t20170323_5535315.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201706/t20170601_5649037.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201706/t20170601_5649116.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201706/t20170621_5718044.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/govpublic/XZQYJ/201611/t20161117_5366803.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201804/t20180412_6140127.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/govpublic/XZQYJ/201609/t20160902_5262939.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/govpublic/SCYJJXXS/201609/t20160901_5260726.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201706/t20170601_5648983.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201710/t20171025_5850040.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201812/t20181205_6164423.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201809/t20180921_6157725.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201902/t20190218_6172024.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201904/t20190416_6179338.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201803/t20180320_6138731.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201805/t20180504_6141419.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201804/t20180420_6140709.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201904/t20190422_6212175.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201805/t20180504_6141418.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201805/t20180521_6142733.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201805/t20180504_6141413.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201805/t20180521_6142731.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201203/t20120327_2546951.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201303/t20130320_3354001.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201404/t20140425_3884555.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201411/t20141121_4246421.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201409/t20140925_4065626.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201403/t20140311_3809883.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201504/t20150413_4524372.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201409/t20140917_4057743.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201401/t20140121_3743917.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201502/t20150203_4393992.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201504/t20150430_4570011.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201505/t20150506_4581636.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201507/t20150709_4737906.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201505/t20150528_4622065.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201601/t20160128_5000588.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201603/t20160307_5042908.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201603/t20160307_5042888.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201601/t20160128_5001675.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201603/t20160330_5076285.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201604/t20160426_5108762.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201805/t20180528_6143243.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201810/t20181024_6161474.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201811/t20181101_6162105.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201109/t20110928_2312690.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201902/t20190221_6172266.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201109/t20110928_2312691.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201901/t20190125_6170710.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201903/t20190312_6173596.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201903/t20190312_6173594.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201904/t20190423_6212471.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201905/t20190516_6305465.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201905/t20190531_6316006.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141456.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141455.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142917.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180508_6141547.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142919.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142920.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142923.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142921.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142924.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201806/t20180605_6151092.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201806/t20180605_6151093.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201806/t20180605_6151132.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201806/t20180619_6152622.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201806/t20180628_6153312.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201807/t20180717_6154244.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201809/t20180920_6157689.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201809/t20180911_6157097.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201809/t20180920_6157688.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201809/t20180929_6159644.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201809/t20180930_6159699.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201403/t20140313_3812809.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201403/t20140312_3811681.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201501/t20150115_4337435.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201409/t20140911_4051130.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201405/t20140523_3913663.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201506/t20150608_4651858.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201502/t20150227_4418128.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201512/t20151209_4928481.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201512/t20151221_4957995.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201606/t20160603_5159963.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201603/t20160308_5043495.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201704/t20170405_5549362.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201705/t20170503_5591465.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170620_5714015.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170622_5722310.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201708/t20170822_5790271.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170627_5728767.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201812/t20181214_6164972.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949614.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200802/t20080229_981783.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949600.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200806/t20080603_1054132.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200806/t20080612_1060386.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200805/t20080508_1034935.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200808/t20080811_1101698.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200809/t20080919_1136245.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200810/t20081010_1147903.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200810/t20081020_1155263.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200811/t20081128_1180739.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200812/t20081209_1186382.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200812/t20081209_1186401.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200903/t20090309_1231638.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200907/t20090724_1318443.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090908_1345975.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090908_1346011.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090925_1358381.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201111/t20111116_2410432.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201207/t20120713_2785863.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201201/t20120105_2451032.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201311/t20131127_3687345.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201311/t20131118_3679466.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200809/t20080902_1124882.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200812/t20081229_1197918.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200607/t20060717_648958.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060522_614399.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060530_619099.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200608/t20060814_666762.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200609/t20060904_679653.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200701/t20070104_750979.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200608/t20060825_674272.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200703/t20070306_780689.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070420_806233.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070424_807868.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070429_811063.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200705/t20070508_811889.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200706/t20070606_828888.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200707/t20070720_855926.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200706/t20070611_832110.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200710/t20071017_905542.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080229_981796.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080218_971819.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080222_977018.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200903/t20090302_1227396.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541969.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541968.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200801/t20080124_960610.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541967.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542158.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542157.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542156.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542721.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542447.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542718.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060120_539248.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060120_539246.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542848.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060127_544523.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200602/t20060210_549123.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200602/t20060224_558063.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200603/t20060314_570153.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200604/t20060412_591894.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060511_608008.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060518_611886.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200903/t20090302_1227410.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200905/t20090504_1266032.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300220.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300211.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201409/t20140911_4051177.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201506/t20150608_4651770.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201506/t20150608_4651843.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201507/t20150728_4766139.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201603/t20160317_5057599.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201803/t20180330_6139436.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201803/t20180330_6139431.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556140.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556143.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170419_5575066.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820159.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170228_5498311.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170208_5470371.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170323_5535890.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170331_5546458.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170321_5532577.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170331_5546446.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5547976.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5548402.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5548406.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5550906.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5551108.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5551094.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5552903.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5552912.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5553398.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5553399.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170410_5554852.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170410_5554854.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556139.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201701/t20170124_5465008.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170724_5757925.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201705/t20170531_5640037.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541189.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/qnhnzc/201811/t20181130_6164109.htm> (referer: http://www.moa.gov.cn/gk/zcfg/qnhnzc/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:16:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5547983.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170630_5731919.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170613_5672363.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170721_5757375.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170906_5808198.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170724_5757925.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170608_5665309.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820159.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824165.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824248.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828755.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556140.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556143.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828817.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170419_5575066.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201804/t20180420_6140709.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180214_6137218.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180222_6137268.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201803/t20180320_6138731.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180213_6137159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201805/t20180504_6141419.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201406/t20140625_3950058.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201403/t20140313_3812809.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201403/t20140312_3811681.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201405/t20140523_3913663.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201409/t20140911_4051130.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201501/t20150115_4337435.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201502/t20150227_4418128.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201506/t20150608_4651858.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201606/t20160603_5159963.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201512/t20151221_4957995.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201603/t20160308_5043495.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201512/t20151209_4928481.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201705/t20170503_5591465.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201704/t20170405_5549362.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170627_5728767.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170620_5714015.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201708/t20170822_5790271.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170622_5722310.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5552912.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5553398.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170208_5470371.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180112_6134888.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134904.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134916.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200805/t20080508_1034935.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200806/t20080612_1060386.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200806/t20080603_1054132.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200809/t20080919_1136245.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200808/t20080811_1101698.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200811/t20081128_1180739.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200812/t20081209_1186382.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200810/t20081010_1147903.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200810/t20081020_1155263.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200903/t20090309_1231638.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090925_1358381.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200907/t20090724_1318443.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200812/t20081209_1186401.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090908_1345975.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090908_1346011.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201111/t20111116_2410432.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201201/t20120105_2451032.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201311/t20131127_3687345.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201207/t20120713_2785863.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134917.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201311/t20131118_3679466.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134902.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171025_5850040.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134899.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171016_5840580.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171102_5858927.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171109_5865569.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171116_5902881.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060530_619099.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200607/t20060717_648958.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060522_614399.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200608/t20060814_666762.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200608/t20060825_674272.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200609/t20060904_679653.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200703/t20070306_780689.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070420_806233.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200701/t20070104_750979.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070424_807868.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200705/t20070508_811889.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070429_811063.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200706/t20070606_828888.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200706/t20070611_832110.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200707/t20070720_855926.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200710/t20071017_905542.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080229_981796.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080218_971819.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200801/t20080124_960610.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171129_5923414.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080222_977018.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123891.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171127_5920159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170414_5560889.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170414_5560977.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170421_5579066.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541969.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541967.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542158.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542157.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542447.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542156.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542721.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542718.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542848.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060120_539248.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060120_539246.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060127_544523.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200602/t20060210_549123.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200603/t20060314_570153.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200604/t20060412_591894.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060511_608008.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060518_611886.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5649116.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5648983.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5649037.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201705/t20170505_5596785.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201705/t20170531_5640037.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170621_5718044.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170614_5677619.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170615_5688787.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170614_5677826.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201708/t20170829_5797329.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170904_5802578.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201708/t20170823_5791602.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170906_5808192.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170921_5821885.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170918_5818317.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170930_5833945.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171011_5837024.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123893.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123904.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126064.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123903.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123885.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126067.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123892.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126057.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180110_6134472.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180102_6133588.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180105_6134191.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201701/t20170124_5465008.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134914.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134900.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180129_6135857.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135983.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135970.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180201_6136265.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135971.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136666.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136662.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136668.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136812.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136737.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136818.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180213_6136943.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170228_5498311.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170323_5535890.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170321_5532577.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170331_5546446.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170331_5546458.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5547976.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5547983.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5548402.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5548406.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5550906.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5551094.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5551108.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5552903.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5553399.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170410_5554852.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170410_5554854.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556139.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201812/t20181214_6164972.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912433.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200709/t20070903_883555.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912443.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949614.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949600.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200809/t20080902_1124882.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200802/t20080229_981783.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200812/t20081229_1197918.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200903/t20090302_1227396.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200903/t20090302_1227410.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200905/t20090504_1266032.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300220.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300211.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541840.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541981.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541980.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541976.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820168.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201406/t20140603_3923826.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541979.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541975.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541974.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171123_5917824.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541968.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200602/t20060224_558063.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541839.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:18:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541977.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 129, in parse_detail
    print(item['art_art_date'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_art_date'
2019-06-07 10:50:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 102, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 10:50:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 102, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:16:38 [py.warnings] WARNING: D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py:105: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 105 of the file D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(detail)

2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556140.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170424_5580935.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170419_5575066.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170427_5584803.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170419_5575074.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556143.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201705/t20170509_5600743.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170608_5665309.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170613_5672363.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201705/t20170509_5600742.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170630_5731919.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170721_5757375.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170724_5757925.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170906_5808198.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824248.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828755.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820159.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820168.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824165.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828817.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180213_6137159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201403/t20140313_3812809.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201403/t20140312_3811681.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201406/t20140603_3923826.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201405/t20140523_3913663.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201409/t20140911_4051130.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201501/t20150115_4337435.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201406/t20140625_3950058.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170208_5470371.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170228_5498311.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170321_5532577.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170331_5546446.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170323_5535890.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170331_5546458.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5547976.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5547983.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5548402.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170401_5548406.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5550906.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5551094.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180112_6134888.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134902.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134900.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180129_6135857.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134904.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134916.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134917.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134899.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180115_6134914.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200805/t20080508_1034935.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200806/t20080603_1054132.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200808/t20080811_1101698.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200809/t20080919_1136245.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200806/t20080612_1060386.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200810/t20081010_1147903.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200810/t20081020_1155263.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201701/t20170124_5465008.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171025_5850040.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171016_5840580.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171116_5902881.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171102_5858927.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171109_5865569.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200811/t20081128_1180739.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171123_5917824.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171129_5923414.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201711/t20171127_5920159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123891.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123893.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200607/t20060717_648958.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060530_619099.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060522_614399.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200608/t20060814_666762.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200609/t20060904_679653.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200701/t20070104_750979.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070420_806233.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070424_807868.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200703/t20070306_780689.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200608/t20060825_674272.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200705/t20070508_811889.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200706/t20070606_828888.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070429_811063.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200707/t20070720_855926.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200706/t20070611_832110.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200710/t20071017_905542.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080229_981796.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541969.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080218_971819.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200802/t20080222_977018.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541967.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060123_541968.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542157.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542159.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542158.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542447.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542156.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542721.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200801/t20080124_960610.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542718.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060124_542848.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060120_539246.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200602/t20060210_549123.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200602/t20060224_558063.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060127_544523.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200604/t20060412_591894.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060511_608008.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200603/t20060314_570153.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200601/t20060120_539248.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200605/t20060518_611886.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170414_5560889.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201705/t20170505_5596785.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170421_5579066.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201704/t20170414_5560977.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201705/t20170531_5640037.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5649037.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5648983.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170621_5718044.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170601_5649116.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170614_5677826.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170614_5677619.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201706/t20170615_5688787.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201708/t20170829_5797329.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170904_5802578.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170906_5808192.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170918_5818317.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170921_5821885.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201708/t20170823_5791602.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201709/t20170930_5833945.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201710/t20171011_5837024.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_3.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126064.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180110_6134472.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126067.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123885.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171227_6126057.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123903.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123904.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201712/t20171219_6123892.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180102_6133588.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200812/t20081209_1186382.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180105_6134191.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200903/t20090309_1231638.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090908_1345975.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200812/t20081209_1186401.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201111/t20111116_2410432.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090925_1358381.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200907/t20090724_1318443.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/200909/t20090908_1346011.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201201/t20120105_2451032.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201311/t20131127_3687345.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135983.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201207/t20120713_2785863.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136662.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180201_6136265.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201311/t20131118_3679466.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135970.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201801/t20180130_6135971.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136666.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180208_6136668.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136812.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136737.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180209_6136818.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170406_5551108.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/nybgz/201802/t20180213_6136943.htm> (referer: http://www.moa.gov.cn/gk/zcfg/nybgz/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5552912.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5552903.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5553398.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170410_5554852.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170410_5554854.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170411_5556139.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201506/t20150608_4651858.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170407_5553399.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201502/t20150227_4418128.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201512/t20151209_4928481.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201606/t20160603_5159963.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201512/t20151221_4957995.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170620_5714015.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201603/t20160308_5043495.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201704/t20170405_5549362.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201705/t20170503_5591465.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170622_5722310.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201706/t20170627_5728767.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201708/t20170822_5790271.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200709/t20070903_883555.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912433.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/xzfg/201812/t20181214_6164972.htm> (referer: http://www.moa.gov.cn/gk/zcfg/xzfg/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949614.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200812/t20081229_1197918.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200905/t20090504_1266032.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200802/t20080229_981783.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200903/t20090302_1227410.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200809/t20080902_1124882.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200903/t20090302_1227396.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949600.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201409/t20140911_4051177.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300220.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300211.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201506/t20150608_4651843.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201507/t20150728_4766139.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201603/t20160317_5057599.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201506/t20150608_4651770.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201803/t20180330_6139431.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/201803/t20180330_6139436.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180508_6141547.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142917.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541839.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141455.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180507_6141456.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541840.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541981.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541976.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541977.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541978.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541979.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541980.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541975.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541974.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060124_542730.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541973.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060124_542162.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060119_539110.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060124_542161.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060124_542448.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180408_6139693.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 104, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 104, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/t20180330_6139379.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_540018.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_540017.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060120_540019.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201804/t20180408_6139692.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540364.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540369.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540361.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540370.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540365.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540367.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540368.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_540366.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_2.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [py.warnings] WARNING: D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py:105: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 105 of the file D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(detail)

2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170427_5584803.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201705/t20170509_5600742.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170608_5665309.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201705/t20170509_5600743.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170613_5672363.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201704/t20170424_5580935.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201706/t20170630_5731919.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170906_5808198.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828755.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820159.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170919_5820168.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170724_5757925.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201707/t20170721_5757375.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824165.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170925_5824248.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142921.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142923.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142924.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201709/t20170927_5828817.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201805/t20180523_6142920.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200906/t20090629_1300220.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200709/t20070903_883555.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912433.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200710/t20071030_912443.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949614.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200801/t20080107_949600.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200802/t20080229_981783.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200809/t20080902_1124882.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212819.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212820.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212821.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190425_6212822.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220185.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220187.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201904/t20190428_6220188.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201702/t20170228_5498311.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170321_5532577.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2017nszd/201703/t20170323_5535890.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2017nszd/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541839.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541840.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541976.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541977.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541978.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541981.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541979.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541980.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/zcfg/fl/200601/t20060123_541975.htm> (referer: http://www.moa.gov.cn/gk/zcfg/fl/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201902/t20190213_6171371.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:17:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2019/201902/t20190228_6172938.htm> (referer: http://www.moa.gov.cn/gk/nszd_1/2019/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    soup_detail = soup.find_all('p').get_text()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 1621, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
2019-06-07 11:19:05 [py.warnings] WARNING: D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py:105: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 105 of the file D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(detail)

2019-06-07 11:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 104, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 104, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:21:06 [py.warnings] WARNING: D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py:105: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 105 of the file D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(detail).p

2019-06-07 11:21:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 104, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:21:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 104, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:21:08 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.moa.gov.cn/gk/zcfg/xzfg/200704/t20070429_811063.htm. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-07 11:22:58 [py.warnings] WARNING: D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py:105: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 105 of the file D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(detail)

2019-06-07 11:22:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 104, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:22:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 104, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:28:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:28:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:36:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:36:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:38:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 49, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-07 11:40:40 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-07 11:40:45 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-07 11:40:45 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-07 11:40:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:40:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 107, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-07 11:40:52 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-10 11:44:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 49, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-10 17:18:20 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-10 17:18:28 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-10 17:18:33 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-10 17:18:34 [crawling.pipelines] ERROR: (1406, "Data too long for column 'art_detail' at row 1")
2019-06-10 17:18:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180330381956312398.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-10 17:18:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.moa.gov.cn/gk/nszd_1/2018/201803/P020180312403213215741.doc> (referer: http://www.moa.gov.cn/gk/nszd_1/2018/index_1.htm)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zcfg_Article_Spider.py", line 106, in parse_detail
    detail = response.xpath("//div[@class='arc_body mg_auto w_855 pd_b_35']").extract_first()
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\response\__init__.py", line 105, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-05-23 17:19:15',
 'art_detail': '\n'
               '         陕农办发〔2019〕89号\xa0'
               '各设区市农业农村（农业）局，杨凌示范区农业局，韩城市农业农村局：2018年全省农业农村系统充分发挥各级产业扶贫技术服务110平台作用，组织调度多方资源，面向产业贫困户，开展了多层次、多渠道、多形式的技术帮扶工作，取得了良好成效。但从检查反馈情况看，个别地方还存在群众对技术帮扶110平台知晓率、利用率较低，技术帮扶针对性、实用性不够、精准度不高，有大水漫灌等现象。针对存在问题，为扎实做好2019年产业扶贫技术服务工作，现就有关事项通知如下：一、明确工作目标2019年，全省产业扶贫技术服务工作要以助力脱贫攻坚、促进乡村振兴战略实施为目标，以29个年度脱贫摘帽县为重点，紧紧围绕“3+X”特色产业布局规划，针对产业贫困户产业发展需求及接受能力，分层分类施策开展技术帮扶。实现产业技术帮扶、技术干部包联、普及性技术培训、重大项目跟踪服务“四个全覆盖”，确保每个产业贫困户都能掌握1─2门生产技能，群众满意率达90%以上。二、抓好重点工作各级农业农村部门要按照“省级抓示范服务，市级抓管理指导，县级抓工作落实”思路，强化措施，扎实工作，切实提升产业技术服务工作质量和效果。（一）完善拓展110平台功能，巩固110体系。根据机构改革变化，省级产业脱贫110技术服务平台重新调整了指挥中心成员、投诉和调度电话（详见附件1）。各市县要严格按照“一把手负总责，分管领导负主要责任”“110指挥平台设置在农业农村部门”的要求，进一步明确110指挥中心机构设置、成员名单及工作职责。公开县级指挥中心产业技术服务联系人、本县各类专家及固定投诉电话，及时满足产业贫困户技术需求，完成服务工作，确保事事有回应，件件有落实。（二）强化帮扶队伍建设,提升帮扶能力。省农业农村厅将组织省级产业体系、科研院所专家成立省级产业扶贫技术服务专家团，建立全省产业扶贫技术帮扶师资数据库和微信群。各市县要建立贫困户产业发展指导员制度，进一步强化“四支技术帮扶队伍”传帮带作用，吸纳更多“土专家”“田秀才”以及科研院所、国企合力团等进入帮扶队伍，壮大帮扶力量，提升帮扶能力和水平。（三）建立结对帮扶制度，夯实包联干部职责。要建立农业干部包联贫困村、技术干部包联贫困户制度，确保每个产业贫困户与1名包联干部和1名技术指导服务干部进行结对帮扶。同时进一步明确包联干部和技术服务干部工作职责，确保贫困户发展产业有人帮，技术指导有人教。（四）突出技术服务重点，提升服务效能。围绕“3+X”产业发展规划，省级主要抓好苹果、羊乳、设施农业等三个千亿级产业的示范性技术服务，市县突出抓好茶叶、设施蔬菜、猕猴桃、冬枣、花椒、食用菌、中药材等区域特色产业的普及性技术服务。在做好“110接警”和主动上门服务培训的基础上，充分发挥云上智农APP和互联网、大数据、人工智能等信息化手段开展在线培训和远程答疑，丰富服务内容，创新服务方式，提升服务效能。（五）探索服务机制，形成帮扶合力。创新机制，转变服务方式，通过政府购买服务等形式，积极探索新型经营主体、农村能人、职业农民等社会力量参与产业脱贫技术服务工作。探索产业扶贫技术服务长效机制，着力解决贫困户发展产业中的困难和问题，提高产业发展能力。三、强化工作保障（一）加强组织领导。2019年产业脱贫工作到了攻坚拔寨、决战决胜的紧要关头，各级农业农村部门要高度重视，将技术服务纳入产业扶贫精准脱贫工作的重要议事日程，按照“一把手负总责，分管领导负主要责任”的要求，加强组织领导，细化工作措施，为工作有力有效开展提供坚强保障。（二）确保资金投入。各级农业农村部门要根据工作需要，安排一定比例的产业扶贫切块资金用于技术服务工作，确保资金保障。同时要积极引导龙头企业、合作社、家庭农场等技术资源，从加快培育当地特色产业链的现实需求出发，积极开展技术服务工作，形成工作合力。（三）强化包抓指导。为促进产业扶贫技术服务工作顺利实施，省级成立关中、陕南、陕北3个工作包抓指导服务组（成员名单详见附件2），对各市县工作开展情况、存在问题等进行不定期的抽查指导。各市（区）也要成立相应的包抓指导组，对县级主体责任履行、110指挥平台作用发挥、包村技术干部到位、帮扶计划实施、技术力量调配、服务质量效果等情况进行常态化指导服务。各县区要加强对乡镇、村两委班子、第一书记、驻村扶贫干部的责任落实、作用发挥、工作成效情况的了解掌握，及时解决工作开展过程中的困难和问题。（四）加强服务管理。各市（区）要按月报送技术服务相关信息，确保信息真实性、准确性和完整性。同时要做好档案资料记录、整理、归档及帮扶效果回访工作，强化工作管理，完善工作机制。（五）注重宣传引导。省农业农村厅将通过中省主要新闻媒体、网站，对各地产业扶贫技术服务工作先进做法及经验进行宣传推广。各市县要充分利用广播、电视、报刊、杂志、互联网等多种媒体，对产业扶贫技术服务的工作典型经验、先进人物进行广泛地宣传报道。从2019年4月起各市（区）须每月向省指挥中心报送1—2篇典型经验材料。\xa0'
               '联 系 人：程丽娟\xa0 杨新农联系电话：029-87335733\xa0 \xa0'
               '029-87400112电子邮箱：sxnmpx@163.com\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '附件：1. 2019年省级产业脱贫技术服务110指挥中心成员名单\xa0 \xa0 2. '
               '2019年省级产业脱贫技术服务工作包抓指导服务组成员名单\xa0'
               '附件.docx\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业农村厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0'
               '2019年4月2日\n'
               '        ',
 'art_source': '陕西省农业农村厅',
 'art_title': '陕西省农业农村厅办公室关于做好2019年产业扶贫技术服务工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-04-02 16:19:47',
 'art_detail': '\n'
               '         '
               '陕农办发〔2019〕73号各设区市农业农村（农业）、畜牧局，杨凌示范区农业局，韩城市农业农村局，厅兽医处，省饲料办：2019年3月11日，农业农村部办公厅印发《关于贯彻落实&lt;国务院关于取消和下放一批行政许可事项的决定&gt;的通知》(农办法〔2019〕3号，以下简称《通知》),其中涉及我厅2项中央制定地方实施行政许可事项（详见附件）。《通知》要求自国务院决定发布之日起，取消“饲料添加剂预混合饲料、混合型饲料添加剂产品批准文号核发”和“新兽药临床试验审批”行政许可，改为备案。请各有关单位严格按照《通知》要求，认真做好取消后衔接落实工作，采取“双随机、一公开”监管、重点监管、信用监管、“互联网+监管”等方式，确保放得开、接得住、管得好。厅兽医处要按照《通知》要求，完善各项监管制度。各相关单位要尽快清理与所涉事项有关的规范性文件和政策性文件，废除不在适用的规范性文件和政策性文件，加快推进相关法规修订，做到改革于法有据、依法推进。各市（区）农业农村部门要按要求做好取消许可后备案工作,确保相关领域管理不出现混乱。\xa0'
               '附件：国务院决定取消的行政许可事项目录（涉及农业农村部分）附件.docx\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业农村厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2019年3月25日\n'
               '        ',
 'art_source': '厅综合行政执法局',
 'art_title': '陕西省农业农村厅办公室关于做好取消和下放行政许可事项的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-04-22 17:50:49',
 'art_detail': '\n'
               '         陕农办发〔2019〕104号\xa0'
               '各设区市农业农村（农业）局，杨凌示范区农业局，韩城市农业农村局：目前，全省小麦已陆续进入抽穗扬花期，也是小麦重大病虫发生危害的主要时期。据天气预报，4月下旬至5月初，全省大部降水偏多，气温偏高，与小麦抽穗扬花期吻合，利于小麦赤霉病发生流行，防控形势严峻。根据《农业农村部办公厅关于加强小麦赤霉病防控工作的通知》（农明字〔2019〕第18号），为切实做好小麦赤霉病防控，遏制病害大范围流行成灾，实现防病治虫保丰收，现就有关事项紧急通知如下：一、强化责任落实。小麦赤霉病属典型的气候型病害，一旦流行将直接影响小麦产量和品质，有效控制赤霉病危害，对实现全年粮食生产目标任务完成、提高小麦品质等具有十分重要意义。因此，各地要坚决贯彻中省部署，把赤霉病防控作为当前农业生产的重要任务，加强组织领导，广泛动员部署，层层落实责任，切实抓好防控措施，确保赤霉病不大范围流行成灾。二、加强监测预警。各地要密切关注气象条件变化，加密监测，全面掌握病情趋势，科学研判病害流行态势，及时发布病害预警信息，指导各地适时开展科学防治，确保不因监测不到位，预报不及时致使错失最佳防控时机。严格执行信息报送制度和重灾情实时报告制度，确保信息渠道畅通。三、实施科学防控。各地要坚持“预防为主、主动出击”的防治策略，紧抓4月20日-30日的防治关键时期，抢抓有利天气，确保大面积防治一次；赤霉病常发重发区域，要密切关注天气预报，如遇连阴雨天气，天晴后及时补防1次。科学选用高效药剂，各地要根据省农业农村厅下发的主要大田作物农药使用指导名录意见，明确用药品种，重点选择氰烯菌酯、烯肟·多菌灵、戊唑醇等高效药剂进行喷雾防治。四、推进统防统治。用好中央和地方财政资金，通过政府购买服务等形式，扶持发展装备精良、技术先进、管理规范、信誉良好的专业化服务组织，大力开展统防统治，大范围实施“一喷三防”。推行统一组织发动、统一技术方案、统一药剂供应、统一防治时间、统一施药作业等“五统一”服务，切实提高防控组织化程度和防控效果，实现农药减量增效。五、精准指导服务。组织专家制定完善小麦赤霉病防控技术方案，开展巡回技术指导，因地因时落实好防控措施。组织机关干部和农技人员深入小麦赤霉病重发区，采取分片包干、进村入户等形式，帮助农民解决实际困难。在防控关键时期，对重点地区开展工作督导，确保防控工作措施落实到位、技术措施落实到田。六、切实抓好宣传。各地要充分利用电视、电台、报纸等新闻媒体，通过手机短信群发、召开现场会、制定宣传牌、出动宣传车、发放技术资料等多种形式，全方位宣传小麦赤霉病危害严重性、发生信息及防治技术，营造防控氛围，提高农民防控积极性，保障小麦生产安全。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业农村厅办公室\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '2019年4月18日\n'
               '        ',
 'art_source': '陕西省农业农村厅',
 'art_title': '陕西省农业农村厅办公室关于加强小麦赤霉病防控工作的紧急通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-05-31 15:15:06',
 'art_detail': '\n'
               '         '
               '陕农办发〔2019〕155号各设区市农业农村（农业）局，杨凌示范区现代农业和乡村发展局，韩城市农业农村局：为认真落实农民专业合作社法，提升农民专业合作社发展质量，培育典型样板，加强示范交流，促进联合合作，助推“3+X”特色产业和陕农品牌培育工程，委托农业科技报社协助编撰《陕西省农民专业合作社示范社名册》。现就有关事项通知如下：一、编撰范围主要是省级10部门认定的陕西省农民专业合作社示范社。生产管理规范、特色产业突出、有绿色农产品认证、注册农产品品牌的市级农民专业合作示范社、十佳社等也可以由市级农业农村部门推荐录入。已被取消农民专业合作社示范社资格的，不得推荐录入名册。二、时间安排从6月份开始，到7月底结束，集中两个月时间完成编撰工作。6月底前，以市（区）为单位，完成需要编入名册的示范社资料及照片推荐工作。7月底前，编辑、核对、整理各市（区）推荐的示范社资料和照片。三、编撰内容市、县级农业农村部门推荐的示范社的资料主要包括四个方面：（一）基本情况。包括名称（全称）、成立时间、成员人数、出资总额、资产总额、经营收入、品牌商标、产品质量认证等，不超过100字。（二）理事长基本情况。包括姓名、年龄、职业、社会职务、主要荣誉等，并提供一寸免冠照片1张。（三）经营范围。包括服务内容、主导产业、主要农产品种类等，并提供农产品相关照片5张左右。（四）联系方式。包括联系人、电话、邮箱、详细地址、邮编以及微信二维码等。四、有关要求（一）提高认识。市、县级农业农村部门要充分认识此次活动重要性，及时安排部署，精心组织，做好资料审核和推荐工作。各级农经机构要切实负起责任，明确专人，按时完成。（二）确保质量。被推荐示范社，一定要高度重视，提供的信息资料、照片要真实、准确，不得弄虚作假，否则取消资格。（三）按时报送。各市（区）农业农村部门请于6月30日前，将拟推荐示范社名单以正式文件报省农业农村厅,示范社的基本情况等编撰内容的电子稿发指定邮箱。\xa0'
               '联系人：省农业农村厅\xa0 杜 勇\xa0 \xa0029-87343330\xa0 \xa0 \xa0'
               '农业科技报社\xa0 申小燕\xa0 \xa0'
               '13572212906\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0张 婉\xa0 \xa0'
               '15129364752邮箱：278792786@qq.com\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业农村厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2019年5月30日\n'
               '        ',
 'art_source': '陕西省农业农村厅',
 'art_title': '陕西省农业农村厅办公室 关于编撰《陕西省农民专业合作社示范社名册》的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-04-02 10:45:27',
 'art_detail': '\n'
               '         '
               '陕农办发〔2019〕86号各设区市农业农村（农业）局、畜牧兽医局，杨凌示范区农业局，韩城市农业农村局，厅机关有关处（室、局）、厅属有关单位:\xa0'
               '为深入贯彻《中共中央、国务院关于实施乡村振兴战略的意见》精神，积极落实2019年中省一号文件和中省农业农村工作会议精神，切实推进种业高质量发展和供给侧结构性改革，进一步加强种业市场监管工作，按照农业农村部《2019年全国种业市场监管工作方案》的安排，结合我省实际，制定了《陕西省2019年种业市场监管工作方案》。现印发给你们，请各地根据本辖区实际细化具体措施，全面推进工作，务求监管实效。工作中遇到新情况新问题，请及时向我厅种业管理处反馈。联系人：刘学通\xa0 '
               '张亚维电\xa0\xa0 话：029—87213182\xa0 87210631邮\xa0 \xa0'
               '箱：liuafu8@163.com\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '陕西省农业农村厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2019年4月1日陕西省2019年种业市场监管工作方案\xa0'
               '为创建公平公正的种业发展环境，全面提升农作物及畜禽种业质量水平，推动现代种业发展，为全省农业生产用种和粮食安全提供坚实保障，根据中省有关农村会议精神及农业部方案要求，制定本方案。一、总体思路以习近平新时代中国特色社会主义思想为指导，以《中华人民共和国种子法》《中华人民共和国畜牧法》以及《中共中央国务院关于实施乡村振兴战略的意见》为基本遵循，全面贯彻落实中省一号文件和中省农业农村工作会议精神，践行新发展理念，围绕推动陕西种业高质量发展这一目标，坚持种业市场专项整治和日常监管相结合，强化事中事后管理，严格市场监督执法，为我省现代种业健康发展营造良好环境。二、工作目标通过开展种业市场专项整治和日常监督检查，严厉打击种业领域各类违法生产经营行为，推动种业市场秩序持续好转，主要农作物种子质量合格率稳定在96%以上；加大对种子生产基地、生产企业、经营主体、重点区域的监管力度，有效遏制套牌侵权、制售假劣、未审先推、非法生产经营转基因种子等违法行为的发生；扎实开展种畜禽质量监督检测，不断提升种畜禽质量水平。三、重点工作（一）种子市场专项检查行动\xa0\xa0\xa0'
               '1. '
               '春季种子市场专项检查行动在春季种子销售旺季，对种子市场、经营主体开展专项检查行动。以玉米、水稻、大豆、棉花、蔬菜种子和马铃薯种薯为主，重点检查种子标签和使用说明、品种审定和登记、品种权许可、经营档案、主体备案和种子质量等。榆林市要围绕非法生产经营转基因玉米种子开展专项治理，按照交界区域联合管、重点治的联打联动治理要求，全面排查辖区内及蒙陕交界区域无证生产经营杂交玉米种子违法行为，推动榆林玉米制种基地规范化建设。检查自2019年3月开始，7月底前全部完成。2. '
               '秋季种子市场专项检查行动秋季种子销售旺季，开展种子市场、经营主体专项检查行动。以小麦、油菜种子和马铃薯种薯为主，重点检查种子标签和使用说明、品种审定和登记、品种权许可、经营档案、主体备案和种子质量等。检查自2019年8月开始，11月底前全部完成。（二）玉米制种基地苗期转基因监管专项行动榆林、延安要以县为单位，组织对辖区内玉米制种田检查，以早检查、早发现、早处理为原则，进行拉网式排查。从春播开始到花期前，核查生产主体、企业资质、委托备案、品种权属及亲本来源，利用转基因快速检测方法对亲本种子和种子田叶片进行全覆盖筛查，防止非法转基因种子生产。在种子生长关键时期，组织开展田间质量检查活动，对发现问题的地块，要从严从速查处，并依法严肃处理相关责任人员，严禁非法生产的转基因种子流出生产基地。同时，榆林市要重点加大对靖边县有关乡镇的排查力度，确保检查到位。检查自2019年4月开始，7月底前全部完成。（三）种子企业监督抽查行动\xa0'
               '1. '
               '企业监督抽查对全省玉米、水稻、棉花及部分蔬菜种子生产经营企业和承储企业开展监督抽查。重点检查企业资质、生产经营档案、标签及种子质量。对于近3年来在各种监督检查中发现有问题或者发生重大质量事件、遭投诉举报较多的企业，实行品种检查全覆盖。抽查2019年11月启动，2020年6月底前全部完成。2. '
               '救灾备荒种子储备检查按照《国家救灾备荒种子储备补助经费管理办法》要求，对2019年承担国家救灾备荒种子储备项目的企业进行检查。重点围绕储备企业资质、储备任务的落实、在储种子的质量、储备资金的使用管理等情况开展检查，确保储备种子数质量完好。2019年5月底前完成对承储企业的检查。（四）种畜禽质量安全监督检查行动\xa0\xa0'
               '1. '
               '种公猪常温精液抽检按照《种猪常温精液》（GB23238-2009）标准，对中省扶持建设且对外销售的种公猪站的常温精液产品进行一轮质量抽检。2019年4月启动，2019年11月前完成任务。2. '
               '畜禽保种场检查对全省30个部省扶持的畜禽保种场进行检查，重点检查保种场保种方案执行情况以及资金使用情况。2019年5月启动，2019年11月之前完成。3. '
               '重大畜禽良种项目督查对农业农村部重点扶持的畜禽良种重大工程项目进行督查，重点督查项目进度与资金使用情况。2019年4月启动,2019年10月之前完成。4. '
               '奶牛生产性能测定对全省30家奶牛场1.5万头奶牛进行生产性能测定（DHI）工作。2019年1月启动，2019年12月底完成。（五）生产用桑蚕种质量抽查行动\xa0\xa0'
               '在蚕桑生产用种之前，配合农业农村部组织的桑蚕种质量监督抽查工作，对我省安康市蚕种场、石泉县蚕种场2018年生产的桑蚕原种和一代杂交种开展质量监督抽查。采取统一抽查检测方式，2019年3月底前结束并于4月中旬报送抽检结果。桑蚕原种按《桑蚕原种》（GB19179－2003）和《桑蚕原种检验规程》（GB/T19178－2003）检验，检验项目为：外观包装（单蛾良卵数、折净率、标签、合格证）、每张良卵数、良卵率、实用孵化率、病卵率、纯度等；桑蚕一代杂交种按《桑蚕一代杂交种》（NY326－1997）和《桑蚕一代杂交种检验规程》（NY327－1997）检验，检验项目为外观包装、卵量、良卵数、良卵率、杂交率、实用孵化率、病卵率等。上述五大专项行动，由我厅种业管理处统一组织安排，厅属有关单位具体组织实施。厅种业管理处将对相关结果进行通报。其中，第（一）（三）项行动由省种子工作总站具体负责实施；第（二）项行动由省种子工作总站会同厅科教处具体负责实施；第（四）项行动由省畜牧技术推广总站具体负责实施；第（五）项行动由省园艺技术工作站具体负责实施。相关单位下发具体实施方案前报厅种业管理处审核。四、有关要求（一）提高认识，强化宣传。种业市场监管是农业农村部门的法定职责，也是深入贯彻落实《种子法》《畜牧法》的重要措施。各地要切实提高认识，加强组织领导，积极开展专项行动。要加大普法宣传，积极做好重大种业违法案件曝光和种业执法先进典型的宣传，营造良好的种业市场监管舆论氛围，为辖区农业生产用种安全履好职、尽好责。（二）细化方案，加强配合。各市（区）农业农村部门要及时对接相关专项行动的具体实施单位，按照方案总体要求，结合本地实际，细化工作方案，落实属地责任，加强督导检查，抓好工作落实。要加强与公安、市场监管等部门的协调配合，形成执法合力。要加强对重大种子违法案件的查处、督办，涉嫌犯罪的要及时移送公安机关，防止以罚代刑。（三）规范执法，检打联动。各地在开展市场监管工作中，要严格按照《种子法》《畜牧法》的规定和相关法规的操作程序要求，全面提高执法水平，切实规范执法行为。按照“双随机一公开”要求，依法依规开展执法检查活动，确保事实清楚、证据确凿、程序合法、文书规范。对检查中发现的无需检测即可界定的违法事实，要立即查处。对检测后发现的问题，要按程序尽快查处。 '
               '各地应在专项行动结束后两周内上报检查总结，总结要求内容详实，要突出检查中发现的问题。对检查发现问题的查处情况，要有阶段性报告和结果报告。行动期间，省农业农村厅将组织力量对各地专项行动开展情况进行抽查。\xa0\n'
               '        ',
 'art_source': '陕西省农业农村厅办公室',
 'art_title': '陕西省农业农村厅办公室关于印发2019年种业市场监管工作方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-04-18 19:41:37',
 'art_detail': '\n'
               '         '
               '各设区市农业农村（农业）局，杨凌示范区农业局，韩城市农业农村局：按照农业农村部办公厅《关于开展第二批国家农业绿色发展先行区评估确定工作的通知》（农办规〔2019〕12号）要求，现就做好第二批国家农业绿色发展先行区评估确定工作通知如下：一、申报条件申报先行区的，应达到以下要求：（一）耕地、水、气候、生物等重要农业资源底数清晰，基本形成与资源环境承载力相匹配、与生产生活生态相协调的农业发展格局。（二）科学使用化肥农药，推进农业投入品减量增效，实现农药化肥使用负增长。实行种养结合，发展循环农业，推进畜禽粪污、秸秆、农膜等农业废弃物资源化利用，畜禽粪污资源化利用率、秸秆综合利用率高于本省及全国平均水平，分别达到70%和83%以上。（三）近两年农产品质量安全例行监测总体抽查合格率不低于97%，没有发生重大农产品质量安全事件;绿色、有机、地理标志农产品认证比例达到10 '
               '%以上。（四）有稳定的技术依托单位，在技术模式引进、集成创新、先行先试、示范推广等方面路径清晰、科学合理。（五）政府重视，建立先行区建设组织领导及部门间分工协作协调机制，编制完成先行区建设规划及实施方案，出台支持先行区建设的政策性文件，整合资源用于先行区建设。二、申报程序（一）组织申报。请各市（区）严格按照农业农村部办公厅文件要求，组织符合条件且意愿强的县（区）人民政府申报，申报书格式见附件。每个市（区）原则上推荐1个先行区。（二）择优遴选。我厅组织相关专家对申报材料进行初审，择优遴选2个县（区），然后会同相关厅局对选出的2个县（区），通过实地核查、现场答辩、专家打分再评选1个拟推荐先行区，经省人民政府同意后报农业农村部、财政部、国家发展改革委等八部门。三、相关要求（一）高度重视先行区申报。国家农业绿色发展先行区涉及面广、技术性强，2019年申报时间紧、任务重，各市（区）农业农村部门务必高度重视，积极会同相关部门，切实抓好申报前期工作，严格把关，确保推荐质量，并安排专人负责此项工作。（二）切实加强先行区建设。各市（区）要切实加强先行区建设，鼓励先行区建设与现代农业示范区、现代农业产业园、长江经济带农业面源污染治理项目县（区）建设相结合，畜禽粪污、农作物秸秆等农业废弃物资源化利用、农业面源污染治理等资金向先行区倾斜，把先行区打造成为农业绿色发展的“展示板”和“排头兵”。（三）按时上报申报材料。请各地于4月25日前，将先行区申报材料（附电子版）一式10份，以正式文件报省现代农业科学研究院。逾期不报的，视为放弃申报。\xa0'
               '联系人：厅发展规划与社会事业处 李侃\xa0 '
               '13201700537\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0'
               '省现代农业科学研究院 \xa0\xa0杨璐\xa0 18220593989\xa0\xa0 邮\xa0 '
               '箱：867582973@qq.com关于开展第二批国家农业绿色发展先行区评估确定工作的通知.docx附件1-国家农业绿色发展先行区申报书格式及内容.doc附件3-国家农业绿色发展先行区评估确定指标体系基础数据表.doc附件2-国家农业绿色发展先行区评估确定指标体系.doc陕西省农业农村厅办公室\xa0'
               '2019年4月18日\n'
               '        ',
 'art_source': '省农业农村厅',
 'art_title': '陕西省农业农村厅办公室关于开展第二批国家农业绿色发展先行区评估确定工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-05-28 11:32:25',
 'art_detail': '\n'
               '         陕农办发〔2019〕148号\xa0'
               '有关设区市农业农村（农机）局（中心），省农垦集团总公司：今年以来，各地按照省农机局、省财政厅《关于下达2019年农机购置补贴和农机深松整地资金计划的通知》（陕农机计发〔2018〕27号）要求，强化工作措施，有序推进春季深松整地工作。目前，全省已完成农机深松整地面积80多万亩，其中榆林市基本完成年度任务、延安市完成年度任务的61%。为了有效推进夏季深松整地项目组织实施工作，现就有关事项通知如下：一、抓好夏季深松整地作业夏季是我省深松整地的重要作业季节，各地要充分考虑秋季阴雨天气影响，立足地域实际，坚持抓早动快，统筹谋划运作。尤其是关中灌区一年两作区的市县，要将深松整地作为夏播整地的重要技术措施来抓，进一步完善推广“小麦机收、深松整地、玉米机播”一条龙作业模式，在抢收抢种的同时，切实抓好夏播前深松整地作业。要紧抓夏收后秋播前的有利时机，适时开展夏闲地深松整地作业，减轻秋季深松整地压力，为年度任务完成赢得主动。二、抓好春季作业资金兑付对于陕北、渭北地区春季已完成的深松整地面积，要抓紧作业面积核查和质量核查，尽早完成资金兑付工作，确保资金兑付及时到位。通过资金及时兑付，调动合作社和机手参与作业的积极性，确保深松整地补助资金安全规范运行。三、抓好作业规范实施各地要进一步加大信息化远程监测设备应用力度，不断提高信息化远程监测水平。要建立健全相关规章制度，加强补助资金兑付环节的风险防控，严格作业补助实施过程管理及档案管理，防止通过虚假作业、重复作业套取财政补助资金等违规行为发生。四、抓好项目组织领导各级农机化主管部门要积极促成县乡政府深松整地工作主体责任的落实，将深松整地纳入政府目标责任考核，用责任考核推进深松整地工作。要利用政府督查职能，适时通报深松整地进度，确保项目实施稳步推进。要鼓励农机大户、农机合作社等组织开展社会化服务，争取成方连片作业，整乡整村推进。要鼓励跨区域开展深松作业，提高机具使用效率。要及时总结宣传深松整地作业的好经验、好做法及产生的经济效益、社会效益，为推进农机深松整地工作营造良好的舆论氛围。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业农村厅办公室\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '2019年5月24日\xa0\n'
               '        ',
 'art_source': '陕西省农业农村厅',
 'art_title': '陕西省农业农村厅办公室关于做好夏季农机深松整地工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-04-28 14:53:07',
 'art_detail': '\n'
               '         '
               '各设区市农业农村（农业）局，杨凌示范区农业局，韩城市农业农村局，厅机关有关处（室、局）、厅属有关单位：“三夏”是我省农时最为紧迫、农机作业任务最为繁重、对农机管理服务工作要求最高的关键时期。为了切实做好今年“三夏”农机管理服务工作，努力提高“三夏”农机化生产水平，现就有关事项通知如下：一、提早安排部署，搞好前期备战各地要立足六个方面，全力做好“三夏”农机管理服务前期备战工作。一是机具准备。结合农机年度检验工作，组织农机监理、管理和推广业务技术骨干进村入户，指导机手及早调试检修机具，确保农机具以良好的技术状态投入生产。二是技术培训。围绕深松整地、保护性耕作、秸秆综合利用以及当地“三夏”主推农机化技术和技术推广项目实施，复训、新训相结合，组织开展技术培训工作，确保农机驾驶操作人员以良好的技能素养投入生产。三是物资储备。督促动员农机经销、维修、供油、零配件供应和农机合作社等各类社会化服务组织，提早做好物资调剂储备工作，以备服务之需。四是《作业证》发放。按照省农业农村厅办公室《关于做好2019年联合收割机插秧机跨区作业证发放管理工作的通知》（陕农办发〔2019〕77号）要求，切实规范《作业证》发放管理工作，确保“联合收割机免费通行”惠农政策落到实处。五是供需衔接。根据当地“三夏”农机作业任务，开展主要作业项目农机具拥有量调查和新增量估算，提前做好农机具引进和外出作业组织工作，确保作业机具供需协调到位，提高“三夏”农机化生产组织管理水平。六是制定预案。针对可能出现的阴雨大风等天气情况，提前制定预案，加强与辖区内农机合作社和农机大户的联系，提高应急反应能力。二、强化服务意识，提升作业水平各地要树立管理就是服务的理念，切实做好服务工作，进一步提高“三夏”农机化作业水平。一是信息服务。系统上下要通过网上发布信息、发送手机短信和开通服务热线电话等多种形式，开展信息服务工作。小麦主产区各县（区）要开通热线服务电话，确保24小时专人值班，随时为机手和农户提供咨询并解决问题。二是技术服务。农机化管理部门要与农机生产（销售）企业加强沟通协调，选派业务技术骨干，开展技术巡回指导、售后和“三包”服务，构筑技术服务保障线。三是协调服务。要组织干部职工深入生产一线，设立接待服务站，加大对跨区作业机具的组织协调力度，既要满足小麦抢收的需要，又要提高机具的利用率，防止“机械扎堆无活干、麦子成熟无机用”的情况发生。四是供应服务。要组织、协调农机维修、农机零配件供应等农机社会化服务组织（单位）延长营业时间，实行夜间值班，有条件的地方要送修、送农机零配件到田间地头，为农机经营户提供优质服务，提高农机作业效率。五是协调做好供油服务。市县农机化管理部门要立足于“三夏”农机优先加油、优惠加油和对集中作业区域送油到田间地头等工作着力点，加强与中石油、中石化和延长壳牌各市分公司（区域办公室）及其加油站的联系，制定落实“三夏”农机便利供油政策措施，保障农机作业用油顺畅供应。三、加强监督检查，促进安全生产“三夏”生产时间紧，任务重，是农机事故的多发期。各级农机化管理部门及其安全监理机构要坚持“安全第一，预防为主，综合治理”的方针，强化安全宣传教育，普及农机安全常识，切实提高农机驾驶操作人员的技能水平和安全意识。既要合理调配力量，加大工作力度，依法做好道路外行驶、作业农业机械的安全检查，违法行为纠正处理，消除事故隐患。又要加强与公安交通管理部门的配合协作，注重发挥县乡道路农机、公安联合执法机构的作用，切实做好县乡道路的农机安全管理工作，严厉查处拖拉机和联合收割机无牌行驶、无证驾驶、疲劳驾驶、超速超载和违章载人等违法违规行为，最大限度地消除不安全因素，促进“三夏”农机安全生产。各级农机化管理部门要指导农机质量投诉机构，切实做好“三夏”期间的农机作业质量、维修质量和售后服务质量监督检查及争议调解处理工作，维护各方当事人的合法权益。四、开展广泛宣传，营造良好氛围各地要加强与当地主流媒体的配合协作，围绕跨区机收进度、农机深松整地、农作物秸秆机械化综合利用、农机作业服务方式创新、农机农艺融合、农机购置补贴政策对“三夏”的促进作用和农机合作组织参与土地规模经营等重点，切实做好“三夏”生产宣传报道工作。在配合媒体宣传的同时，要及时上报反映当地“三夏”农机化生产组织管理创新、调动机械有序流动和平衡作业价格等方面的信息，以便通过省农业农村厅网站进行宣传，促进全省平衡发展。通过广泛宣传，在全社会营造支持农机、关注农机和合力促进农机发展的良好社会氛围。五、切实加强领导，保障顺利进行“三夏”农机管理服务水平是考核衡量各级农机化管理部门组织协调能力的关键。各地要高度重视，切实加强对“三夏”农机管理服务工作的组织领导，夯实责任，形成农机化管理部门牵头抓总，农机管理、监理、技术推广和培训等机构各司其职、联动协作的组织领导机制和工作机制，全力促进“三夏”农机管理服务工作顺利进行。各地要贯彻落实农业农村部农机化司农业机械化生产信息报送制度，“三夏”生产期间继续执行小麦机收进度日报制度（节假日正常上报），从5月25日开始，每日11:30前通过全国农机化综合服务平台“农机直通车”上报“三夏”农业机械作业进度，同时向省农业农村厅农机化处上报《2019年“三夏”农业机械作业进度表》（见附件2）。\xa0'
               '省农业农村厅联系人：王全虎联系电话（传真）：029-87212891省农机化中心联系人：许小平联系电话：029-62822225\xa0'
               '附件：1.2019年“三夏”农机工作准备情况统计表\xa0\xa0\xa0\xa0\xa0 '
               '2.2019年“三夏”农业机械作业进度表附件1：2019年“三夏”农机工作准备情况统计表.docx附件2：2019年“三夏”农业机械作业进度表.docx\xa0'
               '陕西省农业农村厅办公室\xa0\xa0\xa0\xa0\xa02019年4月25日\n'
               '        ',
 'art_source': '厅农机化处',
 'art_title': '陕西省农业农村厅办公室关于做好 “三夏”农机管理服务工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-04-19 10:25:51',
 'art_detail': '\n'
               '         陕农办发〔2019〕106号\xa0'
               '各设区市农业农村（农业）局、畜牧兽医局，杨凌示范区农业局，韩城市农业农村局，厅属有关单位：为全面掌握我省种业发展状况，研究制定我省种业发展规划和指导意见，加快种业发展，夯实我省现代特色农业发展基础，决定在全省范围内开展种业调研活动。现将有关事项通知如下：一、高度重视，精心组织种业是农业的源头，是农业高质量发展的“芯片”。当前，我省现代农业发展正发生着深刻变化，对种业工作提出新的要求，特别是机构改革后，种业的工作面临诸多问题，需要研究解决。在全省开展种业调研活动，旨在摸清我省种业现状、分析制约种业发展的瓶颈问题，厘清工作思路，研究提出种业发展对策，为我省现代种业发展提供理论支撑，筑牢实施乡村振兴战略、产业扶贫和“3+X”工程基础，推进特色现代农业发展。各市（区）务必高度重视，周密部署，精心组织，确保调研取得实效。二、细化方案，落实责任本次调研主要涉及全省农作物种业和畜禽种业。为使调研有序开展，省农业农村厅研究制定了种业调研方案（详见附件），涉及面广、内容多、要求高，各地要结合各自实际，细化调研方案，抽调业务骨干，组建调研队伍，将调研任务落到实处，确保调研工作顺利开展。三、严格时限，抓好落实本次调研从4月22日开始，8月31日结束。其中4月22日—7月31日为全面调研阶段；8月1日—8月10日为调研情况汇总阶段；8月11日—31日为研讨总结阶段。在此期间，省农业农村厅将组织开展调研督导和重点调研，各市县要制定详细的调研工作计划，按照阶段时限要求，强化工作措施，深入基层一线，深入种子企业、种子基地、种子市场，深入种畜禽场、畜禽保种场，与基层干部和群众面对面，与生产经营者面对面，掌握第一手资料，扎实组织开展调研，力戒形式主义、官僚主义；认真撰写调研报告，全面反映种业发展现状，客观分析存在问题和种业面临的形势，提出有针对性的建议意见。\xa0'
               '联 系 人：刘学通联系电话：029—87213182\xa0 13032911008传\xa0\xa0\xa0 '
               '真：029—87210631Q\xa0\xa0\xa0\xa0 Q: 936461647\xa0'
               '附件：1.2019年全省农作物种业调研方案\xa0 \xa0 2.2019年全省畜禽种业调研方案\xa0'
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业农村厅办公室\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '2019年4月18日\xa0\n'
               '        ',
 'art_source': '陕西省农业农村厅',
 'art_title': '陕西省农业农村厅办公室关于组织开展种业调研活动的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业农村厅办公室文件',
 'art_date': '2019-04-17 10:35:39',
 'art_detail': '\n'
               '         陕农办发〔2019〕102号\xa0'
               '各设区市农业农村（农业）局、畜牧兽医局，杨凌示范区农业局，韩城市农业农村局,厅属有关单位:为贯彻落实全国奶牛、肉牛和肉羊遗传改良计划，加快群体遗传改良进程，进一步夯实畜禽种业基础，按照农业农村部种业管理司《关于开展2019年奶牛、肉牛和肉羊核心育种场遴选工作的通知》（农种品函〔2019〕17号）的要求，近期省农业农村厅将在全省组织开展国家奶牛、肉牛和肉羊核心育种场遴选工作。现将有关事项通知如下。\u2003\u2003'
               '一、申报条件\u2003\u2003 '
               '（一）国家奶牛核心育种场申报单位须符合《国家奶牛核心育种场遴选标准》，填报材料的格式和有关评审要求按照《国家奶牛核心育种场申请表》《国家奶牛核心育种场现场评审表》执行。\u2003\u2003 '
               '（二）国家肉牛核心育种场申报标准、程序和申请材料格式按照《〈全国肉牛遗传改良计划（2011-2025）〉实施方案》（农办牧〔2012〕43号）有关规定执行。\u2003\u2003 '
               '（三）国家肉羊核心育种场申报品种包括绵羊和山羊，申报标准、程序和申请材料格式按照《关于印发〈全国肉羊遗传改良计划(2015-2025)〉配套管理办法及技术规范的通知》执行。其中，对山羊核心群基础母羊单品种数量的要求调整为地方品种、培育品种和引进品种山羊800只以上。\u2003\u2003 '
               '二、申报要求\u2003\u2003 '
               '（一）国家核心育种场遴选工作采取企业自愿申报的方式，相关文件电子版可在农业农村部种业管理网站（www.zzj.moa.gov.cn）和中国畜牧兽医信息（www.nahs.org.cn）下载。\u2003\u2003 '
               '（二）各市级畜禽种业行政主管部门要严格按照申报条件，认真组织开展申报和推荐工作。\u2003\u2003 '
               '（三）请于4月26日前，以市为单位将奶牛、肉牛和肉羊的申报材料纸质版和电子版报送省农业农村厅种业管理处。纸质材料要求双面打印，一式6份。\u2003\u2003 '
               '（四）我厅将对各市（区）提交的申报材料进行审查，并向农业农村部种业管理司推荐。\u2003\u2003 '
               '三、联系方式\u2003\u2003省农业农村厅种业管理处\xa0 刘学通电话：029-87213182\xa0 '
               '13032911008Q \xa0Q：936461647\xa0省畜牧技术推广总站 '
               '原积友电话：029-86221442\xa0 '
               '13571919980\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
               '陕西省农业农村厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2019年4月16日\n'
               '        ',
 'art_source': '省农业农村厅',
 'art_title': '陕西省农业农村厅办公室关于组织开展2019年奶牛、肉牛和肉羊核心育种场遴选工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2018-03-06 15:34:51',
 'art_detail': '\n'
               '         陕农业发〔2018〕13号\xa0'
               '各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：根据《中华人民共和国种子法》《农作物种子质量检验机构考核管理办法》有关规定，经我厅考核，镇安县农作物质量检验站具备对外开展农作物种子检验的基本条件和能力，批准为合格种子质量检验机构，颁发《中华人民共和国农作物种子质量检验机构合格证书》，准许在批准的种子检验项目范围内使用农作物种子质量检验机构合格标志。户县、千阳、柞水县农作物种子质量检验站等3家种子检验机构，在机构考核合格证书到期未提交申请材料，依据《农作物种子质量检验机构考核管理办法》第二十四条相关规定，予以注销。特此通告。\xa0'
               '附件：1．陕西省农业厅批准的农作物种子质量检验机构\xa0\xa0 \xa0 '
               '2．陕西省农业厅注销的农作物种子质量检验机构\xa0'
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2018年2月8日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于农作物种子质量检验机构的通告'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2018-04-02 09:48:50',
 'art_detail': '\n'
               '         '
               '陕农业人事【2018】2号厅机关各处（室、局）、厅属各单位：根据《党政领导干部选拔任用工作条例》有关规定，省农业厅决定，免去：侯放亮同志省家畜改良站站长职务，退休。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2018年2月5日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于侯放亮同志免职退休的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2018-04-17 16:38:03',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2018〕43号各设区市农业（农林）、畜牧、农机、果业局（委、中心），杨凌示范区农业局，韩城市农林局，厅机关各处（室、局）、厅属各单位：2018年是改革开放40周年，是实施“乡村振兴”战略的开局之年。为充分展现近年来陕西农业发展成就，用镜头报道奋战在脱贫攻坚、产业扶贫第一线的好人好事，深度发掘农业生产之美、农村生态之美、农民生活之美，展示乡村精神文明建设成果，助推“乡村振兴”战略实施，陕西省农业厅、陕西省摄影家协会决定共同举办2018陕西“乡村振兴·美丽家园”摄影大展。现将具体事项通知如下：一、大展名称2018陕西“乡村振兴·美丽家园”摄影大展二、主办单位陕西省农业厅陕西省摄影家协会三、主题内容本次摄影大展以“立足乡村振兴奋力追赶超越”为主题，以记录和反映新时代农业人在“乡村振兴”伟大实践中的感人身影和场景为着眼点，突出“产业兴旺、生活富裕、生态宜居、乡风文明、治理有效”五大板块，重点围绕农业特色产业、三产融合、产业扶贫等农事活动，主要征集以反映陕西省境内农业田园风光、经济产业、生产模式、乡村风貌、人物风采、民俗活动等内容的摄影作品，体现农村文化、展示农耕文明。四、参展对象本次摄影大展聚焦陕西，所有关心陕西乡村振兴的社会各界人士，均可报名参展。五、奖项设置（一）个人奖：本次摄影大展面向社会设立相机摄影作品组，面向全省农业系统设立“我扶贫、我快乐”手机摄影作品组。组委会将坚持公开、公平、公正的原则，邀请省内外摄影专家组成评委会，对所有参赛作品进行专业审评。奖项设置：一等奖：3名，奖金各5000元；二等奖：6名，奖金各3000元；三等奖：9名，奖金各1000元；优秀奖：30名，奖金各200元；入选奖：102名。本次活动特设置手机摄影作品奖，共50名，各奖励价值100元的手机话费。所有获奖入选作品作者都将获得由省农业厅、省摄影家协会共同颁发的证书。本次大展获奖证书可作为加入陕西省摄影家协会条件之一。以上奖金均为税前价值，个人所得税由主办单位代扣代缴。（二）组织奖：本次大展设立5个团体组织奖。六、参赛要求（一）参赛作品要求紧扣主题，取材于陕西境内。风格题材不限，黑白、彩色均可，数量不得超过10幅组，单幅组照均可（组照不得超过6幅，组照作品须标清序号）。鼓励新近创作的作品参展。投稿作品须填写作品题目、作者姓名、地址、邮编和联系电话、拍摄时间、地点等资料，组照须附100字的作品介绍。（二）本次活动只收数码图片，投稿文件不得小于5MB。所有参赛作品均为作者本人拍摄，不得转载他人作品，不得冒名投稿。谢绝提供电脑创意和改变原始影像的作品，照片仅可做亮度、对比度、色彩饱和度、剪裁的适度调整。大展拒绝接受后期合成、PS处理或对画面增减、大幅度改变色彩等技术处理过的照片。（三）参展作者须拥有对作品完整的著作权。参展作品涉及的著作权、版权、肖像及名誉权等纠纷，均由作者本人负责，主办方不承担任何责任。（四）主办单位有权将入选及获奖作品用于本次活动的宣传、出版物、媒体报道等，不再另付稿酬；入选作品主办单位将向作者调取原始文件，如作者不能按时提供原始文件，属作者自己放弃参展资格。（五）本次大展不收参展费，所有参展作品均不退稿。（六）本次大展的最终解释权归主办单位。凡投稿者，主办方均视为同意并遵守本次大展各项规则。七、截稿日期本次大展截稿时间为2018年8月31日。评奖日期2018年9月10日。展览和颁奖时间2018年9月底（暂定）。八、有关要求（一）本次大展是全省农业系统举办的首次摄影大展，请各单位务必高度重视，安排专人负责联络，按照参赛要求，搞好本区域、本部门的摄影作品选题、拍摄、选稿、投稿等组织工作。（二）请市级各单位负责通知本辖区各县（区）有关单位，以市为单位积极组稿参赛。本次大展将评选优秀组织奖，并将参赛组织情况纳入年度精神文明考核内容。（三）各单位要组织筛选和预选，严把选送作品的数量与质量关。原则上，厅系统各单位至少选送相机摄影作品10幅，各市至少选送相机摄影作品50幅。各单位选送的手机摄影作品不超过20幅。九、投稿地址和联系人投稿地址：陕西省农业宣传信息中心（西安市习武园27号）联系人: '
               '王一珊\xa0\xa0\xa0 联系电话：029－87322996QQ：78265397\xa0\xa0\xa0\xa0 '
               '邮箱:sydz@sxny.gov.cn附件：2018陕西“乡村振兴·美丽家园”摄影大展参展表\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2018年4月12日附件.docx\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于举办2018“乡村振兴•美丽家园” 摄影大展的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2018-03-27 17:14:47',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2018〕34号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：全省休闲农业示范创建工作开展以来，各地高度重视，积极参与，形成了良好的典型示范和品牌带动效应，有力推动了各地休闲农业又好又快发展。为深入贯彻落实中省一号文件关于“实施休闲农业和乡村旅游精品工程”的决策部署，持续发挥示范创建的带动作用，我厅决定继续开展省级休闲农业示范点（2018-2019年度）创建工作。现就有关事项通知如下：一、申报条件申报省级休闲农业示范点的主体，应符合陕西省省级休闲农业示范点认定和运行监测管理工作方案（以下简称《工作方案》）规定的认定范围及基本认定条件。已经认定的全国休闲农业示范点，不纳入申报范围。已经认定的省级休闲农业示范点、省级休闲农家明星村，须对照申报条件重新申报，统一管理。二、申报办法（一）申报主体。应符合《工作方案》中所规定的主体条件。（二）申报材料。包括《工作方案》中所列申报材料，以及市级农业部门推荐文件、每个申报主体10张以上实景图片（jpg格式、2M以上）等。（三）申报程序。请参见《工作方案》中所列申报程序。三、申报数量西安、宝鸡、咸阳最多各申报12个点；渭南、榆林、汉中、安康、商洛最多各申报10个点；铜川、延安最多各申报8个点；杨凌、韩城最多各申报5个点。\xa0'
               '四、工作要求（一）加强组织领导。各市（区）农业部门要把示范创建工作作为实施休闲农业和乡村旅游精品工程的重要举措，切实加强领导，精心组织，做好实地考察、公开评议、从优筛选，从严控制申报数量。（二）强化服务指导。各市（区）农业部门要以示范创建工作为契机，进一步增强服务意识，完善服务体系，拓展服务领域，加大扶持力度，不断提升休闲农业发展水平。（三）做好总结宣传。各地要通过示范创建树立一批产业发展新典型，及时总结推广创建工作中的好经验、好做法，加大宣传推介，多途径、多平台为产业发展营造良好氛围。（四）按时上报材料。以市（区）为单位，于2018年5月31日前，将所有申报材料一式两份报省发展一村一品指导中心，同时附数据光盘一份，并将材料电子版发送至xxnyxh@163.com。联系人：李永刚\xa0 '
               '魏亚娟\xa0\xa0\xa0 电 话：029－87343160邮\xa0 '
               '箱：xxnyxh@163.com附件：1.陕西省省级休闲农业示范点认定和运行监测管理工作方案\xa0 \xa0 \xa0 '
               '2.陕西省休闲农业示范点申报表\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2018年3月26日附件.docx\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于开展2018-2019年度省级休闲农业示范点创建工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2018-02-06 15:36:02',
 'art_detail': '\n'
               '         '
               '陕农业发〔2018〕12号根据《中华人民共和国种子法》《农作物种子生产经营许可管理办法》及《植物新品种保护条例》有关规定，经审核，同意为陕西杨凌伟隆农业科技有限公司、西安鑫丰农业科技有限公司2家企业核发《农作物种子生产经营许可证》（详见附件）。特此通告。附件：核发农作物种子生产经营许可证企业名单\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0\xa0\xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2018年2月1日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于核发农作物种子生产经营许可证的通告'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2018-02-12 09:08:35',
 'art_detail': '\n'
               '         '
               '陕农业发〔2018〕6号各设区市及杨凌示范区、韩城市农业（农林）局（委）、发展改革委、财政局、国土资源局，人民银行西安分行营业管理部、陕西省各中心支行、杨凌支行，各设区市及杨凌示范区、韩城市国家税务局、地方税务局:\u3000\u3000'
               '为贯彻落实《农业部、国家发展改革委、财政部、国土资源部、人民银行、税务总局关于促进农业产业化联合体发展的指导意见》（农经发〔2017〕9号）精神，引导我省农业产业化联合体健康有序发展，现提出以下实施意见。一、总体要求\u3000\u3000'
               '（一）指导思想全面贯彻落实党的十九大精神，以实施乡村振兴战略为总抓手，以推进农业供给侧结构性改革为主线，以带动农民、提高农民、富裕农民为目标，围绕产业兴旺这个重点，创新农业经营方式，发展新型经营主体，积极促进农业产业化联合体发展，延伸产业链、提升价值链、拓宽增收链、构建生态链，推动形成农村一二三产业深度融合、生产要素相互渗透、经营主体协调共进的现代农业经营体系。（二）基本思路农业产业化联合体（以下简称联合体）是龙头企业、农民合作社、家庭农场和专业大户等新型农业经营主体以分工协作为前提，以规模经营为依托，以利益联结为纽带的一体化农业经营组织联盟，具有独立经营，联合发展；龙头带动，合理分工；要素融通，稳定合作；产业增值，农民受益等基本特征。在促进联合体发展过程中，要把握以下原则。一是政府引导，市场主导。坚持从实际出发，科学引导，规范管理，探索促进联合体健康有序发展。充分发挥市场配置资源的决定性作用，推动要素在联合体内各经营主体间自由流动。二是独立经营，联合发展。联合体不是独立法人，各新型经营主体保持独立经营者地位，通过建立章程、签订合同协议，确立权责利益联盟关系，在平等、自愿、互利基础上，开展一体化紧密型经营活动。三是分工明确，运营顺畅。明确联合体内新型经营主体之间的功能定位，充分发挥联合体规模经营优势，形成分工合理、优势互补、高效联合的利益共同体，实现经济效益、社会效益和生态效益的协调统一。四是因地制宜，分类指导。充分尊重联合体内新型经营主体意愿，根据各地农村生产力发展水平、农业生产区域特色以及联合体经营特征，合理确定联合体类型和发展目标，成熟一个发展一个。（三）发展目标按照“一年打基础，两年大发展，三年见成效”的工作思路，大力发展各类联合体，力争到“十三五”末，用3年左右的时间，全省各类联合体达到1000个，创建100个左右的省级示范联合体，重点培育10个年产值超10亿元的省级示范联合体，推动我省联合体建设上规模、上水平，努力实现联合体运行良好，各类经营主体互促共赢，产业、要素和利益联接紧密，经济、社会和生态效益日益明显的发展目标。二、重点工作（一）引导主体联合1．壮大经营主体。各地要在明确农业主导产业的基础上，科学制定产业发展规划，调整产业结构，优化产业布局，着力打造适合各地有特色的产业链。鼓励县级以上农业产业化主管部门开展重点龙头企业认定和运行监测，围绕优势特色产业发展，支持龙头企业上项目、创品牌、扩规模，增强市场竞争力。引导合作社完善规章制度，支持合作社开展产前、产中、产后各环节生产经营和服务。引导农村土地向家庭农场和专业大户有序流转，发展适度规模经营，引导家庭农场和专业大户与农民合作社、龙头企业开展产品对接、要素联结和服务衔接，实现节本增效。2．指导联合体组建。各地要通过专题培训、观摩交流、政策引导等方式，指导龙头企业深化农业产业化经营，在互利共赢的基础上，主动牵手产业发展相关的合作社、家庭农场和专业大户等农业经营主体，共同制定章程，明确权责义务，确定运行机制，制发统一标识，建立办公场所，推行“龙头企业+农民合作社+家庭农场（专业大户、农户或贫困户）”等多元合作模式，组建联合体。3．推动各主体相互融合。以联合体建设为载体，支持核心龙头企业和上下游中小微企业、农民合作社、家庭农场和专业大户挂靠联合、分工协作，构建产业关联度高、功能互补性强的产业集群。支持各经营主体之间以资本、技术、品牌、信息为纽带，通过股份合作、工序衔接、产销对接等方式，组建利益共同体。引导家庭农场和专业大户、农民合作社以土地经营权、劳动力等要素入股龙头企业，支持龙头企业以资金、技术等要素入股家庭农场和合作社，实现联合体内各经营主体深度融合发展。（二）推进产业链接1．开展分工协作。鼓励龙头企业强化供应链管理，制定农产品生产、服务和加工标准，示范引导农民合作社和家庭农场从事标准化生产，引导龙头企业发挥产业组织优势，以“公司+农民合作社+家庭农场”“公司+家庭农场”等形式，联手农民合作社、家庭农场组建联合体，实行产加销一体化经营。鼓励普通农户、家庭农场组建农民合作社，主动开展联合体发展所需的各类专业化、社会化服务，承担农资供应、农机作业、统防统治、生产技术指导等农业生产服务，使合作社成为联合体的“粘合剂”和“润滑剂”。鼓励农户流转承包土地经营权，培育发展家庭农场和专业大户，按照龙头企业和合作社的生产要求，推进标准化种养，开展适度规模经营，不断提高农业生产率。2．延伸产业链条。支持联合体成员利用农产品产地初加工补助政策，建设冷藏库、储藏窖、烘干房等初加工设施，在种养的基础上发展加工、储藏、销售等二三产业。支持联合体核心的龙头企业开展精深加工研发，提升产业链整体附加值，鼓励龙头企业进驻各类现代农业产业示范园区，支持优势产区产地批发市场建设，推进市场流通体系与储运加工布局有机衔接。鼓励联合体在城市社区设立鲜活农产品直销网点，建立直销体系。3．发展新兴业态。鼓励联合体抢抓国家推动农村一二三产业融合发展的重大机遇，选准主攻方向和突破口，大力兴办乡村旅游、电子商务、养老服务、文化创意等新兴产业。支持联合体开发农业多种功能，研发系列特色产品，发展农田艺术景观，培育一批乡村特色产业小镇，树立乡村振兴新样板。（三）促进要素融合1．引导土地规范流转。按照依法、自愿、有偿原则，鼓励农户将承包经营土地采取转包、出租、互换、转让及入股等方式向联合体内新型农业经营主体流转。鼓励农户以土地承包经营权入股等形式向联合体内新型农业经营主体参股。鼓励联合体的专业大户和农民合作社积极开展全程托管或主要生产环节托管，促进专业化、规模化生产。2．实现资金有效流动。龙头企业应发挥自身的资金优势，支持农民合作社开展专业化、社会化服务，帮助家庭农场和专业大户发展农业生产。鼓励龙头企业为家庭农场和专业大户的生产性贷款提供担保等服务。在做得比较好的联合体中选择一批管理民主、运行规范、带动力强的农民合作社，培育发展农村资金互助合作组织。3．强化科技转化应用。鼓励龙头企业加大科技投入，建立研发机构，引导联合体内新型农业经营主体间开展人才交流合作，提高联合体人才队伍专业化水平。支持龙头企业为种养大户提供种苗、防疫、配方施肥、病虫害统防统治、机械化生产等技术服务。鼓励龙头企业向联合体内其他农业经营主体转移推广新品种、新技术、新工艺，加快创新成果在联合体内孵化转化。支持产业技术体系创新团队与联合体联合开展创新活动，积极引用先进生产技术。4．推动信息品牌共享。积极推进联合体信息化建设，促进现代信息技术与联合体内新型农业经营主体的有机融合。鼓励联合体内的龙头企业建立服务网站，为联合体成员发布产品信息，发展电子商务和网上营销，开拓联合体农产品销售渠道。鼓励龙头企业依托联合体建设产品质量安全追溯系统，有条件的纳入国家农产品质量安全追溯管理信息平台。鼓励龙头企业协助农民合作社和家庭农场开展“三品一标”认证。鼓励联合体整合品牌资源，探索设立共同营销基金，联合进行品牌创建、品牌宣传、品牌营销，打造知名度高的共用品牌。（四）实现利益联接1．发展股份合作。鼓励龙头企业采取订单、入股分红、利润返还等方式，与农民合作社、家庭农场和专业大户形成紧密型利益关系。鼓励联合体各成员每年在收益分配前，按一定比例计提风险保障金，完善自我管理、内部使用、以丰补歉机制，提高抗风险能力。支持联合体内龙头企业与农民合作社、家庭农场和专业大户通过双向入股进行利益联结，合作社、家庭农场以生产要素的所有权或经营权入股龙头企业，参与监督企业的经营管理；龙头企业以资金、技术、良种等要素入股合作社、家庭农场和专业大户，组建收益共享、风险共担的利益共同体，使资源变股权、资金变股金、农民变股民，以股论价，按股分红，让农民更多分享二三产业增值收益。2．发展订单农业。在农业生产之前，联合体各成员之间订立具有法律效力的购销合同，约定交售产品的品质、数量、时限、收购价格以及龙头企业承诺的服务内容等事项，明确权利责任。合作社、家庭农场和专业大户根据合同组织生产，企业则按合同要求收购农畜产品，建立稳定的购销关系。建立订单农业诚信黑名单制度，对失信者及时向社会曝光，除去联合体成员资格，降低经营主体的违约风险，确保各类主体的权利与义务统一。3．创新联结方式。引导农户将土地流转给联合体内的龙头企业、合作社、家庭农场和专业大户等经营主体，每年获得稳定的土地流转费。鼓励联合体优先聘用流转出土地的农民，为其提供技能培训、就业岗位和社会保障。以联合体为重点，引导建立土地流转、订单农业等风险保障金制度，并探索与农业保险、担保相结合，提高风险防范能力。加强土地流转、订单等合同履约监督，建立健全纠纷调解仲裁体系，保护双方合法权益。三、扶持政策（一）扶持经营主体。支持龙头企业、农民合作社、家庭农场和专业大户参与产业扶贫，按照有关规定享受税收优惠政策。现有支持各类新型经营主体发展的相关涉农项目资金，重点支持联合体内的龙头企业、合作社、家庭农场和专业大户，采取财政贴息、融资担保、扩大抵（质）押物范围等方式支持联合体发展，鼓励联合体的龙头企业吸纳关联的经营主体发起设立专项担保基金，放大担保基金倍数等方式，解决联合体内新型经营主体融资难融资贵问题。（二）落实用地保障。认真落实省国土资源厅、省农业厅《关于规范全省设施农用地管理促进设施农业健康发展的通知》（陕国土资发〔2015〕34号）精神，规范设施农用地使用，积极解决联合体内新型农业经营主体发展生产设施、附属设施、配套设施农业用地需求。鼓励各地探索解决联合体发展用地难题的办法，在符合规划和用途管制的前提下，每年安排一定比例的新增建设用地指标，优先安排、优先审批，支持引领联合体发展的龙头企业进行农产品加工、仓储物流、产地批发市场等辅助设施建设，并按规定享受相关优惠政策。（三）拓宽融资渠道。各级政府组建的农业信贷担保机构要按照政策要求优先为联合体内各经营主体提供贷款担保和风险补偿。鼓励银行、保险等金融机构开发符合联合体需求的信贷产品、保险产品和服务模式，支持联合体内龙头企业及各类新型经营主体发展。鼓励金融机构对联合体统一核定授信额度，逐年增加对联合体内新型经营主体的授信额度。（四）加强人才培养。鼓励高等学校、科研院所在职科技人员在完成本职工作的基础上，采取兼职兼薪方式到联合体内创业创新。鼓励农业科研院所和大专院校到联合体建立实训、研发基地，开展合作共建。要安排专业技术人员与联合体结对帮扶，抽调专业技术干部到联合体挂职锻炼。为联合体发展提供人才服务。大力推进职业农民培育，开展农产品加工业、农村创业创新、休闲农业和乡村旅游“三类人才培训行动”，为联合体发展提供强大的人才支撑和智力保障。四、保障措施（一）加强组织领导。各地要切实加强对促进联合体发展工作的组织领导，严格落实责任，明确工作任务，定期召开会议，落实政策措施，把促进联合体发展工作纳入目标管理范围，定期考核讲评。各有关部门要根据本意见，结合各自职责研究制定具体的措施办法，并做好相关指导、扶持和服务工作。各市农业产业化主管部门要确定一名干部作为联系人，做好联合体统计调查上报工作，了解联合体发展中出现的新情况，积极研究解决遇到的新问题。（二）开展示范创建。按照不同产业、不同类型，以产业链接、要素流动、利益共赢为内在标准，以经济效益、社会效益、生态效益为外在标准，分类型制定示范联合体评选标准和指标体系，省农业厅会同有关部门制定省级示范联合体评选管理办法，建立和发布示范联合体名录，并实行动态管理，每年组织一次示范联合体集中认定工作。各地可参照制定本级示范联合体评选管理办法。（三）营造良好氛围。各地要切实加强制度机制创新，着力营造加快联合体发展的良好环境，对指导、扶持和服务联合体发展工作中做出显著成绩的单位和个人，给予表彰奖励。充分运用报纸、电台、电视、网络等各类媒体，大力宣传促进联合体发展的相关政策和典型案例，努力营造关心、支持、参与联合体健康发展的浓厚氛围。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\u3000\xa0 陕西省发展和改革委员会\xa0 \xa0'
               '陕西省财政厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省国土资源厅\u3000中国人民银行西安分行\u3000 \xa0'
               '陕西省国税局\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省地方税务局\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2018年1月31日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '关于促进农业产业化联合体发展的实施意见'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2018-04-02 09:50:58',
 'art_detail': '\n'
               '         '
               '陕农业人事【2018】3号厅机关各处（室、局）、厅属各单位：根据《党政领导干部选拔任用工作条例》有关规定，孙力同志任职试用期满，考核合格，经省农业厅2018年3月26日研究决定，任命：孙力为厅政策与法规处处长，任职时间从试用期任职时间算起。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2018年3月27日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于孙力同志试用期满正式任职的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2018-04-25 09:15:40',
 'art_detail': '\n'
               '         陕农业办发〔2018〕51号\xa0'
               '各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：目前，全省小麦正值抽穗扬花期，也是小麦赤霉病发生流行关键时期。4月20日以来持续阴雨与主产区小麦扬花期吻合，赤霉病流行风险加大，据4月24日全省29个小麦赤霉病自动监测点预测，有14个监测点预警病穗率大于3%。根据《农业农村部办公厅关于加强小麦赤霉病防控工作的通知》（农明字〔2018〕第9号），为切实做好小麦赤霉病防控，遏制病害大范围流行成灾，实现防病虫保丰收，现就有关事项紧急通知如下：一、强化责任落实。小麦赤霉病属典型的气候型病害，一旦流行将直接影响小麦产量和品质，有效控制赤霉病危害，对实现全年粮食生产目标任务完成、提高小麦品质等具有十分重要意义。因此，各地要坚决贯彻中省部署，把赤霉病防控作为当前农业生产的一项重要任务，加强组织领导，广泛动员部署，层层落实责任，切实抓好防控措施，确保赤霉病不大范围流行成灾，赢得夏粮丰收主动权。二、加强监测预警。各地要密切关注气象条件变化，加密监测，全面掌握病情趋势，科学研判病害流行态势，及时发布病害预警信息，指导各地适时开展科学防治，确保不因监测不到位，预报不及时致使错失最佳防控时机。严格执行信息报送制度和重灾情实时报告制度，确保信息渠道畅通。三、实施科学防控。各地要坚持“预防为主、主动出击”的防治策略，紧抓4月25日-5月2日的防治关键时期，抢抓有利天气，确保大面积防治一次；赤霉病常发、重发区域，扬花期要迅速进行二次补防。科学选用高效药剂，各地要根据省农业厅下发的主要大田作物农药使用指导名录意见，明确用药品种，重点选择氰烯菌酯、烯肟·多菌灵、戊唑醇等高效药剂进行喷雾防治。四、推进统防统治。各地要充分发挥专业化统防统治的示范引领作用，组织动员专业化服务组织，开展统防统治。推行统一组织发动、统一技术方案、统一药剂供应、统一防治时间、统一施药作业等“五统一”服务，切实提高防控组织化程度和防控效果。要用好中、省小麦病虫防控补助资金，及早组织防控物资，积极实施“一喷三防”，防治病虫，延长灌浆期，提高千粒重。五、精准指导服务。组织专家制定完善小麦赤霉病防控技术方案，开展巡回技术指导，因地因时落实好防控措施。组织机关干部和农技人员深入小麦赤霉病重发区，采取分片包干、进村入户等形式，帮助农民解决实际困难。在防控关键时期，对重点地区开展工作督导，确保防控工作措施落实到位、技术措施落实到田。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2018年4月24日\xa0\n'
               '        ',
 'art_source': '厅办公室',
 'art_title': '陕西省农业厅办公室关于加强小麦赤霉病防控工作的紧急通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2018-05-28 15:57:36',
 'art_detail': '\n'
               '         陕农业办发〔2018〕59号\xa0各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：\xa0'
               '2017年,全省农业系统按照省农业厅产业扶贫技术服务百日大行动安排部署，统筹动员社会各类技术资源，面向贫困村贫困户，广泛开展了多层次、多渠道、多形式的产业扶贫技术服务工作，取得了显著成效。中省新闻媒体对我省产业扶贫技术服务工作做了大量报道，受到了省委省政府和社会各界的表扬和肯定。但个别地方还存在着工作目标责任不明确、工作措施不力、管理监督机制不完善等问题。针对存在问题，为扎实做好2018年产业扶贫技术服务工作，现就有关事项通知如下：\xa0\xa0'
               '一、明确工作目标2018年全省产业技术服务工作要按照“每个产业贫困户至少掌握1-2门生产技能”总体目标，以11个深度贫困县和23个年度摘帽县为重点，根据产业脱贫户和有产业发展意愿的贫困户技术需求及接受能力，分类施策，精准服务，使每个产业贫困户接受不少于4次、累计开展不少于230万户次的技术帮扶，每个有发展产业意愿的贫困户轮训一遍。已脱贫产业户掌握1-2门产业技术，已摘帽贫困县要组建起主导产业技术体系，建立产业扶贫技术服务长效机制，着力解决贫困户发展产业中的困难和问题，提高产业发展能力，巩固脱贫攻坚基础，群众满意率达90%以上。二、强化工作措施各级农业部门要按照“巩固基础、深入推进、创新机制、提升质量”的思路，强化措施，扎实工作，切实提升产业扶贫技术服务工作效能。一要充分发挥110指挥平台作用。按照省农业厅提出的“领导负责、专人管理、专人负责、专人调度”要求，进一步明确110指挥中心成员名单及职责，公开县级指挥中心技术服务联系及投诉电话，及时接收贫困村、贫困户技术服务需求，指令培训机构在规定时间内落实完成指导任务，确保事事有回应，件件有落实，群众满意率达90%以上。二要强化帮扶队伍建设。强化专家团队、县级技术小分队、新型经营主体技术服务小分队和持证职业农民四支技术服务团队的传帮带作用，吸纳更多有实招、接地气、群众欢迎的土专家、田秀才进入帮扶队伍，建立技术帮扶师资数据库，定期开展跟踪问效和业务培训，不断提升帮扶能力和水平。三要丰富服务内容。结合实际，在对产业贫困户进行以种养殖生产实用技术为主要服务内容的基础上，开展农产品质量安全、农产品销售、农产品电子商务、农民手机应用等内容的技术培训。同时要将技术服务与扶志扶智相结合，切实转变贫困户思想观念，帮助其树立脱贫致富的信心和勇气，推进“输血”向“造血”转变。四要转变服务方式。从以接警服务方式为主向接警服务和主动上门服务方式相结合转变，实现双向互通；通过广播、电视、微信、QQ等载体开展学习交流，融入启发式、互动式培训，扩大服务范围，提升服务效果。五要做好信息统计。按照统一要求，指定专人统计技术服务信息，确保数据真实可查，经负责领导审核签名后按季度逐级报送至上级110指挥中心。省市依据统计情况，将定期对全省工作开展情况进行通报，并作为考核工作绩效的重要依据。六要开展调查研究。坚持问题导向，组织人力对产业扶贫技术服务工作开展情况进行全面深入地调查了解，在分析思考的基础上，研讨下一步开展工作的办法及措施，形成一批站位高、把脉准的调研报告，年底前报送至上级农业部门。七要注重模式提炼。对服务工作中涌现出的好做法、好经验进行及时、深入地挖掘、总结和提炼，每市形成1-2个可学习、可借鉴的典型模式，省农业厅组织在全省宣传推广。三、夯实工作责任省市要按照全省（市）产业脱贫攻坚工作统一部署，强化组织领导，夯实工作责任，做好安排布置、统筹协调、包抓督导等工作。要结合实际，制定产业扶贫技术服务工作实施方案，明确指导思想、目标任务、工作重点、工作进度和保障措施等内容；要统筹协调各类产业扶贫资金、农技推广资金等农业项目资金支持技术服务工作；要从组织领导、平台运行、服务措施、服务效果等方面，对市县区工作开展情况进行全面的督导检查和考核评价，确保全省产业扶贫技术服务工作有力有效开展。各县区要按照“一把手负总责，分管领导负主要责任”的要求，履行工作职责，狠抓工作落实，做好服务平台建设、包村联户干部确定、技术人员选派和技术帮扶实施等具体工作。要结合工作需求，强化统筹协调，将果业、畜牧、蔬菜、茶叶等产业部门的领导及专业技术人员纳入指挥平台和技术服务队伍当中；要建立农业技术干部包联产业贫困户长效机制，确保每个贫困村至少有1名技术包联干部；要指导督促农广校、农民科技教育培训中心做好服务接警、师资调度、服务组织和信息传递等工作，第一时间给贫困户送技术、送点子；要加大资金投入，积极探索第三方购买服务机制，引导农业产业化龙头企业、农民合作社、家庭农场和种养大户等技术资源投身到技术服务当中，为产业扶贫技术服务工作顺利开展提供有力保障。各乡镇要充分发挥第一书记和驻村扶贫干部作用，组织第一书记、驻村扶贫干部和农业技术包联干部进村入户，根据贫困户产业资源、服务需求及接受能力，研究制定贫困村、贫困户技术帮扶计划，协调解决贫困户帮扶诉求和帮扶困难，确保帮扶工作在时令、有效果。各村组要把产业扶贫技术服务工作作为推动精准扶贫、加强村党组织建设的一项重要内容来抓，采取走出去、请进来等办法培养1-2名不离乡、不离土的产业技术能人，为长期便捷开展产业扶贫技术服务工作提供人才支撑。要组织当地新型农业经营主体技术骨干、土专家、田秀才等，深入田间地头、生产一线对贫困户开展点对点、面对面、手把手的技术帮扶，让贫困户一看就懂、一学就会，提升技术服务的精准性，着力解决贫困户发展产业中的困难和问题，推进特色产业健康发展。四、加强督导检查为确保全省产业扶贫技术服务工作扎实有效开展，省农业厅将继续成立8个工作包抓督导组，对各市县区工作开展情况进行不定期的检查指导。同时要制定绩效考核办法，对全省工作进行季度和半年考核评价，对存在工作责任不明确、工作措施不力、越级投诉电话较多等问题的市县要进行全省通报。各市区要建立工作包抓督导长效机制，对县区主体责任履行、110指挥平台作用发挥、包村技术干部到位、帮扶计划实施、技术力量调配、服务质量及效果等情况进行常态化的指导监督，对思路清晰、措施有力、成效显著的单位和个人进行表彰奖励，对思路不清、措施不力、成效不佳的单位和个人，进行通报批评，并追究责任。各县区要加强对乡镇、村两委班子、第一书记、驻村扶贫干部的责任落实、作用发挥、工作成效等的指导监督，掌握情况，发现问题，推进产业技术服务工作实现全覆盖。五、注重宣传引导为扩大影响，引起关注，2018年省农业厅将明确专人，联系中央和省上主要新闻媒体，大力开展产业扶贫技术服务宣传访谈活动。各级农业部门和培训机构要充分利用广播、电视、报刊、杂志、互联网等多种媒体对产业技术服务工作中涌现出的好做法、好经验及先进个人事迹进行宣传报道，激发工作热情，提高贫困户主动参与服务的积极性，营造全社会共同参与支持的舆论氛围。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2018年5月10日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于做好2018年产业扶贫技术服务工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2018-05-07 16:21:03',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2018〕33号各设区市农业（农林）、畜牧、财政局（委），国家扶贫开发重点县、片区县农业、畜牧、财政局：为助推产业扶贫精准脱贫再上新台阶，省农业厅、省财政厅2018年继续对我省56个国家扶贫开发重点县、片区县切块下达农业产业帮扶资金。为提高农业产业帮扶资金的指向性、针对性和有效性，确保资金使用效果，省农业厅、省财政厅联合制定了省级农业产业帮扶资金实施指导意见，现印发给你们，各地市要按照意见要求，依托资源禀赋，重点支持苹果、设施农业、羊乳三个千亿级产业和茶叶、猕猴桃、肉羊、肉牛等区域特色产业发展。项目执行过程中如有问题，请及时反馈省农业厅、省财政厅研究解决。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0'
               '陕西省财政厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2018年4月23日\xa02018年农业产业帮扶资金实施指导意见\xa0'
               '为提高农业产业帮扶资金的指向性、针对性和有效性，探索建立科学合理、覆盖全面、指向精准的资金管理新机制，切实发挥财政投入在产业帮扶中的引领支撑作用，制定本指导意见。一、总体思路全面贯彻落实习近平总书记系列重要讲话精神和中省脱贫攻坚战略部署，实施精准扶贫、精准脱贫基本方略，立足贫困县农业资源禀赋和产业优势，突出问题导向、需求导向、市场导向，按照选准特色产业、扶持新型主体、构建利益机制、完善服务体系的思路，以贫困人口增收脱贫为目标，以发挥新型经营主体带动作用、完善利益联结机制、明晰贫困户增收来源为抓手，整合财政涉农资金，加快培育区域优势特色产业，创建特色产业生产基地和加工基地，延长产业链条，强化市场营销，拓展产业功能，促进产业融合，在贫困地区探索建立政府引导、市场运作、主体带动、农户参与的产业扶贫新机制，推进贫困人口精准受益，持续增收。二、基本原则（一）坚持因地制宜选准产业。特色产业既是解决短期增收的抓手，又是巩固脱贫成果提升脱贫水平的依托。要立足贫困地区资源禀赋，综合考虑光热水土条件、生产基础和技术支撑，因地制宜规划产业布局，精准产业定位，形成具有区域特色的规模优势产业。（二）坚持精准覆盖贫困人口。农业产业帮扶项目布局要尽可能覆盖建档立卡贫困村、有发展产业意愿的贫困户，在组织申报、编制计划时，要提出带动贫困人口的指标任务，实现贫困人口精准受益。（三）坚持新型主体引领带动。实施财政补助项目的龙头企业、合作社等新型主体，要积极承担起在脱贫攻坚和农民增收中的社会责任和经济责任，明确采取土地入股、土地流转、劳务报酬等多种形式，带动建档立卡贫困户增收；具备条件的，可采取国家投入资金收益权量化等方式，精确到户到人，使贫困户分享分红收益。（四）坚持公开规范注重绩效。项目资金要专项用于农业产业帮扶工作，分配使用要合理规范，全程公开，接受群众和社会监督。省级将对各县区资金使用情况进行绩效评价，实行以结果为导向的资金分配管理机制。三、资金和项目管理（一）实施范围。支持在国家产业扶贫开发任务较重、建档立卡贫困人口规模较大的56个国家扶贫开发重点县、片区县，特别是深度贫困县和当年脱贫摘帽县开展产业帮扶示范项目建设，专项用于培育农业优势特色产业带动贫困人口脱贫增收。（二）资金规模。按照省委省政府下发的《关于加快深度贫困地区脱贫攻坚工作的实施意见》要求，对于略阳县、镇巴县、汉滨区、紫阳县、岚皋县、白河县、山阳县、柞水县、商南县、丹凤县、镇安县等11个深度贫困县，每县切块下达700万元，其余45个贫困县，每县切块下达500万元，专项用于产业帮扶工作，每县可列支不高于3万元，用于产业帮扶信息监测、统计等工作。（三）使用方向。各县区要按照脱贫攻坚规划和产业脱贫方案，立足当地资源禀赋和产业基础，结合省委省政府农业特色产业发展“3+X”规划布局和总体部署，自主开展产业脱贫，带动贫困户增收脱贫。积极发展苹果、设施农业、奶山羊三个千亿级产业，加快发展陕北、渭北高效果园；重点建设关中、渭北设施农业，陕北山地、沙漠设施蔬菜，以及汉丹江流域设施食用菌板块；以陇县、千阳、富平等核心区为重点，做大做强羊乳产业。同时，因地制宜，支持茶叶、猕猴桃、肉羊、肉牛等区域特色产业发展。各县区要统筹安排项目资金，明确实施区域、支持重点，自主确定具体项目。项目实施主体应为农业企业、农民专业合作社、家庭农场等新型经营主体。要根据项目特点、资金额度、实施主体实际，精准落实带动建档立卡贫困户数量。补助标准应与参与项目建设的建档立卡贫困户数量挂钩。项目资金不得用于平衡预算、偿还债务、建造办公场所、改善办公条件、发放人员工资补贴等无关的支出。（四）项目条件。产业脱贫项目应符合以下条件：一是项目内容为符合产业脱贫需求的种植业、养殖业等地方优势特色产业；二是优先扶持贫困地区具有一定规模，已形成“一县一业、一村一品”的产业生产或加工基地；三是项目主体已建立“企业（合作社）+基地+贫困农户”的利益带动联结机制，申报项目时应提供与贫困户开展订单、股权、劳务等合作的有效证明材料，科学评估产业项目扶贫效应，优先倾斜支持带动贫困户数量多的项目。（五）管理程序。产业帮扶资金切块下达。1．下达资金计划。省农业厅、省财政厅依据年度预算安排方案下达全省产业帮扶资金计划，相关市（区）要在计划下达后的15个工作日内将资金计划下达相关县区，相关县区在30个工作日内将资金落实到具体项目和实施主体。2．组织申报项目。县区农业、财政部门负责组织扶贫示范项目的申报和评审工作。一是制定符合本地区产业特点的项目评审方案和评审标准。二是组织当地新型经营主体申报项目，实行竞争立项。三是坚持公开、公正、合规，评定出符合产业帮扶财政专项支持条件的项目，并落实带动建档立卡贫困户的数量，编制总体方案，报送市级农业、财政部门备案。各县区要依据产业扶贫规划，针对贫困地区特色产业发展薄弱环节和产业发展重点，量身打造、储备一批产业帮扶项目。3．项目审核备案。市级农业、财政部门负责对相关县区方案及项目进行汇总后将总体方案报省农业厅、省财政厅备案。四、工作要求（一）加强组织领导。有关市县要成立协调机构，明确分工，落实责任，密切配合，形成合力。各县农业部门会同财政部门要在本级产业脱贫领导小组的领导下，结合本地实际情况，制定本地实际方案，要在实施区域遴选、实施方案制定、申报单位确定、督查验收和总结宣传等方面加强协调配合，确保公开、公正、合规，共同做好组织实施工作。（二）健全管理制度。各有关市县要结合本意见，制定相应的项目和资金管理办法，建立科学合理、覆盖全面、指向精准的产业帮扶资金管理和使用制度。市、县农业部门要指导项目建设单位建立项目档案，以备检查验收。档案内容主要包括：项目实施方案、公告公示、帮扶资金使用台帐、基地覆盖建档立卡农户的收益统计台账、效益分析、带动的建档立卡户姓名及联系方式、建档立卡贫困户享受财政补助资金方式等材料。（三）加大投入力度。各县区要根据本区域脱贫工作的实际，有针对性地整合各项涉农资金，尽快形成扩大投入、放大效应、合力攻坚的产业精准扶贫投入模式。鼓励各市县采取建立风险池等方式，撬动金融资本、社会资本投入产业扶贫，拓宽产业扶贫投入渠道。（四）强化监督检查。有关市县农业、财政部门要根据报备的项目方案，加强资金管理，管好用好资金，严禁虚报、冒领、截留、挤占、挪用现象发生；加强工作督导、业务指导，及时掌握项目实施情况；加强项目实施情况监督检查，及时纠正项目实施过程中出现的各种问题，确保项目质量。 '
               '（五）开展绩效考评。省上已将产业帮扶工作列入追赶超越季度点评考核指标，每季度对各市进行打分考核，年底要对资金计划下达时效性、管理规范程度、带动建档立卡贫困人口增收等进行综合考评，考评结果将与下年度各县区切块资金规模相挂钩。各相关市县要对项目完成情况、资金使用情况、最终成果和绩效目标完成情况等进行评价，并于2018年12月底前将绩效考评报告、项目验收评分表和项目总结一并报省农业厅、省财政厅。\xa0'
               '附件：2018年农业产业帮扶资金计划表\xa0附件.docx\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅 陕西省财政厅关于印发农业产业帮扶资金实施指导意见的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2018-02-06 08:46:47',
 'art_detail': '\n'
               '         驻陕农纪发〔2018〕3号\xa0'
               '省农业厅、省扶贫开发办公室、省供销合作总社：为了贯彻落实中央纪委《关于2018年至2020年开展扶贫领域腐败和作风问题专项治理的工作方案》和省纪委《关于开展扶贫领域腐败和作风问题专项治理实施方案》的文件精神，进一步强化扶贫领域监督执纪问责工作，为全省打赢脱贫攻坚战提供有力的纪律保障，现提出如下安排意见：一、指导思想以习近平总书记在中央纪委二次全会上的重要讲话精神为指导，充分认识保障打赢脱贫攻坚战的重要性和紧迫性，着力解决扶贫领域群众反映强烈问题，聚焦主责主业，牢固树立“四个意识”,主动担当作为，切实履职尽责，以实际行动不断推动全面从严治党向纵深发展。二、重点内容驻厅纪检组要与各综合监督单位形成合力，强化扶贫领域腐败和作风问题专项治理工作力度。（一）重点是履行主体责任不力,贯彻落实十九大精神和中省扶贫脱贫决策部署态度不坚决、工作不扎实、执行搞变通等问题;扶贫政策、项目、资金等信息不公开、不透明,在脱贫攻坚中履职不力、推诿扯皮,不作为、慢作为、乱作为等问题。（二）重点是贪污侵占、行贿受贿、虚报冒领、截留用、挥霍浪费、吃拿卡要、优亲厚友等突出问题;扶贫项目分配、审批、招投标、验收等环节违规操作、滥用职权、以权谋私等问题;向农村低保危房改造、易地搬迁、产业扶持、对口帮扶以及贫困地区基础设施建设、惠农资金动脑筋、伸黑手等问题。（三）重点是扶贫领域工作不扎实、作风不务实、结果不真实,以会议贯彻会议、以文件落实文件,盲目决策、弄虚作假、数字脱贫,扶持对象识别、项目安排、资金使用管理、措施到户、因村派人、脱贫成效不精准,以及贫困县、贫困村、贫困户虚假“摘帽”等问题。（四）重点是跟进产业扶贫、区域性扶贫开发“资源变资产、资金变股金、农民变股东”改革等,严查项目分配、资金使用、招投标等关键环节违纪问题。坚持“一案双查”,深入查找工作推进、日常监督、制度建设等方面的问题和不足,督促有关职能部门堵塞漏洞、建章立制、强化监管。三、工作要求（一）要提高思想认识。打赢脱贫攻坚战,是我们党对人民的庄严承诺,是一项必须完成的政治任务。2020年如期实现现行标准下农村贫困人口脱贫目标,时间紧迫、任务艰巨。各综合监督单位要切实提高政治站位，着力解决扶贫领域群众反映强烈问题，切实增强群众的获得感、幸福感和安全感，为确保如期打赢脱贫攻坚战奠定坚实基础。（二）要夯实主体责任。各单位党组要制定专项整治具体措施，压实从严治党工作主体责任。纪检、信访、计财、人事等部门要形成合力，各司其职、各负其责,抓好工作落实。要通过会议、文件、实地督导等多种形式，层层传导专项治理工作压力，保持反腐败斗争的高压态势。（三）要拓宽线索渠道。驻厅纪检组和省农业厅、省扶贫办、省供销社要通过对外主动公开投诉举报电话、邮箱、来信、新媒体等平台，密切关注扶贫领域的负面网络舆情，深入分析专项审计、专项督查等资料,广泛收集和主动发现扶贫领域的各类问题线索，并实行台账式管理和分类处置。（四）要加大督查力度。在搞好专项治理日常工作的同时，驻厅纪检组将不定期组织专项督查，具体抽调驻厅纪检组和三个综合监督单位有关人员组成督查组，专项督查各综合监督单位及其所属系统该项工作开展情况，及时印发督查情况通报，并对发现问题提出整改意见和要求，确保专项治理工作顺利推进。请各单位于6月18日和12月18日前将半年、全年专项治理工作情况报驻省农业厅纪检组。重要情况请及时报送。\u3000\u3000\u3000\u3000\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '中共陕西省纪委\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '驻省农业厅纪律检查组\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2018年2月5日\n'
               '        ',
 'art_source': '驻省农业厅纪律检查组',
 'art_title': '关于开展扶贫领域腐败和作风问题专项治理的安排意见'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2018-01-23 15:57:14',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2018〕11号各设区市农业（农林）、畜牧、果业局（委），杨凌示范区农业局，韩城市农林局：据气象预报，受北方冷空气南下和槽前暖湿气流共同影响，1月23日到25日,我省从南向北将出现入冬以来第二次范围广、强度大、持续时间长的雨雪、降温及冰冻天气过程，预计主要降雪时段出现在24日至25日。榆林南部、延安北部小雪；延安南部、铜川、宝鸡、咸阳、杨凌、西安、渭南、汉中、安康、商洛中到大雪；秦岭山区、安康东部及南部、商洛南部有暴雪。整个天气过程降水量：榆林南部、延安北部0～4mm；延安南部、关中4～6mm；陕南6～15mm。降温幅度：陕北8～10℃；关中、陕南6℃左右。最低气温榆林、延安出现在24日凌晨，关中、陕南出现在26日，榆林-18～-16℃、延安-12～-10℃、关中-9～-7℃、陕南-6～-4℃。各级农业部门要高度重视，充分汲取上次雨雪灾害防范应对的经验教训，提前安排部署，强化措施落实，确保农业生产安全。一要强化责任意识。此次降雪降温过程持续时间长、降温幅度大、影响范围广，尤其是关中、陕南仍将是重点区域，易造成油菜、蔬菜、水果等在田作物、幼小畜禽受冻，设施大棚损坏，影响鲜活农产品供给。各级农业部门要牢固树立防灾抗灾减灾思想，强化服务意识，动员一切可以动员的力量，努力把降雪低温冻害影响降到最低程度。要落实主要领导包片，明确工作责任，靠前实施指挥，确保冬季农业生产稳定发展。二要落实应对措施。协调气象部门及时预警预报，利用各种媒体及时发布信息，动员广大农技人员，迅速深入生产一线，组织群众做好设施农业棚体和畜禽圈舍加固以及棚内（圈舍）防寒保温工作，特别是上次雪灾受损的设施，再行检查并修复加固，增强棚体抗压、防风、保暖性能。动员专业合作社等新型经营主体，组织人员及时清除积雪，防止压垮设施。陕南地区要加强油菜、露地蔬菜等作物田间管理，使受冻作物尽快恢复；对果（茶）树采取基部培土、树干包扎等措施防寒防冻，并及时除雪清沟、排涝降湿，减轻灾害影响。三要加强指导服务。完善防寒防冻技术方案，适时派出工作督导组，深入一线核查灾情，指导农民落实防寒保温措施，切实搞好防灾抗灾救灾服务保障。强化值班、值守，及时调度降雪降温实况、灾情和抗灾救灾进展情况，重大气象时段和灾害期间，坚持每日调度和报送。四要抓好产品供给。农业部门要联合有关部门，针对雨雪降温影响，及时发布农产品市场供求信息，引导和组织设施农业生产企业、合作社、种植大户及批发客商，积极组织货源，加大市场供应，保障居民正常生活。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2018年1月23日\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于做好新一轮降雪降温天气防范应对工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2018-01-06 19:42:40',
 'art_detail': '\n'
               '         '
               '陕农业发〔2018〕2号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：1月3日-5日，我省大部出现中到大雪和降温天气，局地出现暴雪、大风。关中地区积雪厚度达10-22cm，部分地区日光温室垮塌、大棚受损严重，设施农业、畜禽养殖遭受较大损失。据气象部门预报，6日-7日我省还有一次降雪降温天气过程。为进一步加强灾害防范应对工作，现就做好雨雪天气设施农业防灾减灾抗灾工作有关事项紧急通知如下：一、加强监测，及时预警各级农业部门及时与气象部门联系，密切关注天气变化，针对灾害发生情况启动应急预案，充分利用广播、电视、网络、手机短信等信息平台，及时发布预警信息和防范措施，指导群众做好灾害防灾抗灾救灾工作。灾害发生后，要组织干部和技术人员深入一线，了解灾情动态，按照层层上报、分级负责的原则，第一时间报送农业灾情，严禁瞒报、漏报、迟报。二、突出重点，强化措施各地要积极行动，组成防灾减灾抗灾工作指导组，分赴受灾地区，组织群众做好以设施蔬菜为重点的防风、防雪、防寒、防冻、保温工作，保障设施蔬菜安全生产。一是组织群众认真排查日光温室和大棚的隐患，堵塞漏风漏气的缝隙，紧固压膜线，防止大风灌入揭棚。二是对无支柱、大跨度的日光温室和大棚要及早准备好应急的支柱，防止棚室垮塌。三是及时听看天气预报，在大幅降温前封闭好棚室，盖好草帘，防止低温冻害发生。四是灾情过后，要及时修复受棚室，加强肥水管理，促进蔬菜恢复生长，提高抗寒抗病能力。同时要做好种苗繁育工作，确保绝收地块重新栽种种苗有效供应。三、提早部署，做好市场供应各级农业部门在组织群众做好生产自救的同时，要针对后期持续降温带来的不利影响，及时调度发布农产品市场供求信息，引导和组织设施农业生产企业、合作社、种植大户及批发客商，积极组织货源，协调公安、交通部门开通“绿色通道”，做好蔬菜、肉类等农产品市场供给，确保主要农产品市场供给稳定。四、落实责任，强化值守冬季设施蔬菜关系广大群众日常生活。各级农业部门要强化责任意识，增强服务观念，实行领导干部分片包抓，技术干部逐村指导，做到任务明确、责任到人、措施到位，扎实做灾害防范和农业生产各项工作，减少因灾损失。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2018年1月6日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于做好雨雪天气农业防灾减灾抗灾工作的紧急通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2018-01-19 09:06:09',
 'art_detail': '\n'
               '         '
               '陕农业发〔2018〕4号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：根据《陕西省农业产业化经营重点龙头企业认定和运行监测管理办法》（陕政发〔2012〕55号）要求，2017年我省开展了省级农业产业化经营重点龙头企业（以下简称省级龙头企业）监测及递补工作。经市县审核推荐、省级专家评审、省农业产业化联席会议审定和社会公示等环节，认定395家省级龙头企业动态监测合格（名单见附件1），保留其“陕西省农业产业化经营重点龙头企业”资格；70家龙头企业因达不到规定标准和要求，监测不合格，取消其“陕西省农业产业化经营重点龙头企业”资格。同时，递补123家企业为“陕西省农业产业化经营重点龙头企业”（名单见附件2）。农业产业化是现代农业的发展方向，龙头企业作为农业产业化发展的关键环节和新型农业经营主体的中坚力量，在“保市场供给、保质量安全、促产业脱贫、促农民增收”中发挥了骨干作用，已成为全省脱贫攻坚队伍中的主力军，农民增收的动力源和稳定器，促进现代农业发展的重要力量。各市区要以习近平新时代中国特色社会主义思想为指导，全面贯彻落实党的十九大精神和中央经济工作和农村工作会议精神，以市场需求为导向，以完善利益联结机制为核心，以推进农业供给侧结构性改革为主线，坚持质量兴农、绿色兴农，主动完善创新龙头企业政策扶持方式和服务管理手段，指导龙头企业积极参与实施乡村振兴战略、产业精准扶贫的重大部署，推动企业在发展新产业、新业态上实现新突破，全面提升企业发展质量和效益，促进我省农业产业化全面快速发展。各市要将本次监测合格及新递补认定的省级重点龙头企业名单及时通报有关县区和龙头企业，强化宣传引导力度。监测不合格的龙头企业，不得使用省级重点龙头企业称号，原则上不再申报省本级财政资金扶持的各类农业项目。农业产业化龙头企业要紧紧抓住经济转型升级新机遇，转变发展思路，走高质量发展新路径，增强企业核心竞争力。积极参与农业产业精准扶贫，探索完善帮扶机制，促进农业增效农民增收，为全省农业农村经济发展和乡村振兴战略实现做出积极贡献。\xa0'
               '附件：1．2017年监测合格陕西省农业产业化经营重点龙头企业名单\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2．2017年递补陕西省农业产业化经营重点龙头企业名单\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2018年1月9日附件1\xa0监测合格陕西省农业产业化经营重点龙头企业名单\xa0'
               '西安东方乳业有限公司西安摩尔农产品有限责任公司西安兆龙食品有限公司陕西康达尔农牧科技有限公司西安市沛民林牧畜业有限责任公司陕西西瑞（集团）有限责任公司※陕西秦龙乳业有限公司西安伊利泰普克饮品有限公司西安市亚宏面粉有限责任公司西安西粮实业有限公司西安航城面粉有限公司西安宏兴乳业有限公司西安市董白面粉有限公司西安鑫谷玉米制品有限公司西安邦淇制油科技有限公司西安格润牧业股份有限公司西安罗曼实业有限责任公司西安市阎良蜂蜜加工厂陕西奇异王果现代有机农业有限公司西安下店玉米开发实业有限公司西安百跃羊乳集团有限公司陕西老蜂农生物科技有限责任公司西安华瑞生物工程有限公司陕西金冠牧业有限公司陕西大统生态产业开发有限公司陕西隆丰种业有限公司西安中王饲料有限公司西安市聚仙食品有限公司西安新天地草业有限公司西安粮油批发交易市场陕西穆堂香调味食品有限公司西安首阳农业生态养殖有限公司陕西雁锦花卉园艺有限责任公司陕西三联果业集团有限责任公司西安市山美食品有限公司西安虎标茶果土产食品有限公司周至富海肉业有限责任公司西安润德绿色农产品有限公司西安市高陵区中王农产品专业合作社西安百之惠实业有限公司西安市户县万邦养殖专业合作社陕西骊佳生态产业园有限公司※西安安诺乳业有限公司西安大成玉米制品有限责任公司天人果汁集团股份有限公司西安白鹿原生态实业有限公司宝鸡得力康乳业有限公司陕西华祥食品（集团）有限公司陕西红果贸易有限公司陕西秦川牛业有限公司眉县金色秦川猕猴桃专业合作社陕西大红袍新科技发展有限公司宝鸡布尔肉羊开发有限公司宝鸡陕丰淀粉有限公司宝鸡市恒丰园农产品发展有限公司陕西太白山制药有限责任公司宝鸡源盛实业有限公司宝鸡凤友油脂有限公司陕西雍城面业有限公司陕西天香食品有限责任公司宝鸡市虹源生物科技有限公司岐山县太子油脂有限责任公司岐山天缘食品有限公司陕西京泰纺织化纤（集团）有限公司陕西天和乳业有限公司岐山华祥纸箱有限公司宝鸡康辉蜂产品有限责任公司陕西华夏果业有限公司眉县秦旺果友猕猴桃专业合作社陕西海通育禽有限公司眉县金桥果业专业合作社宝鸡市陈仓区鑫茂养猪专业合作社宝鸡西合中药饮片有限公司宝鸡同兴果品进出口贸易有限公司陕西秦海鹿业有限责任公司宝鸡阜丰生物科技有限公司蒙牛乳业（宝鸡）有限公司宝鸡市陈仓区绿丰源蔬果专业合作社陕西新贸物流配送连锁有限责任公司宝鸡市科兴药业有限公司陕西眉坞果蔬有限责任公司宝鸡同盛食品有限公司宝鸡太白山美源果品有限公司凤县恒力农业开发有限责任公司陕西昌荣纺织有限责任公司陕西国人菌业科技产业园有限公司※陕西宏福农林开发有限责任公司宝鸡建忠佳家乐食品有限公司※扶风鑫良畜牧养殖开发有限责任公司宝鸡华龙牧业集团有限公司陕西省凤翔县华宇食品有限责任公司陕西海天制药有限公司陕西君碧莎制药有限公司※陕西亚虎食品有限公司益海嘉里（兴平）食品工业有限公司鲁洲生物科技（陕西）有限公司兴平市星光良种猪繁养殖有限公司陕西泾云现代农业股份有限公司陕西省泾阳县自强面粉有限责任公司陕西建兴奶牛繁育有限公司陕西子祺食品集团有限公司陕西心特软食品有限责任公司陕西红星软香酥食品集团有限责任公司陕西百跃优利士乳业有限公司陕西大林果业发展有限公司咸阳佳和乳业有限公司陕西正大有限公司陕西白鹿制药股份有限公司※陕西欣雅纸业有限公司泾阳日新农业开发有限公司旬邑川兴果业有限公司陕西华荣园林景观建设集团有限公司三原聚龙农业科技有限公司陕西雅泰乳业有限公司陕西康大饲料有限公司陕西万家乐实业集团有限公司陕西三原鑫源面粉有限公司咸阳纤手纯棉土织布工艺品有限公司咸阳天丰农业科技有限公司陕西金醇古酒业有限责任公司陕西中盛果业有限公司※长武鑫隆果业有限公司咸阳佰群贸易有限公司陕西蓝海果业有限公司陕西绿野果业集团有限公司※陕西馨盛花卉苗木科技有限公司陕西好农夫农业发展有限公司五得利集团咸阳面粉有限公司咸阳泾渭茯茶有限公司陕西普华永康农副产品冷冻物流有限公司陕西绿盈盈现代农业有限公司陕西星光乳业有限公司陕西圣奥动物药业有限公司三原顺源食品有限责任公司咸阳长丰面粉有限公司陕西多维生态农林科技有限公司陕西百富源粮油科工贸有限公司淳化县欣盛农化有限公司陕西澳美慧乳业科技有限公司彬县天盛果业有限责任公司陕西旬邑石门生态农业有限公司陕西丫丫园艺工程有限公司三原徐木北鹿奶牛养殖专业合作社陕西景盛肥业集团有限公司咸阳三原思味食品有限责任公司陕西三原中盛果业有限公司白水县三联果业有限责任公司白水康家绿色有机农业科研开发有限责任公司白水源兴果业有限公司白水县长虹果业有限责任公司路易（陕西）食品有限公司陕西龙首油脂有限公司陕西省蒲城美尔果农化有限责任公司※渭南市华州区龙源生态有限责任公司白水县合兴果业有限责任公司富平县洋阳柿饼专业合作社※陕西百代可可生态科技有限公司陕西秦力面业有限责任公司陕西红星美羚乳业股份有限公司富平县庄里种鸡场富平鸿天饲料科技有限责任公司陕西富四方柿业有限公司白水县康惠粮果贸易有限责任公司※陕西省白水县山里情食品科技有限公司白水县宝联果业有限责任公司白水安德利果蔬汁有限公司白水县康达果蔬有限责任公司富平县科农果业专业合作社陕西金牛乳业有限公司陕西蒲城建平实业有限公司渭南市油脂化工有限责任公司陕西蒲城永信食品有限公司陕西振华农业科技有限公司渭南市海天利食品有限责任公司渭南市临渭区进元饲料科技有限公司渭南市秦牛食品有限责任公司陕西伟恒生物科技股份有限公司渭南裕美现代农业设施工程有限公司陕西龙宇棉纺实业有限公司陕西蒲城犇犇养殖有限公司陕西蒲城天子果蔬实业有限公司蒲城县金鑫农产品有限公司蒲城金农果蔬有限责任公司陕西蒲城丰瑞达实业有限公司陕西蒲城兴盛果蔬有限公司蒲城兴盛饲料有限公司蒲城县农丰农资经销有限责任公司陕西蒲城兴农生物科技开发有限公司白水县圣源果业有限责任公司蒲城兴文麦草工艺专业合作社陕西旭峥贸易有限责任公司陕西荷丰生态农业开发有限公司白水县盛隆果业有限责任公司陕西润强现代农业发展有限公司陕西恒鑫源现代农业开发有限公司渭南市华隆畜牧有限公司陕西美邦农药有限公司蒲城勇奔果业有限公司蒲城县秦福果蔬有限公司陕西蒲城小平实业有限公司韩城市金太阳花椒油脂药料有限责任公司韩城市宏达花椒香料有限公司陕西省韩城市国力农业发展有限责任公司陕西上林源照金生态农业开发有限公司陕西秦龙山水绿色食品有限公司铜川利民食品有限公司铜川市三联果业有限公司陕西鹏大实业有限公司※陕西供销集团铜川高塬农业有限公司陕西赛德高科生物股份有限公司杨凌圣桑绿色食品有限公司陕西荣华农业科技有限公司杨凌秦岭山现代农业股份有限公司陕西杨凌伟隆农业科技有限公司※陕西大唐种业股份有限公司陕西杨凌富仕特饲料有限公司杨凌秦宝牛业有限公司杨凌新华府现代农业有限公司陕西巨农科技农业有限公司陕西竹园村食品科技股份有限公司陕西省西乡县长林肉类食品有限公司汉中顺鑫鹏程食品有限公司勉县定军米业发展有限责任公司汉中市皇冠农业产业化有限公司陕西绿梦食品有限责任公司汉中市成祥米业有限责任公司陕西秦洋长生酒业有限公司陕西永康农业发展有限公司南郑县同利源茧丝绸有限公司城固县振华生物科技有限责任公司城固县龙宴有限责任公司陕西省西乡县茶业有限责任公司西乡县陕南绿茶有限公司汉中中园农业科技发展（集团）有限公司汉中军鑫农业发展有限公司汉中天利科贸有限责任公司汉中市缫丝有限公司陕西东裕生物科技股份有限公司陕西大秦汉集团有限公司陕西鸿泰实业有限公司汉中山花茶业有限公司陕西汉水大鲵开发有限公司汉中新天地农业发展有限公司陕西鑫科农业科技发展有限责任公司陕西天元粮农发展有限公司※陕西鹏翔茶业股份有限公司西乡县利民粮油工贸有限责任公司汉中市黑凤园农业生态发展有限责任公司汉中珑津茶油科技股份有限公司※陕西龙佳农业科技发展有限公司宁强县千山茶业有限公司汉中市江南油脂有限公司汉中市云山茶业有限责任公司陕西汉中百瑞牧业有限责任公司南郑县金正米业有限公司汉中汇力实业有限公司汉中霖桓农产品开发有限责任公司陕西朱鹮生态农业发展有限责任公司陕西新美新农业科技有限公司汉中市秦岭源绿色农业有限公司汉中市清波农业科技发展有限责任公司宁强县羌州茶业有限责任公司南郑县汉山茶业有限公司城固县张骞丝绸厂陕西锦泰魔芋产业发展有限公司陕西天谷天翔药业有限公司陕西明冠食品饮料有限公司镇坪县美味佳食品有限责任公司安康巴山丝绢有限责任公司旬阳县蚕茧经营有限责任公司安康市民荣实业集团食品有限公司汉阴县秦龙有限责任公司安康市硒源油脂集团有限公司安康市巴山宝业丝绢有限公司陕西省紫阳县康洪茧丝有限公司安康市长寿医药（集团）有限公司安康百瑞丝绸有限责任公司陕西一叶轩生态科技有限公司陕西金福海油脂工业有限公司陕西天新丝绸有限公司陕西省紫阳县富硒食品有限公司紫阳县盘龙天然富硒绿茶有限公司陕西省紫阳县和平茶厂陕西补天食生物科技有限公司\xa0'
               '平利县女娲茗茶有限公司平利县盛丰源食品有限公司旬阳县明文油脂有限公司安康市鸿盛实业有限公司汉阴县盛发魔芋制品有限公司平利县女娲银峰茶叶有限公司安康市汉水韵茶业有限公司白河县兴达农业综合开发有限公司安康市恒翔生物化工有限公司安康市龙飞魔芋食品有限公司安康市明日商贸有限公司旬阳县健兴魔芋食品有限公司安康市龙泰养殖有限公司商南县沁园春茶业有限责任公司陕西省商南县茶叶联营公司镇安县雪樱花魔芋制品有限公司陕西未来绿色农牧开发有限公司陕西省商南县宏源食品有限公司镇安县华联农工商有限公司商洛市国力工贸有限责任公司丹凤县华茂牧业科技发展有限责任公司商洛民乐现代农业科技发展有限公司商洛市柏伦工贸有限公司山阳县金川封幸化工有限责任公司镇安县创盛肉食品有限公司镇安华美农业产业化有限公司丹凤县兴农牧业有限责任公司陕西香菊药业集团有限公司镇安县盛华茶叶发展有限责任公司陕西天士力植物药业有限责任公司陕西天元隆农业科技有限公司陕西智源食品有限公司丹凤县山凹凹生态农牧业发展有限公司陕西丹凤葡萄酒有限公司陕西君威农贸综合有限责任公司商洛市丰联工贸有限责任公司陕西天之润生物科技有限公司陕西省商南县秦东集团有限责任公司陕西汇生源生态农业有限公司※延安制药股份有限公司洛川县农友果业有限责任公司延安劳山鸡业有限责任公司陕西富县绿平果业有限责任公司※延川县兴盛工贸有限责任公司陕西源丰果牧有限责任公司荣华富洋（延安）市场推广及冷库有限公司陕西万福种业有限公司甘泉八千里食品有限责任公司延安中果生态农业科技股份有限公司富县诚鑫农牧发展有限责任公司延安联威农牧有限公司延安恒丰制粉有限责任公司延川县锦春枣业有限责任公司延长华隆果业有限责任公司宜川县宜壶农产品开发有限责任公司延安绿谷田园食品有限责任公司延安圆方（集团）公司洛川美域高生物科技有限责任公司延长圣通农副产品开发有限公司延长长丰牧业科技开发有限责任公司陕西省横山进出口有限责任公司清涧县宏祥有限责任公司榆林市山立农贸集团有限公司榆林市榆阳区菇闻天下菌业有限公司榆林市王贵集团新潮毛皮有限公司榆林市榆阳区瑞丰农业科技有限公司陕西省定边县乳品实业有限公司榆林市天鹏畜禽有限公司榆林市王成商贸有限责任公司榆林市榆阳区聚富牧业有限公司陕西三丰粮油有限公司榆林市惠民食业有限责任公司陕西沙海农业开发集团有限公司陕西华西牧业有限责任公司神木市丰禾生态农业科技开发有限公司陕西通海绒业股份有限公司神木县瑞盛养殖有限责任公司榆林市大志农业科技发展有限责任公司榆林市康达生态农牧有限公司府谷县天漠农产品开发有限责任公司府谷县兴茂农业发展有限公司榆林市中稷农业发展有限公司※榆林市宏驼农业集团有限公司神木县长青农业科技发展有限公司定边县塞雪粮油工贸有限责任公司府谷县民永兴农产品开发有限责任公司府谷县希望养殖有限责任公司陕西省府谷县花乌枣业有限责任公司米脂县益农畜禽养殖有限公司吴堡县黄河红枣业生态开发有限公司榆林市巨人食品科技开发有限公司榆林市四海枣业有限公司陕西清涧县宏图枣业有限责任公司子洲县鼎盛中药材有限责任公司陕西富华油脂工业有限责任公司子洲县天赐中药材有限责任公司靖边县黄土之恋农产品有限公司绥德县老闫家炒货食品有限责任公司榆林市东方红食品开发有限责任公司定边县科发马铃薯良种有限责任公司榆林市榆阳区高科阳光农业开发有限公司靖边县鸿丰农产品有限公司横山县通远综合服务有限责任公司米脂县益康农产品开发有限公司佳县东奥牧业有限责任公司榆林市新田源集团富元淀粉有限公司横山县香草羊肉制品有限责任公司佳县益民现代农业开发有限公司榆林市红满园绿色枣业开发有限公司定边县沃野农业开发有限公司定边县兴隆养殖有限公司\xa0'
               '注：以上名称前带“※”号的为更名企业\xa0附件2\xa0递补陕西省农业产业化经营重点龙头企业名单\xa0'
               '西安鑫丰农业科技有限公司陕西汉唐环保农业有限公司西安方欣食品有限公司现代牧业（宝鸡）有限公司宝鸡海升现代农业有限公司陕西太白雪岭生态农业发展有限公司眉县鹏盛达农副产品购销专业合作社宝鸡市冠友蜂产品有限责任公司宝鸡迪兴农业科技有限公司陕西长麟农林科技有限公司宝鸡市万隆生态农林有限公司宝鸡市金果生态农业科技开发有限公司陕西八戒农牧有限公司宝鸡神农养殖专业合作社陕西凤凰神泉柳林酒有限公司陕西一品万里茶业有限公司兴平市众和现代生态农牧有限公司兴平市秦一辣椒制品有限公司陕西军星农业科技有限公司陕西福瑞特生态农业发展有限公司武功县海鋈皇嘉农业种植专业合作社咸阳苏绘民间手工工艺精品专业合作社咸阳润源生物科技有限公司陕西三原万君果蔬有限责任公司陕西志鑫食品有限责任公司陕西茂腾农业科技示范园有限公司陕西辰烁生态农业有限公司咸阳荣泰农业发展有限公司长武昌盛果业有限公司陕西绿资农业开发有限公司陕西亿丰实业集团有限公司彬县裕才果业农民专业合作社陕西旬邑泉源果品有限公司旬邑县常丰果业有限公司陕西德盛源现代农业发展有限公司澄城县诚达果蔬有限公司陕西建龙果品有限责任公司华阴市常发农林科技开发有限公司大荔大有农业综合开发有限公司陕西沁园现代农业综合开发有限公司合阳县雨阳富硒农产品专业合作社合阳县丰阜农业有限公司陕西粮农富平西瑞面粉有限公司富平县骐进生态农业科技开发有限公司白水县鑫盛农业科技有限责任公司白水县润泉现代农业科技开发有限公司白水县康丰果业有限责任公司白水县美华果业有限责任公司白水县玉星果业有限责任公司陕西澄城尚阳生态禽业有限公司陕西同腾生物科技有限公司蒲城群丰果业有限责任公司陕西蒲城宜兴果业有限公司陕西蒲城大红门肉类食品有限公司陕西蒲城宜安果业有限责任公司蒲城县秦龙果业有限公司陕西大荔景璧肉类食品有限公司陕西大荔沙苑黄花有限责任公司陕西瑞福兴生物科技有限公司陕西晟杰实业有限公司渭南市华州区莲峰现代农业科技发展有限公司渭南裕翔生态农业科技股份有限公司陕西宏大生物科技有限公司陕西洽丰农业科技有限公司陕西省农垦集团沙苑农场有限责任公司陕西富强宏图牧业有限公司铜川市鸿伟实业股份有限公司陕西众兴高科生物科技有限公司杨凌沃邦生态农业股份有限公司陕西海棠生态农林股份有限公司杨凌秦巴山生态农业科技有限公司陕西汉中给力食品（集团）有限公司陕西绿娇子农业开发有限公司陕西宏力农业科技有限公司汉中市龙头山水产养殖开发有限公司汉中邦利农林科技有限公司汉中市瑞丰生物科技有限责任公司陕西洋县志建药业科技有限公司洋县益民绿色农业科技有限公司洋县永辉农业产业发展有限公司陕西金沙滩农业综合开发有限公司陕西省秦川大厨农业发展有限公司宁强青木食品有限公司陕西怡溪春茶业科技有限公司镇巴县长兴实业有限责任公司陕西安康天瑞塬生态农业有限公司平利县田珍茶业有限责任公司陕西嘉晟实业集团有限公司汉阴县民康农林科技开发有限公司岚皋县明富魔芋生物科技开发有限公司安康市京康现代农业开发有限公司镇坪欣陕农业科技有限公司白河县逸酒酒业有限责任公司紫阳县闽秦茶业有限公司陕西原生富硒工夫茶业有限公司平利县申草园茶业有限公司陕西森弗天然制品有限公司山阳县恒瑞肉制品有限公司商南县瑞生实业有限公司陕西广远食品有限责任公司商南县鸿德农林业发展有限公司陕西海源生态农业有限公司子长县顺天实业发展有限公司延川百优生态农业发展有限公司安塞隆鑫果业有限公司洛川绿佳生态农业有限责任公司延安森宇良种苗木繁育有限责任公司延安市宝塔区山牛商贸有限责任公司榆林市榆阳区毛乌素绿洲农业科技有限公司榆林市明杰农业开发有限公司榆林市普惠酒业集团有限公司榆林春蕾绿色禽业有限公司神木市旺洋农业有限责任公司陕西华和实业有限公司神木县益春夏种业有限公司神木县禾泰农业发展有限责任公司府谷县聚金邦农产品开发公司靖边县宇丰农业科技发展有限公司靖边县万科农业科技开发有限公司定边县吉元泰农业开发有限公司绥德县志强枣业有限责任公司绥德县绥德汉食品有限公司佳县一隆农副产品购销有限公司\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于公布监测合格及递补省级农业产业化重点龙头企业名单的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-12-27 16:35:51',
 'art_detail': '\n'
               '         陕西省农业厅关于印发省第二次全国农业污染源普查实施方案的通知\xa0'
               '各设区市农业（农林）、畜牧、农机、果业局（委、中心），杨凌示范区农业局，韩城市农林局，厅机关有关处（室、局）、厅属有关单位：《陕西省第二次全国农业污染源普查实施方案》已经省农业厅行政会议审议通过，现印发给你们，请认真贯彻执行。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年12月21日陕西省第二次农业污染源普查实施方案\xa0'
               '根据《农业部办公厅关于做好第二次全国农业污染源普查有关工作的通知》（农办科〔2017〕42号)和《陕西省人民政府办公厅关于印发省第二次全国污染源普查实施方案的通知》（陕政办发〔2017〕100号）要求，为做好我省农业污染源普查工作，特制订本方案。一、普查工作目标按照“统一领导、分级负责、突出重点、准确真实、查清底数、服务质量”原则，摸清农业污染源基本信息，了解和掌握不同农业污染物的区域分布和产排情况，为农业环境污染防治提供决策依据。掌握种植业、畜禽养殖业生产过程中主要污染物流失量、产生量、排放量及其去向；查清地膜的使用量和残留量、秸秆的产生量和利用量。获取农业生产活动基础数据，建立农业污染源资料档案，完善农业污染源信息数据库和监测管理平台，为做好农业污染源监管提供强有力的技术支撑。明确农业污染源排放规律和主要影响因子，阐明农业污染物的动态变化趋势和分布特征，为控制农业面源污染，指导农业结构调整，优化农业产业布局，促进农业绿色发展提供科学依据。二、普查工作要求（一）普查时点普查标准时点2017年12月31日，时期资料为2017年度资料。（二）普查对象普查对象为种植业源、秸秆、地膜水果套袋和化肥农药包装等农业废弃物、畜禽养殖业源、农业机械移动源。（三）普查内容1．种植业源。普查粮食作物、经济作物和果蔬的主产区的种植情况、肥料和农药使用情况及氮磷流失情况。2．秸秆。普查全省范围内的小麦、玉米、水稻、马铃薯、甘薯、大豆、花生、油菜等作物的秸秆产生量、可收集量和利用量。3．地膜、水果套袋和化肥农药包装等农业废弃物。普查地膜、水果套袋和化肥农药包装等农业废弃物不同农业区域和不同作物的使用量、残留量、回收利用量及分布特征。4．畜禽养殖业源。普查规模和非规模养殖条件下，猪、奶牛、肉牛、蛋鸡和肉鸡养殖过程中畜禽粪便产生量和水污染物排放量。5．农业机械移动源。普查各类农用机械的保有量、产排污相关信息，挥发性有机物、氮氧化物、颗粒物排放情况。三、普查技术路线以农业、统计等相关部门已有统计数据为基础建立农业污染源名录库。基于农业污染源名录库确定抽样调查对象，开展抽样调查，获取普查年度农业生产活动基础数据。根据农业源污染物产生与排放规律，建立不同区域主要农业生产活动基量与污染物产生、排放量对应关系，充分利用第一次全国污染源普查和第三次全国农业普查成果以及已有行政记录和检测统计基础，制修订农业源污染物产、排污系数，根据产排污系数核算污染物产生量和排放量。对于规模化畜禽养殖企业和养殖户发表调查基本信息，对于分散农业污染源以数据共享和抽样发表调查的方式获取基本信息和普查内容。农业机械由相关部门提供，获取保有量、燃油消耗及相关活动水平数据，根据排污系数核算污染物排放量。四、普查质量控制质量控制工作内容包括普查参与机构质控、普查人员质控、普查数据质控、测算结果质控等工作环节，建立质量控制技术规定，开展参与机构考核和筛选、质控人员技术培训，在调查、布点、采样、样品运输、检测、数据录入等普查流程的每个节点配套质量控制技术措施，对产排污量等普查测算结果开展区域验证，对普查结果组织会商、统一发布口径。五、普查组织实施按照“全省统一领导，部门分工协作，地方分级负责，各方共同参与”的原则，充分利用有关部门现有统计、监测和各专项调查成果，借助购买第三方服务和信息化手段，提高普查效率。普查工作时间为2017年至2019年，分普查准备、全面调查、成果总结与发布三个阶段。（一）普查准备1．建立普查机制。成立省、市、县三级农业污染源普查领导小组及其办公室。组织编制普查实施方案，细化技术规定，确定污染物排放核算方法，制定普查工作相关制度；建立普查信息报送和公开、普查数据在线报送等机制；开发建设普查信息系统，做好有关普查技术准备工作。2．组建普查队伍。2017年12月上旬，各市、县组建由专职管理和业务技术骨干、普查指导员和普查员组成的普查队伍。普查员优先聘用基层人员，也可聘用满足普查工作相关规定的第三方机构。普查指导员和普查员均需通过培训持证上岗。省第二次全国污染源普查领导小组办公室（以下简称省普查办）组织对市、县两级普查技术骨干进行培训；各市普查办组织对本行政区域内普查工作人员进行培训。2018年5月前完成各级普查机构管理人员以及普查员和普查指导员的培训。3．开展普查试点。按照自愿申请的原则，各市、县向省农业厅普查办申请普查试点，经省农业厅普查办筛选并报省普查办批准后，开展试点工作。根据试点普查情况，完善普查制度、技术规范和信息系统等。2018年6月底前完成试点工作、清查建库、制定各类技术规范、出台普查员和普查指导员选聘管理办法、第三方参与普查办法、保密管理办法、档案管理办法等。（二）全面调查1．开展入户调查。按照纳入登记调查的畜禽养殖企业和养殖户的基本情况和粪污资源化利用情况，由普查员入户调查采集数据。2018年7月至10月完成入户调查。2．汇总审核数据。入户调查工作结束后，各市、县要及时对普查数据进行汇总审核，对调查资料等普查文件归档入库，建立本行政区普查信息数据库。3．质量核查与评估。普查期间，省、市、县三级农业普查办公室采取监督性监测、执法性监测、在线监测、排污系数核算和物料衡算等多种方式，对涉及各类农业普查数据进行认真核查与评估，对不符合质量要求的数据重新进行调查，直至符合标准。2018年12月底前完成省市县逐级审核、汇总上报国家。（三）成果总结与发布1．总结与验收。全面普查工作结束后，省、市、县三级农业源普查领导小组对本次普查工作进行总结，并逐级报送，内容包括普查组织、调查过程、普查成果、数据质量评估、经验和建议等。2019年6月底前国家完成各省数据审核汇总，建立全国污染源普查数据库和环境统计平台，8月底前分级质量核查和评估，10月底前验收。各级普查办按照国家统一安排部署，积极配合，有序、逐级开展普查工作验收。2．成果发布。普查工作验收结束后，省、市、县分级编制普查公报，经本级普查领导小组审核并报上级普查领导小组审定同意后发布。普查公报发布后，各级农业普查办及时归纳整理污染源普查工作相关资料，移交相关管理部门。3．成果应用。2019年12月底前国家完成普查成果开发应用。根据国家普查成果分析与应用指南，省、市、县根据工作需求，开发数据管理与应用软件，积极分析应用普查数据，为环境统计、排污许可、污染源监管等工作提供依据。六、保障措施（一）加强组织领导。农业污染源普查是农业资源环境保护的基础性工作。各市县农业行政主管部门是农业污染源普查工作的责任主体，对农业源普查工作负总责，及时成立农业污染源普查领导小组，强化职责意识，克服各种困难，明确责任分工，认真做好普查工作。省农业厅成立陕西省第二次农业污染源普查工作领导小组（见附件），主管厅领导任组长，相关处、局、站为成员单位，厅科教处做好农业污染源普查牵头、协调和组织工作，污染普查办公室设在省农业环境保护监测站，负责组织农业污染源普查及日常工作。（二）明确职责分工。农业污染源普查涉及范围广，普查任务重，技术要求高，工作难度大。领导小组下设质控组、种植业源专业组、果业源专业组、畜牧业源专业组、农业机械移动源专业组等5个小组（见附件），各组要按照普查任务，明确承担单位，认真履行职责分工，做好农业污染源普查技术保障工作。（三）争取普查经费。各市县农业部门要根据普查工作方案确定年度工作计划，按照《第二次全国污染源普查项目预算编制指南》（国污普〔2017〕3号）抓紧编制普查项目经费预算申报书，报同级普查办和财政部门审核，列入部门年度预算，保障普查工作顺利开展。（四）严格质量管理。各级农业部门要认真执行农业污染源普查质量管理有关制度，切实做好普查质量管理工作。普查数据要落实到单位和个人，做到可溯源，确保真实准确。对虚报、瞒报、拒报、迟报和伪造、篡改普查数据等行为要严肃追责；对泄漏普查对象有关技术和商业秘密的单位和个人，要按照有关法律法规予以查处。（五）加大宣传力度。各级要加强农业第二次全国污染源普查宣传工作，制订专门宣传方案，利用报纸、广播电视和网络等媒体广泛进行宣传，把宣传工作贯穿污染源普查工作的始终，为污染源普查顺利实施创造全民参与的良好氛围。\xa0'
               '附件：陕西省第二次农业污染源普查工作领导小组\xa0\xa0\xa0\xa0附件\xa0'
               '陕西省第二次农业污染源普查工作领导小组组长：主管厅领导。成员：厅发展计划与财务处、厅科技教育处、厅种植业管理处、省畜牧兽医局、省农业机械管理局、省果业管理局、省农业技术推广总站、省植物保护工作站、省农药管理检定所、省土壤肥料工作站、省园艺蚕桑工作站、省农业环境保护监测站、省畜牧技术推广总站、省动物卫生监督所、省动物疫病预防控制中心、省农业机械安全监理总站、陕西省农业机械鉴定推广总站、省现代农业园区管理指导中心等。农业污染源普查领导小组办公室，设在省环保站，负责组织农业污染源普查及日常工作。1．质控组：由省环保站负责组建并管理。负责有关方案的制定、组织培训、技术咨询、质量控制等工作。2．种植业源专业组：厅种植业处、省农业技术推广总站、省园艺蚕桑工作站、省土壤肥料工作站、省植物保护工作站、省农药管理检定所、省现代农业园区管理指导中心。负责提供种植业的普查信息与污染核算相关数据，配合做好普查成果的分析、应用等工作。3．果业源专业组：省果业管理局、省园艺蚕桑工作站、省现代农业园区管理指导中心。负责提供果业的普查信息与污染核算相关数据，配合做好普查成果的分析、应用等工作。4．畜牧业源专业组：省畜牧兽医局、省畜牧技术推广总站、省动物疫病预防控制中心、省动物卫生监督所、省现代农业园区管理指导中心。负责提供畜禽养殖业的普查信息与污染核算相关数据，配合做好普查成果的分析、应用等工作。5．农业机械移动源专业组：省农机管理局、省农业机械安全监理总站、省农业机械鉴定推广总站。负责提供农业机械与污染核算相关数据，配合做好普查成果的分析、应用等工作。\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于印发省第二次全国农业污染源普查 实施方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-12-28 16:09:21',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕149号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：受强秋淋天气影响，我省灌区小麦播期推迟、播种质量不高、苗情普遍偏弱，为切实做好冬春田间管理，促进苗情转化升级，现就有关事项通知如下：一、高度重视，强化认识9月下旬至10月中旬，我省出现连续阴雨天气，造成灌区小麦播期推迟10—15天，冬前生长积温不足。据田间调查，今年灌区小麦苗小、苗弱、群体不足，部分秸秆还田量大田块，有缺苗断垄现象；另外，小麦条锈病已在部分市县发生，且有加重和扩展趋势，对小麦正常生长发育构成威胁。各地要充分认识当前苗情状况的严峻性，进一步增强工作的紧迫性和责任感，克服麻痹大意思想和侥幸心理，周密部署，科学安排，组织发动群众，狠抓关键措施落实，强化小麦冬春田间管理。二、科学应对，抓住关键各地要组织广大农民群众，开展以冬灌为重点的田间管理，因苗、因地、因时制宜科学管理。一是适时开展冬灌。“夜冻日消，浇完正好”。近期正是开展冬灌的好时机，各地应因地因苗而宜，适时开展冬灌。冬灌尽量选择晴天上午采用小畦灌水，做到当天灌水，当天下渗，不留明水；气温低于0℃时应停止灌水，防止受冻；苗情较差地块可结合冬灌适当追肥。二是及时中耕耙耱。对灌后有裂缝的麦田，在墒情适宜时及时中耕耙耱，破除板结、弥合裂缝、增温保墒，防止冷风倒灌伤根；旱地小麦可进行冬前碾压，踏实表土，保苗越冬。三是抓好弱苗转化。对长势偏弱、冬前群体不足的田块，明春应尽早追施返青肥，促苗早发，提高成穗率。四是抓好病虫草害防控。严密监控小麦条锈病等重大病虫草害发生发展动态，对因播期推迟错过冬前化除的田块，在早春气温回升后及早开展化学除草。三、加强领导，搞好服务冬春小麦田间管理工作，对小麦安全越冬、促弱转壮至关重要，各级农业部门领导要分片包抓，夯实责任，帮助群众解决生产中的实际困难和问题；及时组织干部和技术人员，认真开展苗情、墒情、病虫情调查，制定有针对性的技术意见和措施；充分利用广播、电视、网络等媒体，采取多种形式，开展技术培训、宣传和指导服务工作，确保各项关键技术措施落实到位；加强与气象、水利部门沟通联系，通力协作，紧密配合，促进冬春管理工作扎实有效开展，为明年夏粮丰收打好基础。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年12月27日\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于切实做好冬春小麦田间管理工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2018-01-19 14:52:08',
 'art_detail': '\n'
               '         '
               '陕农业发〔2018〕8号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：按照《植物检疫条例》有关规定，根据我省农业植物有害生物发生分布情况，现将新修订的《陕西省农业植物检疫性有害生物补充名单》予以发布。2010年发布的《陕西省补充植物检疫性有害生物名单》（陕农业发〔2010〕95号文）同时废止。附件：陕西省农业植物检疫性有害生物补充名单\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2018年1月17日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于发布陕西省农业植物检疫性有害生物补充名单的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2018-01-17 16:44:16',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2018〕7号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：根据农业部办公厅《关于印发〈全国农产品加工统计调查制度〉的通知》（农办加〔2017〕31号）要求，为切实做好休闲农业统计调查工作的安排部署，进一步完善我省休闲农业统计调查及动态监测机制，准确掌握产业发展情况，现就有关事项通知如下。一、统计内容（一）各市（区）休闲农业基本情况。统计指标主要包括：经营主体个数、从业人数、带动农户数、接待人次、营业收入、利润总额、从业人员工资总额（详见附件1）。报表包括半年报和年报。（二）各市（区）休闲农业经营主体情况。统计指标主要包括：从业人数、带动农户数、接待人次、营业收入、利润总额、从业人员工资总额（详见附件2）。报表包括半年报和年报。二、任务分工省发展一村一品指导中心负责制定全省休闲农业统计调查和动态监测制度，协调工作进度，开展分析研究，起草统计调查报告等工作。各市（区）农业管理部门负责组织开展本市（区）休闲农业统计调查工作，收集、汇总有关数据，形成本市（区）休闲农业基本情况表、休闲农业经营主体统计年报基层表，并按时上报。三、相关要求（一）加强组织领导。各市（区）农业管理部门要充分增强责任感和紧迫感，切实加强组织领导，把休闲农业统计调查工作作为一项经常性、长期性任务列入年度工作计划，认真组织实施。（二）夯实工作任务。各市（区）农业管理部门要结合实际加强制度建设，细化任务分工，明确进度安排，按照时间节点保质保量地做好统计调查工作，确保情况准确、数据真实、填报规范。（三）按时报送材料。各市（区）休闲农业基本情况半年报、年报（附件1），请加盖市（区）局（委）公章后报送，同时报材料电子版；各市（区）休闲农业经营主体情况半年报、年报（附件2）报材料电子版。以上材料请分别于当年7月10日前、次年1月20日前报至省发展一村一品指导中心。联系人：魏亚娟\xa0 '
               '李永刚\xa0 电\xa0 话：029-87343160邮\xa0 '
               '箱：xxnyxh@163.com附件：1．休闲农业基本情况表2．休闲农业经营主体统计年报基层表3．主要指标解释\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2018年1月16日附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于进一步做好休闲农业统计调查工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2018-01-30 08:49:39',
 'art_detail': '\n'
               '         驻陕农纪发〔2018〕2号\xa0'
               '省农业厅、省扶贫开发办公室、省供销合作总社机关纪委，驻厅纪检组各室：现将《驻省农业厅纪检组2018年工作要点》印发给你们，请结合实际，抓好贯彻落实。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '中共陕西省纪委驻省农业厅纪律检查组\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0'
               '2018年1月23日\xa0驻省农业厅纪检组2018年工作要点\xa0'
               '2018年驻省农业厅纪检组工作的总体思路是：深入学习习近平新时代中国特色社会主义思想，全面贯彻落实党的十九大、十九届二中全会精神，认真学习贯彻中央纪委二次全会、省纪委十三届二次全会精神，坚持党要管党、全面从严治党，加强党章执行和党的十九大精神贯彻落实情况的监督检查，压紧压实“两个责任”，持之以恒正风肃纪，深入推进反腐败斗争，营造风清气正的良好政治生态，强化自我监督、自觉接受监督，建设忠诚干净担当的纪检干部队伍，为决胜脱贫攻坚和全面建成小康社会提供坚强保证。一、学习贯彻党的十九大和中、省纪委二次全会精神1.在学懂弄通做实上下功夫。要认真研读党的十九大报告和党章，学习领会习近平总书记在党的十九届一中全会上的重要讲话精神，坚持读原著、学原文、悟原理，切实在学懂弄通做实上下功夫。要认真学习贯彻落实中、省纪委二次全会精神，督促协助综合监督单位（简称各单位）党组及时研究部署落实全面从严治党工作，修订党组及班子成员党风廉政建设主体责任清单，完善落实履职纪实制度。采取请进来和走出去相结合搞好十九大精神培训，围绕“学习贯彻党的十九大精神推进全面从严治党”这个主题，邀请专家举办一期各单位副处级及以上干部参加的专题辅导，组织各单位支部书记和纪检干部或纪委委员到教育基地进行现场培训。二、督促各单位党组落实好全面从严治党的政治责任2.把党的政治建设摆在首位。要严明党的政治纪律和政治规矩，严肃党内政治生活，坚决维护党中央权威，切实履行派驻纪检组党内监督专责机关职责，加强对党内政治生活状况、党的路线方针政策和民主集中制、请示报告制度等执行情况的监督检查。要协助各单位党组加强政治生态建设，聚焦政治立场、政治原则、政治担当和政治纪律，坚决纠正和查处上有政策、下有对策，有令不行、有禁不止等行为，特别对“七个有之”问题高度警觉，汲取魏民洲等案件的深刻教训，严肃查处搞政治攀附、政治投机和破坏党内政治生态的问题。3.认真落实十项工作协调机制。要认真组织落实《关于建立省纪委驻省农业厅纪检组与省农业厅、省扶贫开发办公室、省供销合作总社等单位工作联系协调机制的实施意见（试行）》，重点是要重视落实还不够到位的参加或列席各单位会议机制、各单位重大事项事前报备机制、监督配合各单位专项工作机制和各单位处级干部选拔任用等工作征求驻厅纪检组意见机制等四项机制的贯彻落实，加大督查通报力度，突出解决各单位“三重一大”事项事前不沟通、事后不报告的问题。同时，督促各单位党组研究制定“三重一大”事项具体清单，并与驻厅纪检组联合印发实施、提出明确要求。4.加强对干部选拔任用的监督。要把干部选拔任用作为派驻监督的重点，认真落实《驻省农业厅纪检组关于在综合监督单位选人用人工作中强化监督执纪问责的意见》，逐步建立和完善各单位副处级及以上党员领导干部廉政档案制度，认真落实领导干部任前廉政法规考试制度和领导干部任职廉政谈话制度，研究出台各单位选拔任用干部征求驻厅纪检组意见的具体办法，认真回复党风廉政意见，从不同层面织牢干部选拔任用的监督网，坚决防止“带病上岗”。5.切实用好“问责”这个利器。要敢于担当、敢于亮剑、敢于问责，对党的领导弱化、党的建设缺失、从严治党责任落实不到位，对维护党的政治纪律和政治规矩失责、贯彻中央八项规定精神不力、选人用人问题突出、腐败问题严重、不作为乱作为等突出问题进行严肃问责，并指名道姓通报曝光典型问题，充分发挥“动员千遍、不如问责一次”的警示作用。同时，要加强对《问责条例》执行情况的监督检查，对该问责而不问责的，也要严肃问责。6.指导各单位做好纪律审查工作。严格执行省纪委问题线索处置管理、谈话函询、执纪审查办法和驻厅纪检组纪律审查、执纪审查工作安全管理办法，加大对各单位机关纪委及直属单位纪委书记做好纪律审查工作的培训指导，切实规范纪律审查工作程序，抽调各单位纪检干部参与驻厅纪检组纪律审查工作，采取“以案实训”的办法，提高纪检干部纪律审查工作能力。三、巩固拓展落实中央八项规定精神成果7.持之以恒纠正“四风”问题。一是把监督检查中央八项规定实施细则精神、省委实施办法执行情况作为重点任务和经常性工作，坚持抓具体、抓经常，化风成俗。二是要紧盯元旦春节、清明五一、中秋国庆等重大节假日，加强明查暗访，发现问题及时通报曝光，形成震慑；要对违规发放津补贴、公车私用或私车公养、大办婚丧喜庆等突出问题紧盯不放，从严执纪问责。三是坚决反对形式主义和官僚主义，对表态多调门高、行动少落实差的严肃问责。要坚决反对特权思想和特权现象，教育引导党员领导干部增强群众感情，严格约束自己，严格家教家风。四是领导干部和纪检干部要带头转变作风，坚持身体力行、以上率下，形成“头雁效应”。四、巩固发展反腐败斗争压倒性态势8.坚持反腐败斗争“零容忍”。要坚持反腐败无禁区、全覆盖、零容忍，坚持重遏制、强高压、长震慑，坚持受贿行贿一起查，聚焦党的十八大以来不收敛、不收手的领导干部，重点查处政治问题和经济问题相互交织形成利益集团的腐败案件，着力解决脱贫攻坚、选人用人、审批监管等重点领域和关键环节的腐败问题。要通过严格执纪审查中发现新的问题线索，通过公开举报电话和信箱、与干部职工座谈、认真分析各类审计报告、开展各类督查活动等渠道，着眼发现违纪问题线索。加强对信访举报线索的整理分析，提出预防和监督执纪工作的意见建议，为领导决策和纪律审查服务。9.深化运用监督执纪“四种形态”。要对违纪问题线索做到精准发现、科学分类、精准处置，充分运用好第一种形态，抓常、抓细、抓长，让红红脸、出出汗成为常态；要坚持把纪律挺在前面，严格执纪问责，让纪律成为不可触碰的底线，对严重违纪涉嫌违法的问题线索进行立案审查，对顶风违纪、性质恶劣、影响极坏的问题线索从严处理。同时，要督促各单位有针对性地建章立制，把制度的篱笆扎得更紧。10.深入开展扶贫领域监督执纪问责。要按照中、省纪委关于开展扶贫领域腐败和作风问题专项治理的安排部署，深入推进扶贫领域监督执纪问责工作，适时召开各单位和各市农业、扶贫、供销部门座谈会，进一步推进扶贫领域腐败和作风问题专项治理。要严肃查处骗取套取、截留挪用、贪污侵占、挥霍浪费、化公为私、优亲厚友，以及侵害贫困群众利益等违纪违法问题，也要严肃查处扶贫工作中作风不实、敷衍塞责，不作为、慢作为、假作为，搞形式主义、弄虚作假甚至失职渎职等突出问题。要公开举报电话和信箱，特别是各级扶贫部门要接听好12317扶贫监督举报电话，广泛接受社会监督，配合审计部门搞好扶贫审计，多渠道发现问题线索。要对发现的问题线索既要认真查处，更要深入剖析、重点研判，找准存在问题的深层次原因，为各单位开展脱贫攻坚工作提出纪检建议。11.督促做好巡视问题整改工作。要对省委巡视组反馈各单位的有关问题，督促各单位认真落实整改，对涉及违规违纪问题的，驻厅纪检组主动出击、严肃问责。要对巡视组移交的问题线索按要求进行分类处置，对反映集中或者倾向性问题，要认真研判、深入分析、掌握动态，及时向各单位党组提出纪检建议。五、多形式经常性深入开展纪律教育12.积极开展各类警示教育活动。一是要以省纪委印发的《贪腐的代价——党的十八大以来严重违纪违法典型案例警示录》为重点素材，在各单位积极开展警示教育；二是要及时向各单位转发中央纪委和省纪委等上级部门有关违反中央八项规定精神问题、扶贫领域腐败和作风问题等方面的典型案例通报；三是要协助各单位组织处以上干部到有关廉政教育基地进行现场警示教育，充分发挥反面典型的警示教育作用；四是要继续办好《廉政教育与工作动态》简报和各单位门户网站《纪检监察》专栏；五是要在各单位组织实施重大事项和重要活动中积极推行廉洁承诺制度，切实将监督关口前移，从源头上有效防范廉政风险。六、严格落实打铁必须自身硬的要求13.建设忠诚干净担当的纪检队伍。纪检干部要牢固树立“四个意识”，带头严守政治纪律和政治规矩，以上率下、作好表率，勇于担当、敢于碰硬，以“越是艰险越向前”的气概和“而今迈步从头越”的勇气，认真履行好党和人民赋予的光荣使命，确保党和人民赋予的权力不被滥用、惩恶扬善的利剑永不蒙尘。要指导各单位重视纪检机构和队伍建设，配齐配强纪检干部，厘清工作职责，强化监督执纪，形成监督合力。要加强对纪检干部业务技能和法律知识的培训教育，切实提高监督执纪能力。要主动做好监察体制改革的相关工作，按监察体制改革的最新要求，认真履行好派驻监察职能。\xa0\n'
               '        ',
 'art_source': ' 中共陕西省纪委驻省农业厅纪律检查组',
 'art_title': '关于印发《驻省农业厅纪检组 2018年工作要点》的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-12-27 16:43:52',
 'art_detail': '\n'
               '         陕农业办发〔2017〕145号\xa0\xa0\xa0'
               '各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：为进一步加强新型职业农民实训基地建设，提升新型职业农民培育效能，根据《陕西省农业厅办公室关于开展省级新型职业农民实训基地申报工作的通知》（陕农业办发〔2017〕119号）要求，经单位申请、县市推荐、专家评审，现决定认定西安市临潼区秦陵石榴专业合作社等50个单位为省级新型职业农民实训基地。希望被认定的基地发挥作用，积极配合培训机构扎实开展新型职业农民实训工作，不断提高参训学员的生产经营能力。各级农业行政部门和职业农民培育工作领导小组办公室要按照省农业厅要求，做好市、县级实训基地的认定、备案、指导、管理和服务工作，确保我省新型职业农民实训工作取得实效。\xa0'
               '附件：2017年省级新型职业农民实训基地认定名单\xa0\xa0'
               '附件.docx\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年12月21日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于2017年省级新型职业农民 实训基地认定结果的通报'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-10-30 17:28:07',
 'art_detail': '\n'
               '         陕农业办发〔2017〕119号\xa0'
               '各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：为进一步加强职业农民实训基地建设，扎实开展新型职业农民培训，培养爱农业、懂技术、善经营的新型职业农民，省农业厅决定认定50个省级新型职业农民实训基地，并组织各市、县(区)认定200个市县级新型职业农民实训基地。现就做好省级实训基地申报工作有关事项通知如下：一、申报范围能够承担新型职业农民实训工作的省市级现代农业园区、农民合作社、农业科技示范园、农业科技示范基地、农业龙头企业等均可申报。2014、2015、2016年度已被认定为省级新型职业农民实训基地的单位不再申报。二、申报条件（一）生产技术先进，技术力量强，符合新型职业农民培养目标，满足新型职业农民实践教学要求。（二）具有满足100人以上实训需要的场地、场所和食宿条件。其中种植类可实训场地面积不少于100亩，养殖类可实训场地面积不少于30亩，实训教室面积不少于100平方米。（三）具有满足实训需要的设施设备，并能代表相关产业的先进性和方向性。其中种植类设备总值不低于100万元，养殖类设备总值不低于30万元。（四）具有一支素质优良、技术先进、实践经验丰富的实训指导教师队伍。（五）制度健全、管理规范，有相应的工作计划和产业发展计划。（六）开展新型职业农民实训工作积极性高，思想认识到位。三、申报程序（一）各项目承担县区职业农民培育办公室组织申报单位如实填写《省级新型职业农民实训基地申报表》（附件1），经县级农业行政主管部门审核后报市区职业农民培育办公室审核。（二）市区职业农民培育办公室对县区报送的实训基地申报材料进行审核和实地核查后，填写《省级新型职业农民实训基地申报单位情况汇总表》（附件2）、《省级新型职业农民实训基地申报情况统计表》（附件3），报送至省职业农民培育办公室。（三）省职业农民培育办公室组织专家对各市区上报的申报单位进行评审，确定拟认定单位名单，并在陕西农业网上公示。（四）省农业厅发文公布省级新型职业农民实训基地认定名单。（五）市县级新型职业农民实训基地由各市县区按照有关规定组织认定，并及时报省职业农民培育办公室备案。四、有关要求（一）开展新型职业农民实训基地申报工作，认定一批实训基地，实行挂牌管理，是做好我省新型职业农民教育培训工作的前提和基础。各级农业行政主管部门要高度重视，及时安排，认真组织，确保申报工作有序进行。（二）西安、宝鸡、咸阳、渭南、商洛、安康、汉中、延安、榆林每市组织申报5-6个，铜川、杨凌、韩城各组织申报2-3个。（三）申报单位要如实填写《省级新型职业农民实训基地申报表》，严禁弄虚作假；各县、市区职业农民培育办公室要对申报单位情况进行认真地审查核实，确保申报信息的真实性、准确性和完整性。（四）各市区培育办务必于2017年11月15日前将申报材料的纸质及电子版报送至省职业农民培育办公室。（五）市县级实训基地主要用于开展初、中级职业农民实训工作，请各市县区务必于12月10日前完成认定并将认定名单及认定情况统计表报省职业农民培育办公室备案。\xa0'
               '联系人：杨新农\xa0\xa0\xa0 029-87315477电子邮箱：shanxijiaowu@163.com\xa0'
               '附件：1. 省级新型职业农民实训基地申报表\xa0 \xa0 2. '
               '省级新型职业农民实训基地申报单位情况汇总表\xa0 \xa0 3.省级新型职业农民实训基地申报情况统计表\xa0 \xa0'
               '附件.docx\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年10月26日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于开展省级新型职业农民实训基地申报工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2017-10-31 11:15:27',
 'art_detail': '\n'
               '         '
               '陕产业脱贫办发〔2017〕33号各设区市产业脱贫办公室，各有关县（区）政府、产业脱贫办公室，省产业脱贫办公室各组成部门：按照省委《关于贯彻落实习近平总书记有关重要批示精神的通知》要求，近期对全省扶贫领域审计、追赶超越审计及第三季度督导中发现的有关产业扶贫存在的问题，开展集中整改。现就有关事宜通知如下。一、明确整改工作总体思路以习近平总书记扶贫开发战略思想为指导，深刻学习领会习近平总书记重要批示精神，按照举一反三、标本兼治的原则，全面梳理查找产业扶贫工作中资金项目、工作作风、帮扶成效等方面存在的突出问题和薄弱环节，对照问题清单，制定落实整改措施，开展专项治理行动，强化工作督导考评，建立完善指导管理制度，构建长效机制，切实落实责任，传导压力，改进作风，堵塞漏洞，确保产业扶贫资金安全、使用高效，产业扶贫项目精准、帮扶到位，使产业扶贫政策和资金项目及时完全高效惠及贫困群众，确保如期实现产业脱贫目标。二、明晰产业扶贫存在的突出问题经对照检查，我省产业扶贫工作中主要存在以下问题和薄弱环节。（一）资金项目方面。部分地方涉农资金整合力度不够，用于产业扶贫比例较低；扶贫资金管理制度不健全，项目主体和安排程序等不明确；项目储备不够，资金使用效率低，存在滞留闲置现象；个别地方在资金尚未生效情况下提前收取年化收益；个别地方通过虚假出资占有企业股份等。（二）产业培育方面。一些地方急功近利，把更多精力投入短平快产业，在长效产业、品牌打造、市场开拓、产品营销上下功夫不够。一些地方方法简单，以简单的直补政策应付过关，没有按照“四化同步”要求设计项目、按照总体规划布局项目、按照市场和贫困户需求配置项目。（三）主体带动方面。参与产业扶贫的各类主体中，部分自身能力不足，不具备带动贫困户发展的能力；部分与贫困户之间虽有带动意向或协议，但没有建立紧密的利益联结机制，缺乏实质性带动；部分享受项目的主体没有真正落实带动贫困户的任务和责任。（四）工作作风方面。一些地方思想认识存在偏差、对标看齐意识不强、协作共事意识偏弱、敢于担当勇气欠缺，工作热情、主动作为不足。特别是部分地方技术帮扶不实，服务内容针对性不强、师资的实践经验不足、服务方式不接地气，服务效果不理想。（五）工作机制方面。部分基层产业脱贫办公室统筹协调机制不顺，缺乏手段，牵不起头、统不了事，部门之间合力不够，各自为阵，统筹协调能力弱。农村集体产权制度改革配套规章制度和政策体系不完善，政策辅导、宣讲、解读体系不健全，学习交流工作不深入。三、聚焦问题落实整改任务认真学习领会中省有关精神和要求，对照问题清单，逐项制定整改措施，分类明确整改时限，分地区分部门落实整改任务，着力开展自查自纠、专项整治活动，健全资金监管和督查考评惩处制度，构建问题整改和防范的长效机制。（一）深化认识提高站位。全省产业扶贫系统认真学习领会习近平总书记批示精神和省委省政府领导批示要求，深化对扶贫领域资金监管、作风建设的特殊性、迫切性、重要性的认识，切实提高政治站位，增强思想行动自觉，高度重视问题整改工作。10月25日前省农业厅召开专题会议，传达学习习近平总书记重要批示精神，研究提出具体落实意见；10月25日—27日，省产业脱贫办公室整理习近平同志关于脱贫攻坚系列重要讲话精神、王岐山同志在中央纪委扶贫领域监督执纪问责电视电话会议重要讲话精神，以及财政专项资金和涉农整合资金使用管理规定等，在全省产业脱贫体系开展网上集中学习活动。（二）开展作风自查自纠。10月25日—30日，在全省产业脱贫系统开展工作作风自查自纠行动。各市县农业部门（产业脱贫办）组织召开一次作风查摆专题会，开展一次自我剖析、一次问卷调查，走访一批下级部门和贫困户，查找工作作风问题。坚决纠正对脱贫攻坚认识不深刻不重视，贯彻中央决策部署不坚决不到位，扶贫工作不务实不扎实，发现问题不整改、搞形式主义、做表面文章等工作作风问题。各地进一步完善技术服务110平台，改进一线帮扶人员工作作风和方法，做实技术帮扶，提高服务质量和水平，提升贫困群众满意度。省上将自查自纠结果作为督导重要内容之一，对问题认识不深刻、剖析不透彻、纠正不到位的要重新自查，省上进行重点督查。（三）开展问题专项整治。一是快速核查审计发现的问题。对第三季度审计发现资金闲置、违规享受扶贫政策、项目推进慢等涉及产业扶贫的问题，有关市县要组织力量逐一核查，10月26日报送核查和整改结果；省农业厅组织核查后，10月27日前将结果报省脱贫攻坚指挥部办公室。二是集中开展专项整治活动。10月下旬至11月中旬，在全省产业扶贫系统开展专项整治活动。各市县要以此次整改为契机，以中省要求为标尺，全面查摆产业扶贫中存在突出问题，列出问题清单，制定整改方案，逐件提出整改措施，明确整改时限，落实责任单位和人员，做到对症下药，靶向治疗。坚持立行立改，对苗头性、倾向性问题早发现、早处理；对群众反映集中，尤其是资金、作风方面的问题重点督办、限期办结；对发现的腐败问题线索及时反映相关部门。省上结合第四季度产业扶贫督导考核，对整改落实情况集中督查，对项目落实情况进行回头看，对项目成效进行评估，逐条逐项对照检查各地问题查摆及整改落实情况，对整改不力、敷衍塞责、走过场的，予以通报批评，并在绩效考核中从严扣分。（四）健全和落实规章制度。坚持标本兼治，在强化问题整改的同时，健全和细化相关规章制度，规范相关程序和行为。省农业厅会同省财政厅修订农业产业脱贫引导资金实施指导意见，进一步细化规范相关管理程序和要求。各市县要规范项目库管理制度，做实做优滚动式产业扶贫项目库，做好项目前期准备工作，使产业项目与资金及时精准衔接，确保项目及时落地。严格执行《财政专项扶贫资金和涉农整合资金使用管理工作导引》、《陕西省财政专项扶贫资金管理办法》相关规定。对产业脱贫引导资金，各县农业部门要在收到资金到账通知5个工作日内拿出具体项目计划，报送财政等部门审核，督促协调财政部门及时拨付资金。对于各有关县区闲置滞留的产业脱贫引导资金，督促县区政府和农业部门提出项目计划，11月底前，各县产业脱贫引导资金必须全部落实到项目；年底前，资金执行进度要达到90%以上。（五）完善督导协调机制。各市县要建立健全产业扶贫协调机制，赋予产业脱贫办公室相应的职能和手段，夯实各组成部门工作责任，形成既分工负责、又相互配合，合力攻坚产业脱贫的工作格局。省产业脱贫办公室建立联合督导制度，每季度对基层组织一轮督导，对需要整改的问题进行反馈、对重大问题挂牌督办。强化工作激励，择优选择一批产业扶贫一线的先进典型，组建先进事迹报告团，巡回演讲，交流经验，激发斗志，弘扬正能量，营造全省重视产业扶贫、推进产业扶贫的氛围。（六）深入推进百日行动任务落实。按照9月12日全省产业扶贫精准脱贫现场会安排部署，全面督促落实“百日行动”六项重点任务，加快项目建设、品牌营销、“三变”试点等工作进度，促进苏陕合作、国企合力团、民企千企帮千村等项目落地。年底前制定下发《关于推进“三变”改革发展集体经济助力脱贫攻坚的工作方案》，并启动“三变”改革“百村示范、千村试点、万村推进”工程，确保年度目标任务顺利完成。各市12月20日前将“百日行动”任务完成情况报送省产业脱贫办公室。\xa0'
               '联 系 人：王 玮\xa0 029-87346631电子邮箱：345814059@qq.com\xa0'
               '陕西省脱贫攻坚领导小组产业脱贫办公室2017年10月24日\xa0'
               '附件：1、产业扶贫抓整改建机制活动学习材料之一：习近平总书记关于脱贫攻坚的重要论述产业扶贫抓整改建机制活动学习材料之一：习近平总书记关于脱贫攻坚的重要论述.docx\xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2、产业扶贫抓整改建机制活动学习材料之二：王岐山同志在中央纪委扶贫领域监督执纪问责电视电话会议上的讲话精神产业扶贫抓整改建机制活动学习材料之二：王岐山同志在中央纪委扶贫领域监督执纪问责电视电话会议上的讲话精神.docx\xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '3、产业扶贫抓整改建机制活动学习材料之三：财政专项扶贫资金和涉农整合资金使用管理工作导引产业扶贫抓整改建机制活动学习材料之三：财政专项扶贫资金和涉农整合资金使用管理工作导引.docx\xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '4、产业扶贫抓整改建机制活动学习材料之四：陕西省财政专项扶贫资金管理办法产业扶贫抓整改建机制活动学习材料之四：陕西省财政专项扶贫资金管理办法.docx\xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '5、产业扶贫抓整改建机制活动学习材料之五：财政部农业部国务院扶贫办关于做好财政支农资金支持资产收益扶贫工作的通知产业扶贫抓整改建机制活动学习材料之五：财政部农业部国务院扶贫办关于做好财政支农资金支持资产收益扶贫工作的通知.docx\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省脱贫攻坚领导小组产业脱贫办公室关于切实做好产业扶贫存在问题整改工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-12-12 14:24:09',
 'art_detail': '\n'
               '         陕农业发〔2017〕94号\xa0\xa0'
               '各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：经2017年第9次省农业厅行政会议研究同意，《陕西省农药经营许可审查细则（试行）》自2017年12月1日起施行，现印发给你们，请遵照执行。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年11月6日\xa0陕西省农药经营许可审查细则\xa0（试行）\xa0'
               '第一章总则第一条为规范农药经营许可审查行为，根据《农药管理条例》和《农药经营许可管理办法》有关规定，特制定本细则。第二条本细则所称农药经营许可审查，是指对农药经营者机构与人员、场所与设施、制度与记录等方面进行的书面审查和实地核查。第三条农药经营许可审查应坚持依法、公平、公正的原则，合理作出审查意见。第四条农药经营许可审查，根据申请人所提交的材料和场地设施进行逐项审查，逐项作出审查结论。第五条本细则适用于陕西省行政区域内农药经营许可审查。\xa0'
               '第二章机构与人员第六条农药经营者应当具有营业执照或统一的社会信用代码，有明确的法定代表人（负责人），有与经营规模相适应的农药经营人员。第七条设立分支机构的，应当注明分支机构的营业场所和仓储场所地址等事项，分支机构应具备农药经营场所的基本设施和条件，免予办理农药经营许可证。农药经营者应当对其分支机构的经营活动负责，分支机构只能有一个母体单位。限制使用农药经营者的分支机构不得经营限制使用的农药品种，需要经营限制使用农药的应当符合《陕西省限制使用农药定点经营布局规划》和有关规定。第八条农药经营人员应当具备下列条件之一：（一）具有农学、植保、农药等相关专业中专以上学历的，不少于8学时的农药法律法规培训；（二）具有农业部颁发的农资营销员职业资格证书的，不少于8学时的农药法律法规培训；（三）其他人员不少于56学时的系统培训学习。第九条经营限制使用农药的经营人员除具备上述第八条外，并应有两年以上从事农学、植保、农药相关工作的经历。\xa0'
               '第三章场所与设施第十条农药经营者应当具有固定的经营场所和仓储场所，布局合理，与其他商品以及饮用水水源、生活区域等有效隔离，并配备相应的消防、防盗等设施。兼营其他农业投入品的，应具有相对独立的农药经营区域和仓储区域。第十一条农药经营者的营业场所和仓储场所应当与经营规模相适应，并符合以下规定：（一）营业场所面积不少于30平方米、仓储场所面积不少于50平方米；营业与仓储在同一个场所的农药经营者，柜台与仓储应进行有效隔离，其总面积不少于80平方米。（二）只从事批发业务的农药经营者，可不设置零售柜台、货架等，但其办公场所面积应不少于30平方米，仓储场所面积应不少于100平方米。第十二条\u3000'
               '农药经营者的经营地点应与申请书一致，可以在经营许可证发放机关的辖区范围内设立分支机构，统一配置仓储和相关设施、设备，分支机构营业场所面积不少于30平方米。第十三条农药经营者应当具有与所经营农药相适应的柜台、专柜，设施、设备，并应满足不同农药品种分区、分类保管、储存的要求。（一）有可追溯电子信息码扫描识别设备和用于记载农药购进、储存、销售等电子台账的计算机管理系统；\u3000\u3000'
               '（二）有与经营农药相适应的柜台、专柜；\u3000\u3000（三）有通风、消防、防盗的设施；\u3000\u3000'
               '（四）有防潮、防霉的设施、设备。第十四条\u3000'
               '农药经营者的营业场所和仓储场所应当干净整洁，货品摆放整齐并设立醒目标志。第十五条经营限制使用农药的经营者，应符合《陕西省限制使用农药定点经营布局规划》和有关规定，有标识明显的销售专柜、仓储场所及其配套的安全保障设施、设备。第十六条农药陈列、储存应当符合下列要求：（一）按照杀虫剂、杀菌剂、除草剂等进行分类摆放，常规农药应与限制使用类农药分区存放（经营卫生用农药的，应当将卫生用农药与其他农药分开）；（二）按照农药外包装图示标志的要求搬运和存放；（三）与仓储场所地面、墙、散热器或供暖管道等之间保持一定间距；（四）陈列存放场所内不得存放食品、食用农产品、饲料等。\xa0'
               '第四章制度与记录第十七条\u3000'
               '农药经营者应当建立以下管理制度：（一）进货查验和进销货台账制度；（二）安全管理和安全防护制度；（三）应急防护和应急处置制度；（四）经营场所和仓储管理制度；（五）农药废弃物回收与处置制度；（六）农药使用指导制度；\u3000\u3000'
               '（七）产品召回制度；（八）人员岗位与培训学习制度；（九）环境卫生管理制度。第十八条农药经营者要按统一要求填写购销台账，设计合理的表式。同时对其他各项制度的落实进行详细记录。记录要及时、真实、准确、完整，具有可追溯性，并保存两年以上。第十九条农药经营者应当采购合法农药产品，购进农药应当按照以下程序进行：（一）对进行业务联系的供货人员进行身份确认，查验供货单位介绍信（介绍信中应有产品品种名称、规格数量、供货日期等）和供货人员身份证。（二）确定供货单位的资质，查验营业执照（或统一社会信用代码）、农药生产许可证（供货单位为生产企业的）或农药经营许可证（供货单位为经营企业的）。（三）对货物的外观、数量、有效期等进行查验，查验无误后方可进货，同时索要进货凭证，做到有效凭证、账、货、记录相符。（四）审核所购入农药的证件和标签，农药证件包括农药生产许可证、农药登记证号、农药标准号和产品合格证，同时农药标签（或说明书）应完整无残缺，与网上备案标签一致。（五）做好入库记录。第二十条禁止向未取得农药生产许可证的农药生产企业和未取得农药经营许可证的农药经营者采购农药。第二十一条农药经营者应当及时清查农业部门公布的假劣农药，并做好记录。第二十二条\u3000'
               '农药经营者销售农药时应当向购买人询问病虫害发生情况并科学推荐农药，必要时应当实地查看病虫害发生情况，并正确说明农药的使用范围、使用方法、剂量、使用技术要求和注意事项，不得误导购买人。第二十三条农药经营者销售限制使用农药时，应当遵守限制使用农药的管理规定，应取得限制使用农药定点经营许可、设立醒目标志，采取实名制购买、弄清去向、标明实际用途等，同时为农药使用者提供用药指导，鼓励开展统一用药服务。第二十四条农药经营者销售农药时，应当开具有效凭证，做到有效凭证、账、货、记录相符。第二十五条限制使用农药不得利用互联网经营，利用互联网经营其他农药的，应当取得农药经营许可证。第二十六条农药经营者应按照农药标签或说明书进行宣传，不得误导购买者。第二十七条农药经营者应当向购买者提供技术咨询服务，在经营场所明示服务公约和质量承诺，公布当地农药监督管理部门监督电话，设置意见簿，指导购买者科学、安全、合理使用农药。\xa0'
               '第五章\u3000审查结论第二十八条\u3000'
               '实地核查的审查结论包括单项审查结论和综合审查结论。实地核查的审查人员应当对照《农药经营许可审查表》（附件1）的每个项目，逐项作出单项审查结论。单项审查结论分为“合格”“轻微缺陷”“不合格”“不适用”。其中，“合格”是指符合相应的规定，“轻微缺陷”是指存在偶然的、孤立的，且是性质一般的问题；“不合格”是指存在区域性的或系统性的问题。对审查结论为不合格或轻微缺陷的，应当逐项说明理由。综合审查结论分为“合格”“基本合格”“不合格”。（一）所有审查项目为“合格”的，综合审查结论为“合格”。（二）同时符合以下情形的，综合审查结论为“基本合格”：１．单项审查结论未出现“不合格”；２．关键项目的审查结论为“轻微缺陷”的总数不超过3项（含3个项），非关键项审查结论为“轻微缺陷”的总数不超过５项（含5项）。（三）有以下情形之一的，综合审查结论为“不合格”：１．单项审查结论出现“不合格”的；２．关键项审查结论出现“轻微缺陷”3项以上；３．非关键项审查结论出现“轻微缺陷”５项以上。第二十九条\u3000'
               '书面审查与实地核查结果不一致的，以实地核查结果为准。申请人对实地核查工作有不同意见的，应当在实地核查工作结束后５日内向上一级主管部门书面反映。对综合审查结论为“基本合格”和“不合格”的，如申请人无正当理由的，应当维持审查意见；有正当理由的，由上一级主管部门裁决。第六章 '
               '附则第三十条本办法未涉及事项，经农药经营者申请，由省农业厅主管处室组织专家论证后，按此细则确定的原则和专家结论办理。第三十一条本细则自2017年12月1日起施行。\xa0'
               '附件：农药经营许可审查表附件.docx\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅印发《陕西省农药经营许可审查细则 （试行）》的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2017-12-18 16:53:14',
 'art_detail': '\n'
               '         驻陕农纪发〔2017〕21号\xa0'
               '省农业厅、省扶贫开发办公室、省供销合作总社机关党委（纪委）：为了深入贯彻落实党的十九大精神，切实把全面从严治党要求落到实处，建设忠诚干净担当的纪检干部队伍，为全省追赶超越提供坚强的纪律保障，近期省纪委制定印发了《关于加强陕西省纪委机关纪律作风建设的规定》，驻厅纪检组据此制定了《纪检干部作风建设守则》，现转发和印发给你们。请你们印发各基层党组织，并组织全体纪检干部认真学习、严格遵守，自觉接受各级党组织和广大干部职工监督。\xa0'
               '附件：1.省纪委关于加强陕西省纪委机关纪律作风建设的规定；2.驻省农业厅纪检组纪检干部作风建设守则。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '中共陕西省纪委\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '驻省农业厅纪律检查组\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年12月18日\xa0附件1：\xa0'
               '省纪委关于加强陕西省纪委机关纪律作风建设的规定为全面贯彻落实党的十九大全面从严治党、深入推进党风廉政建设和反腐败斗争的战略部署，强化全省追赶超越纪律保障把省纪委机关建设成为忠诚干净担当的坚强战斗集体，依据有关纪律要求，现就大家纪律作风建设做出如下规定：1.严明政治纪律。牢固树立“四个意识”，坚定“四个自信”，坚决维护以习近平同志为核心的党中央权威和集中统一领导，始终在政治立场、政治方向、政治原则、政治道路上同党中央保持高度一致。严守政治纪律和政治规矩，严禁妄议中央大政方针、传播政治谣言，对省委、省纪委决策决定评头论足、说三道四；严禁有令不行、有禁不止，严禁拉帮结派、搞“小圈子”，严禁搞两面派、做两面人。2.加强理论修养。深入学习习近平新时代中国特色社会主义思想，原原本本学、融会贯通学，学思践悟、学以致用，把自己和职责摆进去，真正学懂弄通做实。反对学习浅尝辄耻、一知半解，反对学习主动性不强、针对性不够。3.改进调查研究。坚持领导带头，深入基层一线，聚焦重点难点，改进方式方法，注重调研质量，搞好成果转化。反对调研工作搞形式走过场、浮于表面，力戒调研报告东拼西凑、分析问题轻描淡写、对策建议空洞无物。4.强化作为担当。树立敢于担当的精神和勇气，培养善于担当的能力和智慧，把握节凑稳中求进，随时准备经受急难险重任务考验。绝不允许在重大原则问题上不敢亮剑、正气不彰，绝不允许在困难风险面前虚与委蛇、逃避推脱。绝不允许对安排的任务囿于部门利益打折扣、搞变通。5.改进工作作风。勇于开拓创新，反对不思进取、安于平庸。崇尚实干实绩，绝不允许在岗位上混日子、熬时间。对工作认真负责、精益求精，绝不允许浮皮潦草、得过且过。坚决服从工作安排，绝不允许挑肥捡瘦、拈轻怕重。对议定事项一抓到底、有始有终，绝不允许半途而废、虎头蛇尾。6.严肃工作纪律。绝不允许迟到早退、旷工离岗，绝不允许在岗不务正业，绝不允许未经批准休病假、公休假，绝不允许未经审批外出讲课，绝不允许工作文件、材料随意摆放搁置，绝不允许对外泄露、在外传播一轮工作涉密事项。7.严格办案纪律。严禁违规处置问题线索，严禁大案小查、重则轻追，严禁瞒案不报、压案不查，严禁通风报信、跑风漏气，严禁口大气粗、以职压人，严禁越权批办、催办或干预案件处理，严禁擅自使用审查措施，严禁体罚或变相体罚审查对象，严禁违规处置涉案款物，严禁向涉案单位和个人提出与执纪审查无关的要求。8.保持清正廉洁。模范遵守廉洁纪律，带头执行中央八项规定及其实施细则精神，坚决反对奢靡之风、享乐主义，绝不允许参与公款吃喝、出入私人会所，绝不允许以案谋私、借机敛财，绝不允许干预插手工程建设项目及市场领域有关事项，绝不允许不当介入有关事务拉托吃请，绝不允许家属和身边工作人员利用本人职权谋取不正当利益。违反以上规定，依据有关纪律规定严肃处理。本规定自发布之日起施行，适用于省纪委机关、派驻机构，省委巡视机构的在编及借调工作人员。\xa0'
               '附件2：省纪委驻省农业厅纪检组纪检干部作风建设守则\xa0'
               '1.严守政治纪律和政治规矩。牢固树立“四个意识”，坚定“四个自信”，有令必行，有禁必止。2.努力加强理论修养。深入学习习近平新时代中国特色社会主义思想，学思践悟、学以致用。3.切实改进调查研究。坚持深入基层，聚焦重点难点，注重调研质量，搞好成果转化。4.勇于作为敢于担当。坚持原则敢于亮剑，随时准备经受急难险重任务考验，绝不打折扣、搞变通。5.切实改进工作作风。勇于开拓创新、崇尚实干实绩。坚决服从工作安排，认真负责、一抓到底。6.自觉遵守工作纪律。严格执行岗位管理及休假、外出报批制度，严格文件资料管理，绝不泄露涉密事项。7.严格遵守办案纪律。坚决执行省纪委办案纪律“十严禁”要求，严格依规处置问题线索，严格依纪追责问责。8.模范遵守廉洁纪律。带头执行中央八项规定及其实施细则精神，坚决反对“四风”，绝不以权以案谋私。\n'
               '        ',
 'art_source': '省纪委驻省农业厅纪检组',
 'art_title': '省纪委驻省农业厅纪检组关于转发《省纪委关于加强陕西省纪委机关 纪律作风建设的规定》的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2017-12-26 10:53:46',
 'art_detail': '\n'
               '         '
               '驻陕农纪发〔2017〕22号省农业厅、省扶贫开发办公室、省供销合作总社党组：2018年元旦、春节将至，为深入贯彻落实党的十九大和中央八项规定及实施细则精神，持之以恒纠正“四风”，积极营造元旦春节期间风清气正的节日氛围，按照《中共中央办公厅、国务院办公厅关于做好2018年元旦春节期间有关工作的通知》精神和中央纪委、省纪委廉洁过节的有关要求，现就2018年元旦、春节期间做好党风廉政建设有关工作通知如下：一、认真落实全面从严治党主体责任各单位党组要认真组织学习贯彻党的十九大精神，坚定不移全面从严治党，切实加强党的政治建设，牢固树立“四个意识”，严肃政治纪律和政治规矩，坚决维护以习近平同志为核心的党中央权威和集中统一领导。要认真履行全面从严治党主体责任，把紧盯节日节点、持续纠正“四风”、杜绝“节日腐败”作为一项长期的政治任务来抓，特别是“一把手”要管好班子、带好队伍、作出表率，一级抓一级、一层带一层，逐级把主体责任落到实处。要通过学习文件、会议强调、案例教育、短信提示等方式，积极教育引导广大党员干部认真践行崇廉拒腐、尚俭戒奢的优良作风，大力弘扬艰苦朴素、勤俭节约的传统美德，努力营造崇廉尚俭的浓厚节日氛围。二、严格遵守廉洁过节“七不准”要求各单位党员领导干部要带头落实中央八项规定及实施细则精神，带头转变作风、纠正“四风”，带头遵守廉洁自律各项规定，坚决杜绝“节日腐败”，坚决反对特权思想和特权行为。要严格遵守中办和国办提出的廉洁过节“七不准”要求：严禁违规用公款吃喝、旅游和参与高消费娱乐健身活动，严禁用公款购买赠送贺年卡、烟花爆竹等年货节礼，严禁违规收送礼品、礼金、消费卡等，严禁违规操办婚丧喜庆事宜或借机敛财，严禁公车私用或“私车公养”，严禁违规出入私人会所，严禁违规参加老乡会、校友会、战友会，真正把这些具体规定当做不可触碰的“高压线”，铭记在心、时刻警醒、永不触碰。三、从快严肃查处各类违纪违规行为各单位机关纪委要切实履行监督责任，聚焦主责主业，坚守责任担当，把纪律和规矩挺在前面，通过明察暗访、专项督查、随机抽查、现场查验等方式，加大监督检查力度，主动收集问题线索。要科学运用监督执纪“四种形态”，对违反廉洁过节“七不准”要求，对违规发放津贴、补贴、奖金和实物，对用财政性资金举办年会、经营性文艺晚会等突出问题线索，按照“越往后执纪越严”的要求，抓早抓小、动辄则咎、严查快处。对发生顶风违纪问题、“四风”问题禁而不绝，或者对严重违规违纪问题压制不查、隐瞒不报、处理不到位的单位和部门，要实行责任倒查和“一案双查”，严肃追究党组织主体责任和纪检部门监督责任。省纪委驻省农业厅纪检组将对各单位适时进行督查。请各单位分别于2018年1月8日、2月26日前将元旦、春节期间廉洁过节有关工作开展情况报驻省农业厅纪检组。联系电话：87343136\xa0\xa0 '
               '邮\xa0 '
               '箱：zsnytjjz＠sxny.gov.cn\u3000\u3000\u3000\u3000\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0'
               '中共陕西省纪委\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '驻省农业厅纪律检查组\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '2017年12月26日\xa0\n'
               '        ',
 'art_source': '中共陕西省纪委驻省农业厅纪律检查组 ',
 'art_title': '中共陕西省纪委驻省农业厅纪检组 关于认真做好2018年元旦春节期间党风廉政建设有关工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-11-17 15:56:34',
 'art_detail': '\n'
               '         陕农业办发〔2017〕124号\xa0'
               '各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局，厅农业生态环境保护工作领导小组成员单位：为深入贯彻落实中央和省委、省政府关于农业生态文明建设的决策部署，进一步推进全省农业生态环境保护工作，按照《陕西省农业厅关于加强全省农业生态环境保护工作的意见》（陕农业发〔2017〕34号）要求，对全省2017年度农业生态环境保护工作进行年度考核。现将有关事项通知如下：一、考核原则考核实行分级负责和分层考核，由各级农业生态环境保护工作领导小组牵头组织实施。省农业厅农业生态环境保护工作领导小组负责对厅成员单位和市级农业行政主管部门进行考核；各市农业生态环境保护工作领导小组负责对本级成员单位和县区考核；县级农业生态环境保护工作领导小组负责对本级单位考核。二、考核内容主要考核组织领导、制度建设、体系建设、任务完成、技术推广、宣传培训、奖惩事项等7个方面（具体见附件）。三、考核方式考核采取听取汇报、查阅资料、现场检查、座谈交流等方式。考核实行百分制，评分90分及以上为优秀、80分（含）至90分为良好、60分（含）至80分为合格、60分以下为不合格。考核结果经本级领导小组审定后，报同级农业行政主管部门。四、考核安排（一）市县考核。11月20日前，各市、县（区）完成本辖区的考核任务，并将考核结果报厅农业生态环保领导小组办公室。（二）省级考核。省农业厅从厅农业生态环境保护工作领导小组成员单位抽调人员，组成7个考核组，由厅机关有关处（室、局）和厅属单位主要负责人带队。考核时间11月20开始，12月10日结束，具体时间由各考核组确定。具体分组如下：第一组负责咸阳市、铜川市组长：贾朝阳（省果业局副处长）成员：冯学兵\xa0\xa0 '
               '黎青慧第二组负责渭南市、韩城市组长：童建军（省畜牧总站副站长）成员：原积友\xa0 '
               '张建峰第三组负责宝鸡市、杨凌区组长：王胜虎（省农机局调研员）成员：凌\xa0 莉\xa0\xa0 '
               '郭智新第四组负责延安市、榆林市组长：韩春选（厅科教处调研员）成员：周\xa0 敏\xa0\xa0 '
               '李晨光第五组负责西安市、商洛市组长：王阳峰（省农业技术推广总站副站长）成员：郭\xa0 昶\xa0\xa0 杨\xa0 '
               '荔第六组负责汉中市、安康市组长：马宝霞（厅种植业处调研员）成员：苏小记\xa0\xa0 '
               '于福利第七组负责厅成员单位组长：李文祥（厅领导小组办公室主任）成员：韩春选 周 敏\xa0 杨 荔\xa0 '
               '李晨光五、有关要求（一）各市、县（区）必高度重视考核工作，对照考核内容和具体要求，认真梳理总结2017年农业生态环保工作，查漏补缺，形成书面汇报材料，并准备相关佐证资料，对考核中发现的问题要及时制定整改措施，做好整改工作。（二）各考核组要切实负起责任，认真做好考核检查，避免“走马观花”，发现和了解实际工作存在的问题，听取基层意见和建议，及时提出整改要求，指导和规范农业环保工作，确保考核取得实效。（三）考核结束后，各组要形成书面考核报告，并于12 '
               '月15日前报厅农业生态环境保护工作领导小组办公室进行汇总，考核结果适时进行通报。（四）各考核组要严格执行中央八项规定精神，严格遵守廉政纪律，轻车简从，提高效率，维护部门良好形象。\xa0'
               '联系人：李晨光\xa0\xa0\xa0\xa0\xa0\xa0 电话：029-87319762\xa0'
               '附件：陕西省农业生态环境保护工作年度考核打分表\xa0'
               '附件.docx\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年11月9日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于开展2017年度全省农业生态环境保护考核的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-11-20 17:18:08',
 'art_detail': '\n'
               '         陕农业办发〔2017〕129号\xa0'
               '各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：为了全面掌握和客观评价各市县产业技术服务推进情况，总结提炼典型做法与经验，确保全省产业脱贫技术服务工作按期完成。我厅决定对全省产业脱贫技术服务工作进行交叉检查，现就有关事宜通知如下：一、检查时间2017年11月29日至12月5日。二、检查内容按照省农业厅印发的《陕西省产业扶贫技术服务百日大行动实施方案》（陕农业发〔2017〕82号）及省级指挥中心下发的20个文件要求，对各市、县开展技术服务工作情况进行检查。（一）市级指挥中心运行情况。指挥体系组建情况；指挥平台、组织平台、服务平台和技术平台的组建情况；市级督导组成立情况；工作责任制、督导督查制、首问负责制、信息报送制、通报整改制和服务时限制等制度的建立及运行等。（二）市级攻坚支队运行情况。是否按要求组建市级产业技术服务攻坚支援支队；各支队长工作责任履行情况；包抓4个摘帽县、11个深度贫困县和56个贫困县工作情况；支援技术服务困难大、贫困面大和技术力量薄弱的县区情况；指导县区级技术服务小分队情况。（三）县级农业局长履行职责情况。建立“主要领导全面抓、分管领导定点抓、指挥中心负责抓、业务骨干一线抓、技术人员上门抓”的技术服务工作制度情况；组建技术服务指挥中心情况；建立技术干部包村联户制度情况；组建技术服务小分队情况；转变服务方式情况；整合资金资源，积极争取同级政府的支持，全力保障工作经费情况；建立督导考核制度情况。（四）县级农民教育培训机构情况。产业扶贫技术服务具体工作实施情况；协助县级指挥中心做好日常管理工作情况；师资库、教材库的组建，支持经费争取情况，县级技术服务小分队和联系包联贫困村技术干部管理情况；技术服务任务完成情况；对包联贫困村技术干部进行业务能力培训组织情况；工作进展和信息的上报情况；开展产业脱贫户技术服务的宣传工作情况等。（五）包村技术干部服务情况。对贫困村和脱贫户技术服务工作情况；村级技术服务计划的制订和衔接落实情况；组织技术力量解决贫困户技术需求情况；服务信息宣传工作情况；技术服务跟踪问效和记录、档案管理等情况。三、检查方式检查采取听取汇报、查询档案、实地检查和电话抽查相结合的方式进行。每个市实地抽查3个县，主要以56个贫困县为主，4个摘帽县必查。3个县中，进度最好的县1个，进度最慢的县2个，每个县抽查2-3个村，电话抽查每县50户（以电话打通为准），并填写《产业脱贫技术服务交叉检查电话抽查表》（详见附件1）。电话抽查内容为产业贫困户是否知道该向哪反馈技术需求、有没有人对他们进行技术服务、技术服务效果如何，是否满意。四、分组安排检查组成员由各市抽调人员组成，每个市抽调市级110指挥中心指挥1名带队，成员由市级攻坚支队2人，指挥中心调度1人，共4人组成，被检查市需抽调2人配合检查组共同完成检查。具体分组是：（一）西安市，负责检查榆林市（二）宝鸡市，负责检查安康市（三）商洛市，负责检查渭南市（四）铜川市，负责检查汉中市（五）汉中市，负责检查延安市（六）延安市，负责检查咸阳市（七）咸阳市，负责检查商洛市（八）安康市，负责检查西安市（九）渭南市，负责检查宝鸡市（十）韩城市，负责检查西咸新区（十一）榆林市，负责检查铜川市、韩城市\xa0'
               '五、有关要求（一）各检查组按照方案要求尽快完成检查，并形成书面检查报告，填写产业脱贫技术服务交叉检查工作情况汇总表（详见附件2），于12月11日前报省110指挥中心。（二）请各市将交叉检查人员名单于11月24日前报厅科教处。（三）检查人员要严格遵守中央“八项”规定，轻车简从，厉行节约。要改进工作作风，深入掌握第一资料，对技术服务单位、个人做出客观、公正的评价。（四）各市、县农业局要按照检查要求，认真做好相关准备，迎接省级组织的交叉检查。联系人：程丽娟\xa0 '
               '029-87316106\xa0\xa0\xa0\xa0张爱华\xa0 '
               '029-87314637Email：sxnmpx@163.com\xa0'
               '附件：1．产业脱贫技术服务交叉检查电话抽查表\xa0 \xa0 2．产业脱贫技术服务交叉检查工作情况汇总表\xa0'
               '附件.docx\xa0'
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
               '2017年11月19日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于开展全省产业脱贫技术服务交叉 大检查的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-12-05 10:17:34',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕132号各设区市农业（农林）、畜牧、果业局（委、中心）、财政局，杨凌示范区农业局、财政局，韩城市农林局、财政局，省级有关单位：按照省委省政府追赶超越和“五新”战略任务要求，省农业厅、省财政厅以脱贫攻坚为统领，以农业供给侧结构性改革为主线，以绿色发展为导向，以产业精准扶贫和农业现代化为重点，全面实施农业创新提升“十大工程”。为推进“十大工程”建设，结合2018年省级专项资金预算，省农业厅、省财政厅共同研究制定了2018年省级农业专项资金—省级现代农业产业园创建、一村一品和休闲农业发展、主导优势产业发展、农业科技创新驱动、农作物种质资源保护与发展项目申报指南，现印发给你们，并就有关事项通知如下。一、加强组织领导、提高编报质量各市（区）农业、财政部门要切实加强组织领导，按照项目指南要求，结合“十三五”农业发展规划，抓紧组织项目征集申报工作。项目申报要向深度贫困地区倾斜，体现产业项目对产业精准扶贫的引导作用，要提出带动贫困人口的指标任务，采取土地入股、土地流转、劳务报酬、财政资金股份量化等多种形式，带动建档立卡贫困户增收。同时，要按照省级专项资金管理有关要求，科学、合理确定项目绩效目标，填报项目申报信息，不得漏项、缺项，确保按时保质保量完成项目申报工作。二、严格审核把关，规范申报程序项目申报要按照自下而上的原则开展，市级农业行政主管部门要会同同级财政部门组织具备条件的项目单位，按照项目指南要求，编制项目申报书，并对辖区内所报项目进行审核、论证，按照确保重点、绩效优先的原则，对拟申报项目按照《陕西省农业财政专项项目管理办法》规定进行公示，确保项目申报公开、公正。三、其他要求（一）各单位要认真研究，分类组织申报。凡项目申报主体为企业的，在符合项目要求和相关程序的情况下，可优先支持龙头企业申报。申报单位为省级部门（单位）的，要明确填报具体建设内容和详细支出分类明细。（二）申报项目中符合政府采购的事项，须按政府采购程序及要求办理。（三）财政直管县项目申报要纳入所在市区统筹考虑。企业、社会团体等要通过所在地市农业主管部门、财政部门申报项目，网上申报也要通过市县农业主管部门、财政部门审核。（四）申报工作采取网上与纸质并行申报方式，各单位要在报送纸质文件资料的同时，通过省级专项资金项目库系统进行申报（网址：http://xmk.sf.gov.cn）。请各单位于2017年12月15日前将纸质申报材料报送省农业厅、省财政厅各1份，抄送省农业厅发展计划与财务处及相关业务处室各1份。（五）各级农业、财政部门要及时审核专项资金项目库内申报项目，以免无效申报。联系人及联系方式：陕西省农业厅\xa0 '
               '邹艳丽\xa0\xa0\xa0 029-87321683陕西省财政厅\xa0 邢维超\xa0 \xa0 '
               '029-68936115邮箱：nytjhc@163.com附件：1．2018年省级农业专项支持省级现代农业产业园创建项目申报指南2．2018年省级农业专项支持一村一品及休闲农业发展项目申报指南3．2018年省级农业专项支持主导优势产业（种植业）发展项目申报指南4．2018年省级农业专项支持主导优势产业（畜牧业）发展项目申报指南5．2018年省级农业专项支持农业科技创新驱动项目申报指南6．2018年省级农业专项支持农作物种质资源保护与发展项目申报指南\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅 \xa0 \xa0 \xa0 \xa0'
               '陕西省财政厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年12月1日附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅 陕西省财政厅 关于印发2018年省级农业专项资金项目申报 指南的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-12-12 14:21:20',
 'art_detail': '\n'
               '         陕农业发〔2017〕93号\xa0'
               '各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：根据农业部《农药经营许可管理办法》要求，为加强限制使用农药管理，规范农药市场秩序，提高农药经营和使用水平，促进农药产业健康有序发展。保障农业生产和农产品质量安全，现就加强限制使用农药定点经营有关事项通知如下：一、全面实行限制使用农药定点经营限制使用农药是指高毒、高残留和高风险农药，实行限制使用农药定点经营是贯彻落实新修订《农药管理条例》的一项重要内容。各级农业行政主管部门要按照区域、集点、交通等进行科学布局，保证农业生产用药基本需要。（一）实行总量控制。县级在县域内数量不超过5家；每个设区市级根据不同县产业现状，可调剂不超过10家；省级在市级间调剂不超过30家，全省总数不超过665家。杨凌、韩城按县级数量布局。（二）根据作物种类进行区域限制。各级农业行政主管部门要按照地域和种植区域的不同，实行品种限制。蔬菜、果树、茶叶、食用菌、中药材等种植区域集中的乡镇和水源地所在的乡镇内禁止经营剧毒、高毒农药。（三）严格执行禁令。农药经营者要根据农药管理政策的变化，及时对限制使用农药经营品种做出调整，要严格执行农业部和省政府文件（令或公告）中明确限制使用区域的禁令或其他禁令。二、加强限制使用农药的监督管理各级农业行政主管部门要加大对限制使用农药经营的监管力度，确保限制使用农药在经营过程中销售信息100%可查询、流向100%可跟踪、质量100%有保证。（一）实名购买。定点经营单位销售的限制使用农药统一实行实名制购买，凡购买限制使用农药者，须出示有效身份证件并如实报明用途。经营者须对购买者进行实名登记，购买者不出示有效身份证件或不充分说明所购限制使用农药用途的，经营者不得向其销售。（二）销售风险告知。限制使用农药销售者在销售限制使用农药时，应以书面风险单的形式告知购买者限制使用农药的使用范围、剂量和使用风险，涉及高毒农药时还应重申高毒农药禁止用于蔬菜、果树、茶叶、食用菌、中药材等农作物上，购买者必须在告知风险单上签字确认，否则，经营者不得销售。（三）严格审查批准。申请限制使用定点经营单位必须是已取得农药经营许可资格并符合定点经营布局规划。审批实行县级现场审核，市级出具符合定点布局证明，省级受理审批的程序。省级按照法定程序对全省限制使用经营单位进行审批，统一颁发限制使用农药定点经营许可证。（四）从严监管。各地要加大对限制使用农药定点经营的监管力度，对未按规定执行的定点经营单位责令限期整改，对非定点经营单位擅自销售限制使用农药的行为，按照未取得农药经营许可证严肃处理，严厉查处利用互联网经营限制使用农药的行为。三、强化限制使用农药管理组织领导各级农业行政主管部门要按照“谁主管、谁负责”的原则，强化属地管理，认真做好限制使用农药经营管理工作。（一）强化组织领导。各地要成立由主管领导任组长，农药监督管理机构主要负责人为副组长的限制使用农药管理工作领导小组，制定详细的实施方案。（二）开展广泛宣传。要把限制使用农药的风险通过广播、电视、网络、岗前培训班、座谈会、宣传标语、专题培训等多种渠道向广大群众，尤其是农药经营人员、种植户广泛宣传，尽量减少限制使用农药用量，做到能不用尽量不用，必须要用时科学适量使用。（三）严格审批程序。要严格按照布局要求，围绕农业生产安全和农产品质量安全，在不超过规划数量的前提下，合理设置定点经营单位，做到每个定点单位都有设置的依据，对申请定点经营资格的单位，进行严格审查，做到公平公开、程序规范，所有从事定点经营审批的单位和个人，均要按制度办事，用制度约束人，用制度规范审批。（四）加强信息报送。各市农业行政主管部门于每年12月31日前将辖区内县（区）、乡两级的种植结构、定点单位的数量和分布，以及影响本区域农业产业发展的农药品种进行分类汇总，上报省农业厅。自本通知下发之日起，《陕西省农业厅办公室关于全面实行高毒农药定点经营管理的通知》（陕农业办发〔2012〕33号）作废。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年11月6日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于加强对限制使用农药进行定点经营的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-10-30 15:11:12',
 'art_detail': '\n'
               '         '
               '厅机关各处（室、局）、厅属各单位：根据《党政领导干部选拔任用工作条例》有关规定，经省农业厅研究决定，免去：刘俊生同志省植物保护工作总站总农艺师职务，退休。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年10月9日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业关于刘俊生同志免职退休的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-10-20 10:53:48',
 'art_detail': '\n'
               '         '
               '陕农业发〔2017〕89号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：为指导全省农村“三变”改革发展，明确今后一段时间工作思路，按照《中共中央国务院关于稳步推进农村集体产权制度改革的意见》（中发〔2016〕37号）和省委省政府领导指示精神，研究制定了《陕西省“三变”改革工作导引》，现印发你们，并就有关事项通知如下：一、尽快制定完善《“三变”改革实施方案》。各市县要按照《陕西省“三变”改革工作导引》要求，尽快制定并完善本地区实施方案，进一步深化认识，明确改革目标任务和改革程序要求，指导本地“三变”改革有序推进。二、谋划部署“百千万”行动。在落实百村示范工程的基础上，按照省厅“百村示范、千村试点、万村推进”总体布局，尽快安排部署“千村试点”工作，以56个重点贫困县为重点，选取1000个村实施试点，明确任务到县，压茬梯次推进，切实保证“百千万”行动取得实效。三、抓好宣传培训观摩。各市县参照省上“百人团”做法，结合“千村试点”，选派1000名业务干部下沉到村，分层次组织辖域内的“百人团”和“千名业务干部”成员集中观摩学习，开展多层次培训研讨，吃透改革政策，明晰改革思路，切实保证改革不走弯路，不走回头路。“三变”改革是助力全面脱贫攻坚的重要抓手。各市县农业局要高度重视，以《陕西省“三变”改革工作导引》为指导，扎实做好“百千万”行动各项工作，不断激活农村集体资源活力，使集体经济成为带动农民脱贫的生力军、实现农民增收的新引擎，为实现追赶超越，统筹城乡发展，活跃农村经济提供不竭动力。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年10月19日陕西省“三变”改革工作导引农村集体产权制度改革是“三变”改革的前提和基础，“三变”改革是农村集体产权制度改革的有效实现形式，也是促进集体经济发展的有效抓手。为了助力全面脱贫攻坚，活跃农村经济、统筹城乡发展，实现追赶超越，现根据《中共中央国务院关于稳步推进农村集体产权制度改革的意见》（中发〔2016〕37号）和省委省政府领导指示精神，结合我省实际，现制定工作导引如下：一、总体要求（一）指导思想。全面贯彻习近平总书记农村改革和脱贫攻坚的重要讲话精神，遵循中央农村集体产权制度改革意见，牢固树立新发展理念，认真落实“五新”战略要求，围绕“产业集约化、农民组织化、资产股份化、运行市场化、收益长效化”，以推进“三变”改革为抓手，以盘活农村资源资产为重点，以发展壮大集体经济为核心，统筹推进农村集体产权制度改革，不断解放和发展农村社会生产力，创新集体经济的实现形式和运行机制，激发农村改革的新动力，增强脱贫攻坚的新动能，推动改革、发展、脱贫深度融合，促进农业发展、农民富裕、农村繁荣，为推进城乡统筹发展、实现全面小康奠定坚实基础。（二）基本原则。农村“三变”改革涉及面广、政策性强，事关农民切身利益，事关农村长远发展，事关脱贫攻坚全局，必须把握政策底线，结合基层创新，积极稳妥推进。一是坚持因地制宜，不搞一刀切。立足资源现状，结合经济基础，在遵循农村集体产权制度改革政策的前提下，针对不同村组，突出改革重点，实施分类推进，建立试错机制，因地制宜推进。二是充分发挥农民的主体作用。在党委和政府的统一组织推动下，全面落实民主讨论、民主决策、民主监督制度，鼓励农民创新创造，尊重农民根本意愿，保障农民民主权利，维护农民基本利益。三是坚守基本底线。坚守法律政策底线，着力防范各种风险，实现集体所有权不动摇、集体资产不流失、农民利益不受损、扶贫政策不走样，确保集体成员特别是贫困户成为改革的受益者。四是科学统筹协调。以“三变”改革促进产权改革，以产权改革促进农村改革，以脱贫攻坚统揽经济全局，突出“机制创新、利益联结、产业联动”，妥善处理各方利益关系，全面提高改革综合效益，真正把农民带起来、把贫困户嵌进去，实现多方共赢。（三）改革目标。通过以“三变”为重点的产权改革，构建“归属清晰、权能完整、流转顺畅、保护严格”的农村集体产权制度，培植农业农村经济社会发展的新动力，充分激活“沉睡”资源，有效聚集分散资金，引导农民抱团发展，着力打造“股份农民”、发展股份经济、增加股权收益、壮大集体经济，建立“集体经济为纽带、市场主体为引领、农民为核心、贫困户参与”的利益共同体，构建“产业连体、股权连心”的稳固利益机制，实现村村有集体经济、户户有增收项目、人人有脱贫门路。力争到2020年，建立覆盖所有贫困村的农村集体经济组织，基本消除农村集体经济“空壳村”，使集体经济成为拉动农民脱贫的生力军、带动农民增收的新引擎、激活农村经济的新载体。二、推进“三变”改革的路径和抓手按照“突出重点、兼顾一般、分类推进、逐步覆盖”的工作方式，以资源性资产改革为重点，以确权、赋权、活权“三权”改革为基础，以量化集体成员股份权益为关键，以产业精准扶贫为依托，以发展壮大集体经济为根本，围绕“改什么、怎么改、改出效益”，找准抓手，缕清路数，增强操作性，强化指导性，引导“三变”改革科学规范高效推进。（一）抓好“六大任务”，解决“改什么”的问题。按照“政策性、规范性、创新性”要求，依据政策要求，立足改革规律，参照外省经验，结合我省实际，突出抓好六项重点任务。一是全面开展清产核资。以原有集体组织单元为基础，宜村则村、宜组则组，全面开展集体资产清查，重点核实未承包到户的资源性资产、集体所有的经营性资产，以及现金、债权、债务等，查实存量、价值和使用情况，全部公开公示，接受群众监督，经核实确认后，统一建立和完善资产台账。在清产核资的过程中，注意处理好三类特殊情况，对长期借出或违法租赁、转让的，由村委会牵头，尽量清理收回；对侵占集体资产资金的，不论是集体还是个人，都要如数退赔；涉及违规违纪甚至违法的，按职能由相关部门依法依规处理。把农村集体资源资产的家底彻底查清，为推进资源变资产打好基础。二是加快集体资产确权。以村为单元、兼顾队和组，同步推进农村集体土地、建设用地、宅基地、农民房屋、小型水利工程“多权同确”，把集体资产所有权确权到原属的不同层级集体成员和集体组织，由县级职能部门予以颁证，并依次赋予农村集体经济组织行使所有权的权能。财政投资在农村建立的学校、医疗、村两委办公场所、水利设施，全面进行资产划拨；暂不具备颁证条件的，及时进行核查认定，出具资产证明，为实现要素市场化配置创造条件。三是确认集体组织成员。以土地、林地承包为基础，依据有关法律法规，坚持“尊重历史、兼顾现实、程序规范、群众认可”，以户为单元、因地制宜界定集体成员身份，作为集体经济的组成成员和享有集体资产的权利主体，建立健全农村集体经济组织成员登记备案机制，解决成员边界不清的问题，为推进农民变股东奠定基础。四是设置集体资产份额。对集体资源性资产、经营性资产、财政投入的集体资金，统筹考虑户籍关系、农户人口、对集体经济积累的贡献等因素，在民主讨论的基础上，妥善协调平衡各方利益，折股量化到户或者到人，形成集体所有成员按户持有的份额，由村集体经济组织颁发股权证书。对财政投入贫困户的专项资金，直接量化为贫困股金，由村集体经济组织持有并经营，作为集体特殊股，所得收益归贫困户所有，一并将成员股、集体股、贫困户优先股“三类股份”规范设置。对扶贫资金投入形成的经营性资产，所有权固化给集体，收益权由集体和贫困户按一定比例分配，配套实行贫困户脱贫退出的动态调整机制。五是建立集体经济组织。同步发展两类农村集体经济组织，在以经营性资产为主的经济发达村，推行股份合作制改革，组建农村股份经济合作社；在以资源性资产为主的村组，倡导先行组建农村集体经济合作社，作为股份合作制改革的初级阶段，条件成熟后再提升为股份经济合作社，有条件的鼓励组建农村股份经济合作社。农村集体经济组织建立后，按照“制定组织章程、民主选举理事会监事会、机构法人登记”等程序，由乡镇政府审核批准，县级农业行政主管部门登记并颁发证书，有关部门据此办理银行开户等手续，规范有序推进，依法开展经营管理活动。把现有的农村扶贫合作、资金互助组织，吸纳到集体经济组织中来，联合开展脱贫攻坚；鼓励和引导农村集体经济组织与新型经营主体联手组建有限责任公司等经济实体，提高开放度，拓展经营范围，适应市场经济发展需要。推行村支部书记在集体经济组织中“短期内兼职理事长、长期性担任名誉理事长”的办法，协调处理好“支部统领、村民自治”事务与村集体经济组织独立运营的关系；鼓励在外经商、进城务工、返乡创业等人员以及高校毕业生，领办村集体经济；结合新型职业农民培育，加大集体经济职业经理人培育，放大农村“能人”效应。探索农村集体经济组织领导层薪酬待遇的有效形式，调动村干部服务集体经济组织的积极性，形成共同支持集体经济发展的强大合力。六是加强集体资产管理。建立健全村集体资产与财务管理制度，加快建设集体资产监管平台，推动农村集体资产管理制度化。立足“大产业、多领域”，打破农业农村经济界限，推行市场化运营，建立县级产权交易中心，推动包括农村集体产权在内的各类经济发展资源要素市场化流转。充实农村财会队伍，推行村集体财务代理制度，充分发挥村支部、集体经济组织监事会的双重作用，完善村财公开、民主监督程序，健全村集体经济内控机制。加强县镇农经机构建设，强化农经管理业务指导，严格执行《农村集体资产管理条例》，落实农村集体经济组织日常监管、定期审计等各项监督制度，及时查处和纠正侵害集体经济组织及成员的行为，确保农村集体经济组织健康发展。以上六项任务是推进“三变”改革的基础工作和关键环节，各地宜因地制宜确定优先序，创新工作方法，细化操作内容，为“三变”改革提供基础支撑。（二）突出“三种类型”，解决“怎么改”的问题。立足我省农村集体经济现状，坚持“突出特点、各有侧重、抓点示范、同步推进”，分类实施改革，增强针对性，提高精准性。一是有序推进经营性资产为主的股份制改革。在形成一定规模经营性资产、由集体统一经营的城中村、城郊村、经济发达村，严格按照中省既定政策和统一部署，开展股份合作制改革。在清产核资的基础上，县级党委政府围绕集体成员界定、经营资产股权到户量化到人、集体公积（公益）金提取比例等关键问题，出台指导意见，确定股份改革村组；改革村组按照“坚持原则、因地制宜、民主协商、规范操作”的要求，扎实稳步推进，与全国步调一致，用5年时间基本完成，实现经营资产变股份、集体成员变股东。二是稳步推进集体资产“空壳村”改革。对基本没有经营性资产，也没有成规模、可开发的集体资源性资产的村组，发挥党支部、村委会的体制优势，把承包到户的资源性资产聚集起来，引导农民立足主导产业，加强与新型经营主体对接，开展土地股份合作、一二三产融合，发展规模化经营，提高组织化水平，带动贫困户抱团发展，引导分散资源变资产；聚合产业发展、扶贫开发等资金，参股入股市场主体，获取分红收益，实现农民变股东。各级财政可整合涉农资金，为贫困村注入集体经济发展股金，省财政每年安排专项资金、实施跟进配套。集体股暂不量化，重点是积累集体经营性资产，壮大集体经济，为集体成员永久受益创造条件；同步引导到户的产业扶贫资金转为贫困户优先股，由集体持有统一经营或合作经营，确保贫困户有一定的比例收入。三是重点推进资源性资产为主的村组改革。严格按照“三变”改革六项重点任务，突出简便易行，以未承包到户的集体土地、林地、“四荒”地等资源性资产为主，以及财政投资形成的固定资产，全面进行评估作价、量化到户，作为集体经济的主要资产股，推进资源变资产；对财政扶持集体经济、产业发展、扶贫开发等资金，作为集体成员股和贫困户优先股，明确股金份额，实现资金变股金，建立集体经济持续发展与集体成员稳定受益的有效机制。扶持的重点以市县财政为主，利用扶贫到户专项、涉农整合资金等，向集体经济组织注资，设立贫困户优先股。按照每户0.5-1万元的标准，一次性注资，覆盖所有贫困户，由村集体经济组织持有和运营，明确每年的固定分红比例，确保贫困户率先受益、稳定受益。四是实施“三变”改革“百千万”行动。按照“有清晰的思路、有普遍的试点、有典型的范例”要求，坚持抓点示范，实施梯次推进，以全省56个重点贫困县为主，开展“百村示范、千村试点、万村推进”行动，逐步推进覆盖所有行政村的“三变”改革。今年年底前，突出摘帽贫困县和深度贫困县，确定100个贫困村，实施“三变”改革“百村示范工程”，全面完成“三变”改革并组建农村集体经济组织，其中佛坪县所有行政村全覆盖；2018年上半年，再选择1000个试点村，全面完成改革任务；各地在试点的基础上，压茬复制推进，力争2019年底前10000个以上的村完成“三变”改革，到2020年基本实现应改可改行政村全覆盖。在“百千万”行动总的布局下，按照“分级试点、复制推广、全面推进”的要求，创造一批典型经验，破解一批改革难题，制定一批配套政策，形成一批制度成果，激活农村要素，优化资源配置，释放改革红利。（三）推广“三类模式”，解决“改出效益”的问题。坚持“支部引领、主体带动、产业支撑”的路子，引入市场机制和资本运作模式，重点推进“体制带动、产业拉动、组织推动”三类模式，创立农村集体经济组织的运行体制，构建各方共赢的利益联结机制，把“三变”改革成果转化为集体经济发展活力，形成发展现代农业、繁荣农村经济、促进农民增收、实现全面脱贫的持久动力。一是“党支部+集体经济+贫困户”的体制模式。以党支部为引领，把集体经济组织作为所有集体成员的载体，把贫困户作为政策支持的特殊群体，聚集资源、联合抱团，提高农民组织化程度，实行农村集体经济组织自主经营或对外开展合作经营或与新型经营主体相互入股等“多条腿走路”，构建适应市场经济发展的实力型农村集体经济体制。对跨村集中连片发展农业规模经营的，探索建立联村党委，创新“规划共谋、资源共享、产业共建、矛盾共调”的协作机制，充分发挥“党支部+”的体制优势，推动区域经济整体发展。二是“园区承载、一县一业、一业一龙头”的产业模式。借助脱贫攻坚国企“合力团”和“千企帮千村”的优势，以发展园区经济为主导，以一二三产融合为方向，结合现代农业园区、扶贫产业园区、农产品加工园区、电商物流园区“四类园区”建设，每村跟进1-2项优势主导产业、每个主导产业确定1个龙头企业、每个龙头企业至少联结1个农村集体经济组织，选准选好保障系数较高的盈利产业项目，集中配套建设、逐步改善提升农村基础设施，优化农村经济发展条件。推进农村集体经济组织与“合力团”企业相互参股、共同经营，集体所得收益由农村集体经济组织按成员在集体中的股权份额分配。三是“集体引领、主体联合、贫困户抱团”的生产组织模式。推动集体经济的组织优势、经营主体的市场优势、农民个体的生产积极性“三个有机结合”，改变传统的买方卖方关系，优化生产组织方式，构建利益联结机制。对现在仍是分散经营的，发挥农村集体经济组织的牵头组织作用，引导贫困户统一流转土地或入股到农村集体经济组织，推动集体经济组织与龙头企业、专业合作社、社会化服务组织合作经营，提高生产效益；对正在发展规模经营的，在农村集体经济组织统一标准、统一生产管理要求的基础上，生产作务环节实行家庭适度规模“包工包产”方式，实现新型的“统分结合”；对具备向外合作条件的，发挥集体经济的主导作用，组织贫困户抱团参与，推动农村集体经济组织、新型经营主体、贫困户联产联业、联利联心，既保证集体成员的基本收益，又增加一份扶贫政策的优先收益。同时，鼓励基层立足资源优势、产业特点和发展基础，大胆试点探索，积极创新机制，进一步丰富集体经济、市场主体与农民群众特别是贫困户协同发展的多种有效模式，及时总结提炼，多途径推进农村集体经济发展壮大。三、推进“三变”改革的政策与措施实践证明，推进农村特别是贫困地区“三变”改革，依靠制度创新、优化生产关系，能够产生巨大的综合效益。农村改革，往往牵一发而动全身，需要全省上下通力合作、强化措施、积极探索、强力推进。（一）加强组织领导，夯实各级责任。把“三变”改革列入县级脱贫攻坚的重点考核内容，推进“三变”改革与脱贫攻坚统筹谋划，在全省形成上下联动、层层负责的工作机制。一方面，强化组织领导。全省“三变”改革由各级党委牵头抓总，政府相关部门合力推进，不再设置新的领导组织机构，由各级农村集体产权制度改革领导小组牵头抓总，下设的办公室组织实施。省级领导小组负责统筹部署，市级领导小组负责督导协调，县级党委政府是责任主体、具体组织实施，乡镇党委政府抓好推进落实，村支部组建改革班子、全身心投入。另一方面，落实部门职责。各级农业部门做好业务指导，确保“三变”改革有序推进；农村工作部门研究解决“三变”改革中出现的问题，注重搞好与其他改革的衔接，发挥改革的综合效应；组织部门配套跟进农村基层党组织建设，出台鼓励农村能人返乡创业、领办集体经济的政策，为“三变”改革提供强有力的组织保障；国土部门尽快制定农村集体资产所有权认定办法，加快确权颁证工作；党委政府督查部门加强“三变”改革督查力度，确保工作进度；各级脱贫攻坚指挥部办公室将“三变”改革作为季度督查的重要内容，加强考核，传导压力，推动落实。各有关部门把“三变”改革纳入本部门重点工作，加强协作配合，出台政策措施，确保“三变”改革落地生根。（二）加大资金整合，强化扶持引导。围绕“三变”改革，整合资源、调整投向、优化政策，形成多个层面共同支持的格局。一是进一步加大涉农资金整合。引导相关资金注入农村集体经济组织，作为集体经济发展的启动股金，助推“三变”改革和集体经济。对农村集体经济组织与新型经营主体建立合作联结机制，给予财政项目重点支持，实现两类市场主体同扶持、同发展；把易形成固定资产的，以集体股的形式用于壮大村集体经济；财政扶持农村集体经济发展的试点项目，重点投向贫困地区“三变”改革试点示范村。二是进一步改革财政拨投机制。推广留坝县等地的有效做法，明确投向农村的基础设施建设、农村产业发展重大项目，以村集体经济组织或集体经济组织与新型经营主体联合组建的有限责任公司为实施主体，实行“建管护一体化”机制，改善提升农村水电路网基础设施建设水平，减少村集体经济组织的公益性支出，不断积累集体经营资产、增加贫困户收益；对于农村治安、保洁等公益性服务，推行政府向村集体经济组织“购买服务”的方式，提升农村集体经济组织的市场竞争力。三是进一步强化政策支持力度。加快清理废除各种阻碍集体经济发展的不合理规定，落实农村集体经济组织的契税、印花税、登记费等“三免两税一费”政策，对农业生产设施用地优先调整用地指标，推行农产品加工、休闲农业用电用水优惠价格制度，开辟集体资产抵押担保信贷“绿色通道”，开发集体经济组织发展产业的保险新品种，搭建政策性金融机构注资集体经济的投融资平台，营造有利于“三变”改革、壮大集体经济的政策环境。（三）强化培训指导，广泛宣传动员。以政策解读、培训指导、宣传引导为抓手，确保“三变”改革规范推进、集体经济科学发展。一是建立“三变”改革“百人团”辅导员。近期，省农业厅联合省委农工办，抽调100名省、市农业农村工作技术骨干，筛选各地“三变”改革典型，分片观摩学习，集中开展研讨，熟悉程序步骤，掌握农民易于接受、符合实际的工作方法，梳理形成适合不同经济、资源条件的改革路径，下沉到100个“三变”改革示范村，开展包县帮村指导，打造一支省级“三变”改革技术骨干队伍，指导市、县完善工作方案，创建改革示范样板。二是下派“三变”改革千名指导员。以县为重点，选派1000名技术人员，扎根到1000个“三变改革”试点村，面向镇、村宣讲解读改革政策，全程指导“三变”改革试点。以镇村干部和直接参与改革的工作人员为主，组织举办多层次的培训班、现场会，确保干部自己想明白、给群众讲明白，提高一线人员推进“三变”改革的政策水平和专业能力。三是开展“三变”改革百日宣传动员。利用冬闲和春节等农时季节，结合产业扶贫，选派工作组进村入户，以村干部特别是贫困群众为主，集中100天时间，开展大范围、高频次的宣传动员和思想发动。编制图解式、步骤化的宣传小册子，通过农民易于掌握的形式，提炼、简化“三变”改革环节和工作流程，调动群众参与改革的积极性主动性，营造良好的改革氛围。重点把外出创业的农村“能人”动员回来、留在家乡，带领群众一起推改革，带头领办集体经济，带动农民脱贫致富。（四）注重操作环节，助推“三变”改革。一是下发专门工作方案。各市县党委政府下发《关于推进“三变”改革发展集体经济助力脱贫攻坚的工作方案》，明确任务，夯实责任，强化措施，推动实施。二是召开现场推进会议。各市县党委政府尽快召开“三变”改革现场会或经验交流会，总结试点经验，加大模式推广，全面安排部署，督促各地因地制宜、加快推进“三变”改革。三是健全基层农经体系。各市县党委政府出台加强县镇农经体系建设的指导意见，明确县镇农经机构的编制基数、单位级别、性质等问题，强化农村改革的体系支撑，加大“三变”改革的政策引导、培训辅导和业务指导。\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于印发陕西省“三变”改革工作导引的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 49, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-10-16 17:50:33',
 'art_detail': '\n'
               '         '
               '陕农业发〔2017〕85号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：为深入贯彻落实中央和省委省政府关于打赢脱贫攻坚战的战略部署，扎实推进产业脱贫户技术服务工作，全面完成技术培训全覆盖任务，省农业厅制定了《陕西省产业扶贫精准脱贫技术服务工作规划（2017-2020年）》，现印发你们，请认真贯彻落实。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年10月11日陕西省产业扶贫精准脱贫技术服务工作规划（2017-2020年）为进一步加大贫困地区产业脱贫户技术服务力度，切实增强贫困户自我发展能力，全面打赢脱贫攻坚战，按照《陕西集中连片特困地区特色产业精准扶贫规划（2016-2020年）》《关于加快产业扶贫精准脱贫工作的意见》《关于印发陕西省农业科技助推产业扶贫精准脱贫指导意见等3个意见的通知》要求，结合我省实际，特制订本规划。一、规划背景（一）科技助推产业扶贫成效。今年以来，全省围绕产业扶贫精准脱贫要求，统筹协调全省农业科技力量，大力推进农业科技助推产业扶贫精准脱贫工作，构建了“专家定点联系到县、农技人员包村联户、实用技术普及培训到人”工作机制，推行了“技术指导、农技推广、普及性技术培训全覆盖”，提高了贫困地区技术水平，提升了贫困户自我“造血”能力，助推了产业发展。一是组建专家团队帮扶指导到县。依托省级产业技术体系和农业科研教学单位，组建陕西省农业产业扶贫精准脱贫专家服务团，指导市、县成立298个专家服务团队，吸纳4000多名专家，实行层级指导，梯队式精准服务，实现产业扶贫专家团队工作指导全覆盖。组织产业技术体系、市级农科院（所）、涉农院校认领贫困县，建立科技对口帮扶指导关系。二是下派农技人员结对包联到户。1.4万农技人员与5.9万贫困户建立技术帮扶关系，因户施策，开展点对点、面对面、手把手的帮扶指导和技术培训,56个贫困县建立农业科技示范基地698个，示范带动8万多贫困户发展特色产业。三是推进实用技术普及培训到人。以村为单位，以户为单元，采取“农民需求、专家上门，菜单式服务”方式，实施精准培训，把技术送到田间地头，开展培训3001班次，培训贫困户17.1万人次。鼓励引导职业农民和贫困户结对帮扶，通过吸收贫困户进园、进社、进场等直接帮扶，利用技术、资金、销售等优势，提供生产资料、技术培训、帮扶创业等方式，帮助贫困户发展产业，提高技术技能，调动了产业脱贫致富的积极性。（二）存在问题。一是培训责任没有完全落实，管理机制、监督机制不完善；二是部分地方对贫困户产业脱贫精准培训认识不够，重视不足，安排部署不到位，缺乏整体安排和切实可行的培训方案；三是组织力度不够，培训场次少，覆盖面小，并且培训重心没有下沉，部分群众没有接受到培训；四是培训方式单一，课堂教学多，田间实训少，集中大班多，分散小班小，针对性不强，精准性较差，培训效果不理想。（三）面临形势。一方面，全省产业扶贫工作成效显著，亮点纷呈，但与省委、省政府要求，与贫困群众期盼仍有很大差距，到2020年完成78.3万户228.7万贫困人口脱贫，尤其是39.6万户124.5万人实现产业脱贫致富，时间紧、任务重、要求高、压力大。另一方面，贫困群众具体情况复杂，年龄偏大、综合素质较低、接受能力差、观念思想僵化、因循守旧，产业脱贫缺乏信心，技术需求弱，参与度不高，新技术不愿学、不想学，学了也不愿用、用不好；需求呈现多元化、个性化和区域化；产业规模小，管理水平与效益偏低，技术需求以简单、明了、实用、实效的实用技术为主，对技术服务工作方式方法提出新挑战。二、指导思想、基本原则与目标任务（一）指导思想。按照中央脱贫攻坚的战略部署和中、省有关产业扶贫精准脱贫的具体要求，紧盯建档立卡贫困人口产业发展，按照技术“服务到村、指导到户、精准到人”的总体要求，实现技术培训向技术帮扶带转变，课堂教学向实际应用转变，普及性培训向精准指导转变，专家指导向能人带动转变，确立“做给农民看，教会农民干，帮着农民赚”的新型培训理念，统筹和动员社会各类科技资源，广泛开展多层次、多渠道、多形式的技术服务，提高贫困户的产业发展能力，全面巩固和夯实脱贫攻坚基础。（二）基本原则1．统一指挥，上下一体。建立省市县三级技术服务110指挥体系，统一步调，统一指挥，形成上下一体，左右联动，齐抓共管的工作局面。2．产业引导，精准服务。围绕贫困地区产业脱贫户的产业发展需要，因地制宜，因人施策，精准到人，精准到技术。3．注重效果，重心下移。突出一线，深入田间地头，开展面对面、手把手帮扶指导，通过帮带扶等措施，确保取得实效。4．县级为主，省市统筹。坚持县级在产业扶贫攻坚中的主体地位，省市加大统筹力度，县级落实相关责任，全力抓好技术服务工作。5．创新模式、完善机制。根据区域、产业等不同特点，采取灵活方式，总结提炼模式，建立健全培训评价、激励、监督和考核机制。（三）目标任务。以56个国家级贫困县为重点，以39.6万产业脱贫户124.5万贫困人口为目标，发挥全省农业人力资源优势，通过建立产业脱贫技术服务110指挥体系，实施帮带扶策略，加大产业脱贫户技术服务力度, '
               '确保服务到村、产业到户、技术到人，覆盖所有贫困村贫困户。按照产业脱贫目标任务，以摘帽县和深度贫困县为核心，兼顾已脱贫农户和其他贫困户，加大技术服务力度，每年使每个贫困家庭接受技术培训和指导服务4次以上。 '
               '到2020年，全省累计开展脱贫户技术服务650万人次以上，贫困家庭至少有一人掌握1-2门符合产业发展需求、学得会、用得上的生产技术，每村培养1名技术能手，促进贫困人口稳步增收，全面实现产业脱贫目标。三、技术服务重点（一）科学制订方案。县级农业部门要制订技术服务规划，成立产业技术服务小分队，建立技术干部包村联户制度，确保1个村1名技术干部。包村技术干部要主动上门、入户调研，征询贫困户培训需求，会同扶贫包村干部、村级组织共同制订技术帮扶计划，主体要精准、主题要精准，时间要精准，要求要精准。（二）强化工作流程。包村技术干部将村级技术帮扶计划提交指挥中心，指挥中心指令县农民教育培训机构统筹协调师资，在指定时间、指定地点完成服务任务。村组织、包村技术干部、扶贫包村干部共同确定服务场地，发动贫困户，做好服务保障。县级农民教育机构要建立贫困户技术帮扶档案，做到一村一档装订成册，档案包括村级帮扶计划，技术服务内容、进度和效果评价，资料和讲稿，影像资料，参加人员花名册等。（三）创新服务方式。改变传统培训方式，建立起做给农民看，带着农民干，帮着农民赚的帮带扶式新型服务理念，实现5个转变。一是普及性培训向精准指导转变。改“大水漫灌”的方式为“精确滴灌”，将一般性的农民培训改为针对贫困户的技术服务，深入贫困村、贫困户，以村为单位，户为单元，以人为对象，开展“定点、定向、订单”式服务，确保产业脱贫户年接受技术指导不少于4次。二是全面培训向专项技术转变。坚持问题导向，切实依据农民技术需求开展单项服务、专项服务，技术服务内容要精准，努力做到服务内容与群众需求相契合，服务效果与增收目的相吻合。三是课堂教学向实际应用转变。根据农民的学习特点和接受能力，以现场实训为主，充分利用农业园区、农民实训基地、科技示范基地、家庭农场、企业合作社基地，通过看得见、摸得着方式，浅显易懂的语言，深入浅出的道理，使农民更容易接受技术。四是大班教学向重质量的小班转变。通过多频次的小班培训，使每个贫困户有机会与老师面对面、手把手，增强服务针对性，确保技术服务效果。五是常规培训向帮带扶转变。鼓励新型经营主体、职业农民、农村能人通过吸纳贫困户帮工，对贫困户开展技术服务指导，教技术、传经验，发挥传、帮、带作用，建立帮带扶式新型技术服务理念。（四）内容突出实用。一是突出转变贫困户思想理念，摒弃固有的观念、陈旧的思想，树立产业脱贫致富的信心，敢于接受新事物、新技术。二是围绕长期和短期产业发展需求，突出生产性技术的简单、明了、实用、实效和轻简化，确保农民一看就懂、一学就会、一干就有效益。三是突出贫困户市场意识教育，加大农产品销售、电子商务等方面培训力度，解决贫困户卖难问题。（五）丰富服务载体。充分发挥现有公益性单位的专家、干部力量，主要包括28个省级现代农业产业技术体系，10个市级农科所，西北农林科技大学、杨凌职业技术学院等高层次专家团队，以及全省3万多名农技人员、产业扶贫精准脱贫科技培训师资库4000多名专家，扎实推进技术服务工作。同时要吸纳社会力量参与，鼓励引导新型经营主体，尤其是职业农民、种养大户、农民专家、农村能人等参与进来，建立一支最接地气、最受农民欢迎的师资队伍。（六）提升服务效果。技术服务过程中，融入启发式教育，互动式交流，服务结束后，征询服务意见，开展效果评价。包村技术干部要组织贫困户相互交流，研讨学习成果，畅谈学习收获，互相启发，相互提醒，汇总收集贫困户意见和建议，督促贫困户使用好所学技术，真正做到学有所成、学以致用。四、项目支撑（一）设立脱贫技术服务专项。争取省级财政支持，加大脱贫技术服务投入力度，建立服务专项。同时，从2018年开始，调整省级职业农民塑造工程项目，用于脱贫技术服务。（二）整合调整各类涉农技术服务项目。对各类中省涉农技术服务项目、产业发展项目，尤其是职业农民培育、农技员培训、新型经营主体培训等项目，进行整合调整，集中优势资源，全力推进脱贫技术服务工作。（三）争取农业产业脱贫切块资金。积极协调，争取从省级农业产业脱贫项目中列支一定的技术服务专项，确保服务工作全面开展。五、工作措施（一）加强组织领导。产业脱贫是脱贫攻坚的重要抓手，科技助推产业脱贫必须持之以恒抓好科技培训。各级农业部门要高度重视，加强组织领导，将脱贫技术服务纳入产业扶贫精准脱贫工作的重要议事日程，建立省市县三级技术服务110指挥体系，协调好指挥中心和培训机构关系，做到有令必行。各级各部门要发挥工匠精神，下足“绣花”功夫，做精做细技术服务工作。（二）强化统筹协调。县级是技术服务的责任主体，省级要做好统筹和协调工作，市县要细化规划任务，明确工作职责、任务和重点，分工协作，相互配合。整合统筹社会资源，发挥国企合力团、百校合力团的作用，帮助贫困地区增强稳定脱贫的内生发展动力。各技术推广机构、科研院所、西北农林科技大学、杨凌职业技术学院等要全力配合，积极参与，真抓实干，主动作为，组织动员科技人员参与技术帮扶指导，为打赢脱贫攻坚战提供强有力的科技支撑。（三）完善工作机制。建立群众参与机制，发动贫困户不等不靠，积极参与，主动配合，走依靠劳动脱贫致富奔小康之路；建立县级农技人员包村联户机制，了解脱贫户需求、制订技术帮扶计划、提交服务申请、组织服务场地和人员；建立新型经营主体、职业农民、农村能人包抓补贴机制，对吸纳贫困户就业、参与帮带扶的新型经营主体予以政策支持、资金扶持和项目倾斜；建立信息报送制度，实行信息每周上报；建立首问负责制，简化工作程序，提高工作效率，全程跟踪服务；建立工作包抓督导机制，省农业厅抽调科教口单位人员成立工作组，实行分片抓市督县，了解问题情况，督导工作开展。（四）加大宣传引导。各级各部门要采取多种形式宣传，让产业脱贫户享有知情权，提高主动参加服务的积极性。通过宣传技术服务中涌现的好经验、好做法、好典型，营造社会共同参与支持的舆论氛围。（五）严格监督考核。各级农业部门要对产业脱贫户技术服务工作进行全面监督考核，重点考核技术服务110指挥体系建立及运转、工作安排部署、县农民教育培训机构工作开展、县级技术干部包村等情况，对工作不力的单位和个人，将严肃追责。\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅印发陕西省产业扶贫精准脱贫技术服务工作规划的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-10-30 15:05:22',
 'art_detail': '\n'
               '         '
               '厅机关各处（室、局）、厅属各单位：根据《公务员法》、《陕西省农业厅干部任用工作暂行规定》中干部退休有关规定，经省农业厅研究决定，免去：朱志岐同志厅发展计划与财务处调研员职务，退休。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年10月9日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于朱志岐同志免职退休的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-10-18 14:36:30',
 'art_detail': '\n'
               '         '
               '陕人社函〔2017〕856号各市（区）人力资源和社会保障局、农业（农林）、畜牧、果业局（委），省级有关部门，省农业厅厅属各单位：按照我省2017年职称评审总体安排，为了做好今年我省农业、工程系列中、高级职称评审工作，现将推荐评审和报送评审材料有关事项通知如下：一、评审范围在我省从事农学、园艺、土肥、植保、畜牧、兽医、农业工程等专业技术工作并符合申报条件的专业技术人员。达到国家法定退休年龄的人员不得申报，公务员和参照公务员法管理的工作人员不得申报。二、申报条件（一）思想政治条件遵守宪法和法律，热爱本职工作，具有良好的思想品德和职业操守。申报人员近5年个人年度考核为合格以上等次，有下列情形之一的，不得申报：1．任现职以来年度考核不合格1次以上或被单位通报批评者；2．任现职以来出现重大工作事故，造成恶劣影响的；3．受到党政纪处分，处分期未满的；4．提交弄虚作假材料的，取消当年参评资格，并在全省通报批评，三年内不得重新申报。（二）岗位条件对实行专业技术岗位管理的事业单位，按照评聘结合的原则，上报人员数和空缺岗位数按照1：1申报。当年能够空出的专业技术岗位，可以提前使用。各市（区）人社部门对本市（区）申报单位的岗位情况进行审核、把关。（三）学历、资历条件专业技术人员所取得的学历必须为国家教育部门认可的学历，所学专业与本人所从事专业相同或相近。1．申报研究员（农业研究人员，下同），具有大学本科以上学历，并聘任副研究员满5年。2．申报高级农艺师（畜牧师、兽医师、工程师）、副研究员，具备下列条件之一（以下第3-7条，须任对应的中级技术职称满5年）：（1）具有博士学位，并聘任中级技术职称满2年；（2）具有硕士研究生学历，并聘任中级技术职称满4年；（3）大学本科毕业；（4）后取大学本科学历，从事本专业技术工作满15年；（5）大专毕业后直接从事本专业技术工作满20年，或后取大专学历并累计从事本专业技术工作满25年；（6）在县、乡单位（不含市辖区域内单位）工作的专业技术人员，中专毕业直接从事本专业技术工作满28年，或后取中专学历并累计从事本专业技术工作满30年；（7）对不具备规定学历，或不符合专业技术工作年限要求者，但任现职期间，业绩显著、贡献突出并获得省（部）级科技进步（农业推广、丰收计划）奖一等奖前七位，二等奖前五位，两项以上三等奖前三位，可破格申报评审：破专业工作年限者，可比规定年限提前3年申报；破学历者（中专学历的省、市及市辖区域内单位人员），须从事本专业技术工作满28年。3．申报农艺师（畜牧师、兽医师、工程师，下同），具备下列条件之一：（1）具有大学本科或专科学历，并聘任对应的助理级技术职称满4年；（2）全日制统招硕士研究生毕业后，从事农业专业技术工作满3年，经考核合格，可认定为农艺师。（3）获得博士学位后，经考核合格，可认定为农艺师；（四）论文条件参评论文须与申报人员的工作岗位、业绩密切相关。期刊须具有ISSN或CN刊号，增刊、专刊、特刊、论文集不予认可；著作须具有ISBN书号。1．申报研究员，具备下列条件之一：（1）公开出版发行的本专业学术著作（不含论文、报告等汇编）1本，其中省级单位本人执笔5万字以上，市级单位本人执笔4万字以上；（2）在中文核心期刊上作为第一作者或通讯作者发表本专业研究性学术论文3篇。2．申报副研究员，具备下列条件之一：（1）公开出版发行的本专业学术著作（不含论文、报告等汇编）1本，其中省级单位本人执笔4万字以上，市级单位本人执笔3万字以上；（2）在中文核心期刊上发表本专业研究性学术论文3篇，其中第一作者或通讯作者2篇。3．申报高级农艺师（畜牧师、兽医师、工程师）省、市（区）级单位申报人员具备下列条件之一：（1）公开出版发行的本专业学术著作1本，其中本人执笔3万字以上；（2）在省级及以上科技类期刊上作为前2名作者发表本专业论文2篇，其中第一作者1篇。县、乡级单位申报人员具备下列条件之一：（1）公开出版发行的本专业著作1本，其中本人执笔1万字以上；（2）在市级及以上科技类期刊发表本专业论文2篇，其中前2名作者1篇。4.申报农艺师在省级及以上科技类期刊上发表本专业论文2篇，其中第一作者1篇。（五）职称外语条件申报评审农业、工程系列职称的技术人员，对外语不作统一要求，不作为必备条件。确实需要评价职称外语水平的，由用人单位根据专业岗位要求自主评价。申报农业研究系列职称的技术人员，取得全国职称外语等级考试A级合格证书或符合我省职称外语免试条件。（六）计算机应用能力条件计算机应用能力考试不作统一要求，不作为必备条件。确实需要评价计算机水平的，由用人单位根据专业岗位要求自主评价。（七）继续教育申报人员从2013年开始，每人每年参加继续教育公需课学习不少于24小时，专业科目不少于56小时。继续教育证书审验合格。三、报送材料内容及要求申报职称评审的专业技术人员提出申请，用人单位负责对申请人申报材料的真实性完整性进行审核。对审核通过人员的申报材料在单位进行五个工作日的公示。公示无异议后，将申报材料按照管理权限逐级上报。不受理个人直接上报的和越级上报的评审材料。（一）《专业技术职务任职资格评审表》一式3份（贴照片）。评审表须用A3纸双面打印，中缝装订。（二）《农业中（高）级职称评审简表》（附件5）中级一式10份、高级15份（A3纸打印），单位审核后，签署意见并加盖公章。（三）近五年《年度考核登记表》各一份（装订），考核为优秀等次的，并附考核结果文件，复印件加盖公章。（四）附件材料1套。有关证件统一用A4纸复印，单位盖章，按以下顺序装订成册，并编写目录表及页码。附件材料由各市农业和人社部门审核后，在封面、目录页加盖公章确认。1．《职称申报诚信承诺书》（附件2）（个人、单位负责人签字，加盖公章）。2．任现职以来个人技术工作总结1份，不超过1000字用A4纸打印。本人所在单位须对总结中所述事实的真实性、准确性负责，并加盖公章；3．破格人员单位出具业绩推荐材料一份，不超过800字；4．国家教育部门认可的各学段的学历学位证书；5．任职资格证书；6．专业技术职务聘任证书或单位聘文；7．职称外语考试合格证或免试证明（农业研究人员）；8．继续教育证书；9．任现职以来获成果奖、荣誉奖证书、专利证书、成果鉴定证书、技术标准和规范、承担的项目、课题等主要业绩证明材料。（五）任现职以来发表的能代表本人学术水平的论文原件2－3篇（字数1000字以上）。所发表论文在目录处标注并在杂志中折叠以便查找，论文不需提供复印件；论文刊用通知、用稿清样及报纸不能作为参评论文。（六）省级有关厅局、各市人社部门出具委托评审函，厅直属单位报送推荐评审报告1份。（七）《农业中（高）职称申报参评人员汇总表》（附件6）1份，同时报送Excel格式电子文档。（八）各市（区）人社部门，提前收集留存申报人两寸近期蓝色背景免冠证件照2张（与评审表所用照片相同），用于办理资格证书。（九）其他要求1．申报人员要按申报材料填报说明（附件1）的要求，认真填写并提供相关材料。2．报送的奖励、论著、工作业绩等材料必须是任现职期间形成的，不得出现任现职以前的材料；复印件须清晰可辨。3．申报材料（含论文）用牛皮纸质档案袋封装（无破损、每人限1袋）。材料袋正面须粘贴《申报材料目录表》（附件3），背面粘贴《职称申报公开监督卡》（附件4），材料袋底部和两个侧面粘贴打印有地市、单位、姓名的标识；申报人证书原件用纸质资料袋封装（每人1袋），并在材料袋注明证书原件、单位及姓名。四、有关情况说明（一）参评人员的工作年限、任职资格年限计算时间截止为2017年12月31日。（二）职称资格确认外省（含中央驻陕、军队转业）调入我省的农业系列（含农业工程，下同）专业技术人员职称确认，按照确认工作要求和我省对本专业技术职务任职条件进行资格审核。评委会对申报人可同时进行职称确认和职称晋升。（三）职称资格转换已评聘专业技术职务的非农业系列专业技术人员，本人确因工作需要而转换到农业系列专业岗位，须在农业系列工作岗位工作满一年以上，按照职称转换工作要求和本专业技术职务任职条件进行转换评审。（四）根据人社部《关于加强基层专业技术人才队伍建设的意见》（人社部发〔2016〕57号）精神，进一步加大对基层专业技术人才的政策倾斜，对县及县（不含市辖区）以下基层专业技术人员参加职称评审时，予以政策倾斜。（五）根据《中共陕西省委陕西省人民政府关于贯彻落实&lt;中共中央国务院关于打赢脱贫攻坚战的决定&gt;的实施意见》（陕发〔2015〕20号）要求，鼓励各类人才扎根我省贫困地区建功立业，贫困县专业技术人员参评职称时给予政策倾斜。（六）按省物价局核定的收费标准，中级职称评审每人200元，高级职称评审每人400元。有关表格及附件，可在陕西农业网（www.sxny.gov.cn） '
               '“政府文件—农业厅人事文件”栏下载。五、报送材料时间及地点各市（区）、省级单位统一于2017年11月15日前，将申报材料报送省农业厅人事处，愈期不再受理。附件：1．申报材料填报说明2．职称申报诚信承诺书3．申报材料目录表4．职称申报公开监督卡5．农业中（高）级职称评审简表6．农业中（高）级职称申报参评人员汇总表\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省人力资源和社会保障厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0\xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年10月11日附件1-4.doc附件5.doc附件6.xls评审表.doc\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省人力资源和社会保障厅 陕西省农业厅 关于开展2017年度全省农业、工程系列 中、高级职称评审工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-10-24 16:54:22',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕105号各设区市农业（农林）、畜牧局（委），杨凌示范区农业局，韩城市农林局，厅机关有关处（室、局）、厅属有关单位，省农垦集团、省果业集团：根据《农业部办公厅关于印发2018年农业部部门预算项目任务指南的通知》（农办财〔2017〕62号）要求，现就做好2018年农业部部门预算项目申报工作通知如下：一、各市农业部门要认真研究农业部部门预算各专项项目指南，严格按照指南中申报单位、条件等要求，结合本市实际情况，组织项目申报。对拟推荐项目，要严格审核项目资料，按照《陕西省农业专项项目管理办法》有关要求，公示无异议后，按要求上报，避免无效申报。厅机关有关处（室、局）要加强业务范围内项目申报的组织指导工作。厅属单位按照农业部指南要求，申报相关项目。二、2018年农业部部门预算项目申报工作按照公开申报、自下而上、逐级编制的原则，由符合相关资质和条件的项目单位按照项目指南要求，编报项目申报书。各级农业行政主管部门不得代编代报。三、各单位要按照农业部2018年部门预算项目指南要求,合理测算项目资金、编报项目支出，不得随意调整资金经济分类明细表中的支出科目。经济分类明细表中没有列支的支出科目，一律不得编报。除个别项目确需列支租车费等其他交通费用外，各单位均不得编报“三公经费”、会议费、其他交通费用等预算。四、省管县的项目纳入所在市级农业行政主管部门统筹考虑，不单独申报。项目申报的具体条件、要求及申报材料格式请查看农业部2018年农业部部门预算项目指南（网址http://www.moa.gov.cn）。五、各单位务必于2017年11月20日前以计财字号文件将项目申报材料报送厅发展计划与财务处和相关业务处（室、局），申报材料在农业部项目指南要求的份数上增加2份。各申报单位通过农业部部门预算项目管理系统（网址：http：//202.127.45.78）进行申报，未通过系统申报或逾期未报的视为放弃。联 '
               '系 '
               '人：邹艳丽联系电话：029-87321683\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年10月19日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于申报2018年农业部部门预算项目的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-10-13 15:55:35',
 'art_detail': '\n'
               '         陕农业发〔2017〕84号\xa0 \xa0 '
               '为加强全省农业品牌建设，促进陕果品牌提升，省农业厅组织开展了全省猕猴桃优秀品牌及优秀电商评选，全省11个市（区）38家企业44个品牌参与评选。经企业自愿申报，市（区）县审查推荐，省级专家评审，决定授予“眉县猕猴桃”等2个品牌为2017年陕西省猕猴桃优秀区域公用品牌；陕西齐峰果业有限责任公司“齐峰缘”商标等16个品牌为陕西省猕猴桃优秀品牌；陕西齐峰果业有限责任公司等10个单位为陕西省猕猴桃优秀电商。请获奖品牌持有单位以此为契机，不断锐意进取，努力打造经得起时间考验的优秀品牌，树立陕果良好形象。全省各级果业部门要以先进为榜样，积极实施品牌战略，不断加大促销力度，共同推动我省优质猕猴桃产业又好又快发展。\xa0'
               '附件：1．2017年陕西省猕猴桃优秀区域公用品牌\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2．2017年陕西省猕猴桃优秀品牌\xa0 \xa0 \xa0'
               '3．2017年陕西省猕猴桃优秀电商\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年10月9日 \xa0附件1\xa0'
               '2017年陕西省猕猴桃优秀区域公用品牌\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
               '区域公用品牌\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '持有单位\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '眉县猕猴桃\xa0 \xa0\xa0\xa0\xa0\xa0\xa0'
               '眉县果业技术推广服务中心\xa0 \xa0 \xa0 \xa0 '
               '周至猕猴桃\xa0 \xa0\xa0\xa0\xa0\xa0\xa0周至县果业局 \xa0'
               '附件22017年陕西省猕猴桃优秀品牌序号品牌名称企业名称1齐峰缘陕西齐峰果业有限责任公司2眉香金果眉县金桥果业专业合作社3秦旺眉县秦旺果友猕猴桃专业合作社4岐安唐陕西永红猕猴桃专业合作社5百恒陕西百恒有机果园有限公司6大爷海宝鸡眉县兄弟果业专业合作社7民香宝鸡民香猕猴桃专业合作社8周一村西安周至周一有机猕猴桃专业合作社9金色梅海眉县金色秦川猕猴桃专业合作社10佳忆德商南县佳忆德果业有限责任公司11鹏盛达眉县鹏盛达农产品购销专业合作社12幸福洋陕西幸福洋果业科技有限公司13猴娃桥眉县猴娃桥果业专业合作社14昕果杨凌森果猕猴桃专业合作社15绿益隆陕西绿益隆农林发展有限公司16Love \xa0 '
               'panbda宝鸡福罗瑞斯园艺有限公司\xa0'
               '附件32017年陕西省猕猴桃优秀电商序号电商企业名称1陕西齐峰果业有限责任公司2陕西玩果电子商务有限责任公司3陕西玩味电子商务有限公司4商南县佳忆德果业有限责任公司5眉县金桥果业专业合作社6陕西云果农业科技有限公司7陕西美农网络科技有限公司8杨凌金红果农业发展有限公司9渭南长寿塬果业种植农民专业合作社10陕西八女子商贸有限公司\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于公布2017年陕西省猕猴桃优秀品牌优秀电商评审结果的通告'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-09-30 11:32:22',
 'art_detail': '\n'
               '         '
               '陕农业发〔2017〕82号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：为贯彻省委脱贫攻坚行动部署，落实产业扶贫精准脱贫工作要求，完成产业脱贫户技术培训全覆盖任务，省农业厅决定在全省开展技术服务百日大行动，编制了《陕西省产业扶贫技术服务百日大行动实施方案》，现印发给你们，请认真贯彻落实。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年9月29日陕西省产业扶贫技术服务百日大行动实 施 方 '
               '案为贯彻落实省委脱贫攻坚行动部署和产业扶贫精准脱贫工作安排，提高科技助推产业精准脱贫能力，如期完成产业脱贫户技术服务全覆盖工作任务，省农业厅决定在全省开展产业脱贫技术服务百日大行动。为确保技术服务扎实有效开展，制定如下方案。一、总体思路根据全省产业扶贫精准脱贫工作部署，发挥科技的助推作用，以提高贫困户生产技能为导向，以增加贫困户产业收入为目标，结合产业发展，按照技术“服务到村、指导到户、精准到人”的总体要求，实现技术培训向技术服务转变，课堂教学向一线实训转变，普及性培训向精准指导转变，专家指导向能人带动转变，确立“做给农民看，教会农民干，帮着农民赚”的新型培训理念，统筹和动员社会各类科技资源，广泛开展多层次、多渠道、多形式的技术服务，提高贫困户的产业发展能力，为产业扶贫精准脱贫提供强力技术支撑。二、目标任务以4个脱贫摘帽县和11个深度贫困县为重点，对56个贫困县全覆盖，以技术服务整村推进为前提，以贫困户为单元，分类施策，精准服务，年底前对39.6万户产业脱贫户，开展全方位、多轮次的技术服务，确保每个脱贫户掌握1-2门生产技能，每个脱贫村培养1名技术能手，增强贫困户产业发展能力。三、工作重点（一）组建技术服务指挥体系。为确保百日行动扎实开展，在各级农业行政主管部门和产业脱贫办的组织领导下，全省建立省、市、县三级产业脱贫技术服务110指挥体系，实行主管领导负责制，专人管理、专人负责、专人调度，总体协调调度技术服务活动。指挥中心向社会公开电话，方便群众、社会、新闻监督单位监督。三级指挥中心遵循服务顺畅、流程规范、零失误的原则，形成上下联动、左右贯通、反应灵敏、快速高效的工作运行机制，做到事事有回应、件件有落实，为贫困户提供高效、快速、便捷技术服务。（二）建立干部包村联户制度。产业脱贫户技术服务，县级是主体。县级农业行政主管部门要统一安排部署，建立技术干部包联贫困村机制，确保每个贫困村至少有1名技术干部。包村干部要增强责任心，定期主动上门，进村入户，研究贫困村和贫困户产业资源、产业基础和制约问题，征询贫困户技术需求，和扶贫包村干部、村级组织共同制定贫困村技术帮扶计划，明确培训内容、培训方式和培训时段，将帮扶计划向县级110指挥中心提出申请，农民教育培训机构3日内，组织完成田间技术指导任务。（三）组建技术团队。全省主要组建4支技术服务团队，在指挥中心调度下，在农民教育培训机构组织下，共同做好贫困户的技术指导。一是组建各级专家团队。省农业厅组建72人组成的陕西省产业扶贫精准脱贫专家服务团，组织29个技术团队对56个贫困县进行对口技术帮扶，市级成立47个专家团队，县级226个，4000名专家参与，共同助力产业脱贫工作。二是组建县级技术服务小分队。县级以基层农业技术人员为主体，组建若干个产业技术服务小分队，作为技术师资纳入县级农民教育培训中心，统一管理，统一调度。三是组建新型经营主体技术团队。充分发挥现代农业园区、农业合作社、家庭农场、农业龙头企业等新型经营主体优势，促进产业带动和技术服务相结合，干中学、学中干，提高贫困户的生产技能。四是组建农业农村能人技术服务团队。充分发挥职业农民、种养大户、农民专家、农村能人技术优势，与贫困户结对子，开展技术传帮带活动，典型引路，示范引导，提高贫困户产业发展能力。（四）精准技术服务。技术服务要坚持问题导向、因人施策的原则，以实用技术为主，分类展开技术帮扶。一是分类开展技术培训。对有劳动力的贫困户，开展定点、定向、菜单式技术指导；对留守妇孺，采取主体带动和托管等方式，带着看、教着干、帮着赚。二是培养农村技术能手。每个贫困村，至少选定1名农村能人，纳入职业农民培育计划，开展能干、能讲、能写的“三能型”技术提升培训，树立典型，做给贫困户看，带领贫困户干。三是开展产业技术指导。农技人员和贫困户建立对口帮扶关系，上门开展点对点、面对面、手把手技术服务；帮助贫困村制定技术帮扶计划，建立帮扶档案，做到一户一本台账、一户一套帮扶措施，实行精准施策。四是职业农民结对帮扶贫困户。发挥持证职业农民技术优势，带动贫困户进园、进社、进场，教技术，传经验；依托国家职业农民培育项目，鼓励职业农民培育对象，和贫困户开展结对帮带扶活动，提高其技术技能。（五）转变服务方式。对贫困户的技术服务，要重心下移，进村入户，根据村级培训计划，合理安排，整村推进。技术干部要主动上门征询贫困户需求，合理安排，确保每一个产业脱贫户都能接受技术服务。技术帮扶全部实行田间教学，充分利用农业园区、农民实训基地、科技示范基地、家庭农场、企业合作社基地，手把手、面对面、点对点地进行培训，提高服务效果。（六）指导实用管用。一是突出转变贫困户思想理念，摒弃固有的观念、陈旧的思想，树立产业脱贫致富的信心，敢于接受新事物、新技术。二是围绕长期和短期产业发展需求，突出生产性技术的简单、明了、实用、实效和轻简化，确保农民一看就懂、一学就会、一干就有效益。三是突出贫困户市场意识教育，加大农产品销售、电子商务等方面培训力度，解决贫困户卖难问题。（七）健全工作档案。三级技术服务指挥110中心，要建立详细工作流程，做好工作记录，跟踪服务效能，全过程存档立卡。县级农民教育机构要建立贫困户技术帮扶档案，做到一村一档装订成册，档案包括村级培训计划，农户培训内容，培训进度和效果，培训资料及讲稿，培训人员花名册等。（八）提升服务效果。技术服务过程中，融入启发式教育，互动式交流，服务结束后，征询服务意见，开展效果评价。包村干部要组织贫困户相互交流，研讨学习成果，畅谈学习收获，互相启发，相互提醒，汇总收集贫困户意见和建议，督促贫困户使用好所学技术，真正做到学有所成、学以致用。四、进度安排全省产业脱贫技术培训百日大行动，从2017年10月开始到2017年12月底结束，共分三个阶段：第一阶段：宣传启动阶段（2017年10月9至20日）省农业厅印发《陕西省产业脱贫技术培训百日大行动实施方案》；各市按照省厅安排部署，成立工作机构，加强协调指导，强化监督考核；各县区加强组织领导，统一安排部署，明确责任主体，制定实施方案，细化工作措施，强化监督落实，建立健全管理制度。第二阶段：组织实施阶段（10月21日至12月31日）全省按照工作方案要求，扎实开展脱贫户技术服务。各级农业主管部门重点抓好指挥调度、运转协调、措施保障，产业脱贫办公室要做好督导检查。各级指挥中心高效、顺畅、规范运转，做好衔接服务。教育培训机构认真组织开展技术服务，做好日常工作管理。第三阶段：考核总结阶段（2018年1月）省级产业扶贫督导考核组对产业扶贫工作考核时，将对县级技术服务百日大行动落实情况进行全面评价。县级要根据考核办法，对指挥中心、培训机构、包抓干部和培训师资进行考核。认真总结百日大行动，挖掘先进经验和典型模式，加以推广。五、保障措施（一）加强组织协调。各级各部门要高度重视技术服务工作，精心组织谋划好百日大行动。各技术推广机构、科研院所、西北农林科技大学、杨凌职业技术学院等要全力支持，全力保障，确保科技人员参与技术帮扶指导。市县要强化组织协调，细化行动方案，明确工作职责、任务和重点，确保技术服务百日大行动取得实效。（二）明确工作职责。省级做好统筹和协调工作；市级负责检查督促本级部门和县区落实大行动各项任务；县级农业局是技术服务的责任主体，一把手负总责，分管领导负主要责任，技术服务指挥中心和农民教育培训机构各司其职，严格流程，抓好落实，强化考核，做好服务保障工作；建立“主要领导全面抓、分管领导定点抓、业务骨干一线抓、技术人员上门抓”的技术包村制度，夯实责任到人。百日大行动实行信息周报制，专人负责，逐级报送工作进展。（三）加大支持力度。省农业厅已经统筹中央和省财政职业农民专项资金，安排一定比例用于支持市县技术服务工作。各贫困县要充分利用省农业厅产业扶贫切块资金和中省产业发展资金等，加大技术服务支持力度，确保百日大行动的资金保障。统筹各类技术资源和成果资源，引导龙头企业、合作社、家庭农场和种养大户技术资源，投身到技术服务百日大行动中，形成强大工作合力。（四）严格督导检查。省厅成立了百日大行动工作促进组，负责抓市督县，各市也要成立相应工作组，对县区工作进行全面督导指导。县级农业部门要对产业脱贫户技术服务百日大行动进行全程监督管理。省农业厅扶贫联县驻村干部要将百日大行动作为工作主要内容，定期对包联贫困县进行督导，省级产业脱贫督导督查组将县级技术服务百日大行动列入督导范围，通过随机抽样，入户调查，加强对县级主体责任的督查，对落实不到位、出现过失的，严格追究责任，确保产业脱贫户技术服务全覆盖。（五）加强宣传引导。各级农业宣传部门，要多种形式宣传，总结大行动中好思路、好经验、好做法，树立有突出贡献的单位和个人典型事迹，激发工作热情，营造社会共同参与支持的舆论氛围。\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅印发陕西省产业扶贫技术服务百日大行动 实施方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-10-13 15:52:41',
 'art_detail': '\n'
               '         陕农业发〔2017〕83号\xa0'
               '为加强全省农业品牌建设，促进陕果品牌提升，省农业厅组织开展了全省苹果优秀品牌及优秀电商评选，全省11个市（区）82家企业95个品牌参与评选。经企业自愿申报，市（区）县审查推荐，省级专家评审，决定授予“洛川苹果”等8个品牌为2017年陕西省苹果优秀区域公用品牌；洛川美域高生物科技有限责任公司“美域高”商标等25个品牌为陕西省苹果优秀品牌；陕西池阳绿农电子商务有限公司等20个单位为陕西省苹果优秀电商。请获奖品牌持有单位以此为契机，不断锐意进取，努力打造经得起时间考验的优秀品牌，树立陕果良好形象。全省各级果业部门要以先进为榜样，积极实施品牌战略，不断加大促销力度，共同推动我省优质苹果产业又好又快发展。\xa0'
               '附件：1．2017年陕西省苹果优秀区域公用品牌\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2．2017年陕西省苹果优秀品牌\xa0 \xa0 \xa0'
               '3．2017年陕西省苹果优秀电商\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年10月9日 \xa0附件1\xa02017年陕西省苹果优秀区域公用品牌\xa0\xa0\xa0\xa0\xa0 '
               '区域公用品牌\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '持有单位\xa0\xa0\xa0\xa0\xa0 '
               '洛川苹果\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0'
               '洛川县苹果产业协会\xa0\xa0\xa0\xa0\xa0 '
               '白水苹果\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0'
               '白水县果业局\xa0\xa0\xa0\xa0\xa0 咸阳马栏红苹果\xa0\xa0 \xa0\xa0\xa0\xa0\xa0'
               '咸阳市果业协会\xa0\xa0\xa0\xa0\xa0 '
               '铜川苹果\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '铜川市果业局\xa0\xa0\xa0\xa0\xa0 '
               '榆林山地苹果\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0'
               '榆林市农学会\xa0\xa0\xa0\xa0\xa0 '
               '旬邑苹果\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0'
               '旬邑县果业服务中心\xa0\xa0\xa0\xa0\xa0 '
               '凤翔苹果\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0'
               '凤翔县农产品质量安全检验\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0'
               '检测站\xa0\xa0\xa0\xa0\xa0 '
               '长武苹果\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0'
               '长武县果业服务中心 \xa0'
               '附件22017年陕西省苹果优秀品牌序号品牌名称企业名称1美域高洛川美域高生物科技有限责任公司2陕富陕西富县绿平果业有限责任公司3YANDI陇县盛源果品有限责任公司4九州龙陕西九州果业有限公司5畔里洛川石泉畔里苹果专业合作社6雍翔红凤翔县南务红苹果专业合作社7子午水晶陕西子午实业发展有限公司8果哒哒延安中果生态农业科技股份有限公司9曹儒凤翔县绿宝果业有限责任公司10延刚洛川民丰农民专业合作社11韓仕凱逹洛川县凯达果品有限责任公司12高塬凤陕西供销集团铜川高塬农业有限公司13汇承陕西杨凌汇承果业技术开发有限责任公司14鑫富百洛川县富百苹果专业合作社15硕耀铜川市耀州区柳林果品专业合作社16秦平澄城县润康源苹果农民专业合作社17绿冰富县宏佳果贸有限责任公司18奇果铜川市印台区奇威果业农民专业合作社19老舅家铜川市绿岭果业有限公司20周原红岐山县金红苹果专业合作社21爷台山淳化恒春苹果专业合作社22洛富洛川绿塬红苹果专业合作社23宜壶宜川县高树梁果业专业合作社24秦源香扶风县六盘山果业贸易有限责任公司25鼎四方蒲城县四方苹果专业合作社\xa0'
               '附件32017年陕西省苹果优秀电商序号企业名称1陕西池阳绿农电子商务有限公司2陕西子午实业发展有限公司3延安中果生态农业科技股份有限公司4陕西玩味电子商务有限公司5陕西黄土高坡农林畜发展有限公司6陕西富平御品人间农业开发有限公司7陇县昊盛电子商务有限公司8岐山科力果业专业合作社9陕西兰花花生态农产品开发有限公司10榆阳区陕北兄弟杂粮专业合作社11铜川市印台区五顺果业农民专业合作社12陕西德联创电子科技有限公司13绥德县焉头农副产品网专业合作社14铜川市印台区奇威果业农民专业合作社15岐山县老果农苹果专业合作社16铜川秦安现代农业投资有限公司17陕西杨凌汇承果业技术开发有限责任公司18礼泉县君德宝种植养殖专业合作社19延川荣泽工贸有限责任公司20陕西顶端果业科技有限公司\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于公布2017年陕西省苹果优秀品牌优秀电商评审结果的通告'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-10-10 15:49:23',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕112号各设区市农业（农林）局（委），杨凌示范区农业局、韩城市农林局：为落实产业扶贫精准脱贫工作要求，扎实开展产业扶贫技术服务工作，实现技术培训向技术服务转变、课堂培训向实训转变、专家指导向综合服务转变，确保产业脱贫户技术服务全覆盖。经研究，决定组建省市县三级产业脱贫技术服务110指挥体系，现就有关事项通知如下：一、功能职责110指挥体系主要负责协调调度贫困户技术服务工作，24小时运转，公开接收村级和贫困户个人技术需求，指令农民教育培训机构尽快落实，完成指导任务。二、组织结构110指挥体系实行层级管理制度，省、市、县分级成立产业脱贫技术服务110指挥中心。110指挥中心由各级农业行政主管部门组建，挂牌运行。指挥中心设指挥1-2名，分管领导任指挥，调度3-6名。指挥负责指挥中心运行，调度具体负责接收指令、跟踪问效和信息收集工作。三、工作流程（一）制订计划。县级下派技术干部包村，技术干部进村入户征询产业脱贫户技术需求，制订村级技术服务计划，上报县级指挥中心。（二）发布指令。县级指挥中心接到村级培训需求后，指令县农民教育培训机构开展服务活动。（三）技术服务。县级农民教育培训机构接受指令后，组织协调技术服务小分队和社会师资，3日内在指定地点完成技术服务任务。（四）联动运行。县级指挥中心在协调工作中遇到困难，向市级指挥中心请求协助，市级中心在县际间和市级机构间协调解决，如仍无法解决，向省级中心请求协助，省级中心在全省范围内协调解决。四、有关要求（一）加强组织领导。省农业厅组建了产业脱贫技术服务110指挥中心，各市、县农业部门要参照成立指挥中心，于10月12日前，将市、县级机构和人员、电话报省农业厅备案。10月15日起，全省110指挥体系正式启动运行。（二）落实主体责任。县级农业行政主管部门是产业脱贫技术服务的责任主体，尽快成立若干产业技术服务小分队，保证及时到户指导；建立干部技术包村制度，确保1个贫困村1名，逐户征询，制订村级贫困户技术服务计划；各级农业部门大力支持指挥中心和农民教育培训机构工作，确保各类师资能按时、保质完成任务。县级农民教育培训机构是日常工作机构，服从指挥中心调度，统筹协调师资、教材、培训经费等，按照村级培训计划和贫困户个人需求完成服务任务。（三）确保政令畅通。指挥体系必须运行规范、反应灵敏、快速高效，政令畅通，下级服从上级，有令必行，行必顺畅，形成上下联动、左右贯通的工作机制，做到事事有回应、件件有落实，为群众提供优质服务。（四）健全工作制度。实行工作时限制，县级指挥中心接到村级培训请求后，立即向农民教育培训机构发出指令，3日内完成服务任务。规范运行管理，制定工作计划，完善工作记录，健全工作档案。实行信息畅通制，各级指挥中心将服务电话向社会公布，并张贴到村到户，电话24小时畅通，随时接讯，及时处理，方便群众、社会、新闻单位监督。实行首问负责制，工作人员要端正服务态度，全程跟踪服务，提高服务效率。实行信息周报制，调度每周将技术服务进展报送本级指挥，指挥分析后，报送主要领导、本级产业脱贫办公室和上级指挥中心。（五）强化督促考核。市、县农业行政主管部门要对技术服务工作进行检查监督考核。省农业厅产业脱贫督导督查组和省厅联县驻村干部，要将县级技术服务列入督查督导范围，对责任落实不到位、出现责任过失的，严格追究责任，确保产业脱贫户技术服务全覆盖。  '
               '联系人：厅科教处\xa0 程丽娟\xa0 '
               '029-87316106\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0'
               '15202964581\xa0\xa0\xa0\xa0\xa0\xa0\xa0 省农广校\xa0 张爱华\xa0 '
               '029-87314637\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '13279281996\xa0'
               '附件：省级产业脱贫技术服务110指挥中心成员名单\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年9月29日附件\xa0省级产业脱贫技术服务110指挥中心成员名单\xa0指挥：戴建昌\xa0 '
               '省农业厅科教处长\xa0\xa0 \xa0\xa0\xa0\xa0\xa0'
               '电话：029-87321782\xa0 \xa0 \xa0 张养利 \xa0省农民教育培训中心主任 \xa0'
               '电话：029-87322635调度：庞怀礼 \xa0省农业厅科教处调研员 \xa0\xa0\xa0'
               '电话：029-87318202\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '18209237126\xa0 \xa0 \xa0 吴晓红 \xa0省农民教育培训中心副主任 \xa0'
               '电话：029-87322634\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '13572176815\xa0 \xa0 \xa0 申\xa0 巍 \xa0省农业厅科教处副调研员\xa0 \xa0'
               '电话：029-87321775\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '187106447785\xa0 \xa0 \xa0 张爱华 \xa0省农民教育培训中心科长\xa0 \xa0 '
               '电话：029-87314637\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '13279281996\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于建立产业脱贫技术服务110指挥体系的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-09-29 10:17:29',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕107号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：按照《农业部办公厅关于开展农药大检查保障农产品质量安全的通知》（农办农〔2017〕24号）要求，为进一步加强农药管理，严格控制农药生产、经营、使用中存在的安全风险，切实保障农业生产和农产品质量安全，为党的十九大胜利召开营造和谐稳定环境，我厅决定于2017年9月下旬至10月中旬在全省开展农药大检查。现就有关事项通知如下。一、总体要求认真贯彻落实中央关于农产品质量安全的决策部署和国务院领导的重要指示精神，以落实《农药管理条例》及配套规章为契机，结合陕西省农业厅办公室《关于印发陕西省农药行业安全生产大检查实施方案》（陕农业办发〔2017〕105号），坚持问题导向，突出重点环节，强化责任落实，集中开展农药大检查，重点排查非法非标生产农药、违规经营农药、超限使用农药等问题，及时整改、依法处置，防止出现农药生产、经营、使用安全事故，保障农业生产安全、农产品质量安全和生态环境安全。二、检查重点（一）依法依规生产情况。重点检查农药登记证、生产许可证或批准证书等证件是否齐全，农药产品是否依法依规生产，原材料采购与产品生产销售记录是否规范。对生产限制使用农药的企业，要追溯产品去向。对近年发现存在质量问题严重或群众举报反映强烈的企业，要重点抽查产品质量。排查无证生产农药情况，严格依法查处非法非标生产、制假售假、违规添加其他农药成分的企业。（二）高毒农药经营情况。重点检查农药经销商是否存在违规销售高毒农药、无证农药、假冒伪劣农药等行为。对蔬菜、瓜果、茶叶、食用菌和中草药材等经济作物主产区及粮经作物混作区的高毒农药经营门店，重点检查是否有专柜销售、实名购买、台账记载，掌握高毒农药进货来源和销售去向。（三）科学选药用药情况。针对果菜茶重点产区，检查农药禁限用措施落实情况。对重点种植大户、农民合作社及统防统治组织，检查农药使用记录，是否存在违规在蔬菜、瓜果、茶叶、食用菌和中草药材等作物上使用甲拌磷、克百威、涕灭威等高毒农药的情况，是否超剂量、超范围、缩短安全间隔期使用农药。加强农药残留检测，重点检测种植大户、农民合作社等单位，对检出禁用农药和残留超标的，要及时采取召回、销毁等措施控制风险，并追查源头、追踪流向，依法追究相关责任。三、检查方式（一）开展自查。大检查采取自查与抽查相结合的方式。自查阶段由各县区结合本地农药生产经营及农业生产实际，制定本辖区农药大检查具体实施方案，并按照方案深入开展相关内容的自查。自查的重点是辖区内农药生产、经营和使用中非法非标生产农药、违规经营农药和超限使用农药等问题，特别是对种植大户、农民合作社、统防统治组织等新型经营主体要重点排查。（二）督查抽查。督查由各市组织实施，各市要抽调机关干部和技术人员组成联合工作组，对本辖区内各县区的农药生产、经营和使用情况及自查情况进行督查。省农业厅将结合全省农药行业安全生产大检查开展情况，在各县区自查、市级督查的基础上，配合农业部检查工作组，适时开展督导和随机抽查。四、保障措施（一）加强组织领导。省农业厅成立农药大检查领导小组，分管厅领导任组长，厅种植业处主要负责同志任副组长，厅办公室、厅法规处、省农业技术推广总站、省植保植检站、省农药检定所主要负责同志为成员，办公室设在省农药检定所。各市县要成立由政府分管负责同志任组长的农药大检查工作领导小组，精心组织，广泛动员，落实责任，全面开展农药大检查。（二）创新检查方式。各地在开展农药大检查中，要坚持问题导向、创新检查方式，确保检查取得实效。上下联动检查。上一级制定检查方案，落实工作责任，开展工作督导。下一级严格按照上一级的方案要求和工作任务，细化措施，逐项落实。自查抽查结合。以高度的自觉开展自查，尽力做到全覆盖，不留死角。同时，开展督导和抽查，做到任务落实、措施落实。在农药生产经营重点省份和果菜茶重点产区，以县为单位组织开展交叉检查，做到相互学习、相互促进。（三）依法依规处置。对检查中发现有违规生产、经营和使用的，要依照《农药管理条例》的规定和相关法律的要求，严格处置、依法处置。对造成农业生产和农产品质量安全事件的经营者和使用者，依法严惩。构成犯罪的，要依法追究刑事责任。（四）强化宣传引导。各市县要充分利用报刊、广播电视及新媒体，宣传开展农药大检查的重要性和紧迫性，广泛动员社会力量，参与并支持农药大检查。农业部门要密切关注舆情动态，及时回应舆论关切，组织专家学者、权威机构等进行科学解读，避免引发不实炒作。并将农药大检查好做法、好经验进行广泛宣传，营造农药监督良好氛围。（五）加强信息报送。市县农业部门要认真总结分析本辖区农药生产、经营和使用的基本情况、存在问题，进行认真梳理，同时对本次农药行业安全生产大检查的主要经验做法、取得成效、影响农业生产和农产品质量安全的突出问题、意见建议等进行全面总结。各市级农业部门务必于10月15日前将本辖区农药大检查总结报告（含电子版）报送厅种植业管理处和省农药管理检定所。省农药管理检定所 '
               '联系人：郭学军联系电话：029-87321947邮\xa0\xa0\xa0 '
               '箱：icasx@163.com\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年9月22日\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室 关于开展农药大检查保障农产品质量 安全的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-09-04 16:00:02',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕85号各设区市农业（农林）、畜牧局（委）、财政局，杨凌示范区农业局、财政局，韩城市农林局、财政局，各有关省财政直管县农业局、财政局：为了做好我省2017年动物疫病防治工作，根据财政部《关于拨付2017年动物防疫等补助经费的通知》（财农〔2017〕62号）精神，省农业厅与省财政厅共同研究，现将2017年中央动物防疫资金计划下达你们，并就有关事项通知如下。一、工作目标通过项目实施，进一步提高经费统筹使用效率；确保强制免疫密度达到90%，平均抗体合格率常年保持70%以上；保障强制扑杀措施实施，有效控制和清除传染源；促进养殖环节病死猪无害化处理率不断提高，有效预防、控制和扑灭动物疫病，促进养殖业发展，保护人体健康，维护公共卫生安全。二、项目内容及经费安排按照财政部、农业部《关于印发&lt;动物防疫等补助经费管理办法&gt;的通知》（财农〔2017〕43号）和农业部、财政部《关于调整完善动物疫病防控支持政策的通知》（农医发〔2016〕35号），以及省农业厅、省财政厅印发的《陕西省调整完善动物疫病防控支持政策暂行方案的通知》（陕农业发〔2016〕102）精神，按照“大专项＋任务清单”有关要求，主要实施以下项目内容。（一）强制免疫补助资金。强制免疫项目主要是用于实施国家重点动物疫病开展强制免疫、免疫效果监测评价、人员防护等相关防控措施，以及实施强制免疫计划、购买防疫服务等方面。按照《农业部财政部关于调整完善动物疫病防控支持政策的通知》（农医发〔2016〕35号）以及省农业厅、省财政厅印发《陕西省调整完善动物疫病防控支持政策暂行方案的通知》（陕农业发〔2016〕102号）精神，原中央财政安排的基层动物防疫工作补助经费一并纳入强制免疫补助。1．购置强制免疫疫苗。省级严格审核各市申报的疫苗计划，并结合疫苗实际招标价格和疫苗用量，经测算，本次拨付各市和省农业厅（省动物卫生监督所）强制免疫疫苗经费5643万元（详见附件），杨凌示范区疫苗经费（数量较少），安康、商洛市少量奶牛A型口蹄疫疫苗经费下达省农业厅（省动物卫生监督所），由省农业厅（省动物卫生监督所）与供货企业结算。按照强制免疫疫苗据实结算的要求，本次下达的经费同陕农业计财〔2017〕41号文件下达的疫苗配套经费以及陕农业计财〔2016〕111号文件预拨的疫苗经费一并用于本年度疫苗经费结算。2017年强制免疫疫苗中标供货企业及费用结算由省农业厅（省动物卫生监督所）另行通知。2．实施强制免疫计划。按照农业部和我省2017年动物疫病强制免疫计划，对高致病性禽流感、口蹄疫、布鲁氏杆菌病、小反刍兽疫等畜禽重大动物疫病进行强制性免疫。根据主要强制免疫畜禽疫病工作量，结合我省畜牧业规模化发展现状，按照原中央拨付我省的基层动物防疫工作经费规模进行测算，并对地域大、畜禽存量少、基础设施较差的贫困县和省财政直管县中的山区县进行倾斜（资金从养殖规模化程度较高、地方财政较好的市县调剂），主要用于开展免疫效果监测评价所需试剂、药品、耗材等。每个市级10万元；每县（区、市）2万元，其中56个贫困县区每县3万元；韩城市5万元；省农业厅（省动物疫病预防控制中心）免疫效果监测评价50万元，共计423万元。分配方案详见附件。3．评价免疫监测效果。根据《2017年陕西省动物疫病监测和流行病学调查计划》免疫效果监测评价的要求，对各市（含所有涉农县、区、市）开展免疫效果监测评价工作进行补助，并对贫困县区适当进行倾斜。各设区市市级10万元；每县（区、市）2万元，其中56个贫困县区每县3万元；韩城市5万元；省农业厅（省动物疫病预防控制中心）免疫效果监测评价50万元（详见附件）。4．加强防疫人员保护。根据各市区动物防疫工作任务，对各市（含所有县、区、市）动物防疫人员防护进行补助，并对贫困县区适当进行倾斜，主要用于防疫人员在免疫、监测、动物卫生监督、疫情处理时所需防护用品等。每个市级10万元；每县（区、市）2万元，其中，56个贫困县区每县3万元；杨凌示范区、韩城市各5万元；省农业厅（省动物卫生监督所人员防护经费45万元，省动物疫病预防控制中心人员防护经费10万元）人员防护经费55万元，共计439万元。分配方案详见附件。（二）重大动物疫病强制扑杀补助资金。主要用于2016年3月1日至2017年2月29日期间，因重大动物疫病和奶牛布病、结核监测阳性净化强制扑杀，给予养殖者的补助。根据各市区申报，经审核，分配西安等5市扑杀补助130万元（详见附件）。（三）养殖环节病死猪无害化处理补助资金。主要用于2016年3月1日至2017年2月29日期间，养殖环节生猪无害化处理，给予养殖者的补助。根据各市区申报，经审核，分配西安市等市无害化处理补助943万元（详见附件）。三、有关要求（一）动物防疫等补助经费使用管理坚持公开透明原则，各级兽医主管部门、财政部门要通过多种形式推进信息公开，做好政策内容、补贴对象、补贴标准、受益对象等信息公开公示，认真落实好群众的知情权、参与权和监督权。（二）各级农业、财政部门在资金分配时，要专项用于强制免疫补助、强制扑杀补助、无害化处理补助等，严禁用于兴建楼堂馆所、弥补预算支出缺口等与动物防疫无关的支出。（三）各级财政部门和兽医主管部门要加强动物防疫等补助经费的预算执行管理，提高预算执行的及时性与有效性；同时，要加强对补助经费分配、使用、管理情况进行监督检查，发现问题及时纠正，提高资金使用效益。结转结余的动物防疫等补助经费，按照财政部关于结转结余资金管理的有关规定处理。（四）各市兽医主管部门会同财政部门要于12月20日前报送项目实施总结，内容包括政策落实、预算执行、资金使用、监督管理、存在问题及有关建议等方面。附件：2017年中央动物疫病防治补助经费计划表\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '陕西省财政厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年9月1日附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅 ',
 'art_title': '陕西省农业厅 陕西省财政厅 关于下达2017年中央动物防疫资金 计划的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-08-30 16:47:11',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕84号各设区市农业（农林）局、果业局（委）、财政局，杨凌示范区农业局、财政局，韩城市农林局、财政局：\xa0\xa0\xa0 '
               '为推动农业供给侧结构性改革，培育农业农村发展新动能，促进农业转型升级、提质增效和农民增收，2017年中央财政专项实行“大专项+任务清单”的管理方式，按照“放管结合、效益为先”的原则，在推进项目资金整合的同时，下放资金使用管理权限。为扎实推动项目管理方式改革，切实完成我省相关项目任务，按照《农业部财政部关于做好2017年中央财政农业生产发展等项目实施工作的通知》（农财发〔2017〕11号）要求，省农业厅会同省财政厅研究制定了《2017年陕西省农业生产发展资金项目实施方案》和《2017年陕西省农业资源及生态保护项目实施方案》。现印发给你们，请按照方案要求，做好项目组织实施工作。承担项目任务的贫困县（区）按照中省涉农资金整合支持贫困县发展试点要求，根据各县（区）产业脱贫方案，结合本地实际，开展资金整合。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0'
               '陕西省财政厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年8月29日附件.doc\xa0\n'
               '        ',
 'art_source': '陕西省农业厅 ',
 'art_title': '陕西省农业厅  陕西省财政厅 印发农业生产发展等中央财政专项项目 实施方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-09-05 15:38:13',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕102号各设区市农业（农林）、果业局（委、中心），杨凌示范区农业局，韩城市农林局：为加快我省农业品牌建设，促进农产品电子商务发展，根据农业部、省委省政府关于农业品牌推进工作的要求，我厅决定在全省开展苹果、猕猴桃优秀品牌、优秀电商评选工作，现就有关事宜通知如下：一、申报范围申报范围为陕西省境内苹果、猕猴桃生产、加工、经销企业（合作社、园区）。二、申报条件（一）优秀品牌评选具体要求详见《2017年陕西省苹果猕猴桃优秀品牌评选申报条件》（附件1）。（二）优秀电商评选具体要求详见《2017年陕西省苹果猕猴桃营销电商评选申报条件》（附件2）。三、组织管理（一）本次评选成立领导小组和专家组，领导小组组长由省农业厅分管厅领导担任，成员由相关部门、单位负责同志组成；专家组由省、市、县及科研单位专家组成。（二）此次评选由省农业厅组织，省优质农产品开发服务中心负责实施。（三）苹果、猕猴桃优秀品牌、优秀电商获奖证书、奖牌由省农业厅统一印制、颁发。（四）各地市建立相应评审推荐机构，具体承担本区域内参评品牌和电商的组织申报、评审和推荐工作，对所推荐的产品的真实性和质量负责。四、评选程序本次评选按照申请人申请，市县农业（果业）行政主管部门审核，省农业厅统一组织集中评审的方式，分四个步骤进行。（一）组织申报。申请人按照苹果、猕猴桃类别，如实填写《2017年陕西省苹果（猕猴桃）优秀品牌评选申请表》（附件3）和《2017年陕西省优秀电商评选申请表》（附件4），报所在市县（区）行政主管部门，初审合格后由市级农业（果业）主管部门统一报送省优农中心。（二）组织评审。省农业厅组织专家对申报材料的完整性、真实性、适用性以及对参评企业的经营实力、品牌影响力、销售市场份额、管理能力与发展潜力等进行集中审议，本着优中选优的原则形成拟获奖名单。（三）网上公示。将经过评审的拟获奖名单，在陕西农业网进行公示。（四）颁奖宣传。对于公示后无异议的品牌和企业，由省农业厅发文，在中国&amp;bull;陕西（洛川）国际苹果博览会、中国&amp;bull;陕西（眉县）猕猴桃产业发展大会上颁奖（发布），并做好后续宣传推荐工作。五、有关说明与要求（一）本次评选活动坚持&amp;ldquo;自愿、科学、公开、公正、公平&amp;rdquo;的原则，不收取任何费用。（二）各市要高度重视，组织遴选本地区管理规范、有一定生产规模和市场带动能力的知名企业参与评选。（三）请各市农业（果业）部门按照要求，于9月20日前将附件纸质材料一式两份，审核汇总后报省优质农产品开发服务中心，电子版发送至指定邮箱。（四）本通知和所有附件均可从陕西农业信息网（http://www.sxny.gov.cn）或陕西省优质农产品开发服务网（http://yzncp.sxny.gov.cn）下载。六、联系方式省农业厅市场信息处 '
               '胡维超 029-87321648省优质农产品开发服务中心 黄浩 13488107721连辉 '
               '13572828655联系电话：029-86269692电子邮箱：ynxxke@163.com邮寄地址：西安市莲湖区未央路38号邮政编码：710016附件：1．2017年陕西省苹果猕猴桃优秀品牌评选申报条件\xa0\xa0\xa0\xa0\xa0 '
               '2．2017年陕西省优秀电商评选申报条件\xa0\xa0\xa0\xa0\xa0 '
               '3．2017年陕西省苹果（猕猴桃）优秀品牌评选申请表\xa0\xa0\xa0\xa0\xa0 '
               '4．2017年陕西省优秀电商评选申请表\xa0\xa0\xa0\xa0\xa0 '
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年9月5日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于开展苹果猕猴桃优秀品牌优秀电商评选工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅函',
 'art_date': '2017-09-29 10:21:45',
 'art_detail': '\n'
               '         '
               '陕农业函〔2017〕341号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：根据国务院办公厅《关于进一步加强农药兽药管理保障食品安全的通知》（国办发明电〔2017〕10号）精神和全省农药管理工作推进会要求，为迎接农业部《农药管理条例》专项监督检查，加快推进全省农药经营许可工作，现将有关事项通知如下：一、材料报送（一）农药经营人员专业教育培训机构认定情况；（二）《农药经营许可办事指南》（需加盖单位公章）；（三）农药管理机构、职能、人员编制、经费落实等情况；局党委专题研究《农药管理条例》落实情况；（四）《农药管理条例》宣贯情况及农药安全生产大检查和农药大检查情况。二、信息报送（一）本市（区）及辖区内各县（区）负责农药管理的农业局分管领导姓名、联系方式，主管行政科室名称、负责人及联系人姓名、联系方式等信息；（二）本市（区）及辖区内各县（区）具体从事农药管理工作的机构名称、负责人、联系人姓名、联系方式等信息。三、有关要求（一）高度重视。此次需要报送的信息和材料较多，涉及不同的单位和部门，各市（区）要高度重视，明确部门，做好协调衔接工作，指定专人进行相关信息、材料的收集和汇总，并按要求进行上报。（二）及时上报。各单位务必于2017年9月30日12：00前将上述信息和材料以正式文件上报省农业厅种植业处及省农药管理检定所，并将电子文件发送至指定邮箱，10月1日之后我厅将对各市(区)信息和材料上报情况进行通报。联系人：省农药管理检定所 '
               '白伟联系电话：029-87334420\xa0 '
               '13991856361邮箱：icasx@163.com\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年9月26日\n'
               '        ',
 'art_source': '陕西省农业厅 ',
 'art_title': '陕西省农业厅关于报送农药管理工作相关情况的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-09-04 14:48:02',
 'art_detail': '\n'
               '         '
               '陕农业发〔2017〕72号根据《中华人民共和国种子法》《农作物种子生产经营许可管理办法》及《植物新品种保护条例》等法规定，经审核，批准发放榆林市金日种业有限责任公司等6家企业《农作物种子生产经营许可证》（详见附件）。特此通告。附件：农作物种子生产经营许可证企业名单\xa0\xa0'
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年9月1日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于核发农作物种子生产经营许可证的通告'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-09-29 10:14:31',
 'art_detail': '\n'
               '         '
               '各设区市农业（林）局（委），杨凌示范区农业局，韩城市农林局：为贯彻落实新修订的《农药管理条例》对限制使用农药的管理要求，省农业厅制定了《陕西省限制使用农药定点经营布局规划（征求意见稿）》，现公开征求各地意见。请结合当地实际，认真研究，提出修改意见，务于9月25日前报省农药管理检定所。逾期未报，按无不同意见处理。联系人：霍缙巍 '
               '电话87331231\xa0 '
               '邮箱16187823@qq.com\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年9月18日陕西省农业厅限制使用农药定点经营布局规划（征求意见稿）为进一步加强限制使用农药管理，规范农药市场秩序，促进全省农药产业健康有序发展，提高农药经营和使用水平，根据《农药管理条例》和《农药经营许可管理办法》等法规、规章和规定，制定本规划。一、指导思想以习近平总书记“绿色发展理念”为指引，以当地农业生产布局规划和病虫害发生实际为依据，科学布局限制使用农药经营网点数量和地理分布，通过进一步强化经营主体责任、管理部门监管责任，推进科学用药，促进规范运行，加强市场监管，保障我省农业生产安全、农产品质量安全和生态环境安全。二、目标任务通过合理布局、总量控制，严字当头，强化管理等多项措施，力争在年底完成全省限制使用农药定点经营布点工作；发布全省限用农药名录；实现限制使用农药销售100%信息可查询、流向100%可跟踪、质量100%有保证。三、限用品种限制使用的农药品种主要包括高毒、高残留和高风险农药三类。省农业厅对农业部正式公布的限制使用农药品种名单和以农业部（或农业部办公厅）文件（部令或部公告）形式发布的限制使用农药品种进行常年挂网并及时更新；对以陕西省政府（省政府办公厅）文件（令或公告）形式发布的限制使用品种进行梳理并向社会进行公布。四、基本原则1.总量控制原则。各级农业行政主管部门要按照区域、集点、交通等进行科学布局，保证农业生产用药基本需要。县级在县域内而已数量不超过5家；每个设区市级根据不同县级产业现状，可调剂不超过10家；省级在市级间调剂不超过30家，全省总数不超过665家，杨凌、韩城按县级数量布局。要严格控制数量，科学布局，采取择优公开等方式确定限制使用农药经营者。2.区域品种限制原则。为保障农业生产安全、农业产业安全，我省对定点经营单位销售的限制使用农药品种按照地域和种植区域的不同，实行品种限制。蔬菜、果树、茶叶、食用菌、中药材等种植区域集中的乡镇和处于人类生活水源地所在的乡镇内禁止经营剧毒、高毒农药；在旱作粮食主产区禁止经营残留期较长的除草剂；在特定品种果区禁止经营植物生长调节剂。3.实名购买原则。定点经营单位销售的限制使用农药统一实行实名制购买，凡购买限制使用农药者，须出示有效身份证件并如实报明使用用途。经营者须对购买者进行实名登记，购买者不出示有效身份证件或不充分说明所购限制使用农药用途的，经营者不得向其销售限制使用农药。4.销售风险告知原则。限制使用农药销售者在销售限制使用农药时，应以书面风险单的形式告知购买者限制使用农药的使用范围、剂量和使用带来的风险，在涉及高毒农药时还应重申高毒农药禁止用于蔬菜、果树、茶叶、食用菌、中药材等农作物上，购买者必须在告知风险单上签字确认，否则，经营者不得销售。五、组织实施1.优化定点单位布局。我省实行高毒农药定点经营以来，在保障农业生产和产业发展方面发挥了重要作用。各地要在原高毒农药定点单位的基础上进一步优化，更加合理地科学布局，要把限制使用农药定点经营单位规划布局作为提升农产品质量安全和农业生产安全的重要载体，摆上更加突出位置，创新工作思路，认真组织实施。2.明确申请审批程序。申请限制使用定点经营单位必须是已取得农药经营许可资格并符合定点经营布局规划。审批实行省级受理审查，县级现场审核，市级出具符合定点布局证明，省级审批的程序。县级负责受理本行政区域内和经营地址（或库房）在本辖区内的限制使用农药经营单位的申请，负责对经营人员年限，销售专柜（加锁）和有关规章制度等3个方面进行审查，对通过公开竞争的方式达到限制使用经营单位标准的上报市级。市级按上述原则对县级上报的进行审核，符合要求的出具符合定点经营布局证明上报省级。省级按照法定程序对全省限制使用经营单位进行审批，统一颁发限用农药定点经营许可证，同时收回农药经营许可证。3.监测限制使用品种。各地要对辖区内的限制使用农药品种进行动态监测分析，随时掌握使用品种、使用量，对使用效果进行风险评估，采取得力措施降低使用风险，并于每年的6月30日前和12月30日前上报有关情况。同时，对辖区内种植品种结构、面积以及影响产业发展的农药品种进行统计上报，省上将根据各地农药品种使用风险情况，制定全省限用农药品种区域名录。六、保障措施1.加强风险宣传。各地要把限制使用农药的风险通过广播、电视、网络、岗前培训班、座谈会、宣传标语、专题培训等多种形式向广大群众，尤其是农药经营人员、种植户广泛宣传，尽量减少限制使用农药用量，做到能不用尽量不用，必须要用时尽量少用。要把限制使用农药定点经营的重要意义和有关要求进行认真全面的解读，使其深刻领会定点经营的重要性、必要性和紧迫性，为限制使用农药定点经营的开展营造良好的社会氛围。2.严格落实规划。各地要严格按照规划要求，围绕农业生产安全和农产品质量安全，在不超过规划数量的前提下，在本辖区内合理设置定点经营单位，做到每个定点单位都有设置的依据和合理性。同时，对申请定点经营单位资格的，严格进行资料审查和现场审查，要公平公开、严格条件、规范程序，所有从事定点经营审批的单位和个人，均要按制度办事，用制度约束人，用制度规范审批。3.强化监督检查。各地要加大对限制使用农药经营的监管力度，严格按照要求对定点经营单位进行管理，对未按规定执行的定点经营单位责令限期整改，累计超过3次以上，取消其定点经营资格。对非定点经营单位擅自销售限制使用农药的行为，要按照未取得农药经营许可证严肃处理，严厉查处利用互联网经营限制使用农药的行为。4.加强组织领导。定点经营规划布局是贯彻落实新修订农药管理条例的一项重要内容，各级农业行政主管部门要高度重视，严密组织，做到一把手负总责，分管领导亲自抓，农药监管机构要做好各项具体工作。各市农业行政主管部门务必在10月31日前将辖区内县（区）、乡两级的种植结构、定点单位的数量和分布，以及影响本区域农业产业发展的农药品种进行分类汇总上报。\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅 关于征求〈陕西省限制使用农药定点经营布局 规划(征求意见稿)} 意见的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-09-07 17:02:16',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕87号各设区市农业（农林）局（委）、果业局，杨凌示范区农业局，韩城市农林局，有关省财政直管县农业局：为扎实推动中央财政专项 '
               '“大专项+任务清单”管理方式改革，切实完成我省相关项目任务，按照《农业部财政部关于做好2017年中央财政农业生产发展等项目实施工作的通知》（农财发〔2017〕11号）和《陕西省农业厅陕西省财政厅印发农业生产发展等中央财政专项项目实施方案的通知》（陕农业计财〔2017〕84号）要求，我厅研究制定了《2017年陕西省果菜茶有机肥替代化肥试点工作方案》《2017年陕西省部级绿色高产高效创建项目实施方案》《2017年陕西省耕地保护与质量提升工作方案》《2017年陕西省旱作农业技术推广项目实施方案》《2017年陕西省部级农业生产社会化服务项目实施方案》《2017年陕西省农业生产发展资金支持茶产业发展项目实施方案》《2017年陕西省支持农民合作社发展项目实施方案》《2017年陕西省农村一二三产业融合发展项目实施方案》。现印发给你们，请按照方案要求，抓紧做好项目组织实施工作。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa02017年9月6日附件.docx\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅 印发2017年果菜茶有机肥替代化肥试点等 中央财政专项项目实施方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅函',
 'art_date': '2017-09-29 10:32:28',
 'art_detail': '\n'
               '         '
               '陕农业函〔2017〕345号各设区市农业（林）局（委），杨凌示范区农业局，韩城市农林局：根据新修订的《农药管理条例》和农业部《农药经营许可管理办法》，省农业厅制定了《陕西省农药经营许可审查细则》（征求意见稿）、《陕西省农药经营许可工作程序》（征求意见稿），现公开征求各地意见。请结合当地实际，认真研究，提出修改意见，务于10月10日前报省农药管理检定所。逾期未报，按无不同意见处理。联系人：雷琪电话：87337703邮箱：1094543812@qq.com\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年9月27日陕西省农药经营许可审查细则（征求意见稿）第一章\xa0 '
               '总则第一条为贯彻落实《农药管理条例》和《农药经营许可管理办法》，规范农药经营许可审查行为，特制定《陕西省农药经营许可审查细则》。第二条\xa0 '
               '本细则所称农药经营许可审查，是指对农药经营者从机构与人员、场所与设施、制度与记录等方面进行的书面审查和实地核查。第三条\xa0 '
               '农药经营许可审查应坚持依法、公平、公正的原则，合理作出审查意见。第四条\xa0 '
               '农药经营许可审查，应当根据申请人所提交的材料和场地设施进行逐项审查，逐项作出审查结论。第五条\xa0 '
               '本细则适用于陕西省农药经营者。第二章\xa0 机构与人员第六条\xa0 '
               '农药经营者应当具有统一的社会信用代码，有明确的法定代表人（负责人），有与经营规模相适应的农药经营人员。第七条\xa0 '
               '设立分支机构的，应当注明分支机构的营业场所和仓储场所地址等事项，分支机构应具备农药经营场所的基本设施和条件，免予办理农药经营许可证。农药经营者应当对其分支机构的经营活动负责。限制使用农药经营者的分支机构不得经营限制使用的农药品种，需要经营限制使用农药的应当符合限制使用农药定点经营规定。第八条\xa0 '
               '农药经营人员应当具备下列条件之一：（一）具有农学、植保、农药等相关专业中专以上学历，不少于8学时的农药法律法规培训；（二）具有农业部颁发的农资营销员职业资格证书，不少于8学时的农药法律法规培训；（三）不少于56学时的系统培训学习。第九条\xa0 '
               '经营限制使用农药的农药经营人员除具备上述第八条外，并应有两年以上从事农学、植保、农药相关工作的经历。第三章\xa0 '
               '场所与设施第十条\xa0 '
               '农药经营者应当具有固定的经营场所和仓库，布局合理，与其他商品以及饮用水水源、生活区域等有效隔离，并配备相应的消防、防盗等设施。兼营其他农业投入品的，应具有相对独立的农药经营区域和仓储区域。第十一条\xa0 '
               '农药经营者的营业场所和仓库场所应当与经营规模相适应，并符合以下规定：（一）营业场所面积不少于30平方米、仓库场所面积不少于50平方米；营业与库房在同一个场所的农药经营者，柜台与库房应有所隔离，其总面积不少于80平方米。（二）只从事批发业务的农药经营者，可不设置零售柜台、货架等，但其办公场所面积应不少于30平方米，仓库面积应不少于100平方米。第十二条\u3000'
               '农药经营者的经营地点应与申请书一致，可以在经营许可证发放机关的辖区范围内设立分支机构，统一配置仓储和相关设施、设备，营业场所不少于30平方米。第十三条农药经营者应当具有与经营的农药品种、规模相适应的设施、设备，并应满足不同农药品种分区、分类保管、储存的要求。（一）有可追溯电子信息码扫描识别设备和用于记载农药购进、储存、销售等电子台账的计算机管理系统；\u3000\u3000'
               '（二）与经营农药相适应的柜台、专柜；\u3000\u3000（三）有通风、消防、防盗的设施；\u3000\u3000'
               '（四）有防潮、防霉的设施、设备。第十四条\u3000'
               '农药经营者的营业场所和仓库应当干净整洁，货品摆放整齐并设立醒目标志。第十五条经营限制使用农药的，应符合全省限制使用农药的定点经营布局规划，有明显标识的销售专柜、仓储场所及其配套的安全保障设施、设备。第十六条农药陈列、储存应当符合下列要求：（一）按照杀虫剂、杀菌剂、除草剂等进行分类摆放，常规农药应与特殊农药分区存放（经营卫生用农药的，应当将卫生用农药与其他农药分开）；（二）按照农药外包装图示标志的要求搬运和存放；（三）与仓库地面、墙、散热器或供暖管道等之间保持一定间距；（四）陈列存放场所内不得存放食品、食用农产品、饲料等。第四章\xa0 '
               '制度与记录第十七条\u3000'
               '农药经营者应当建立以下各类管理制度：（一）进货查验和进销货台账制度；（二）安全管理和安全防护制度；（三）应急防护和应急处置制度；（四）经营场所和仓储管理制度；（五）农药废弃物回收与处置制度；（六）农药使用指导制度；\u3000\u3000\xa0\xa0\xa0'
               '（七）产品召回制度；（八）人员岗位与培训学习制度；（九）环境卫生管理制度。第十八条\xa0 '
               '农药经营者要按统一要求填写购销台账，同时应设计合理的表式，对其他各项制度的落实进行详细记录。记录要及时、真实、准确、完整，具有可追溯性，并保存两年以上。第十九条\xa0 '
               '农药经营者应当采购合法农药产品，购进农药应当按照以下程序进行：（一）对进行业务联系的供货人员进行身份确认，查验供货单位介绍信和供货人员身份证。（二）确定供货单位的资质，查验营业执照（或统一社会信用代码）、农药生产许可证（供货单位为生产企业的）和农药经营许可证（供货单位为经营企业的）。（三）对货物的外观、数量、有效期等进行查验，查验无误后方可进货，同时索要进货票据，做到有效凭证、账、货、记录相符。（四）审核所购入农药的证件和标签，农药有关证件包括农药生产许可证、农药登记证号、农药标准号和产品合格证，同时农药标签（或说明书）应完整无残缺，与网上备案标签一致。（五）做好入库记录。第二十条\xa0 '
               '禁止向未取得农药生产许可证的农药生产企业或者未取得农药经营许可证的其他农药经营者采购农药。第二十一条\xa0 '
               '农药经营者应当及时清查农业部门公布的假劣农药，并做好记录。第二十二条\u3000'
               '农药经营者销售农药时应当向购买人询问病虫害发生情况并科学推荐农药，必要时应当实地查看病虫害发生情况，并正确说明农药的使用范围、使用方法、剂量、使用技术要求和注意事项，不得误导购买人。第二十三条\xa0 '
               '农药经营者销售限制使用农药时，应当遵守限制使用农药的管理规定，应取得限制农药经营定点许可、设立醒目标志，采取实名制购买、弄清去向、标明实际用途等，同时为农药使用者提供用药指导，鼓励开展统一用药服务。第二十四条\xa0 '
               '农药经营者销售农药时，应当开具有效凭证，做到有效凭证、账、货、记录相符。第二十五条\xa0 '
               '限制使用农药不得利用互联网经营。第二十六条\xa0 '
               '农药经营者应按照农药标签或说明书进行宣传，不得误导购买者。第二十七条\xa0 '
               '农药经营者应当向购买者提供技术咨询服务，在经营场所明示服务公约和质量承诺，公布当地农药管理部门监督电话，设置意见簿，指导购买者科学、安全、合理使用农药。第五章\u3000'
               '审查结论第二十八条\u3000'
               '实地核查的审查结论包括单项审查结论和综合审查结论。实地核查的审查人员应当对照《陕西省农药经营许可审查表》（附件）的每个项目，逐项作出单项审查结论。单项审查结论为“合格”“轻微缺陷”“不合格”“不适用”。其中，“合格”是指符合相应的规定，“轻微缺陷”是指存在偶然的、孤立的，且是性质一般的问题；“不合格”是指存在区域性的或系统性的问题。对审查结论为不合格或轻微缺陷的，应当逐项说明理由。综合审查结论分为“合格”“基本合格”“不合格”。（一）所有审查项目为“合格”的，综合审查结论为“合格”。（二）同时符合以下情形的，综合审查结论为“基本合格”：１.单项审查结论未出现“不合格”；２.关键项目的审查结论未出现“轻微缺陷”，非关键项审查结论为“轻微缺陷”的总数不超过５个。（三）有以下情形之一的，综合审查结论为“不合格”：１.单项审查结论出现“不合格”的；２.关键项审查结论出现“轻微缺陷”的；３.非关键项审查结论为“轻微缺陷”的总数超过５个。第二十九条\u3000'
               '书面审查与实地核查结果不一致的，以实地核查结果为准。申请人对实地核查工作有不同意见的，应当在实地核查工作结束后５日内向上一级主管部门书面反映。对综合审查结论为“基本合格”和“不合格”的，如申请人无正当理由的，应当维持审查意见；有正当理由的，由上一级主管部门裁决。第六章附则第三十条\xa0 '
               '本细则自发布之日起施行。附件：陕西省农药经营许可审查表附件.docx陕西省农药经营许可工作程序\xa0'
               '（征求意见稿）根据新修订的《农药管理条例》和《农药经营许可管理办法》有关规定，为规范我省农药经营许可有关工作，特制订本程序。一、申请与受理1. '
               '许可申请。农药经营单位按照自愿的原则，向辖区内的农业行政主管部门提出申请，填写农药经营许可申请表（由农业部统一制定格式），递交以下书面资料：（一）农药经营许可证申请表。（二）法定代表人（负责人）身份证复印件；（三）经营人员的学历或者培训证明； '
               '（四）经营场所和仓储场所地址、面积、来源、平面图等说明材料及照片； '
               '（五）计算机管理系统、可追溯电子信息码扫描设备、安全防护、仓储设施等清单及照片；（六）有关管理制度目录及文本；（七）申请材料真实性、合法性声明；（八）农业部规定的其他材料；（九）申请经营限制农药的应先取得《农药经营许可证》，并应符合我省《限制使用农药定点经营布局规划》和国家有关规定。申请材料应同时提交纸质文件和电子文档。2. '
               '分级受理。农药经营单位是县级工商营业执照的由县（区）级农业行政主管部门负责受理；市级工商营业执照的，根据经营单位申请由市级或经营场所所在县级农业行政主管部门负责受理；省级工商营业执照的，根据经营单位申请由省级或经营场所所在地市级或县级农业行政主管部门负责受理。3. '
               '受理时限。县级以上农业行政主管部门应于收到农药经营单位提交申请资料之日的5个工作日之内，对申请者提供的申请资料进行审查，符合要求的出具《农药经营单位审查受理通知书》，对资料不符合要求的，退回申请资料并书面说明理由。二、审查与决定1. '
               '分级审查。按照谁受理，谁审查的原则，县级以上农业行政主管部门，对申请农药经营许可的经营单位要进行实地核查，核查应派3名以上农药执法人员进行实地核查。对申请省级或市级农药经营许可的农药经营单位的实地核查，可以委托县级农业行政主管部门进行，也可以省市县联合进行。实地核查要按《陕西省农药经营许可审查细则》规定的《陕西省农药经营许可审查表》要求，逐项进行审查并做详细的审查记录。2. '
               '审批决定。县级以上农业行政主管部门应在受理之日起20个工作日内作出审批决定。对实地核查合格的，核发农药经营许可证；对基本合格的，在20个工作日后重新实地核查，合格的核发农药经营许可证；不合格的书面通知申请人并说明理由。三、延续与变更农药经营许可证有效期为5年。有效期届满，需要继续经营农药的，农药经营者应当在有效期届满90日前向原发证机关申请延续。1. '
               '延续申请。申请农药经营许可证延续的，应当向原发证机关提交以下材料：（一）农药经营许可证延续申请表；（二）农药经营许可证复印件；（三）农药经营条件变化情况的说明及相关资料；（四）农药经营情况综合报告；（五）农药经营负责人、经营人员的专业培训情况。2. '
               '延续审批。原发证机关应当自受理申请之日起20个工作日内做出审批决定，符合条件的，准予延续；不符合条件的不予延续，书面通知申请人并说明理由。未在规定期限内提交申请的，不予延续。3. '
               '变更申请。农药经营许可证有效期内，改变农药经营者名称、法定代表人（负责人）、住所、仓储场所地址、调整分支机构的，应当自发生变化之日起30日内向原发证机关提出变更申请，并提交变更申请表和相关证明等材料。原发证机关应当自受理变更申请之日起20个工作日内办理。符合条件的，重新核发农药经营许可证；不符合条件的，书面通知申请人并说明理由。县级以上农业行政部门对农药经营单位申请设立和变更分支机构，应进行实地核查，分支机构经营场所除库房外应符合《陕西省农药经营许可审查细则》实地核查的要求。核查合格的进行备案变更，不合格的不进行备案变更。每个分支机构只允许有一个母体单位。经营范围增加限制使用农药的,应当按照《农药经营许可管理办法》的规定重新申请限制使用农药经营许可证，收回原农药经营许可证。限制使用农药经营者的分支机构不得经营限制使用农药，需经营限制使用农药的，应当符合限制使用农药定点经营布局规划和有关规定。未取得限制使用农药经营许可的经营单位，擅自销售限制使用农药的，吊销其农药经营许可资格，经营单位负责人10年内不得从事农药经营活动。4. '
               '遗失补办因农药经营许可证遗失、损坏的，应当说明原因并提供相关证明材料，及时向原发证机关申请补发。\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于征求《陕西省农药经营许可审查细则》 《陕西省农药经营许可工作程序》 （征求意见稿）意见的函'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅函',
 'art_date': '2017-09-29 10:24:46',
 'art_detail': '\n'
               '         '
               '陕农业函〔2017〕344号省农药工业协会，省内各生产企业：根据新修订的《农药管理条例》、《农药生产许可管理办法》和《农药生产许可审查细则》，省农业厅制定了《陕西省农药生产企业规范运行管理办法》（征求意见稿），现公开征求意见。请结合实际，认真研究，提出修改意见，务必于10月10日前报省农药管理检定所，逾期未报，则视为无意见。联系人：于福利\xa0\xa0 \xa0'
               '电\xa0 话：029-87337703 \xa0邮\xa0 '
               '箱：sxnjzx@163.com\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年9月27日\xa0'
               '陕西省农药生产企业规范运行管理办法（征求意见稿）为了规范农药生产行为，加强农药生产企业运行管理，保证农药产品质量，根据《农药管理条例》、《农药生产许可管理办法》和《农药生产许可审查细则》，特制定本办法，作为企业日常管理和执法人员监管的基本要求，达到企业运行有依据、工作有程序、生产有痕迹、质量有控制、记录可查询、产品可追溯。1 '
               '机构1.1 企业名称、法定代表人、企业住所应该与营业执照或社会统一信用代码中的一致。1.2 '
               '实际生产地址应当与营业执照地址相同。若不同，实际生产地址应该与生产许可证上载明的地址一致。1.3 '
               '应有明确的内设部门，各部门职责明确，有组织机构图，标明各部门之间的关系。1.4 '
               '具有相关质量体系文件与管理制度，并严格执行，保存相关质量管理运行记录。2 人员2.1 '
               '企业应配备足够的管理人员、技术人员、操作人员、检验人员，具体的人员要求见《农药生产许可审查细则》。制定人员上岗考核制度，人员应经过与其岗位相适应的专业教育、培训，并应有相应的专业技术知识和经验，经考核合格后聘用上岗。国家规定的特种岗位必须持证上岗。企业负责人、管理人员、技术人员、检测人员、特种设备操作人员等必须为长期聘用的人员。2.2 '
               '人员岗位设置合理，明确岗位任职资格、职责、权限和相互关系，应有所有人员一览表。应至少设立企业负责人、部门负责人、技术负责人、质量负责人、设备管理员、生产技术员、质量监督员、仪器管理员、安全员、检测员、生产人员、特种设备操作员、采购人员、销售人员、档案管理员、库房管理员、保安等。所有人员必须熟悉自己的岗位职责，并能认真熟练履职。2.3 '
               '应建立人员档案，人员档案内容应包括个人简历、学历证书、培训经历、劳动聘用合同、岗位聘用文件、年度绩效考核结果、奖惩等内容，做到一人一档，及时更新。2.4 '
               '制定人员培训制度，有各类人员的短期和长期培训计划，应有实施记录，并对培训效果进行评价。2.5 '
               '有各类人员的录用、管理和绩效考核评价制度，明确录用条件、管理制度、考核、奖惩办法等。2.6 '
               '有人员劳动保护管理制度，并为员工提供必要的劳动防护用品。2.7 '
               '建立健全员工的职业性健康监护档案。新进人员在上岗前应进行职业性健康检查，检查结果应及时告知被查者本人。2.8 '
               '由于工作原因造成事故的，应按照有关规定申请和为其办理工伤保险待遇。有条件的可为员工购买意外伤害商业保险。3 厂区3.1 '
               '企业应当拥有固定生产场地。租赁厂房和生产用地的，租赁期限不得少于五年，租赁合同有效状态不低于一年。3.2 '
               '企业生产地址应符合《农药生产许可审查细则》的要求。厂区规划应符合国家安检、消防、环保、政府规划部门的要求，取得安全生产许可、环境评价、环境监测报告、职业健康证据、政府建设批复与验收合格证据等。3.3 '
               '企业应有生产布局平面总图，生活、办公、检测、研发、生产、库房等应不同功能区应集中设置，相对独立。相互影响的区域应有效隔离，互不干扰。3.4 '
               '质检机构应当独立设置，仪器分析室、化学分析室、天平室、样品室（留样室）、加温室等要有效分开。3.5 '
               '厂区布局应充分考虑风向和管理的需要，整个布局要按照生产流程设计，便于操作。厂区不同功能区应分区明确，标志清晰。3.6 '
               '除草剂、植物生长调节剂、杀鼠剂生产车间应当与其他农药生产车间有适当的安全距离，避免交叉污染。3.7 '
               '厂区不同功能区应设立门禁装置，进入和使用有影响工作质量的区域应有明确的限制和控制，设置权限，出入登记，并建议进行在线监控。3.8 '
               '厂区应根据需要设计上、下水，生活污水、工业污水分别排放，进行处理达到要求后排放，或统一收集后交由有资质的环保处理单位进行集中处理。3.9 '
               '厂区电气线路布局合理，便于生产工作进行，动力满足生产的负荷需要，并符合安全要求，重点危险部位加装防护设施。3.10 '
               '如有需要，应配置停电、停水等应急设施。3.11 '
               '厂区应合理设计气路，对于易燃高压气体，应做好防爆防燃措施，必要时设立防爆墙。3.12 '
               '厂区应配备必要的防尘、防废气等环保处理设施，满足环保的要求。3.13 '
               '易燃易爆品和易制毒品应有符合要求的保存场地，有专人管理。3.14 进入厂区需着工作服，佩戴工作证。3.15 '
               '厂区道路标志清晰，人、小轿车、货车分流，应有明显的限速标志和车辆停放区。3.16 '
               '厂区原料、成品、包材分类存放，物品堆放整齐，消防器材配备完善，便于取用。3.17 '
               '厂区应配备足够的消防器材、安全防护和应急处理设施，定期检查，及时更新、更换，保证随时可用、可靠、有效。灭火器材应放置于便于拿到、相对空旷的位置，并应设立醒目的标识。设置必要的逃生和消防通道，标志明显，任何车辆停靠不得占用。3.18 '
               '厂区应设计绿化，绿化面积不低于总面积的30%，有专人负责所有绿色植物的修剪、除草、浇水等养护工作，同时不得在绿化区晾晒衣物，堆放垃圾等。4 '
               '设备4.1 '
               '具备与其所生产剂型相适应的生产装置与设备，其性能满足生产要求，运转正常。所配备的主要生产装置与设备能实现自动化生产，具体设备要求见《农药生产许可审查细则》。4.2 '
               '有生产设备一览表，内容包括：名称、唯一性标识、型号规格、出厂号、制造商名称、技术指标、购置时间、单价、用途、管理人、使用人等。制定生产设备管理制度，确保生产设备维护完好，正常运转。4.3 '
               '有生产装置工艺流程图、生产装置平面布置图，制定操作规程并上墙，便于操作人员使用。4.4 '
               '对生产装置要进行正常的清洗、维护和保养，并及时记录，确保正常运转，不出现交叉污染。4.5 '
               '有利用可追溯电子信息码从事生产、销售的设施，能满足正常生产要求。制定产品可追溯制度，达到生产有记录，流通可追溯。4.6 '
               '具有申请生产原药（母药）产品质量标准规定的检测仪器设备和检测手段；其性能和精度应能满足生产合格产品的要求。4.7 '
               '有仪器设备一览表，内容包括：名称、唯一性标识、型号规格、出厂号、制造商名称、技术指标、购置时间、单价、检定（校准）周期、用途、管理人、使用人等。4.8 '
               '有仪器设备购置、验收、调试、检定（校准）使用、维护、故障修理、降级和报废处理程序，并应有相应记录。4.9 '
               '对出具数据的检测仪器、计量设备要进行计量检定或校准，对检测结果有影响的主要设备要进行功能检查。对使用频次高的、稳定性差的和脱离了实验室直接控制等的仪器应进行期间核查，以确保其性能满足检测仪器。4.10 '
               '仪器设备应贴有唯一性标识和计量状态标识，由专人负责管理保养，在用仪器设备的完好率应为100%，并进行正常的维护。4.11 '
               '有仪器设备操作规程，并便于操作人员对照使用。4.12 '
               '生产设备和仪器设备应独立建档，一机一档。内容包括：仪器设备名称、唯一性标识、型号规格、出厂号、制造商名称、购置、验收、调试记录，接收日期、启用时间、使用说明书（中文）、放置地点、历次检定、使用、检查、维护、保养、损坏、故障、改装或修理记录等。4.13 '
               '生产设备和仪器设备应有使用记录，记录应能满足试验再现性和溯源的要求，内容包括：开机时间、关机时间、开关机状态、工作内容、环境因素（如有需要）、使用人等。（仪器设备使用记录）4.14 '
               '有计量标准和标准物质一览表，内容包括：标准物质（基准试剂））名称、编号、来源、有效期。制定计量标准和标准物质管理程序，有符合要求的贮存场所，专人管理，在用的标准物质（基准试剂、溶液）应在有效期内。4.15 '
               '标准溶液配制、标定、校验和定期复验应有记录。5 生产管理5.1 原材料采购与管理5.1.1 '
               '应制定原材料采购与管理制度，明确原材料的采购程序，采购文件的控制、供方及外协单位的评价与控制、采购合同的控制、采购产品的验证控制、出入库管理等内容。5.1.2 '
               '应制定进货查验制度，查验产品质量检验合格证和有关许可证明文件，不得采购、使用未依法附具产品质量检验合格证、未依法取得有关许可证明文件的原材料。5.1.3 '
               '应制定相关进货检验制度，明确检验项目和要求，按有关控制指标对原材料进行检验，以保证原材料质量。5.1.4 '
               '应制定供应商评价制度，对影响产品质量的主要原、辅材料供应商及外协单位的资质和产品质量保障能力进行全面评价，编制合格的供应商名录，实行动态管理。5.1.5 '
               '应制定原材料进货记录制度，如实记录原材料的名称、有关许可证明文件编号、产品合格证、规格、数量、供货人名称及其联系方式、进货日期等内容。原材料进货记录应当保存2年以上。5.1.6 '
               '应制定原材料仓储管理制度，出入库应履行审批程序，填写并保存出入库记录。5.2 生产工艺及过程管理5.2.1 '
               '有完善可行的工艺管理制度及考核办法，明确工艺管理部门、执行部门的职责、权限及其相互关系，操作人员应严格按操作规程等工艺文件进行生产、操作的纪律要求。5.2.2 '
               '有生产工艺流程图及工艺说明，有与生产范围相关的工艺文件明细表，并与实际工艺文件相符。工艺流程应经过小试、中试，最后至工业化生产。5.2.3 '
               '主要工序应有工艺指标台账，有主要生产工艺中控指标及控制、考核办法。5.2.4 '
               '各工序有操作规程，应便于操作人员对照使用。新工艺或特殊工艺需要在生产前对操作人员集中培训，并确保操作人员操作熟练。5.2.5 '
               '严格按照工艺参数及操作规程进行操作，及时进行现场操作记录，发现有异常尽快沟通解决或按程序上报。5.2.6 '
               '对产品质量有影响的中间生产过程，应建立生产过程中控检验程序。如果出现不合格样品，应及时查找原因采取纠正措施，并提出防范改进措施。5.2.7 '
               '生产过程中应利用可追溯电子信息码实现产品的可追溯，追溯码清晰可以识别规定内容。5.2.8 '
               '有产品标签及包装管理制度，产品标签内容应该与农业部备案标签一致，必须真实并与产品内在质量一致。产品包装应不腐蚀、不渗漏，装箱整齐，无药渍，数量准确，随箱说明书等资料齐备。5.3 '
               '质量控制5.3.1 '
               '企业应设置相对独立的质量控制和检验部门，能独立开展工作，确保不受任何来自商业、经济等利益因素的影响，保证诚信度。5.3.2 '
               '应当制定产品质量管理制度，明确出厂销售的产品，应当经质量检验合格并附具产品质量检验合格证。5.3.3 '
               '应当按照产品质量的要求，制定相关产品企业标准，或采用国家、行业标准。所制定或采用的标准必须经过验证，确保技术指标合理，检测方法可行，并经技术负责人确认。5.3.4 '
               '按程序在相关部门进行标准备案，并确保备案标准和上报登记标准一致。5.3.5 '
               '对所有在用检测标准进行分类编号，并建立产品质量标准目录。5.3.6有专人负责标准的制修订、查询、收集工作，对在用标准进行受控管理，确保使用有效标准。5.3.7 '
               '产品包装前依据质量标准进行抽样检验，成品包装完成后按产品包装规定进行取样并检验。所有检验应有完整的原始记录。5.3.8 '
               '应当制定不合格品的控制和处置程序。对检验中发现的不合格品应按规定进行标识、隔离和处置，有效防止不合格品转入下道工序和出厂。不合格品经返工后应重新进行检验。5.3.9 '
               '对检验合格的样品，出具产品质量检验合格证，准予出厂。5.3.10 应建立有质量争议产品的处置制度。5.4 '
               '出厂销售管理5.4.1 应建立生产台账管理制度，如实记录生产情况；5.4.2 '
               '应建立农药产品出入库管理制度，如实记录产品储存情况；5.4.3 '
               '应当建立农药出厂销售记录制度，如实记录农药的名称、规格、数量、生产日期和批号、产品质量检验信息、购货人名称及其联系方式、销售日期等内容。农药出厂销售记录应当保存2年以上。5.4.4 '
               '应当利用产品可追溯电子信息码，建立农药销售台账，做到流向可查询。5.5 产品事故与召回5.5.1 '
               '应建立产品事故处理制度和产品召回制度，明确产品事故处理程序、产品召回程序。5.5.2 '
               '生产企业发现其生产的农药对农业、林业、人畜安全、农产品质量安全、生态环境等有严重危害或者较大风险的，应当立即停止生产，通知有关经营者和使用者，向所在地农业主管部门报告，主动召回产品，并记录通知和召回情况。5.5.3 '
               '组织召开质量事故分析会，分析发生的原因，厘清责任，提出纠正和预防措施，并形成事故分析报告。对于农业生产者和农药经营者的损失，根据损失情况协商予以赔偿，不能协商一致的，走司法程序进行处理。5.5.4 '
               '应建立客户投诉处理制度，填写并保存客户投诉处理的记录。5.5.5 '
               '对于发生一般的质量事故应立即采取紧急措施，防止事故蔓延，按事故处理制度进行处理。5.5.6 '
               '因质量原因退货和收回的产品，应在企业质量管理部门监督下按照环保要求进行销毁，涉及其它批号时，应同时处理。6 安全管理6.1 '
               '应当符合国家安全生产管理方面的要求。6.2 应建立农药安全生产管理制度、职业卫生和劳动保护管理制度，并按制度执行。6.3 '
               '企业应设立安全员，负责安全生产的监督检查。切实落实安全生产责任制，安全生产应涵盖生产、经营活动的所有场所。6.4 '
               '企业应制定事故应急处理制度，制定应急预案，开展各部门安全操作方面的教育培训，进行事故应急演练等。6.5 '
               '企业应制定危险化学品和剧毒药品管理制度，领用必须办理相关审批手续，剧毒药品应实行双人双锁保管。6.6 '
               '接触有毒有害物质、危险化学品的操作人员，必须按规定佩戴个人防护用品，严格按照操作规程进行操作，严防起火、爆炸和中毒事件的发生。6.7 '
               '各部门安全员应定期不定期检查安全工作，发现隐患应及时采取措施，防患于未然。6.8 '
               '操作中如出现意外事件，有可能危及人身安全健康时，应采取相应的安全防护与隔离措施，在保证人身安全的情况下，阻止事态扩大，并向上级报告，把伤害和损失减少到最低限度。6.9 '
               '当发生中毒事故时，应立即将中毒者移开中毒现场，送到通风的地方，设法排出体内毒物，并速送医院。6.10 '
               '危险化学品和剧毒药品如发生丢失，应及时查找并立即向当地公安部门报告。7 '
               '环境保护7.1应当符合国家环境保护管理方面的要求。7.2 '
               '企业应建立环境保护管理制度，并按制度执行，确保环保设施配备齐全，运转正常，排放的废气、废水、废渣经过处理达到环保要求后排放。7.3 '
               '企业应建立农药废弃物回收与处置制度，应包括过期农药、中间体、原材料、使用后的农药废弃包装物等，确保全部按要求进行回收与处置。7.4 '
               '鼓励企业对废弃物等实行废物再回收利用。7.5 '
               '生产部门/车间应及时对产生的废弃物进行分类和收集，企业应与有环保资质的化学废弃物处理单位签订处理协议，收集后交由统一处理，并保留交接处理的有关证明记录存档。7.6 '
               '企业应制定污染物泄露的应急处理预案，当出现环境污染时，采取一切措施，控制污染的扩大，并上报当地环保部门。7.7厂区所产生的生活垃圾禁止与工业废弃物混放。8 '
               '产品贮存与运输管理8.1 '
               '企业应建立农药产品仓储管理制度和运输管理制度，并按制度执行。如果属于危险化学品，应该符合国家危险化学品的贮存和运输要求。8.2 '
               '农药产品仓储管理制度应当规定库位规划、堆放方式、垛位标识、库房盘点、环境要求、库房安全、出入库记录等内容。8.3 '
               '出入库记录应当包括产品名称、规格、生产日期、入库数量和日期、出库数量和日期、库存数量、保管人等信息。8.4 '
               '不同产品的垛位之间应当保持适当的距离。8.5 不合格产品和过期产品应当隔离存放并有清晰标识。8.6 '
               '应在产品装车前对运输车辆的性能、安全状况实施检查，产品应捆绑结实或密封严实，避免抛洒。8.7 '
               '如果产品运输实行外包，应对服务方的资质、服务质量进行评价，合格的列入合格供应商目录，并进行必要的培训。8.8 '
               '产品运输应有完整的运输交接记录，货物流向明确。9 文件与记录管理9.1 '
               '制定文件与记录管理制度，规定文件的制定、维护、受控、修改等程序和记录的填写程序，规范生产、经营等各项活动中形成的文件和记录。9.2 '
               '文件与记录应包括：国家、部门下发的与本企业直接有关的法律、法规、文件和规定等；涉及机构、人员等方面内容的重要文件、质量体系文件、规章制度等；产品质量标准及其他有关标准；生产工艺流程、操作规程等；仪器设备档案；人员档案；对外行文和工作计划、总结等；质量记录及技术记录等；产品销售记录等。9.3 '
               '制定档案管理制度，明确档案的管理职责和归档时限，规范生产、经营等各项活动中形成的具有查考利用价值的文件、记录、资料、检验报告等的管理。9.4 '
               '资料经整理后，各部门应及时交档案管理员存档，并认真履行交接手续。9.5 '
               '档案管理员要及时接收各种记录，严格按照一事一档的原则进行分类、编号、保管，做好各类档案的整理工作，便于查阅。9.6 '
               '因工作需要借阅、复制技术资料须履行相关审批程序。9.7 '
               '存放档案资料场所应干燥整洁，具有防潮、防虫、防火、防盗、防尘、防鼠、防晒设施，室内严禁吸烟或存放易燃、易爆物品。应采取保密措施，外来人员不得进入档案室。9.8 '
               '定期保存的技术资料如超过保存期，由档案管理员提出销毁申请，经相关责任人确认无保留价值、批准后，在主管人的监督下，档案管理员进行销毁。\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于征求《陕西省农药生产企业规范运行管理办法》（征求意见稿）意见的函'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-07-26 17:13:07',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕65号各相关市农业局、畜牧局（委）、财政局，省农垦集团总公司：为了做好我省2017年粮改饲工作，按照《农业部财政部关于做好2017年中央财政农业生产发展等项目实施工作的通知》（农财发〔2017〕11号）要求，省农业厅会同省财政厅研究制定了《2017年陕西省粮改饲工作实施方案》。现印发给你们，请遵照执行。\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0陕西省财政厅\xa0 \xa0'
               '2017年7月24日附件.doc\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅 陕西省财政厅 印发2017年粮改饲工作实施方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-08-24 17:39:13',
 'art_detail': '\n'
               '         '
               '陕农业发〔2017〕71号各有关市、县、区人民政府，各有关市、县、区农业（果业）局、公安局、交通运输局、商务局、工商行政管理局，省公路局、省高速集团、省交通集团、省高速公路收费管理中心：为保护我省苹果产业健康发展，有效阻截苹果蠹蛾疫情入侵，根据省政府领导批示，现将《陕西省苹果蠹蛾疫情防控工作方案》印发给你们，请遵照执行。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省公安厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省交通运输厅 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省商务厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省工商行政管理局\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年8月21日陕西省苹果蠹蛾疫情防控工作方案为防止苹果蠹蛾疫情传入，确保我省果业生产安全，根据《陕西省农业重大有害生物及外来生物入侵突发事件应急预案》的规定，特制定本方案。1.组织领导1.1原则按照政府统一领导，职能部门参与，逐级落实责任的原则，上下联动，共同开展苹果蠹蛾疫情防控。1.2组织协调省政府分管农业副省长领导全省苹果蠹蛾疫情防控工作；省政府办公厅负责协调防控工作，在省农业厅设立省苹果蠹蛾疫情防控办公室，具体任务是：（1）与相关部门共同研究确定全省苹果蠹蛾疫情防控的方针、政策、工作思路和总体行动计划，以及全省苹果蠹蛾疫情防控应急保障措施。（2）监督检查各地、各部门的疫情防控工作,协调解决防控工作中出现的问题；（3）向省政府、农业部报告全省工作情况。1.3各省级部门职责省委宣传部负责新闻媒体疫情信息发布管理，加强对网络、报纸等传媒的监控。省农业厅负责制订苹果蠹蛾监测、防控技术方案；对疫情防控进行技术指导；组织开展全省苹果蠹蛾疫情调查、监测、阻截防控、宣传、培训工作；向省政府报告疫情发生及监控动态。省公安厅负责拦截所有入陕原料果运输车辆，移交农业部门进行检疫检查。负责染疫果品销毁现场秩序维护，保障工作人员人身安全，配合农业部门开展违法案件查处。省财政厅负责落实疫情普查监测、阻截防控以及人员培训等工作经费。省交通厅负责为疫情阻截工作提供便利条件，利用可变情报板等平台做好苹果蠹蛾阻截防控宣传工作，配合做好检疫检查和风险果检疫处置工作。省商务厅负责规范果品市场秩序，加强果品经销商诚信行为的监督管理，配合植物检疫机构做好检疫检查。省工商局负责在其职责范围内对果品、果树种苗市场进行监管。省政府法制办负责做好有关拟发布疫情防控政策的合法性审查工作。省监察厅负责对苹果蠹蛾阻截防控工作中违法及渎职行为实施监督及执纪问责。省果业局负责组织开展果园疫情监测普查。1.4地方领导机构苹果主产区的市、县、区政府苹果蠹蛾疫情防控工作领导机构，制订疫情监控工作方案，负责本辖区疫情的具体调查监测、阻截封锁、控制扑灭等工作。1.5现场指挥机构发现苹果蠹蛾疫情后，当地政府要立即成立现场应急指挥部，由市长、县长、区长任指挥长，负责苹果蠹蛾疫情发生现场的应急处理和协调指挥，组织进行封锁扑灭等工作。1.6技术咨询机构由省植保总站、西北农林科技大学、全国农技推广服务中心、省果业局等单位专家组成省苹果蠹蛾疫情防控技术小组，解决疫情防控中出现的技术问题。2.预防和预警2.1信息收集省苹果蠹蛾疫情防控办公室要及时收集国内外苹果蠹蛾疫情发生发展情况，果树苗木、农产品调入情况。2.2疫情调查苹果主产区的县（市、区）农业部门每年5月下旬至6月上旬、8月中旬至8月下旬，组织果业、植保、农技、园艺等部门，按照《陕西省苹果蠹蛾调查监测技术方案》的要求进行两次疫情调查。调查结束后将《陕西省果实苹果蠹蛾调查情况汇总表》、《陕西省苹果蠹蛾田间调查汇总表》和调查监测工作总结上报省苹果蠹蛾疫情防控办公室。发现疫情要随时报告，不得迟报、瞒报、漏报。2.3疫情监测按照《陕西省苹果蠹蛾调查监测技术方案》，每年4月10日至9月30日，各地植物检疫机构负责一类核心监测区的苹果蠹蛾监测，合理设置监测点，并在果实采收前，对监测的果园及附近1公里内果园进行2－3次调查，检查有无苹果蠹蛾被害果实。果业部门负责二类重点监测区、三类一般监测区果园苹果蠹蛾监测。3.防控措施3.1预防措施任何单位和个人，从外省调进果树苗木前，要取得调入地植物检疫要求书。对一次引进种苗数量较大的，调入地植物检疫部门要派人前往调出地进行产地检疫。严禁从苹果蠹蛾疫区或疫情发生区调入果树苗木。加强对调入果树苗木的复检。无《植物检疫证书》的果品一律不得进入果汁加工企业、果品交易市场、超市进行加工和销售。严禁苹果蠹蛾疫区的果品进入我省。对来自疫情发生区的水果进行复检，严防苹果蠹蛾传入我省。3.2疫情阻截每年从8月15日起，到11月30日止（由省农业厅根据原料果运输情况适当调整），经省政府批准设立的苹果有害生物临时检查站（2017新柱批文806号）对进入我省运输果品的车辆进行检查。检查工作严格按照《陕西省苹果蠹蛾公路检查工作流程》规定进行。检查期间，各检查站每7天向省苹果蠹蛾疫情防控办公室上报1次检查情况。3.3疫情防控应急联动在监测、检查过程中，发现疫点和染疫果品时，市级苹果蠹蛾疫情防控工作领导机构应在12小时内派员到达现场，省农业厅24小时内派员到达现场，各相关单位应根据各自职责，采取果断措施进行处置。发生疫情后，当地人民政府应按照《陕西省农业重大有害生物及外来生物入侵突发事件应急预案》的要求，启动预案，组织封锁及铲除疫情。4.保障措施4.1经费保障按照分级负责的原则，市、县、区财政负责落实本辖区苹果蠹蛾疫情防控工作经费。省级财政负责省级苹果蠹蛾疫情防控工作所需经费，根据情况对相关县区调查监测与阻截防控工作经费给予适当补助。4.2物资保障根据疫情防控工作需要，各级农业行政主管部门要储备充足的苹果蠹蛾应急防控药品和物资，满足年度疫情防控需要。苹果蠹蛾诱捕器由省上统一购置。4.3队伍保障各市应建立疫情应急防控专业队伍，配备必须的疫情处置、铲除、销毁设施设备，以及控制扑灭的植保机械，满足疫情应急防控需要。4.4技术培训省农业厅每年举办1-2期苹果蠹蛾疫情普查及防控知识培训班，为苹果蠹蛾防控提供技术保障。市、县、区农业部门要通过科技下乡、集中讲课等方式，对广大果农和应急防治专业队人员进行培训，提高果农参与苹果蠹蛾防控的自觉性、主动性。4.5媒体宣传新闻媒体报道苹果蠹蛾疫情防控工作时，必须征得省苹果蠹蛾疫情防控办公室同意。省委宣传部应加强对网络传媒的监控，严防不实疫情消息传播。5.监督检查各级苹果蠹蛾疫情防控工作领导机构要加强对疫情防控工作的督导检查。5.1检查市、县、区苹果蠹蛾疫情防控工作领导机构要组织相关单位，定期对辖区内苹果蠹蛾防控工作进行检查。5.2抽查省苹果蠹蛾疫情防控办公室组织相关部门，不定期对全省苹果蠹蛾防控工作开展情况进行抽查。6.奖励与责任追究对在苹果蠹蛾防控工作中做出突出贡献的单位和个人，省苹果蠹蛾疫情防控办公室每2年、省政府每5年表彰奖励1次。对不履行职责、义务的单位和个人，造成严重后果的，按照国家有关法律和法规规定，追究相关责任人的责任。\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '关于印发陕西省苹果蠹蛾疫情防控工作方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-08-09 16:42:30',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕76号各有关市农业、畜牧局（委）、财政局：根据国务院办公厅《关于加快推进畜禽养殖废弃物资源化利用的意见》（国办发〔2017〕48号）精神，按照《农业部财政部关于做好2017年中央财政农业生产发展等项目实施工作的通知》（农财发〔2017〕11号）要求，结合我省实际，现就申报2017年畜禽健康养殖项目有关事宜通知如下。一、总体思路（一）指导思想。认真贯彻党中央、国务院加快推进畜禽养殖废弃物资源化利用有关决策部署，统筹推进“五位一体”总体布局和协调推进“四个全面”战略布局，牢固树立和贯彻落实创新、协调、绿色、开放、共享发展理念，坚持源头减量、过程控制、末端利用的治理路径，以畜牧大县和规模养殖场为重点，以沼气和生物天然气为主要处理方向，以农用有机肥和农村能源为主要利用方向，推广畜禽健康养殖工艺，建设和升级改造畜禽粪污收集、贮存、处理设施，全面推进畜禽养殖废弃物资源化利用，加快构建种养结合、农牧循环的可持续发展新格局，为全面建成小康社会提供有力支撑。（二）基本原则1．坚持整县推进。以县为基本单元，根据资源环境承载能力和产业发展基础，统筹考虑畜牧业生产发展和粪污资源化利用，科学确定畜禽养殖废弃物利用技术路径，整县推进畜禽养殖废弃物资源化利用。2．坚持重点突破。以畜禽规模养殖场为重点，突出生猪和奶牛产业，指导老场改造升级，对新场严格规范管理，鼓励养殖密集区进行集中处理，推进种养结合、农牧循环发展。3．坚持分类指导。根据不同区域资源环境特点，结合不同规模、不同畜种养殖场的粪污产生情况，坚持“一场一策、填平补齐”的原则，推广经济适用的粪污资源化利用模式。二、主要技术模式与扶持环节（一）主要技术模式。根据我省畜牧业发展现状和环境资源特点，因地制宜确定主推技术模式。畜禽养殖场应以源头减量、过程控制、末端利用为核心，重点推广经济适用的通用技术模式。1．源头减量。生猪、奶牛规模养殖场改水冲粪为干清粪，采用节水型饮水器或饮水分流装置，实行雨污分离、固液分离、高压冲洗、暗沟排污、回收污水循环清粪等有效措施，从源头上控制养殖污水产生量。2．过程控制。规模养殖场建设必要的粪污处理设施，使用堆肥发酵菌剂、粪水处理菌剂和臭气控制菌剂等，加速粪污无害化处理过程，减少氮磷和臭气排放。3．末端利用。生猪和奶牛等规模化养殖场鼓励采用“种养结合”和“粪便垫料回用”等技术模式，促进畜禽粪污就近就地还田利用。“种养结合”模式。养殖场采用干清粪或水泡粪清粪方式，污水进行氧化塘或厌氧发酵处理后，就近应用于农作物生产。固体粪便经过堆肥后就近或异地用于农田。“粪便垫料回用”模式。规模奶牛养殖场粪污进行固液分离，固体粪便经过高温快速发酵和杀菌处理后作为牛床垫料或肥料，污水通过氧化塘贮存或厌氧发酵进行无害化处理，回冲粪沟或做肥水施用。“集中处理”模式。依托专业化粪污处理企业，对周边养殖场的固体粪便或污水实行专业化收集和运输，并按无害化和资源化要求集中处理和综合利用。“污水肥料化利用”模式。针对周边配套农田、山地、果林或茶园充足的规模养殖场，养殖污水通过氧化塘贮存或沼气工程进行无害化处理，在作物收获后或播种前作为底肥施用。实现资源化利用和粪便污“粪污专业化能源利用”模式。依托大规模养殖场或第三方粪污处理企业，对一定区域内的粪污进行集中收集，通过大型沼气工程或生物天然气工程，沼气发电上网或提纯生物天然气，沼渣生产有机肥，沼液通过农田利用或浓缩使用。（二）扶持环节。财政资金重点支持改造雨污分离及污水管道设施，购置机械清粪设备、固液分离设备、固体粪便堆肥设施、污水氧化塘处理贮存设施、污水厌氧发酵设施、沼液贮存设施、肥水输送和农田利用设施等。三、实施范围与申报条件根据我省畜牧业区域布局和畜禽养殖废弃物资源化利用现状，畜禽健康养殖项目突出生猪养殖大县和奶牛养殖大县，整县推进畜禽粪污资源化利用，优先支持旬邑、澄城和洛川生猪大县种养业有机结合、循环发展试点县，优先支持澄城、陈仓等畜牧业绿色发展示范（创建）县，优先支持农业部确定的畜牧大县。已承担国家种养业循环一体化项目的县不再申报安排。项目县区应具备以下条件：一是产业发展有规模。生猪年出栏30万头以上或者奶牛存栏3万头以上的县（区、市）；二是废弃物处理有基础。县域内畜禽养殖废弃物资源化利用工作有一定基础；三是县级人民政府对畜禽养殖废弃物资源化利用工作高度重视，畜牧部门工作推动有力。四、投资规模与申报数量（一）投资规模。依据农业部下达我省资金控制规模，2017年全省拟扶持10个左右整县健康养殖项目，每县投资规模控制在1000万元左右，每个规模养殖场开展粪污资源化利用设施建设补助标准为20-50万元。（二）建设目标。项目实施期限为一年，通过项目实施，项目县构建种养循环发展机制，畜禽粪污资源化利用能力明显提升，全县生猪或奶牛粪污综合利用率达到75%以上，规模养殖场粪污处理设施装备配套率达到95%以上。（三）申报数量。西安、宝鸡、咸阳和渭南市各申报2个项目县，汉中、安康、商洛、延安和榆林市各申报1个项目县。\xa0'
               '五、项目申报程序与评审各市农业（畜牧）主管部门和财政部门要根据当地畜牧业生产实际，结合畜牧业发展规划，组织县区进行自愿申报。由县区畜牧主管部门会同财政部门整县编制项目申报书（格式详见附件），经市级畜牧主管部门会同财政部门初审后，于2017年8月15日前以正式文件上报省农业厅和财政厅各1份，同时报送省畜牧兽医局项目申报书10份。项目评审工作由省农业厅会同省财政厅组织实施，采取竞争立项方式，通过听取汇报、质疑、答辩、量化打分，进行评审。根据评审结果确定拟扶持项目县（区）名单，在陕西农业网上公示，公示无异议后由省农业厅会同省财政厅批复实施方案。六、管理要求（一）加强组织领导。各地要高度重视畜禽粪污资源化利用工作，项目县区政府要成立项目实施工作领导小组并下设办公室，做好相关工作协调，力争县域内规模养殖场粪污资源化利用达到全覆盖，推动畜牧业生态养殖、绿色发展再上新台阶。（二）加大政策扶持。项目县区要围绕标准化规模养殖、沼气资源化利用、有机肥推广等关键环节出台扶持政策，支持和引导社会资本开展畜禽粪污资源化利用设施建设，提升规模养殖场、第三方处理机构和社会化服务组织粪污处理能力。（三）严格项目审查。县级畜牧主管部门要因地制宜、科学制定可操作性项目实施方案，按照“一场一策”要求建设单位、确定建设内容和补助标准。市级畜牧主管部门要加强指导，严把项目审查关，不成熟的项目坚决不上报，为项目的顺利实施奠定基础。\xa0'
               '附件：2017年畜禽健康养殖项目申报书(样本格式)\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '陕西省财政厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 2017年8月7日附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅 ',
 'art_title': '陕西省农业厅 陕西省财政厅 关于申报2017年畜禽健康养殖项目的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-08-28 11:23:32',
 'art_detail': '\n'
               '         '
               '陕农业发〔2017〕69号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：发展休闲农业是扎实推进我省特色现代农业建设、增加农民收入、建设社会主义新农村的重要举措，是促进城乡居民消费升级、发展新经济、培育新动能的必然选择。为深入贯彻落实省委、省政府、农业部关于加快发展休闲农业的系列部署和要求，推动全省休闲农业又好又快发展，助推产业扶贫，提出如下意见。一、重要意义休闲农业是现代农业新型产业形态，也是现代旅游新型消费业态，正成为农业农村经济新的增长点和增长极。近年来，我省休闲农业发展呈速度加快、布局优化、质量提升、领域拓展的良好态势，在一些地区已成为新热点、新亮点、新看点，对带动农民脱贫致富发挥了积极作用。当前及今后一个时期，随着城乡居民生活水平提高、休闲时间增多、交通设施改善和消费需求不断转型升级，休闲农业仍有旺盛市场需求，仍将处于黄金发展期。大力发展休闲农业，有利于推动农业和旅游供给侧结构性改革，有利于促进农村一二三产业融合发展，有利于形成多要素集聚、多产业叠加、多领域联动、多环节增效，有利于带动农民就业增收和推进精准脱贫，是延伸农业产业链、提升价值链、优化供应链的重要方式，是发展全域旅游和大众旅游的重要渠道，也是促进城乡一体化发展的重要载体。二、总体要求（一）指导思想深入贯彻习近平总书记“绿水青山就是金山银山”的重大科学论断，牢固树立创新、协调、绿色、开放、共享发展理念，以省第十三次党代会精神为指引，以推进农业供给侧结构性改革为主线，以促进农民就业增收、满足居民休闲消费需求、建设美丽乡村为着眼点，以促进产业升级、激发消费活力、推动产业扶贫为着力点，加强统筹规划和规范管理，创新工作机制，优化发展政策，加大公共服务，推进农业与旅游、教育、文化、康养等产业深度融合，大力提升休闲农业发展水平，为城乡居民提供望山、见水、忆乡愁的高品质休闲旅游体验目的地，着力将休闲农业培育成提升农业、繁荣农村、富裕农民的新兴支柱产业。（二）基本原则一是以农为本、促进增收。要以农业为基础、农民为主体，着重构建利益共享、多方共赢的利益分享机制，增强农民自主发展意识，激发农民创业创新活力。二是规划先行、特色发展。要规划先行、因地制宜、突出特色、适度发展，避免低水平重复建设。三是融合互动、相互促进。要加强与乡村旅游、传统村落传统民居保护、美丽乡村建设、精准扶贫、林下经济开发、森林旅游、水利风景区旅游等有机融合，推动与相关产业共生共荣、互惠发展。四是政府引导、市场运作。既要发挥政府在政策扶持、规范管理、公共服务、营造环境等方面的引导作用，也要发挥市场在配置资源中的决定性作用，实现政府搭台、主体唱戏、大众受益。五是环境友好、绿色发展。要统筹考虑资源和环境承载能力，利用与保护并举，生产与生态并重，实现经济、社会、生态全面可持续发展。（三）主要目标到2020年，全省休闲农业产业规模进一步扩大，年接待1.5亿人次以上，营业收入超过150亿元，从业农民收入较快增长；基本形成布局合理、类型多样、功能完善、特色鲜明的产业格局；服务水平、发展质量和发展能力进一步增强，成为全省继粮、果、畜、菜、茶之后的第六大农业支柱产业。三、重点任务（一）加强规划引导按照生产生活生态统一、一二三产业融合发展的总体要求，因地制宜编制休闲农业发展规划。积极推进，多规合一，做好与当地土地利用规划、异地扶贫搬迁规划等有效衔接。引导各地遵循乡村发展规律、经济发展规律和产业发展规律，扬农村长处，补农村短板，留乡土味道，挖农业文明，推动休闲农业，近城、靠景、依产（特色农业产业）、沿路、有序布局、合理发展。重点开发建设以西安为核心的都市休闲农业圈，着力打造陕北黄土风情、关中农耕民俗、陕南山水风光三大板块，构筑沿渭河、汉江、黄河、丹江四条黄金水道，南北交通干线、关中环线两条黄金干线的六大休闲农业带。充分发挥国家级、省级休闲农业示范县（点）的典型带动作用，引导全省形成一圈引领、三区联动、六带升级、多星扩散的发展格局。（二）优化供给质量鼓励各地以市场需求为导向，深入开发农业多种功能，依托农村绿水青山、田园风光、乡土文化等资源，强化农业产品、农事景观、环保包装、乡土文化和服务设施的创意设计，开发个性化、特色化、差异化产品和服务，不断丰富休闲农业业态和产品，优化产品供给体系。有规划地发展休闲农园、休闲农庄、乡村酒店、特色民宿等乡村休闲度假产品，大力发展休闲度假、旅游观光、养生养老、创意农业、农耕体验、乡村手工艺。鼓励农村集体经济组织创办休闲农业合作社，或与社会资本联办休闲农业企业。支持有条件的乡村建设以农民合作社为主要载体、让农民充分参与和受益，集循环农业、创意农业、农事体验于一体的田园综合体。鼓励各地探索农业主题公园、农业嘉年华、教育农园、摄影基地、特色小镇等新业态，提高产业融合综合效益。（三）改善基础设施以全国休闲农业示范点、全国休闲农业星级企业（园区）、中国美丽休闲乡村和省级休闲农业示范点为重点，扶持建设一批功能完备、特色突出、服务优良的休闲农园、休闲农庄、休闲乡村。着力改善休闲农业经营场所道路、供水、宽带、停车场、厕所、垃圾污水处理、游客综合服务中心、餐饮住宿洗涤消毒设施、农事景观观光道路、休闲辅助设施等基础服务设施。进一步改善休闲农业基地种、养、加条件，实现特色农业加速发展、环境净化美化和服务能力同步提升。鼓励因地制宜兴建特色餐饮、特色民宿、购物、娱乐等配套服务设施，不断增强服务水平和能力。（四）推动产业扶贫对具有一定资源禀赋的贫困地区，要充分发挥乡村各类物质与非物质资源富集的独特优势，按照保护与传承同步、传统与现代融合的方式，发展农业＋旅游、＋教育、＋文化、＋康养等新产业新业态，加快实现一村一品、一村一景、一村一韵。优先支持建档立卡贫困户加入休闲农业合作社，发展休闲农家、小型采摘园等，带动贫困地区传统种养业转型升级，促进贫困地区脱贫致富。要积极探索社会资本参与贫困地区发展休闲农业的利益分享机制，引导和支持社会资本开发农民参与度高、受益面广的项目，着力推动产业精准脱贫。要通过发展参与度高的休闲农业体验项目，完善配套服务设施，使游客来得了、留得住、还想来。要着力开发当地原生态农特产品，精心设计包装，使游客看着好、吃着香、能带走，带动贫困地区优质农副土特产品种植养殖和加工销售。各地休闲农业示范点（园）都要充分利用游客资源，创造条件设立农产品专区、专柜，方便周边群众就地销售农特产品。（五）培育知名品牌积极参与农业部组织的全国休闲农业示范县（市、区）创建、中国美丽休闲乡村推介、休闲农业精品景点线路推介等活动，培育打造全国知名品牌。按照省统筹、市负责工作机制，继续做好省级休闲农业示范点创建和运行监测工作，培育打造省级休闲农业知名品牌。统筹利用现有资源建设农业教育、社会实践和研学旅游示范基地。开展省内休闲农业精品景点线路推介，吸引城乡居民到乡村休闲消费。鼓励各地充分利用互联网、物联网、微信等现代信息传播技术，因地制宜开展多种形式的品牌创建与推介活动，培育地方品牌。四、保障措施（一）加强组织领导各级农业部门要从战略和全局高度深化对发展休闲农业的认识，切实负起牵头落实本地休闲农业发展的工作责任。要将休闲农业纳入当地国民经济和社会发展规划，列入部门重要议事日程，认真履行规划指导、监督管理、协调服务的职责，组织拟定发展战略、政策、规划、计划并指导实施，切实提高推动休闲农业科学发展的能力。积极与发展改革、财政、国土、住房和城乡建设、工业和信息化、水利、林业、文化、旅游、扶贫等相关部门对接协调，争取支持，构建农业部门牵头、相关部门支持的工作体系，不断形成工作合力。（二）强化政策落实认真贯彻落实中、省关于推进农村一二三产业融合和促进休闲农业发展的相关意见精神，强化各项政策落地措施。在用地政策上，要用足用活城乡建设用地增减挂钩及关于农村集体经营性建设用地自办、入股等方式发展休闲农业等政策。要积极向当地政府汇报，争取将休闲农业项目建设用地纳入土地利用总体规划和年度计划合理安排。要支持有条件的地方通过盘活农村闲置房屋、集体建设用地、四荒地、可用林场和水面等资产资源发展休闲农业。在财政政策上，要鼓励各地整合财政资金，将中省有关乡村建设资金向休闲农业集聚区倾斜。要探索采取以奖代补、先建后补、财政贴息、设立产业投资基金等方式加大财政扶持力度。在金融政策上，要积极搭建银企对接平台，创新融资模式，鼓励利用PPP、众筹、互联网＋等模式，引导社会资本投资。鼓励担保机构加大对休闲农业支持力度，帮助经营主体解决融资难题。（三）加大公共服务对休闲农业管理人员、经营人员、从业人员组织多种形式的培训，提升人才素质，积极探索培育休闲农业职业经理人，为产业发展提供人才储备。依托科研教学单位建立一批设计研究中心、规划中心、创意中心，为休闲农业发展提供智力支撑。鼓励社会资本参与休闲农业宣传推介平台建设，增强线上线下营销能力，加快构建网络营销、网络预订和网上支付等公共服务平台，全面提升行业信息化水平。强化行业运行监测分析，构建完善的休闲农业统计监测制度。鼓励各地根据实际情况制定地方行业标准，推动本地休闲农业规范有序发展。鼓励各级农业部门利用多种模式开展公益宣传推介，不断扩大休闲农业产业影响力。鼓励各地举办特色鲜明、影响力大、公益性强的农事节庆活动，努力营造发展良好氛围。鼓励各地加强行业服务组织建设，加快形成自我管理、自我监督、自我服务的社会化服务体系。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年8月25日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于加快发展休闲农业助推产业扶贫的意见'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-08-17 15:44:07',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕90号各设区市农业（农林）局（委），杨凌示范区农业局，韩城市农林局：为全面提高农药经营人员素质，推动全省农药经营人员培训工作的有序开展，为全省实施&amp;ldquo;农药经营许可&amp;rdquo;打下坚实基础，根据新修订的《农药管理条例》《农药经营许可管理办法》对农药经营人员的资格要求，我厅特制定了《陕西省农药经营人员培训工作方案》，现印发给你们，请遵照执行。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年8月3日陕西省农药经营人员培训工作方案为全面提高我省农药经营人员的业务水平和法律意识，规范从业行为，确保农药经营人员素质达到农药经营许可要求，根据国务院《农药管理条例》和农业部《农药经营许可管理办法》等相关规定，特制定本方案。一、目的意义提升我省农药经营人员的业务水平和服务质量，增强守法经营意识，通过对相关法律法规和基本业务知识培训，使农药经营人员达到熟悉农药管理规定、掌握农药和病虫害防治专业知识。能够指导使用者安全合理使用农药的目的，确保我省农业生产安全、农产品质量安全及人畜安全。二、培训对象年满18周岁，具有初中以上文化程度，在我省行政区域内从事农药经营的负责人、经营人员。三、培训方式农药经营人员按照自愿的原则，选择本经营单位所在地，经本市（区）农业行政主管部门认定的，具有教育培训资质的专业教育培训机构进行集中脱产培训学习，经营人员跨区域参加培训的不予认可。培训费用由经营人员或经营人员所在单位承担，培训机构按国家有关规定合理收取。四、时间安排2017年9月30日前各市（区）完成培训机构的考核认定，2018年6月1日前，全面完成现有农药经营人员的培训工作。五、培训内容（一）农药管理法规。新修订《农药管理条例》《农药经营许可管理办法》《农药标签和说明书管理办法》等政策法规、法律条文、配套规章的学习，不少于8学时；（二）农业基础知识。《作物栽培学》《农业生态学》《植物营养学》等农业基础知识学习，不少于16学时；（三）植保基础知识。《植物化学保护》《农药学》《植物病理学》《农业昆虫学》等植保基础知识学习，不少于24学时；（四）农药安全知识。农药科学合理使用、农药安全保管、使用安全防护、中毒急救措施等农药安全基础知识学习，不少于8学时。具有农学、植保、农药专业中专以上学历或具有农业部颁发的农资营销员职业资格证书人员需进行不少于8学时的农药法律法规培训；其他人员需进行不少于56学时的系统培训学习。六、培训机构开展农药经营人员培训的机构为经市（区）农业行政主管部门公开认定的具有教育培训资质的专业教育培训机构。我省辖区内具有资质的专业教育培训机构可向所在地的市（区）农业行政主管部门提出农药经营人员培训资格书面申请（书面申请材料主要包括机构代码证、教育培训资质、办学条件、师资力量等），经现场考核认定（认定前认定单位要对认定的程序、方法、要求等进行公示）被确定具有农药经营人员培训资格的专业教育培训机构，各地要对其机构名称，办学地址、联系电话等信息予以公示，广泛接受社会监督，确保整个认定过程公开、透明。培训结束后，组织学员进行考核，对考核合格者，颁发农药经营人员培训证书，培训证书应载明培训时间、培训课程、培训学时等。每期培训开班前，培训机构要对培训时间、培训人员、课程设置、收费标准等信息予以公示，并向市（区）农业行政主管部门进行备案。七、有关要求（一）及时组织开展培训。各市（区）农业行政主管部门是培训机构监管的责任主体，要高度重视农药经营人员培训工作，制定工作方案，确定专人负责，尽快认定培训机构，对培训机构实行动态管理，对于教学松散、考核不严、师资薄弱的机构撤销其培训资格。（二）培训实行&amp;ldquo;三堂课&amp;rdquo;制度。市（区）农业行政主管部门确定专人参加开班前的第一堂课，检查学籍档案、核实学员身份等。在培训期间，随机抽查一堂课，了解学员对培训的评价，逐步完善培训方式，丰富培训内容。参与最后一堂课，对结业考试工作进行监督检查，对该期培训工作做出总体评价。要建立好学籍档案，保留好课程表、报到册、签到册、考核试卷等，以便核对查验，确保整个培训过程不流于形式。（三）鼓励统一报名培训。鼓励省农资商会等协会、社会团体组织本协会、团体会员统一报名，独立开班培训，加快培训进程，为农药经营许可制度的全面贯彻实施赢得时间。（四）加强信息报送。各市（区）要及时将培训工作方案、培训机构名单报省农业厅种植业处备案，并于每月5日前将本月培训计划、上月开班情况、人员培训情况等上报省农业厅种植业处。\xa0\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于印发《陕西省农药经营人员培训工作方案》的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-07-24 11:26:43',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕84号各设区市农业局（委），杨凌示范区农业局，韩城市农林局：7月份以来，我省出现大范围持续高温少雨天气，除汉中、安康外各地均出现不同程度旱情，局部地区发生冰雹灾害，对农业生产造成不利影响。据气象部门预测，7月26日前，我省大部地区晴热天气持续，陕北南部、关中、陕南东部部分地方最高气温维持在35℃以上，旱情将呈加剧蔓延之势，为有效应对天气影响，切实抓好秋季农业生产，现就有关事项通知如下：一、层层落实责任今年是党的十九大召开之年，也是推进农业供给侧结构性改革和转型升级深化之年，做好防灾减灾工作、夺取全年农业丰收意义重大。各级农业部门要牢固树立&amp;ldquo;抗大旱、抗长旱&amp;rdquo;的思想，进一步加强组织领导，层层落实责任，增强服务观念，实行领导干部分片包抓，技术干部逐村指导，做到任务明确、责任到人、措施到位，扎实做好后期的灾害防范和农业生产各项工作，力争全年粮食再获丰收。二、加强监测预警各级农业部门要主动与气象等有关部门沟通联系，密切关注天气变化，及时了解雨情、水情和灾害发生动态，组织专家会商，科学研判发展趋势，发布灾害性天气预警信息和应对措施，组织群众提早做好防御工作。严格落实值班制度和领导带班制度，准确调度灾情，为科学抗灾、及时救灾提供依据。灾害发生后，要及时深入一线，靠前指挥，了解灾情动态，按照层层上报、级级负责的原则，第一时间报送农业受灾情况。三、推进科学抗灾秋粮种植范围广、种类多，要因作物、因区域、因苗情管理。各地要结合天气情况和作物生长发育进程，组织专家分区域、分作物制定技术方案，开展分类指导。出现旱象的地区，要联合水利部门开动一切水利设施，加快灌溉速度，努力扩大灌溉面积，保障秋作物正常生长发育；遭受洪涝的地区，要及时排水，防止水淹根系死亡，适时除草放墒，防止草荒；对已受短时暴雨、冰雹危害的田块，要及时覆土扶苗，加强肥水管理和病虫防治，快速恢复生长，打好丰产基础。四、强化服务指导各级农业部门要灾前防范、灾后救助并重。一是充分利用广播、电视、网络、手机等信息平台，广泛宣传防御灾害天气的关键措施，增强群众的防范意识，提高主动防灾避灾能力。二是储备好化肥、种子、农药、遮雨布（塑膜）、抽水机具等救灾物资，及时检修灌溉设施、设备，做好防灾救灾准备，确保生产急需。三是做好以玉米二代粘虫、马铃薯晚疫病等为主的重大病虫监测预报和防治工作，大力推进专业化统防统治，有效遏制病虫暴发为害，确保秋粮丰收。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年7月20日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于切实做好防灾减灾保秋粮工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-07-19 17:25:48',
 'art_detail': '\n'
               '         \xa0'
               '陕农业发〔2017〕57号各设区市农业局（委），杨凌示范区农业局，韩城市农林局：为加快培育新型农业经营主体，推进农民合作社规范化建设，促进家庭农场健康发展，按照《陕西省农民合作社示范社评定及监测办法》《陕西省示范家庭农场评定及监测办法（试行）》，分两批认定陕西省农民合作社示范社891家（不含取消省级示范社资格的合作社）和陕西省农民用水组织示范组织21家，分两批认定陕西省示范家庭农场1017家。经按地域和专业分类，形成陕西省农民合作社示范社、陕西省农民用水组织示范组织、陕西省示范家庭农场名录，现予以公布。各级农业部门要与发改、财政、水利、林业、工商、税务、供销、银监等部门加强联系协调，加大对省级示范社、用水示范组织、示范家庭农场的指导、扶持和服务，落实并完善各项扶持政策，加大支持力度，在涉农项目安排、财政奖补、金融支持等方面给予更多的倾斜，增强示范社、用水示范组织和示范家庭农场的市场竞争力和凝聚力，带动农户发展规模经营。各级农业部门要指导示范社实行民主管理、社务公开、惠顾返还，特别是财政扶持资金形成的资产量化到成员，不断提升合作社规范化水平。同时，加强典型示范合作社、示范家庭农场的宣传报道，扩大社会影响力和示范带动效应，为促进产业脱贫，农民增收，农村经济社会稳定发展贡献力量。附件：1.陕西省农民合作社示范社名录\xa0\xa0\xa0\xa0\xa0 '
               '2.陕西省农民用水合作组织示范组织名录\xa0\xa0\xa0\xa0\xa0 3.陕西省示范家庭农场名录\xa0 \xa0'
               '陕农业发〔2017〕57号附件.doc\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年6月26日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于公布陕西省农民合作社示范社陕西省示范家庭农场名录的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-07-10 17:09:59',
 'art_detail': '\n'
               '         '
               '陕农业人事〔2017〕9号厅机关各处（室、局），厅属各单位：根据《公务员法》和《陕西省农业厅干部任用工作暂行规定》中干部退休有关规定，经省农业厅研究决定，免去：杨晓萍同志厅办公室副调研员职务，退休。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年4月25日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于杨晓萍同志免职退休的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-07-20 16:22:22',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕64号各有关市农业、畜牧局（委）、财政局：根据《农业部财政部关于做好2017年中央财政农业生产发展等项目实施工作的通知》（农财发〔2017〕11号）精神，为做好我省2017年高产优质苜蓿示范建设项目申报工作，现就有关事项通知如下：一、项目申报条件（一）集中连片。申报单位具有适宜苜蓿标准化种植的土地，面积2000亩以上，集中连片，同时提供土地使用权证明文件或土地租赁合同（截止2017年7月5日租赁期限在7年以上）。若申报主体土地条件好，面积3000亩以上，土地可相对集中连片，但最多不超过3块。（二）申报对象。农民饲草专业生产合作社、饲草生产加工企业、奶牛养殖企业（场）和奶农专业生产合作社。（三）资质条件。申报单位应具有独立法人资格，符合申报对象4类主体，且资产结构及经营状况良好，无不良诚信记录，并具备以下条件：1、农民饲草专业生产合作社和奶农专业生产合作社需成立1年以上（以项目申报时间为准），且有规范的章程、完善的管理制度，有独立的银行账户和会计账簿，建立了成员账户，实行独立的会计核算，财务管理和收益分配制度健全。2、饲草生产加工企业：需具有A级（含）以上资信等级（未申请过银行贷款的企业除外），具有苜蓿生产加工经验，注册资本200万元（含）以上。3、奶牛养殖企业（场）：奶牛存栏300头以上的标准化规模养殖企业（场）。对于符合项目申报条件，且申请集中连片种植3000亩以上或已大面积开展苜蓿种植的企业（场、合作社）予以优先支持。二、项目建设原则（一）突出优势，集中连片。项目建设以苜蓿优势产区和奶牛主产区为重点，优先支持土地资源、水资源和产业基础等优势突出的地区，不断提升优势产区的苜蓿综合生产能力和产业化经营水平。（二）草畜结合，协调发展。鼓励农民饲草专业生产合作社、饲草生产加工企业与奶牛养殖企业（场）、奶农专业生产合作社建立长期的合作关系，促进苜蓿生产与奶牛养殖有机结合，不断提高奶牛科学养殖水平。（三）专业生产，示范带动。按照专业化、标准化、规模化和集约化生产的要求，发挥示范片区带动作用，促进饲草生产加工方式转变。三、项目建设区域与任务选择陕北苜蓿优势产区和关中奶牛主产区实施，共扶持建设2.7万亩高产优质苜蓿示范片区。四、项目投资补助标准和补助方式中央财政补助资金对符合项目条件的单位按照每亩600元的标准给予补助。补助资金主要用于改良苜蓿品种、实行标准化生产、改善生产条件、提升质量安全水平等方面。项目立项后，财政部门将先期安排50%的补助资金。项目验收合格，公示期满无异议，财政部门再安排剩余50%的补助资金。对于验收不合格的，由财政部门会同农业主管部门追回预先安排的50%补助资金，或限期整改后安排剩余50%的补助资金。五、申报程序和要求1、各有关市要按照项目申报条件，积极组织辖区内的饲草专业生产合作社、饲草生产加工企业与奶牛养殖企业（场）、奶农专业生产合作社做好项目申报工作。项目申报要与区域产业脱贫结合，发挥项目带动作用，明确量化带动贫困户数量和指标。2、对符合条件的申报对象，组织申报单位编制项目实施方案（编写提纲见附件），市级畜牧（农业）主管部门提出审查意见，并对拟申报项目进行为期5天的公示，公示无异议后，于2017年7月30日前会同财政部门上报省财政厅、省农业厅，抄送省农业厅发展计划与财务处、省畜牧兽医局及省财政厅农业处各1份。3、申报单位需提供以下证明材料：项目申报单位营业执照和企业法人营业执照复印件；项目申报单位开户行出具的资信等级证书（未申请过银行贷款的企业不需提供）；项目单位适宜苜蓿标准化种植的土地证明（注明土地类型：坡地、滩地、梯田等），有土地使用权证明文件或土地租赁合同，租赁方必须为项目申报单位；项目单位为奶牛养殖企业（场）的，需提供当地畜牧部门备案登记表；项目建设地点的平面图（拐点标注经纬度）。市县农业主管部门、财政部门要对申报单位提供的证明材料进行核实，对其真实性负责。附件：2017年XX县（市、区）高产优质苜蓿示范建设项目实施方案\xa0\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0'
               '陕西省财政厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年7月19日附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅  陕西省财政厅关于申报2017年高产优质苜蓿示范建设项目的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2017-07-24 08:43:22',
 'art_detail': '\n'
               '         '
               '驻陕农纪发〔2017〕13号省农业厅、省扶贫开发办公室、省供销合作总社党组：为了认真落实省委《关于印发&lt;中央第十一巡视组对我省巡视回头看反馈意见整改方案&gt;的通知》和省纪委《关于认真做好巡视整改工作的通知》中有关选人用人问题整改意见，强化动议方案审查和干部任前把关，切实防止干部带病提拔，根据《中国共产党党内监督条例》、《党政领导干部选拔任用工作条例》、中共中央办公厅《关于防止干部带病提拔的意见》及省委实施办法，现就在综合监督单位（以下简称各单位）选人用人工作中强化监督执纪问责提出如下意见：一、明确监督重点对象和范围根据派驻机构职能定位，驻省农业厅纪检组对各单位推荐副厅级干部及后备干部人选、选拔任用处级干部进行监督，重点对选拔任用处级干部进行全程监督。各单位机关纪委应当加强对科级干部选拔任用工作的监督管理和执纪问责工作。二、严审选拔动议及工作方案坚持先定原则，后议人选。各单位党组根据工作需要和各单位各处室领导班子建设实际，按照以事择人、按岗选人的要求，就选拔任用的职位、条件、范围、方式、程序等提出干部选拔任用的初步动议及工作方案，在一定范围内充分酝酿吸收意见后，书面征求驻省农业厅纪检组意见，纪检组重点就初步工作方案的规范合理性、公平公正性进行审查，提出改进的意见和建议后，动议单位党组研究审定并最终形成民主推荐处级干部工作方案。各单位组织人事部门应严格按方案公开公正的推荐选拔相关人选，驻省农业厅纪检组或委托机关纪委对推荐过程的关键环节进行现场监督。三、从严落实凡提四必要求各单位党组要加强任前把关，坚持前移审核关口，认真做到该审早审、该核早核，对纳入考虑范围的有关人选，提前审核其政治表现和廉洁自律等情况，切实把凡提四必要求落到实处。一是要做到干部档案凡提必审，重点对三龄两历一身份（三龄是指年龄、工龄、党龄；二历指学历、工作经历；一身份指干部身份）等重要信息，逐人逐卷逐页逐项进行严格审核，对档案有涂改、造假等现象的，一律进行核实并做出处理；二是要做到个人有关事项报告凡提必核，把核查结果作为评价识别领导干部是否对党忠诚老实的重要标志、是否清正廉洁的重要依据、健康与否的重要诊断；三是要做到纪检监察机关意见凡提必听，在研究确定考察对象前，各单位组织人事部门要书面征求驻省农业厅纪检组对有关人选的廉政意见，并提供干部档案和个人事项报告审核的书面结论意见；四是要做到对线索具体的信访举报凡提必查，对考察及公示期间收到的信访举报,启动快查快办核查程序，对发现问题影响使用的，及时中止选拔任用程序，对疑点没有排除、问题没有查清的，暂缓办理任职手续。同时，要为那些受到诬告、诽谤、陷害的干部澄清正名，严肃处理打击报复、诬告陷害行为。四、执行好廉政考试及谈话制度各单位要认真落实领导干部任前廉政法规考试制度，拟任职的处级领导干部在任前必须参加廉政法规考试，在任职公示期间，各单位应将参加考试人员基本情况书面报送驻省农业厅纪检组，及时通知相关人员参加廉政法规考试，驻省农业厅纪检组向省纪委申领复习资料、申请考试、抽题监考、评判试卷、通报成绩。考试成绩合格者方能任用，不合格者需要进行补考，补考不合格者不予任用。由于特殊原因未按时参加考试者，经各单位组织人事部门同意并写出书面说明后，可参加下一次考试。各单位要认真落实领导干部任职廉政谈话制度，在处级领导干部任职通知下发后一个月内，由各单位商驻厅纪检组对新任处级领导干部进行集体或个别廉政谈话。谈话对象应结合本职工作实际写出廉政承诺书，并于廉政谈话前分别报送驻厅纪检组和所在单位机关纪委存档备案。廉政谈话结束7日内，由谈话对象所在单位和部门负责，将个人廉政承诺书以适当方式进行公示，接受干部群众监督。五、严格追究干部带病提拔责任建立健全干部带病提拔问责机制。凡出现带病提拔的问题，都要对选拔任用过程进行倒查，存在隐情不报、违反程序等失职渎职行为的，不仅追查当事人，而且追究责任人，一查到底、问责到人。要逐一检查动议、民主推荐、考察、讨论决定、任职等各个环节的主要工作和重要情况，甄别相关责任人的责任。对干部在政治品质、道德品行、廉洁自律等方面存在违规违纪问题，但由于领导不力、把关不严、考察不准、核查不认真，甚至故意隐瞒、执意提拔，造成干部带病提拔的，要按照有关规定严肃追责。凡因干部带病提拔造成恶劣影响的，由单位党组会同纪检组进行认真自查反思，做出深刻检查。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '中共陕西省纪委驻省农业厅纪检组\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年7月21日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '中共陕西省纪委驻省农业厅纪检组关于在综合监督单位选人用人工作中强化监督执纪问责的意见'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-06-05 14:39:12',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕68号各设区农业局（委），杨凌示范区农业局、韩城市农林局：为宣传基层农技人员不畏艰苦、为农服务的高尚品德，展示他们务实重干、开拓创新的精神风貌，为农技推广事业发展营造良好的社会氛围，鼓励广大农技人员扎根基层、爱岗敬业，农业部决定在全国开展&amp;ldquo;寻找最美农技员活动&amp;rdquo;。为做好我省推荐工作，现将有关事宜通知如下：一、范围和名额（一）寻找范围。最美农技员寻找范围为基层农技推广机构长期从事农业技术推广服务并取得突出成效的农技人员，不包括行政编制人员。（二）推荐名额。2017年农业部将确定100名最美农技员，按照1:5比例从各地遴选500名候选人。各市拟推荐候选人名额以2016年底各市、县基层农技推广机构编制内人员数量为主要测算依据，详见附件1。农业部将从上述100名最美农技员中，择优产生2017年度&amp;ldquo;全国十佳农技推广标兵&amp;rdquo;资助人选。二、入选条件最美农技员推荐人应为仍在农业技术推广一线工作的基层农技人员，并符合下列条件。（一）热爱祖国，拥护中国共产党领导，品行端正，无违法犯罪和党纪政纪处分记录。（二）精通业务工作，推广了多项农业关键技术，常年深入生产一线开展服务，积极为产业脱贫提供服务，为当地粮食增产、农业增效、农民增收做出了突出贡献。（三）受到省市县级以上表彰奖励，得到当地农业部门、农技推广机构、农民群众等各方面的普遍认可，事迹感人。（四）在县乡从事农技推广服务工作累计在15年以上（不含以行政编制身份从事农技推广工作时间），计算时间截止到2017年6月30日。事迹特别突出的农技人员可不受从事农技推广服务工作时间限制，但须由所在地县（市、区）政府出具证明函。三、工作程序（一）拟推荐对象所在单位在充分发扬民主、广泛征求意见基础上，经过民主推荐、领导班子集体研究决定后，提出拟推荐对象，填写&amp;ldquo;寻找最美农技员活动&amp;rdquo; '
               '推荐申报表（见附件2）并附推荐人学历学位、主要业绩等证明材料，报送县级农业行政主管部门。（二）县级农业行政主管部门牵头成立审核委员会，会商农机、畜牧、果业部门，组织对推荐人选及相关资料进行核查，核查合格的进行公示。公示无异议的，签署意见并加盖公章后自下向上逐级推荐。（三）省、市、县农业行政主管部门牵头成立推荐评审委员会，对推荐人选所在单位、所在地推荐工作规范性和相关材料进行审核后，按照本区域的推荐名额产生推荐人选，公示无异议后向农业厅报送本市推荐函及推荐人员有关材料。推荐函包括推荐工作及公示情况等，并附本市最美农技员推荐人选基本情况表（见附件3）。（四）农业厅组织对各市推荐材料进行形式审查后，经评议、公示等程序，无异议后向农业部报送我省推荐函及拟推荐人员有关材料。四、有关要求（一）各市县农业行政主管部门要坚持公开、公平、公正，把扎根基层、业绩突出、贡献卓著的基层农技人员遴选出来。近年部分市评选出的本市最美农技员，可简化工作程序，直接经市推荐评审委员会审议通过后，作为本市最美农技员推荐人选（须附相关证明材料）。（二）推荐材料要真实、准确、规范，成绩和贡献要重点突出、言简意赅，避免面面俱到、空话套话。公示内容包括拟推荐对象基本情况和主要成绩、贡献，公示时间为5个工作日。公示期内，如有书面、实名投诉，应及时处理，并明确提出是否继续推荐的意见。（三）严肃工作纪律，加强监督检查，杜绝暗箱操作。对于伪造成绩、贡献、材料等行为，经查实后撤销其推荐资格。五、推荐材料报送（一）电子材料报送。各市推荐函及推荐申报表电子版请发送到厅科教处电子邮箱。（二）纸质材料报送。市级农业部门统一将本市推荐函及推荐申报表等材料报送到厅科教处。推荐申报表一式10份，其中原件2份，复印件8份。（三）报送截止时间。各市推荐材料报送截止时间为2017年6月10日，纸质材料以寄出材料邮戳时间为准。六、联系方式联系人：申 '
               '巍 农业厅科教处电 '
               '话：029&amp;mdash;87321775，029&amp;mdash;87320250（兼传真）邮 '
               '箱：njtgsx@163.com通讯地址：西安市习武园27号 邮政编码：710003附件: 1. '
               '各市最美农技员推荐人数\xa0\xa0\xa0\xa0\xa0 2. '
               '&amp;ldquo;寻找最美农技员活动&amp;rdquo;推荐申报表\xa0\xa0\xa0\xa0\xa0 3. '
               '最美农技员推荐人选基本情况表\xa0\xa0\xa0\xa0 '
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年5月27日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于开展“寻找最美农技员”活动的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2017-07-07 17:16:33',
 'art_detail': '\n'
               '         '
               '各市、县（区）植保植检站：粘虫是跨区域迁飞性、暴发性的重大害虫，具有集中暴发和隐蔽危害的特点，严重威胁玉米生产安全。据监测，近期二代粘虫在我省夏玉米田部分地区发生危害，局部田块受害严重，全省发生面积230万亩，结合气象预报，预计全省二代粘虫发生面积500万亩，且三代粘虫在局部有集中危害可能。为切实做好粘虫防控工作，现就有关事项紧急通知如下。一、 '
               '加强组织领导，落实防控责任7-8月份是粘虫发生危害重要时期，及时防控关系玉米丰收大局。各地务必高度重视，切实加强组织领导,落实病虫害防控属地责任，建立健全防控机制。对重发区要组织人员包片联系，防控关键时期组派精干力量，分赴重点区域，深入生产一线，开展督导检查，确保防控责任和措施落实到位。二、加强调查监测，明确常发重发区域各地要结合实际，采取系统监测和大田普查相结合的方法，组织技术人员深入田间地头，认真调查监测，全面掌握虫态发展、危害情况，摸清发生面积和重发区域。长安、蓝田、岐山、扶风、兴平、泾阳、潼关、华阴等县（市、区）要根据粘虫发生动态，结合天气情况，及时发布预警信息，向广大农民宣传虫情动态及防治信息。三、加强物资准备，开展专业防控粘虫繁殖速度快，具有成群迁移危害等习性，容易形成短期内集中暴发成灾态势。各地要未雨绸缪，完善防控预案，积极做好应急防控资金、物质、人员等准备工作；要突出重点区域和防治关键时期，大力开展专业化统防统治和应急防控；对虫情基数高、危害程度重、涉及面积大的地方，要及时向农业行政部门汇报，争取防控资金和行政支持，必要时采取地面大型机械和航化作业等高效防控手段，迅速控制粘虫危害与扩散蔓延。四、加强培训宣传，落实技术措施当前，正值盛夏高温季节，群众防控意识普遍淡薄。各地要充分利用新闻媒体，广角度、高频次的向广大群众宣传粘虫危害的严重性和防控的重要性，确保信息覆盖面和入户率。要因地制宜，科学制定防控技术方案，指导群众优先选用高效、低毒、低残留的农药，落实减量控害；要通过举办培训班、印发明白纸、召开现场会等形式，大力开展防控技术培训宣传，指导农民科学用药，适时开展防控，确保农业生产和生态环境安全。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省植物保护工作总站\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年7月7日\n'
               '        ',
 'art_source': '陕西省植保站',
 'art_title': '陕西省植物保护工作总站关于做好玉米粘虫防控工作的紧急通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-05-18 16:19:38',
 'art_detail': '\n'
               '         陕农业发〔2017〕45号\r\n'
               '\r\n'
               '各设区市农业局（委），杨凌示范区农业局、韩城市农林局，西北农林科技大学、杨凌职业技术学院，各省级农业产业技术体系，厅机关各有关处（室、局）、厅属各有单位：\r\n'
               '为充分发挥农业科技在产业扶贫精准脱贫中的助推作用，按照《陕西省脱贫攻坚领导小组产业脱贫办公室关于印发加快推进产业扶贫精准脱贫工作意见的通知》（陕产业脱贫办发〔2017〕6号）要求，我厅决定组建陕西省农业产业扶贫精准脱贫专家服务团，并开展对口帮扶工作，现就有关事项通知如下：\r\n'
               '一、充分认识科技在产业扶贫精准脱贫中的助推作用\r\n'
               '脱贫攻坚事关全面建成小康社会，事关贫困群众民生福祉，是“十三五”期间农业农村工作的一号工程，也是农业部门的重要职责所在。扶贫必扶智，要扶知识、扶技术、扶思路，帮助和指导贫困群众掌握发展的一技之长，着力提升脱贫致富的综合素质，从根本上铲除滋生贫穷的土壤。技术支撑是农业部门的优势所在，也正是贫困户发展产业面临的普遍难题。农业科技脱贫是产业扶贫精准脱贫的重要内容，是贫困地区农业发展方式转变的内在要求，是增加农民收入的重要方式。各级农业部门要立足技术精准帮扶，指导贫困地区做强地区主导产业、做大特色产业、发展小众产业，积极破解制约贫困地区产业发展的关键技术难题，推动“输血”向“造血”转变，解决贫困户自我发展和脱贫可持续问题，从根本上打赢脱贫攻坚战。\r\n'
               '二、组建产业扶贫精准脱贫专家团队\r\n'
               '省农业厅组建由省级农技推广单位、西北农林科技大学、杨凌职业技术学院、市级农科所（院）主要负责人及28个省级农业产业技术体系首席科学家为成员的陕西省农业产业扶贫精准脱贫专家服务团（名单详见附件1），负责全省产业精准脱贫的总体技术指导，帮助市县开展扶贫产业规划论证、技术指导和培训等工作。各市及贫困县（区）要建立市、县级专家服务团队，县级专家服务队要涵盖种、养、加工、服务、农机、土肥、植保、环保等方面专家和心理辅导师，中高级技术职称，可以根据实际需要外聘专家。\r\n'
               '三、建立对口帮扶指导关系\r\n'
               '依据56个贫困县（区）资源禀赋和产业发展情况，结合省级农业产业技术体系、市级农科所（院）、西北农林科技大学、杨凌职业技术学院的科技资源优势，坚持自愿选择原则，在充分征求技术对口帮扶和贫困县（区）意见的基础上，建立一对多或多对一的对口帮扶指导关系（见附件2）。省级农业技术推广单位要按照省农业厅安排，选派技术人员进驻贫困县（区），对口联县驻村开展技术指导。各对口帮扶单位和团队要以培育产业为基础、以市场需求为导向，协助贫困县（区），做好产业规划、布局、技术、咨询工作，指导县级专家服务队开展工作，为贫困县（区）产业发展提供技术支持。\r\n'
               '四、明确对口帮扶任务\r\n'
               '（一）开展技术研发集成。立足贫困地区产业发展农民增收问题，发挥技术和项目优势，帮助引进、研发、集成、组装一整套集约式、轻简式技术，研发中小微农业产业的核心关键技术，加快一二三产融合、农机农艺融合、农产品加工、农业信息、休闲农业等综合技术应用，加速应用大数据、云平台、物联网、互联网+农业的一体化融合，快速推进技术覆盖。\r\n'
               '（二）开展技术示范推广。统筹项目、成果等资源，将科技团队自身拥有的农业科技成果、项目、试验示范、科技服务活动等尽量向贫困县（区）、贫困村和贫困户倾斜。帮助当地农技部门、新型经营主体建立农业科技示范基地、产业园区等，示范应用新技术新成果，以点带面，辐射带动农业科研成果的推广。\r\n'
               '（三）开展技术培训。围绕贫困村、贫困户的需求，大力开展普及性技术培训，在关键农时季节，要深入田间地头，深入贫困户家中，有针对性的举办各种技术培训会、培训班，开展手把手的技术培训和技术指导，切实提高贫困户的技术水平。同时要加大对当地农技人员、职业农民、新型经营主体的培训力度，帮助当地建立一支本土化的农业专家队伍。\r\n'
               '五、强化对口帮扶工作保障\r\n'
               '省级农业产业扶贫精准脱贫专家服务团成员单位和对口帮扶单位、组织要高度重视对口帮扶工作，把这项工作列入产业扶贫精准脱贫的重要内容，从讲政治的高度上精心组织谋划部署，坚持主要领导负总责，明确分管领导、责任部门和联络人员，积极为对口帮扶人员提供便利条件和经费保障。各对口帮扶单位和团队要深入开展调查研究，吃透县情，根据贫困户科技需求，明确帮扶目标任务和技术措施，制定工作方案，精心组织实施，并确定专人负责，加强与省农业厅的沟通联系，每月月底上报相关情况。各省级农业产业技术体系首席科学家要切实行动起来，和贫困县（区）签订技术帮扶协议，带领技术团队深入对口帮扶贫困县（区），将全年工作重点和主要精力安排在贫困县（区）。各贫困县（区）要主动与对口帮扶单位联系，安排专人对接，为专家团队提供必要的工作条件，积极配合做好各项技术帮扶工作。\r\n'
               '附件：1. 陕西省农业产业扶贫精准脱贫专家服务团\r\n'
               '\xa0\xa0\xa0\xa0\xa0 2. 各单位团队对口帮扶贫困县（区）安排名单 附件.doc\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年5月12日\r\n'
               '\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于开展农业科技对口帮扶助力产业扶贫精准脱贫工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-06-28 15:40:31',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕54号各有关市农业、畜牧、财政局（委），省农垦集团：为推进农业结构调整，加快发展草牧业，根据《农业部财政部关于做好2017年中央财政农业生产发展等项目实施工作的通知》（农财发〔2017〕11号）精神，农业部、财政部推进专项转移支付预算编制环节源头整合改革，探索“大专项+任务清单”管理方式。2017年，按照任务清单，农业部、财政部继续在我省实施粮改饲试点，并增加了任务量。为切实落实我省2017年粮改饲试点任务，现就有关事项通知如下：一、工作原则（一）坚持需求导向，产销对接。综合考虑草食畜牧业发展现状和潜力，以畜定需、以养定种，合理确定粮改饲种植面积，确保生产的饲草料销得出、用得掉。（二）坚持因地制宜，分类指导。充分考虑本地资源条件，尊重种养双方意愿，集成品种选择、田间管理、收贮加工、饲喂使用等技术，发展具有本地特色的饲草料品种。（三）种养结合，规模适度。把养殖场流转土地自种、订单生产等种养紧密结合的生产组织方式作为优先支持方向，协调推进适度规模种养，同步提升饲草料品质和种养效益。二、实施范围根据中央下达我省粮改饲试点任务量，继续在临潼、陇县、岐山、泾阳、乾县、合阳和省农垦集团实施项目的基础上，新增加9个县区。按照“以关中奶畜大县为主，兼顾陕北肉羊大县”的原则，结合各市草食家畜发展和玉米种植现状，宝鸡、咸阳市各新增2个县区，西安、铜川、渭南、延安和榆林市各新增1个县区。新增县区应具备以下四个条件。（一）奶牛等草食家畜养殖基础好，规模化程度较高；（二）县级政府重视种植结构调整和草食畜牧业发展；（三）农民粮改饲积极性高、养殖场户收贮条件好；（四）优质青贮饲草料需求5万吨以上。优先安排奶牛存栏5000头以上大型养殖场所在县区。三、任务分配各县区结合实际需求进行申报，2016年试点县区申请青贮量不超过2016年计划任务，2017年新增县区申请青贮量不低于5万吨（按1亩地约3吨青贮测算）。各县区申报任务量中规模养殖场收贮量应占收贮总量50%以上。省上结合各县区申报情况，运用因素法（主要因素为饲草需求和玉米种植面积）对县区任务进行测算分配。四、相关要求各市农业主管部门要组织相关县区深入了解区域内以奶牛为主的草食家畜规模化养殖、全株玉米青贮需求、青贮玉米种植情况，按照“以畜定需、以养定种”的原则申报青贮任务需求量，并填写粮改饲任务申报表，商同级财政部门确定新增县区，于7月1日前以正式文件上报省农业厅、省财政厅，抄送省农业厅发展计划与财务处、省畜牧局畜牧处和省财政厅农业处。附件：粮改饲任务申报表联系人：省农业厅计财处\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '邹艳丽\xa0\xa0\xa0\xa0\xa0\xa0 '
               '029-87321683省财政厅农业处\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '邢维超\xa0\xa0\xa0\xa0\xa0\xa0 '
               '029-68936115省畜牧局畜牧处\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '王鹏飞\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '029-87344000\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '陕西省财政厅\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年6月27日附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅  陕西省财政厅关于申报2017年粮改饲试点任务的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-05-11 09:07:34',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕57号各设区市农业局（委），杨凌示范区农业局，韩城市农林局：根据《农业部办公厅关于开展中国美丽休闲乡村推介工作的通知》（农办加〔2017〕10号）精神，农业部决定继续开展中国美丽休闲乡村推介活动。为切实做好我省2017年中国美丽休闲乡村申报推介工作，现就有关事项通知如下：一、申报类型申报中国美丽休闲乡村以村为主体单位，主要类型分为历史古村、特色民居村、现代新村、特色民俗村等四种。集中连片发展较好、以休闲农业和乡村旅游为主要产业的特色小镇也可申报。二、基本条件申报村应以农业为基础、农民为主体、乡村为单元，依托悠久的村落建筑、独特的民居风貌、厚重的农耕文明、浓郁的乡村文化、多彩的民俗风情、良好的生态资源，因地制宜发展休闲农业和乡村旅游，功能特色突出，文化内涵丰富，品牌知名度高，农民利益联结机制完善，具有较强的示范辐射和带动作用。农业部已认定的中国最有魅力休闲乡村和中国最美休闲乡村，不再申报。具体条件为：（一）生态环境优美。能够贯彻落实中央保护环境的要求，制定了具体有效的环境保护措施，自觉推动绿色发展、循环发展和低碳发展，形成山水林田湖有机生命综合体和资源节约型空间格局、产业结构、生产方式和生活方式。（二）产业功能多元。农业功能得到充分拓展，农耕文明、田园风貌、民俗文化得到传承，农业生产功能与休闲功能有机结合，一二三产业有机融合，就地吸纳农民创业就业容量大，带动农民增收能力强。（三）村容景致独特。乡土民俗文化内涵丰富，村落民居原生状态保持完整，基础设施功能齐全，乡村各要素统一协调，传统文化与现代文明交相辉映，浑然一体，村容景致令人流连忘返。（四）精神风貌良好。基层组织健全，管理民主，社会和谐；村民尊老爱幼，邻里相互关爱，村民生活怡然自得；民风淳朴，热情好客，诚实守信。三、申报数量各市（区）各申报1个村。四、申报程序（一）乡村申报。村在对照基本条件进行自我评估的基础上，填写《2017年中国美丽休闲乡村申报表》，向县级农业管理部门提出申请，并附本村综合情况相关材料。（二）县级审核。县级农业部门负责对本县申报的乡村进行审核，择优向市级农业部门推荐，并登录中国休闲农业网（www.crr.gov.cn）填写相关材料的电子申报文档。（三）市级推荐。市级农业主管部门经实地考察、综合评议后，择优正式行文向省农业厅推荐。纸质推荐文件一式两份，于6月30日前报至省发展一村一品指导中心，同时将所有申报材料电子版发送至xxnyxh@163.com。（四）省级评审。省农业厅组织有关专家对各市推荐的申报村进行综合评审，按照农业部分配给我省的指标择优推荐上报。五、有关要求（一）此次推介为政府公益工作，不收取任何费用。（二）申报村相关佐证材料只通过网络提交，无需纸质版。联 '
               '系 人：田 庚 '
               '电话：029－87343160电子邮件：xxnyxh@163.com附件：2017年中国美丽休闲乡村申报表\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年5月9日附件.docx\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于申报中国美丽休闲乡村的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-05-11 15:31:41',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕55号各有关市农业局（委）：为深入开展&amp;ldquo;到2020年农药使用量零增长行动&amp;rdquo;，加快推进农业绿色发展，农业部于2017年开展了果菜茶病虫全程绿色防控试点行动，我省有10个苹果主产县列入了试点县。根据农业部种植业管理司《关于印发〈果菜茶病虫全程绿色防控试点方案〉的通知》（农农（植保）〔2017〕7号）要求，结合我省实际，特制定了《陕西省果菜茶病虫全程绿色防控试点实施方案》，现印发给你们，请结合各地实际，细化实施方案，强化责任落实，确保取得实效。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年5月5日陕西省果菜茶病虫全程绿色防控试点实施方案为加快推进农业绿色发展，落实农业部种植业管理司《关于印发果菜茶病虫全程绿色防控试点方案》（农农（植保）〔2017〕7号）精神，做好果菜茶病虫全程绿色防控试点工作，探索产出高效、资源节约、环境友好的技术模式和工作机制，特制定本方案。一、总体思路贯彻新发展理念，紧紧围绕农业供给侧改革工作主线，大力实施&amp;ldquo;质量兴农&amp;rdquo;战略，以绿色发展为引领，以改革创新为动力，突出果菜茶优势产区、核心产区、知名品牌基地，开展果菜茶病虫全程绿色防控示范，集成绿色防控技术模式，主攻农产品质量，增加绿色、有机、无公害农产品供给，推进种植业转型升级和可持续发展。二、工作目标选择果菜茶优势产区开展病虫全程绿色防控试点。2017年首先在 '
               '5市的10个苹果和1个猕猴桃主产县集成绿色防控技术模式，打造绿色品牌基地。力争用3-5年时间，初步建立起全程绿色防控的组织方式和政策框架，集成推广全程绿色防控的技术模式和服务机制。具体目标是&amp;ldquo;一减两提&amp;rdquo;：（一）化学农药用量明显减少。到2020年，试点县（市、区）果菜茶化学农药使用量减少30%以上，示范基地化学农药使用量减少50%以上。2017年试点县（市、区）果树化学农药使用量减少25%以上，示范基地化学农药使用量减少35%以上。（二）病虫绿色防控覆盖率明显提高。到2020年，试点县（市、区）果菜茶病虫绿色防控覆盖率达到50%以上，示范基地果菜茶病虫绿色防控覆盖率达到100%。2017年试点县（市、区）果树病虫绿色防控覆盖率达到35%以上，示范基地病虫绿色防控覆盖率达到90%以上。(三)农产品品质明显提升。到2020年，试点县（市、区）加快推进&amp;ldquo;三品一标&amp;rdquo;认证，创建一批地方特色突出、特性鲜明的地理标识和知名品牌，100%符合食品安全国家标准或农产品质量安全行业标准。三、试点布局按照果菜茶优势区域分布，由各市推荐和专家审定，在苹果、蔬菜和茶叶优势产区，选择当地政府重视、绿色防控基础好、技术力量强的县，分批开展试点工作。2017年，在延安市的洛川县、宝塔区、宜川县、黄龙县、咸阳市的礼泉县、旬邑县、长武县、渭南市的白水县、蒲城县和铜川市的印台区建立苹果全程绿色防控试点县10个；在西安市的周至县建立猕猴桃全程绿色防控试点县1 '
               '个。每个试点县（市、区）要依托农业新型主体，建立集中连片的示范基地，果树和茶叶每个示范基地2万亩以上，露地蔬菜每个示范基地1万亩以上。各试点县（市、区）根据发展需要和生产实际，逐年扩大示范基地面积。各果菜茶主产市、县也可参照本方案，积极试点，建立示范基地。四、重点任务（一）提升病虫绿色防控水平。根据果菜茶的生产实际，集成全生育期绿色防控技术模式，重点推广农业健身栽培、花期蜜蜂授粉、免疫诱导抗性、理化诱控害虫、生态和天敌控害、病虫基数控制等措施。在做好病虫系统监测的基础上，优先选用生物药剂，科学对症选择绿色、高效、安全的化学药剂组合，精准用药；选择新型施药器械，高效施药，提高农药利用率，最大程度减少化学农药使用。（二）提升绿色防控与有机肥替代化肥结合水平。在推广绿色防控的同时，要加力推进有机肥替代化肥，实现绿色防控与有机肥替代化肥的有机融合，用健康的土壤和绿色的方式，生产绿色、有机、无公害农产品，满足消费者多样化、特色化和营养健康的消费需求。（三）提升标准化生产与品牌创建水平。加快制订果菜茶绿色防控技术规范和产品标准，推进设施标准化、生产过程标准化、投入品标准化，实现良好农业规范。在此基础上，创响一批特色突出、特性鲜明的区域公用品牌和企业品牌，提高产品知名度和附加值。（四）提升病虫防控专业化水平。通过开展果菜茶全程绿色防控示范，扶持一批植保专业服务组织，推进病虫绿色防控措施落地。引导农民合作社、种植大户、龙头企业等新型经营主体，示范推广病虫全程绿色防控技术，打造一批特色优质果菜茶生产基地。五、保障措施（一）强化责任落实。各试点市、县（市、区）农业部门要将病虫全程绿色防控与有机肥替代化肥试点协同推进，加强协调，搞好服务，推进落实。省农业厅成立由分管厅长任组长、厅种植业处、省植保站等相关处、站主要负责人为成员的实施领导小组，办公室设在省植保站。各示范县（市、区）要成立政府主要负责同志任组长的实施领导小组，明确责任，强化措施，做好组织实施，确保取得实效。各试点县要细化实施方案，确定工作负责人和技术指导专家，并报省植保站。省农业厅将加强对病虫全程绿色防控的实施指导，定期调度进展，协调技术落实，形成上下联运、协同推进的工作格局。（二）强化政策扶持。落实病虫害防控专项补助资金，依托&amp;ldquo;五区一园&amp;rdquo;，支持果菜茶病虫全程绿色防控，结合实施果菜茶有机肥替代化肥行动，聚合资源，聚焦力量，同向推进，发挥政策集合效应。在争取中央专项资金补助的同时，省上将整合有关专项资金预以补助。各试点市、县（市、区）要积极争取当地财政部门的支持，加大对病虫全程绿色防控的支持力度，共同打造绿色高效示范基地。各果菜茶主产县也要根据当地主导产业，加强对示范工作的引导支持，积极推进本地区绿色防控工作。（三）强化指导服务。各试点县（市、区）要明确一名责任人和一名技术指导专家，具体负责制订试点实施方案、技术方案和组织实施工作。植保技术部门要因地制宜，参照《陕西省苹果绿色防控技术方案》（陕植发【2017】20号），集成本地果树全程绿色防控技术方案。通过专题讲座、组织现场观摩、示范展示、果园现场培训和指导等多种形式，推广普及果菜茶病虫全程绿色防控知识技能，让农民群众看到实实在在的防控效果，增强应用自觉性。（四）强化宣传引导。各试点县（市、区）要树立示范牌。充分利用广播、电视、报刊、信息网、手机微信公众号等媒体平台，宣传果菜茶病虫全程绿色防控的重要意义，营造良好氛围。要善于在实践中挖掘基层的鲜活成功案例，总结其全程绿色防控的好做法、好经验，树立可复制的典型，建立技术推广的长效机制。\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于印发陕西省果菜茶病虫全程绿色防控试点实施方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2017-05-05 10:38:13',
 'art_detail': '\n'
               '         '
               '陕产业脱贫办发〔2017〕7号厅各包市联县驻村工作组：落实帮扶措施是实现产业脱贫的关键，全面了解和掌握产业帮扶一线情况是指导和推进工作的基础。各包联小组及每位成员，要迅速入村进户，客观、真实、细致的摸清贫困村、贫困户基本情况，特别是产业帮扶措施到位情况、好的作法、存在问题，在此基础上形成有针对性意见和建议。请各组将表格和书面汇报材料于5月9日18时之前报送厅产业脱贫办公室，厅领导拟于5月10日左右听取部分驻村工作组情况汇报。联系人：申鹏飞 '
               '联系电话：029-87346631邮 箱：sxtscyfp@163.com附表：1. '
               '陕西省农业厅产业脱贫包联村基本情况调查表2. 陕西省农业厅产业脱贫包联村新型经营主体调查表3. '
               '陕西省农业厅产业脱贫包联村贫困户入户调查表4. '
               '陕西省农业厅产业脱贫包联村帮扶情况调查表\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
               '陕西省脱贫攻坚领导小组\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0 '
               '产业脱贫办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年5月4日 附件.doc\n'
               '        ',
 'art_source': '陕西省脱贫攻坚领导小组产业脱贫办公室',
 'art_title': '关于围绕帮扶措施落实切实搞好调研工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-06-09 16:27:15',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕70号各设区市农业局（委），杨凌示范区农业局，韩城市农林局：为切实做好我省家庭农场的规范化建设工作，强化示范家庭农场动态管理，促进全省家庭农场健康发展，进一步加快构建新型农业经营体系，根据《陕西省示范家庭农场评定及监测办法》（陕农业发〔2016〕101号）规定，决定开展省级示范家庭农场评定工作，同时对2015年评定的1017家省级示范家庭农场进行监测评价。现就有关工作通知如下:一、评定及监测原则陕西省示范家庭农场评定和监测工作要严格按照《陕西省示范家庭农场评定及监测办法》规定的标准，注重当地主导产业和优势特色产业，遵循公平、公正、公开、公信的原则，确保示范家庭农场优胜劣汰的动态管理机制，推荐真正代表当地家庭农场规范化、标准化和品牌化建设水平，具有较强经济实力和示范带动能力的家庭农场。二、评定条件申报省级示范家庭农场必须符合《陕西省示范家庭农场评定及监测办法》规定的标准，需经县级农业行政主管部门认定，并已被评定为市级示范家庭农场（在工商部门登记的优先），要求经营者专业素养高，经营规模适度，基础设施完备，生产技术标准，经营管理规范，经济效益较高，示范带动力强。请农业行政主管部门逐项对照，严格把关，不符合的不得申报和推荐。三、名额分配本次申报推荐省级示范家庭农场共1000家，具体名额分配见附件1，各地确有优秀示范家庭农场的，也可以少量突破名额限制。同时，各市（区）监测2015年认定的省级示范家庭农场中，监测不合格的，可递补增加相同数量的申报推荐名额。推荐申报示范家庭农场要兼顾产业分布，对生产粮油等大宗农产品和提供有关服务的家庭农场予以适当倾斜。四、评定程序1. '
               '申请。由符合条件的县级示范家庭农场申报，如实填写《陕西省示范家庭农场申报推荐表》（附件2，以下简称《申报表》），向县级农业行政主管部门提出申请，并提供相关资料。2. '
               '推荐。县级农村经营管理机构负责对申报材料的真实性进行审核，并择优推荐，将审查推荐意见及申报材料以正式文件上报市级农业行政主管部门。3. '
               '上报。市级农业行政主管部门认真组织专家评审，对县级推荐的示范家庭农场择优推荐。对复核合格的，在《申报表》上签署审核意见并加盖公章，依次填写《陕西省推荐示范家庭农场名单汇总表》（附件3），以市级农业主管部门的正式文件，按照《陕西省推荐示范家庭农场名额分配表》（附件1）数量向省农业厅等额推荐。4. '
               '评定。省农业厅组织组织农业、畜牧、果业、农机、农产品质量安全、农村经营管理等方面专业人员组成评审小组，对各市申报材料进行审核，形成省级示范家庭农场拟定名单，并通过陕西农业网向社会公示。公示无异议的，由省农业厅命名为&amp;ldquo;陕西省示范家庭农场&amp;rdquo;，发文公布并颁发证书，列入陕西省示范家庭农场名录，作为家庭农场扶持项目库。五、动态监测省级示范家庭农场动态监测的对象是指陕西省农业厅公布的省级示范家庭农场名单的文件（陕农业发〔2015〕61号和陕农业发〔2015〕108号）中评定的共1017家省级示范家庭农场。监测标准严格按照《陕西省示范家庭农场评定及监测办法》关于省级示范家庭农场标准和有关监测的规定，特别是有关取消示范家庭农场资格的五种情况。对因遭遇自然灾害等造成经营收入或生产规模骤降，难以达到省级示范家庭农场认定标准的，经市级农业行政主管部门综合评价后仍有恢复能力的，可予以保留一年省级示范家庭农场资格，并在监测汇总表中予以备注。六、监测程序（一）示范家庭农场自愿填写《陕西省示范家庭农场监测信息表》（附件4），并提交省级示范家庭农场经营管理情况报告。（二）县级农业行政主管部门依据示范家庭农场提供的报告和监测表，按照《陕西省示范家庭农场评定及监测办法》对辖区内的示范家庭农场进行调查核实，对符合省级示范家庭农场认定标准的，填写陕西省示范家庭农场监测合格名单汇总表（附件5）；对不符合省级示范家庭农场标准的，填写陕西省示范家庭农场监测不合格名单汇总表（附件6）。（三）县级农业行政主管部门依据监测情况形成本县省级示范家庭农场监测报告，连同附件以正式文件报送市级农业行政主管部门，市级农业行政主管部门对县级监测情况进行审核并形成本市监测报告报送省农业厅。七、几点要求（一）各省级示范家庭农场要如实提供有关材料，材料填写完整、按照规定时间上报。填报材料不完整不准确、无正当理由不按时上报的，视为放弃参加评定或监测不合格。填报材料弄虚作假的，一经查实，取消其省级示范家庭农场资格。（二）各县农业部门要高度重视示范家庭农场的评定和监测工作，切实负起责任，依照评定和监测标准，对示范农场经营状况进行实地考察，并对照标准进行审核，严格把关，认真做好申报材料真实性的审查、复核、推荐等工作，确保评定和监测工作扎实到位。(三)各市推荐陕西示范家庭农场名单汇总表、监测报告、监测合格名单汇总表、监测不合格名单汇总表等以正式文件于2017年7月30日前报送至省农业厅农经处，电子版一并报送。邮寄地址：西安市莲湖区习武园27号邮 \xa0'
               '编：710003联系人：庹书炜电 \xa0话：029-87340856传 \xa0真：029-87321844邮 \xa0'
               '箱：sxsnhb@163.com附件：1. 陕西省推荐示范家庭农场名额分配表2. 陕西省示范家庭农场申报推荐表3. '
               '陕西省推荐示范家庭农场名单汇总表4. 陕西省示范家庭农场监测信息表5. 陕西省示范家庭农场监测合格名单汇总表6. '
               '陕西省示范家庭农场监测不合格名单汇总表\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年6月6日附件.docx\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于开展省级示范家庭农场评定及监测工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-05-15 09:03:24',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕60号各设区市农业局（委），杨凌示范区农业局，韩城市农林局：根据《农业部办公厅关于开展全国休闲农业和乡村旅游示范县（市、区）创建工作的通知》（农办加〔2017〕11号）精神， '
               '农业部决定2017年继续开展全国休闲农业和乡村旅游示范县（市、区）创建工作。为切实做好我省全国休闲农业和乡村旅游示范县（市、区）创建工作，现就有关事项通知如下：一、基本条件示范创建对象以县（含县级市、区）为主体，全区域发展休闲农业和乡村旅游资源优势明显、整体发展水平高的地级市，可视情况进行整体创建。申报创建的县（市、区）应具有以下基本条件：（一）规划编制科学。编制了休闲农业和乡村旅游发展规划，发展思路清晰，功能定位准确，布局结构合理，工作措施有力。县（市、区）探索了有效的农民利益链接机制，有成熟的农村一二三产业融合发展典范和模式。（二）优势特色突出。具有发展休闲农业和乡村旅游的资源禀赋、区位优势、产业特色和人文历史，形成一定规模的产业带或集聚区；主要休闲农业和乡村旅游点有地域、民俗和文化特色，体验项目和餐饮服务有较强的吸引力；能够依托当地特色种植业、养殖业和农产品加工业开发设计休闲农业和乡村旅游产品，农业与加工、文化、科技、生态、旅游等产业有机融合。（三）扶持政策完善。当地政府认真贯彻党中央、国务院关于加强&amp;ldquo;三农&amp;rdquo;工作的方针政策，能够根据本县（市、区）休闲农业和乡村旅游发展的实际需求，创设完善扶持政策并落实为具体工作措施。（四）工作体系健全。具有明确的休闲农业和乡村旅游的管理职能和主管部门，有健全的管理制度，已建立休闲农业和乡村旅游行业协会等行业自律组织。重视公共服务，能为经营点提供信息咨询、宣传推介、教育培训等服务。（五）行业管理规范。围绕农家乐、休闲农庄、休闲农业园、民俗村等类型建立管理制度和行业标准。近3年内无安全生产和食品质量安全事故发生，无擅自占用耕地和基本农田行为，无以破坏农业生产为代价发展休闲农业和乡村旅游现象，没有发生污染和破坏生态环境的事件。（六）基础条件完备。县域范围内的休闲农业和乡村旅游点要做到通路、通水、通电，网络通讯畅通，能够借助互联网等新技术，设置电子商务推介平台，住宿、餐饮、娱乐、卫生、路标、停车场等基础设施要达到相应的建设规范和公共安全卫生标准，生产生活垃圾实行无害化处理。（七）发展成效显著。休闲农业和乡村旅游是县域经济发展的主导产业，主要指标在全省处于领先水平；休闲农业和乡村旅游点总数须超过100个，精品线路10条以上，其中要有10个以上精品点在省内有一定的知名度；年接待游客100万人次以上，从业人员中农民就业比例达到60%以上，近三年游客接待数和营业收入年均增速均超10%。二、申报数量2017年农业部分配我省上报指标2个。每市（区）可申报1个，如无符合条件县区可不报。超名额申报的退回重报。三、申报程序（一）县级自我创建。按照自愿申报原则，通过自我创建，达到全国休闲农业和乡村旅游示范县（区、市）创建条件的县（市、区），均可申报。由各县（市、区）级农业管理部门填写《全国休闲农业和乡村旅游示范县（市、区）申报表》，附本县（市、区）休闲农业和乡村旅游发展情况、发展规划等材料，上报市级农业管理部门。（二）市级审核推荐。各市（区）农业管理部门负责综合评审、择优推荐1个县（区），正式行文并附相关申报材料报省农业厅。（三）省级择优上报。省农业厅对各市（区）上报的材料进行审核，并组织有关专家对申报县（区）进行综合评审、随机现场核查后，按照农业部分配给我省的指标择优推荐上报。四、有关要求各市（区）农业主管部门要把示范创建活动作为引领休闲农业和乡村旅游发展的重要举措，按照标准从优筛选，从严控制申报数量。要以示范创建为契机，加大对休闲农业和乡村旅游发展典型的宣传推介，努力打造知名品牌，为产业发展营造良好氛围。推荐文件和相关申报材料一式两份（同时报所有材料电子版），于8月15日前报至省发展一村一品指导中心。联 '
               '系 人：田 庚电 '
               '话：029－87343160电子邮件：xxnyxh@163.com附件：全国休闲农业和乡村旅游示范县（市、区）申报表\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年5月12日附件.docx\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于申报全国休闲农业和乡村旅游示范县的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅函',
 'art_date': '2017-05-18 16:16:47',
 'art_detail': '\n'
               '         '
               '陕农业函〔2017〕74号各设区市农业局（委），杨凌示范区农业局，韩城市农林局，各有关单位：为充分发挥我省农业技术专家在特色现代农业发展中的重要作用，实现农科教产学研推的有效对接，按照《陕西现代农业产业技术体系建设方案》要求，省农业厅决定新建农村能源环保、饲草饲料、辛辣蔬菜、甘薯、石榴、家兔等6个省级现代农业产业技术体系，并对其他22个省级现代农业产业技术体系有关专家进行调整。同时聘任邱凌、李文祥、姚军虎、李海英等专家为首席科学家，郭康权、刘保忠、李长忠、殷振江等专家为岗位专家。现将28个体系岗位设置和专家名单予以印发，请各产业技术体系按照&amp;ldquo;112&amp;rdquo;工作机制，扎实工作，为我省追赶超越做出新的贡献。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年3月6日\xa0 附件.docx\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于印发陕西省现代农业产业技术体系名单的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-05-03 16:52:28',
 'art_detail': '\n'
               '         '
               '陕农业人事【2017】5号厅机关各处（室、局）、厅属各单位：根据《党政领导干部选拔任用工作条例》有关规定，经省农业厅研究决定，免去：张文峰同志省棉花原种场副场长（正处级）职务，退休。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年2月10日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于张文峰同志免职退休的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-04-21 15:21:12',
 'art_detail': '\n'
               '         陕农业函〔2017〕121号\r\n'
               '\r\n'
               '各设区市农业局（委），杨凌示范区农业局，韩城市农林局，省农垦集团总公司，西咸新区建设环保局：\r\n'
               '为深入贯彻落实省委省政府大力促进休闲农业发展的决策部署，持续发挥示范创建的带动作用，我厅2016年开展了省级休闲农业示范点创建活动，认定示范点69个。按照《陕西省农业厅办公室关于印发&lt;陕西省省级休闲农业示范点认定和运行监测管理工作方案&gt;的通知》（陕农业办发〔2016〕65号）要求，我厅决定对获认定示范点运行情况进行监测。现就有关事项通知如下。\r\n'
               '一、提高认识\r\n'
               '休闲农业是新型农业产业形态和旅游消费业态，是推进农村一二三产业融合发展的有效载体，是促进农村经济发展的有力动能，是实现农民创业就业的重要途径。做好省级休闲农业示范点运行情况监测，是各级农业主管部门掌握产业发展动态、研究制定扶持政策、促进产业健康快速发展的重要基础，是履行指导、管理和服务职责的重要内容，对于提升工作水平和服务能力具有重要意义。要通过开展示范点运行监测工作树立一批典型，及时总结推广好经验、好做法，加大宣传推介，多渠道、多方式营造推动休闲农业发展的良好氛围，推动全省休闲农业又好又快发展。\r\n'
               '二、健全机制\r\n'
               '根据《陕西省省级休闲农业示范点认定和运行监测管理工作方案》，省级休闲农业示范点运行监测工作实行“省统筹、市负责”工作机制。省农业厅制定有关标准、组织实施监测管理等工作。市级农业部门负责对本辖区获认定示范点开展年度发展基本情况监测及突发（重大）情况实时监测。\r\n'
               '三、加强监测\r\n'
               '（一）发展基本情况年度监测。监测内容包括：示范点2016年度经营管理、示范带动情况，服务功能，及可持续发展能力等。\r\n'
               '（二）突发（重大）情况实时监测。监测内容包括：示范点由于防范措施不力或防范不当，导致重大农产品（食品）质量或生产安全事故，造成人员生命和财产重大损失的；在提交有关材料时存在严重造假行为的；存在重大经营困难停止经营半年以上的；有其他违反国家法律、法规和政策行为的。\r\n'
               '四、相关要求\r\n'
               '（一）发展基本情况年度监测。由省级休闲农业示范点撰写正式书面报告（附件1）、填写重点运行指标监测表（附件2）。书面报告和监测表一式两份，以市（区）为单位于2017年5月31日前正式行文报省农业厅。材料电子版同时发送至xxnyxh@163.com。\r\n'
               '（二）突发（重大）情况实时监测。示范点在经营过程中出现上文所列突发（重大）情况的，市级农业部门须迅速甄别情况，并在情况发生后15个工作日内书面报告省农业厅。\r\n'
               '联系人：李永刚 魏亚娟（省发展一村一品指导中心）\r\n'
               '电 话：029－87343160\r\n'
               '邮 箱：xxnyxh@163.com\r\n'
               '附件：1. 陕西省省级休闲农业示范点年度发展报告\r\n'
               '2. 陕西省省级休闲农业示范点重点运行指标监测表\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年4月20日\r\n'
               '附件.docx\r\n'
               '\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于做好省级休闲农业示范点运行监测工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-05-02 10:26:21',
 'art_detail': '\n'
               '         '
               '陕农业发〔2017〕41号各有关设区市农业局（委）、财政局，韩城市农林局、财政局，有关省财政直管县农业局、财政局：根据财政部《关于拨付农业生产救灾及特大防汛抗旱补助资金的通知》（财农〔2017〕22号）精神，结合我省实际，经省农业厅、省财政厅共同研究，现将夏粮病虫防控补助资金下达你们（详见附件），主要用于小麦病虫及蝗虫等生物灾害防控。现就有关事项通知如下：一、实施区域今年夏粮病虫防控以关中、陕南小麦生产重点县及关中、陕北农区蝗虫重点发生区为主，突出病虫害常发、重发区。二、实施内容资金重点用于小麦条锈病、赤霉病、白粉病、穗期蚜虫、吸浆虫等重大病虫和农区蝗虫等生物灾害的应急防控和统防统治。主要包括：农业灾害实地监测、评估、核灾补助；生物灾害防控措施所需的物资材料补助，包括购买药剂、药械、燃油及生物防治、综合防治、生态控制技术应用费、技术指导费、作业费等；建立农业生产救灾示范区，依托新型农业经营主体，开展专业化统防统治与绿色防控融合示范。三、有关要求（一）强化组织领导。各级农业和财政部门要切实加强组织领导，明确职责分工，结合本地实际，按照高效便民、不误农时的原则，及时拨付资金，积极推进项目实施。（二）强化资金监管。各级财政和农业部门要切实加强资金监管，确保专款专用。要注重发挥纪检等部门的监督作用，对挤占、截留、挪用的相关单位和人员追究责任，确保政策落实到位。（三）强化监督检查。各级农业技术部门要组织专家、农技人员，深入一线开展技术指导和服务，确保补助资金使用效果。农业主管部门、财政部门要加强资金监督检查，加快项目实施进度，于2017年6月30前，对本辖区资金使用情况进行检查验收，并将结果报省农业厅和省财政厅。附件：2017年夏粮病虫防控补助资金计划表 '
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅 '
               '陕西省财政厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年4月25日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅  陕西省财政厅关于下达2017年夏粮病虫防控补助资金计划的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-04-26 10:10:56',
 'art_detail': '\n'
               '         陕农业发〔2017〕37号\r\n'
               '\r\n'
               '各设区市农业局（委），杨凌示范区农业局，韩城市农林局：\r\n'
               '为加快培育新型职业农民，促进我省职业农民队伍成长壮大，按照《陕西省新型职业农民认定管理办法》（陕农业办发〔2016〕48号）要求，对完成高级职业农民教育培训和参加现代青年农场主培养计划，并符合认定条件的培育对象，由县、市逐级推荐上报，经省职业农民培育工作领导小组办公室组织专家评审考核，省职业农民培育工作领导小组审定，网上公示无异议，决定认定薛晓峰等369人为全省第四批新型高级职业农民（名单附后）。\r\n'
               '希望被认定的职业农民进一步加强学习，不断提高自身素质。号召全省农业从业者向高级职业农民学习，积极投身现代农业，扩大产业规模，提升发展能力，为促进农业增效、农民增收和农村发展做出新贡献。\r\n'
               '附件：陕西省第四批新型高级职业农民名单 附件.docx\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年4月23日\r\n'
               '\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于认定第四批新型高级职业农民的通报'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-04-27 16:57:52',
 'art_detail': '\n'
               '         陕农业发〔2017〕40号\r\n'
               '\r\n'
               '各设区市农业局（委），杨凌示范区农业局，韩城市农林局：\r\n'
               '为保证农业产业化省级重点龙头企业队伍的活力，激发龙头企业在精准扶贫和三产融合发展中发挥更大的示范带动作用，根据《陕西省农业产业化经营重点龙头企业认定和运行监测管理办法》(陕政发〔2012〕55号，以下简称《办法》)的相关规定，拟对农业产业化省级重点龙头企业近两年运行情况进行动态监测。现就有关事宜通知如下。\r\n'
               '一、监测对象\r\n'
               '本次监测对象为陕农业发〔2015〕97号文件公布的2015年监测合格及递补的省级农业产业化重点龙头企业。\r\n'
               '为便于掌握全省省级以上重点龙头企业整体运行情况，国家级重点龙头企业只在省级监测网络系统填报相关指标，不必上报纸质材料。\r\n'
               '二、监测程序和材料\r\n'
               '本次动态监测和推荐递补同时进行。对市级监测不合格的企业，可由市级按照不合格企业数的2倍提出推荐递补企业名单建议。\r\n'
               '（一）龙头企业\r\n'
               '省级重点龙头企业向所在市区农业产业化主管部门提出监测申请，同时报送以下纸质材料（只须原件一份），并按以下要求提供的材料顺序编写《目录》，胶订成册后（勿用其他装订方法）报送市级农业产业化主管部门。\r\n'
               '1.企业监测（递补）材料封面格式（见附件1）。\r\n'
               '2.企业经济运行情况表。具体内容见附件2，需在农业产业化信息系统中先填报，经市级主管部门审核通过后，再打印表格。填报表格必须做到“两个一致”：即纸质材料与系统填报数据一致；填报财务数据与年度审计报告数据一致。\r\n'
               '3.企业发展农业产业化情况（3000字左右，需同时在系统中填报）。围绕企业推进精准扶贫，促进农村一二三产业融合发展的情况撰写材料，需要说明企业经济运行情况、建设原料生产基地情况、企业与农户的利益联结方式（对合作制、股份合作制，特别是精准扶贫的情况进行详细说明）、带动农民就业增收情况，以及宣传促销、加强质量安全管理、科技创新、参与公益事业等情况。\r\n'
               '4.企业营业执照和组织机构代码（或统一社会信用代码）复印件。\r\n'
               '5.会计师事务所出具的企业2015年度和2016年度完整财务审计报告。相关会计报表须由会计师事务所盖骑缝章，或在每页盖章，否则，视为不合格审计报告。\r\n'
               '6.人民银行征信报告。由企业开户行查询人民银行征信系统后出具，具体说明2015-2016年企业有无银行资信方面的问题。\r\n'
               '7.县级（含）以上国税部门和地税部门出具的企业纳税情况证明。对申请监测的企业说明两年内（2015年1月-2016年12月）企业有无涉税违法问题。对申请递补的企业说明三年内（2014年1月-2016年12月）企业有无涉税违法问题。\r\n'
               '8.县级（含）以上农业或其他法定监管部门出具的质量安全情况证明。说明2015-2016年企业是否存在产品质量安全方面的问题。\r\n'
               '9.县级（含）以上农村经营管理或农业产业化主管部门出具的企业带动农户情况。说明2015-2016年企业带动农户的利益联结方式、带动农户数、带动农户增收数等情况。\r\n'
               '10.企业注册商标和品牌的证明材料。\r\n'
               '11.企业应享受优惠政策的落实情况。说明2015-2016年企业享受到的财政、税收、信贷、出口等方面的政策扶持情况。\r\n'
               '12．申请更名企业情况。已更名的企业需提供工商行政管理部门同意企业变更名称的材料、更名后的企业营业执照复印件，以及更名原因、更名后的企业与原企业关系的说明。上报监测材料时使用的企业名称及企业公章，应与更名后的企业营业执照一致。\r\n'
               '填写《企业经济运行情况表》时，带动的农户数量应与主管部门开具的带动农户证明材料显示的数量一致。企业如有以下情况，应附证书复印件：获得“三品一标”认证，获得出口备案，获得省级以上科技奖励或荣誉，通过ISO9000、 '
               'HACCP等质量认证，获得中国名牌产品证书、中国驰名商标、省级名牌产品或著名商标等品牌认证等，并加盖企业公章。\r\n'
               '（二）市级农业产业化主管部门\r\n'
               '请于5月31日前以市级农业产业化主管部门的正式文件向省农业厅报送以下纸质材料（一式两份）：\r\n'
               '1．撰写省级重点龙头企业监测分析报告（同时须发送文字格式电子版到cyhzyyy@163.com）。各市（区）农业部门在审查企业所报材料内容真实、格式规范的基础上，按照《办法》第八、九条规定，严格对照相关标准进行审核，撰写监测分析报告，提出初步监测结果建议，内容包括：\r\n'
               '①企业的总体情况、运行特点，特别是在产业扶贫精准脱贫中的做法、企业发挥的作用，与农户建立利益联结机制带动农户情况，参与一带一路投资合作情况等，存在的问题及下一步建议；\r\n'
               '②审核不合格企业的情况，说明企业不合格的原因；\r\n'
               '③更名企业名单和更名原因。\r\n'
               '2．推荐递补企业情况。提出推荐递补企业建议，并附以下材料：①表明市级农业、发改、财政、税务、人民银行、工商、食药监等部门同意推荐递补企业的材料；②表明市级人民政府同意推荐递补企业的材料。\r\n'
               '3．审核合格企业、更名企业和推荐递补企业上报的所有纸质材料（一份原件）。\r\n'
               '三、有关要求\r\n'
               '（一）各市（区）农业产业化主管部门和各有关龙头企业在准备纸质材料的同时，需登录“陕西省农业产业化信息统计系统监测认定模块”网址：http://stat.sxaia.com。（系统使用说明书、企业账号、监测序号等另行通知；递补企业的企业账号、递补序号，待市级主管部门确定递补企业名单后，再向省级申请予以下发）进行网上填报和审核。网上填报截至日期为5月31日，逾期系统自动关闭，无系统申报资料视为监测不合格或递补无效。\r\n'
               '（二）省级重点龙头企业监测是对龙头企业采取优胜劣汰激励机制的有效手段。各市区要高度重视，严格审核，指导企业选择执业质量高的会计师事务所为企业提供专业规范的财务审计服务，确保监测工作的准确、有效和公正。各市监测工作情况将作为年度考核、评选先进和项目安排的重要参考依据。\r\n'
               '（三）各地推荐递补龙头企业时，优先推荐符合认定条件、运行良好、与农户利益联结紧密、带动作用显著、在产业扶贫、三产融合和供给侧结构改革中涌现出的优秀企业。\r\n'
               '（四）龙头企业应按要求如实提供有关材料，不得弄虚作假。如有舞弊行为，经查实，视为监测不合格企业，所在市（区）不得推荐递补企业。\r\n'
               '联系人：董海燕：029-87322849 13709292259\r\n'
               '段瑾：029-87319975\r\n'
               '系统技术：朱婷婷：029- 86181379 13572260081\r\n'
               'QQ：405616417\r\n'
               '附件：1. 省级重点龙头企业监测材料封面格式 附件.docx\r\n'
               '\xa0\xa0\xa0\xa0\xa0 2. 企业经济运行情况表（表1-8） 附件2.xlsx\r\n'
               '\xa0\xa0\xa0\xa0\xa0 3. 企业经济运行情况表指标解释\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年4月24日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于开展农业产业化省级重点龙头企业监测工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-05-03 16:55:50',
 'art_detail': '\n'
               '         \xa0'
               '陕农业人事【2017】6号厅机关各处（室、局）、厅属各单位：根据军转干部定职有关规定，经省农业厅研究，任命：崔浩明为省农业机械管理局农机装备处调研员，任职时间自登记备案之日算起。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年3月29日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于崔浩明同志任职的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-05-03 17:02:26',
 'art_detail': '\n'
               '         '
               '陕农业人事【2017】8号厅机关各处（室、局）、厅属各单位：省农业厅2017年3月27日研究决定，任命：惠景峰为厅政策与法规处调研员；杨晓萍为厅办公室副调研员。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年4月10日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于惠景峰等同志任职的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-05-03 16:59:57',
 'art_detail': '\n'
               '         '
               '陕农业人事【2017】7号厅机关各处（室、局）、厅属各单位：按照省委组织部《关于推荐白卫华同志挂职工作的函》（陕组干函【2017】29号）通知，省农业厅研究决定，任命：白卫华为厅发展计划与财务处副处长（挂职）。挂职时间一年，挂职期满，挂任职务自行免除，不再另行通知。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年3月29日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于白卫华同志挂职的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-05-02 10:26:11',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕25号各有关市农业局、畜牧局、财政局，有关省财政直管县农业局、畜牧局、财政局，省畜牧技术推广总站：为做好我省草原鼠害虫害防治工作，按照农业部防治工作有关要求，省农业厅和省财政厅研究制定了《陕西省2017年草原鼠害防治工作实施方案》和《陕西省2017年草原虫害防治工作实施方案》，现印发给你们，请遵照执行。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅 '
               '陕西省财政厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年4月25日陕西省2017年草原鼠害防治工作实施方案为有效预防控制草原鼠害，减轻草原危害，做好2017年我省草原鼠害防治工作，特制订本方案。一、2017年草原鼠害发生趋势预测近年来，我省认真组织实施草原生态建设保护项目，草原植被明显好转，部分鼠种的密度明显下降，但地下鼠害有所上升，尤其是改良草场和人工草地，成为新的防控重点。根据对我省鼠害监测站点监测数据分析，2017年形成危害的主要鼠种依然是中华鼢鼠、达乌尔鼠兔、达乌尔黄鼠、长爪沙鼠、子午沙鼠、三趾跳鼠等，危害面积约800万亩，严重危害面积约420万亩，防治任务艰巨。长城沿线风沙区的榆林市六个县（区）的长爪沙鼠、子午沙鼠、三趾跳鼠，平均密度300-400个有效洞口/公顷，严重地块可达700个有效洞口/公顷；陕北黄土高原丘陵沟壑区大部分草场的达乌尔黄鼠、达乌尔鼠兔，平均密度190-310个有效洞口/公顷，严重地块可达400个有效洞口/公顷；中华鼢鼠在全省的大部分草场均有分布，尤其是人工草场，平均密度260-330个新土丘/公顷，严重地块可达550个新土丘/公顷。二、防治任务和区域继续按照&amp;ldquo;加强动态监测，科学分析布局，突出重点防区&amp;rdquo;的防治原则，结合草原鼠害发生的实际情况，实行综合治理。（一）在鼠害严重危害地区开展鼠害综合防治300万亩。各县区生物措施防治面积不少于总防治任务的80%（防治任务详见附表）。（二）项目县（市）开展鼠害调查、监测预警及技术培训。（三）宝鸡、铜川、延安、榆林市负责鼠害应急物资储备，开展鼠害动态监测预报及技术培训。（四）陕西省畜牧技术推广总站组织开展草原鼠害监测预警分析，防治新技术、新药品的引进、试验示范和技术培训。三、时间安排3-5月份，实地调查各市县鼠害发生动态，上报鼠害监测预报结果。5-7月份，广泛宣传，严密监测，做好防治资金、技术及物资的准备。组织各测报站、点做好预测预报，及时掌握鼠害发生发展动态；聘请有关专家对有防治任务市、县（区）的专业技术人员进行技术培训。6-8月份，全面开展防治工作。根据鼠害状况，省市县统一组织专业技术人员，深入鼠害防治一线，及时指导群众安全用药、科学防治，有效控制鼠害的扩散蔓延，坚决杜绝草原鼠害的大面积爆发。11-12月份，进行工作总结，吸取经验教训，为今后草原鼠害防治工作积累经验。四、保障措施（一）加强组织领导，狠抓工作落实。各有关市县要成立由草原行政部门主要领导参加的草原鼠害防治指挥部，夯实工作责任，认真组织落实草原鼠害防治工作。并结合当地实际制定项目实施方案，抓住关键时期和重点环节，细化防治目标和任务，提出资金使用意见，加强督促和指导，落实各项工作措施。（二）严格规范操作，加强科学指导。认真贯彻执行农业部有关草原治鼠灭鼠的政策及技术规程，在防治工作开始前对参加灭治的技术人员和农民进行集中培训，现场讲解灭鼠常规知识，示范投饵等关键技术及方法，对拌饵及各小组质量监督员等重点环节人员实行上岗培训，基本做到业务指导有骨干，实际操作有基础，检查监督有方法。在防治进程中，及时组织有关技术人员深入防治一线，解决群众在防治过程中遇到的问题和困难，提高灭鼠效果。（三）科学监测预警，及时掌握鼠情动态。一是由省草原工作站负责鼠害监测方法、数据采集及处理标准的培训指导，建立鼠情周报、月报和专报制度，促进草原鼠害预测预报工作的规范化和制度化建设；二是在鼠害发生和防治期，各有关市县实行24小时值班制度，并按相关要求，抽调业务骨干深入鼠灾防治一线，严密监测鼠情发展动态，实行周报制，于每周二上报省草原工作站，确保灾情信息畅通。三是积极培养农民群众定点测报员，建立起一支稳定的群众监测队伍，群防群治，提高草原鼠害防治水平。（四）采用生物技术，控制草原鼠害。积极组织引进高效低毒低残留生物药剂开展草原鼠害防控工作，草原鼠害常发区要重点推进C型、D型肉毒素和雷公藤甲素生物药剂应用范围和力度，坚决杜绝化学药品对草地生态环境造成的污染，同时在距离人畜居住较远的草原空阔地带设立一定鹰架、鹰墩，以实现天敌对鼠害危害的长期持续控制，确保草原生态环境持续好转和草原生物链相对平衡稳定。附表：2017年草原鼠害防治任务分配表\xa0 '
               '附表.docx\xa0陕西省2017年草原虫害防治工作实施方案\xa0'
               '为有效控制草原虫害，保障我省草业健康发展，结合我省草原虫害发生区域和特点，制定本方案。一、2017年草原虫害发生趋势预测根据我省草原虫害监测站监测数据统计分析，从去年秋季越冬基数和今春越冬成活率调查来看，预计今年我省草原虫害危害面积约300万亩，严重危害面积约170万亩，总体发生规模较上年有所下降。东亚飞蝗的发生范围仍以黄河、渭河、洛河沿岸的滩地草场、黄河鸡心滩和卤泊滩为主，危害程度较上年有所下降；土蝗和笨蝗仍呈点状发生，发生范围仍以渭北旱塬草场及延安、榆林的坡塬草场为主，危害程度中等偏轻。二、防治任务和区域继续遵循&amp;ldquo;集中连片、统防统治&amp;rdquo;的原则和&amp;ldquo;治改并举&amp;rdquo;的措施，加强动态监测，在预测预报的基础上，因地制宜地开展生物防治、生态控制和化学防治，进一步扩大生物防治在草原虫害防治中所占的比重。（一）在虫害严重危害地区开展虫害综合应急防治110万亩。各县区生物措施防治面积任务不少于总防治任务的50%（防治任务见附表）。（二）项目县（市）开展虫害调查、监测预警及技术培训。（三）渭南、延安、榆林开展虫害调查、监测预警及技术培训。（四）陕西省畜牧技术推广总站组织开展全省草原蝗虫监测预警分析，新药剂、新技术的引进、试验示范和技术培训。三、时间安排3-5月份，实地调查各市县蝗虫发生动态，上报虫害监测预报结果。5-7月份，广泛宣传，严密监测，做好防治资金、技术及物资的准备。各测报站、点根据虫害发生发展态势及时做好预测预报工作，掌握虫情发生发展动态。聘请有关专家对专业技术人员进行技术培训。6-8月份，全面组织开展防治工作。根据虫害危害情况，省市县技术部门统一组织专业技术人员，深入虫害防治一线，及时指导群众安全用药、科学防治，有效控制虫害扩散蔓延，坚决杜绝草原虫害大面积爆发。9月份，积极开展秋蝗清除，并结合人工种草和草场改良等方法，进行草场生态综合治理。根据今年防治情况，开展秋蝗越冬基数调查，为来年草原虫害综合防控提供依据。同时，各级各部门开展虫害防控总结工作，吸取经验教训，为今后草原虫害防治奠定基础。四、保障措施（一）加强组织领导，夯实目标责任。各有关市县要成立由草原行政部门主要领导、分管领导参加的草原虫灾防治指挥部，夯实工作责任，认真组织落实草原虫害防治工作；要结合当地实际制定项目实施方案，抓住关键时期和重点环节，细化防治目标和任务，提出资金使用意见，加强督促和指导，落实各项工作措施。（二）科学监测预警，及时掌握虫情动态。一是由省草原工作站负责虫情监测方法、数据采集及处理标准，建立虫情周报、月报和专报制度，促进草原虫害预测预报工作的规范化和制度化建设；二是在蝗虫发生和防治期，各有关市县实行24小时值班制度，并按相关要求，抽调业务骨干深入蝗灾防治一线，严密监测虫情发展动态，实行周报制，于每周二上报省草原工作站，确保灾情信息畅通。三是完善省市县三级监测预警体系，配备必要的监测设备和通讯器材，改善目前现有的测报手段和条件，全面提高测报水平。四是积极培养农民群众定点测报员，建立起一支稳定的群众监测队伍，群防群治，提高草原虫害防治水平。（三）加强科学指导，制定防治方案。一是省草原站牵头开展生物防治、生态控制的试验、示范，为我省草原蝗虫的长期持续控制，探索好方法和新措施。二是在防治工作中，省、市、县业务部门要抽调业务骨干深入蝗防一线，开展防前技术指导、防中督促落实、防后检查总结，积极参与和掌握蝗防全过程。三是继续加大草原虫灾生态综合治理力度。在小面积天然草场中，大力推广牧鸡灭蝗技术，在有效控制虫害的同时提高当地群众的养殖效益。四是继续坚持虫害防治与草场翻耕补播等生态恢复措施相结合，有效提高虫害灭治效果。（四）广泛宣传动员，提高群防意识。利用广播、电视、报刊等多各种媒体向社会广泛宣传草原蝗虫危害的严重性和防治的必要性，努力提高农民的草原防蝗意识。充分利用科技下乡、乡间集会等大型活动，采取现场讲解和散发宣传资料等形式，大力宣传草原蝗虫防治的新药剂和新方法，使广大群众对草原蝗虫的生物防治和生态控制有认识并接受，以减少化学防治给畜牧业生产及草原生态环境带来的危害，使农民群众自觉防治，主动投工、投劳、投资，确保全省草原虫害防治工作的顺利开展。附件：2017年草原虫害防治任务分配表 '
               '附表.docx\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅  陕西省财政厅印发2017年草原鼠害虫害防治工作实施方案的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-05-04 10:14:48',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕22号各设区市农业局（委），杨凌示范区农业局，韩城市农林局，厅属有关单位：现将《陕西省2017年农业科教能环工作要点》印发给你们，请结合当地实际，认真贯彻执行。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年3月2日陕西省2017年农业科教能环工作要点2017年全省农业科教能环工作的总体思路是认真贯彻落实中央1号文件和中省农村农业工作会议精神，紧紧围绕&amp;ldquo;追赶超越&amp;rdquo;总目标，聚焦厅党组&amp;ldquo;12345&amp;rdquo;战略布局和&amp;ldquo;六个持续推进&amp;rdquo;要求，深入推动农业供给侧结构性改革，加快推进农业转型升级，持续实施科技创新驱动发展战略，不断深化农业科技体制机制，全面加强农业科技创新、农技体系建设、职业农民培育、农村能源环保工作，力争攻克重大农业技术难题20项，组装配套集成示范实用技术30项，农业科技贡献率提高到56%；培训农技员7500人，遴选培育农业科技示范户2万户，建设科技示范基地210个，示范点1000个；发挥1000个培育基地作用，培育10000名新型职业农民，认定不少于80%；新建养殖小区沼气工程90处，建立24个农业面源污染综合防治示范点，继续开展土壤重金属修复试验示范，为推进农业供给侧结构性改革，提升特色现代农业建设水平提供科技和人才支撑。一、实施科技创新驱动，强化现代农业支撑（一）加快农业科技创新。依托陕西省农业科技创新同盟，优化整合全省农业科技资源，构建运转高效、开放共享的农业研发体系，促进原始创新、协同创新、管理创新和成果转化创新。坚持问题导向和市场导向，按照&amp;ldquo;专家引领，专业融合，联合攻关&amp;rdquo;的科技创新思路，以项目为抓手，组织开展重大核心技术攻关和组装集成，解决我省主导产业的重大关键问题20个，加快形成创新集成技术体系和模式。围绕主导产业转型升级，推行&amp;ldquo;科研推广单位+新型经营主体&amp;rdquo;的科技研发方式试点，着力解决农业科技成果落地问题，加速科技成果转化。采取设定指标、公开竞争的形式，确定2018年重大科研项目，引导科研资金向重点领域和重点课题倾斜。加大实施农业种质资源保护、开发与应用。协助做好国家延安苹果科技创新园区建设。（二）推进产业体系建设。根据我省特色产业发展需要，新组建甘薯、辛辣蔬菜、石榴等6个产业技术体系，筹备2018年新建5个体系，进一步完善已有的22个体系，加快建设&amp;ldquo;配置合理、层次分明、运转高效、支撑有力&amp;rdquo;的陕西现代农业产业技术体系。按照&amp;ldquo;112&amp;rdquo;工作机制要求，围绕产业发展组织28个体系发挥参谋、推广、破题、组装等作用，提出28个产业发展意见，解决制约产业发展的重大难题100多项，推广研究成果200多项，引进集成组装轻简化技术200多项，开展大型高层次培训200多场次，研讨论坛30次以上，加快特色现代农业发展。围绕小麦、水稻、苹果等22个产业转型升级示范县建设，积极开展科技服务，开展各种形式科普宣传，引导社会消费理念，助力农业供给侧结构性改革，促进特色现代农业转型升级。（三）加速科技成果转化。瞄准农业可持续发展和产业精准脱贫，组装、配套、集成示范各类实用技术30项，推行&amp;ldquo;专业指导、社会化服务实施、新型市场主体承载&amp;rdquo;的农业技术推广新机制，加快实用技术推广。立足我省生产实际，尤其是针对春旱、伏旱、秋淋等自然灾害，组织全省农业科研、教学和推广单位专家、农技人员进入大户、大企、大社、大场，通过技术培训、咨询、科技成果推广等活动，全方位开展科技服务。组织厅属单位和有关专家积极参加&amp;ldquo;2017年陕西省文化、科技、卫生三下乡&amp;rdquo;活动和&amp;ldquo;科技之春宣传月&amp;rdquo;活动，切实提高农民科学素质。加强知识产权保护工作，加大对专利、商标、版权等侵权假冒行为的打击力度。大力支持杨凌农业高新技术示范区建设，积极参与第二十四届杨凌农高会，加快高新技术成果转化。（四）加强转基因生物安全监管。坚持&amp;ldquo;属地管理、部门协作、检打联动&amp;rdquo;原则，全面加强农业转基因生物安全监管工作，严厉打击农业转基因生物非法试验、制种、销售、种植等行为，保障农业转基因生物产业健康发展。按照《关于做好2017年农业转基因监管工作的通知》要求，突出重点，加强试验、南繁基地、品种审定、种子生产、种子经营、进口加工等关键环节，杜绝非法转基因试验生产经营行为。严查严打，加大试验研发、品种审定、种子生产经营、对进口加工转基因生物等环节的查处力度，持续保持打击违法转基因的高压态势，严防违法事件的发生。充分利用多种途径，分层次开展形式多样的宣传培训活动，普及法律到乡村到农户，让广大干部群众了解相关法律规定。实行信息月报制度，落实专人负责，确保信息上下畅通。（五）健全市级创新平台。加快推进市级农科所（院）实验室建设步伐，逐步建成与当地主导产业配套、区域特点明显、优势学科突出的专业科研单位。推进市级农科所（院）转型，争取将市级农科所（院）建成专业所，承担科技研发、教育培训、推广试验示范、人才培训、重大项目的终端承载基地任务，提高科技服务能力。继续组织市级农科所（院）长外出考察，学习先进理念、思路、经验，提高市级农科所（院）的科研能力和水平。（六）完善创新激励机制。建立市场导向的科技成果转化收益分配机制，提高科技人员成果转化收益比例，加快科技成果产学研协同转化和就地转移转化。督导各市农业行政部门落实&amp;ldquo;三个&amp;rdquo;不低于50%的科技成果转化规定，鼓励有条件的单位按照不低于80%执行，建立健全以绩效工资为核心的薪酬分配激励制度。探索科技成果与推广绩效分类评价体系，支持专业人员跨区域跨行业流动，建立农业科技成果转化交易服务平台。二、加强农技体系建设，推动科技转化应用（七）构建&amp;ldquo;一主多元&amp;rdquo;农技体系。以公益性农业技术推广机构为主体，引导高校、科研院所、涉农企业及其他机构参与农技推广，促进公益性和经营性组织协同发展。着力推进推广机制创新，巩固现有乡镇（区域）农技推广机构，在产业集聚区大力发展社会服务组织。完善以&amp;ldquo;专家+试验示范基地+农技推广人员+科技示范户+辐射带动户&amp;rdquo;的技术服务模式。建立一批主导产业区域性集成技术示范区，筛选整合省级主推技术，加快实用技术推广步伐。（八）提升农技人员素质。按照农技员培训&amp;ldquo;陕西模式&amp;rdquo;，对全省市、县、乡3级农技人员和农业站长（主任）进行业务技术培训，培训7500人次。举办3期全省高级职称农技人员研修培训班，全面提升高级人才的科学素养和推广水平。组织培训者培训班２期，开展培训需求调研分析，创新培训模式，加强考核评估，提升培训的质量效益。鼓励高校涉农专业毕业生到乡镇从事农业技术推广服务工作，改善农技推广队伍结构，提高推广服务水平。积极推行农技员持证上岗，对岗定向，倒逼农技人员提高工作积极性。（九）激发农技服务活力。全面推行农技人员绩效考核，从体系建设物化补贴的5%中列支奖励费用，对成绩突出的个人给予奖励，从先进评选、职称晋升、培训深造等方面大胆试点。抓好1市4县政府购买农技服务的试点，继续扩大试点范围，进一步拓展购买服务范围、充实内容、优化方式，满足各类农业生产经营主体全方位、个性化和全程式的农业科技需求，不断提高科技推广服务效能。积极开展农技推广服务PPP服务试点，探索农技推广项目申报制。建立&amp;ldquo;自下而上&amp;rdquo;按需求申报安排基层农技推广补助项目的工作方式，提高项目补助的针对性。创新激励机制，鼓励农业技术推广人员进入家庭农场、农民合作社和农业产业化龙头企业开展技术合作。完善运行制度，健全考评激励机制，确保农技推广效果。（十）大力推广实用技术。以&amp;ldquo;互联网＋农技推广&amp;rdquo;为驱动，积极利用基于移动互联的农技推广服务云平台、订阅农业科技网络书屋以及手机APP、微信、微博、QQ群等新媒体服务手段推广农业技术，服务主导产业，推进农业科技进村入户。围绕特色现代农业发展，做好主导品种和主推技术的筛选发布工作，提高主导品种和主推技术入户率和到位率。全省精选培育农业科技示范户2万户，建设科技示范基地210个，示范点1000个，辐射带动周边农户16万户，建立不同层次、不同规模的示范平台，形成上下有机衔接、层次比较分明、分工比较明确的示范推广平台体系，全面提高农业科技覆盖率。三、提高教学服务水平，加快培育职业农民（十一）强化培育体系建设。完善&amp;ldquo;一主多元&amp;rdquo;培训体系，实施市级农广校、陕西省职业农民培训学院标准化建设，通过基础设施条件、师资队伍建设，进一步增强培训实力。认定省级职业农民实训基地50个，认定市县级实训基地200个。择优确定22个基地，落实建设补贴，改善实训手段。加强师资库建设，吸纳各方人才，组建专业师资团队，形成数量充足、结构合理、素质优良的指导教师队伍。创新教师管理机制，开展知识更新培训，支持市县培训专兼职教师。（十二）规范培训方法。全年培育新型职业农民10000人，认定不低于8000人，依托陕西省职业农民培训学院系统化对1000人持证中高级职业农民进行理论培训。重点开展现代青年农场主培养、新型农业经营主体带头人轮训，择优选取培育对象，精准确定学习内容、方式方法、教学管理和保障措施。制定培训质量评价体系，建立教育培训评价标准。以&amp;ldquo;四个课堂&amp;rdquo;为载体，开展多层次、多渠道、多形式培育试点，探索不同类型职业农民培育方式、方法和路径。进一步完善&amp;ldquo;理论授课、网络辅导、基地实训、认定管理、帮扶指导、扶持发展&amp;rdquo;的培育模式，开展20次远程视频教育专题。（十三）加大认定管理。加大职业农民认定力度，扩大认定规模，初中高级认定不低于承担任务的80%。进一步健全职业农民信息档案，加强认定后职业农民备案工作，对取得证书的职业农民实行动态管理，做好复审工作。（十四）加大政策支持扶持。加大扶持政策力度，做好中、高级持证职业农民创业支持，扶持务农创业。整合有关涉农产业项目和补贴项目，支持职业农民做大产业。四、推动能源环保建设，促进农业持续发展（十五）稳步推进能源建设。不断提高养殖小区沼气工程建设水平，新建90处，稳步发展规模化大型沼气工程，鼓励开展沼气发电、集中供气、沼肥配送等，探索沼肥、沼气有效利用方式，形成&amp;ldquo;多元化投入、市场化运作、专业化服务&amp;rdquo;的运行机制。完成太阳能热水器、省柴节煤灶、太阳灶等项目，引导利用光伏发电、小风电、小水电等成熟能源技术，推广生物质固体成型燃料及生物质取暖炉、高效预制组装架空火炕等新型节能技术，推进农村节能减排。指导抓好千阳县光伏试点项目实施。（十六）开展循环农业示范。推广&amp;ldquo;种植业-秸秆-畜禽养殖-粪便-沼肥还田&amp;rdquo;、&amp;ldquo;养殖业-畜禽粪便-沼肥-种植业&amp;rdquo;等循环模式，促进沼气沼肥高值高效利用。积极实施延川县现代农业示范基地建设项目，加快建设县级循环农业模式示范点。加大沼肥配送推广，推动沼肥配送市场化运营。加强对12个万吨有机肥企业联盟的项目实施监管力度，保障项目预期目标的实现，做大做强有机肥产业，促进农业废弃物资源化利用工作再上新台阶。（十七）综合防治面源污染。实施汉丹江、渭河、延河、无定河、黄河流域沿岸等&amp;ldquo;五大流域&amp;rdquo;农业面源污染综合防治工程，健全农业面源污染监测网络，开展周期性定位监测。按照&amp;ldquo;一控两减三基本&amp;rdquo;要求，协调相关部门做好化肥和农药施用量零增长，开展秸秆、畜禽粪便、农田残膜等农业废弃物资源化利用。分区域建立综合防治示范点24个，推广农业清洁生产技术，集成各专业技术、项目、措施等开展综合防治示范。（十八）防治土壤重金属污染。开展土壤污染状况详查，建立完善数据库，开展监测预警，逐步推进耕地土壤环境质量类别划定试点工作，继续在陕南3市和渭南市部分县开展土壤重金属修复试验示范。五、加强科教体系建设，切实转变行风政风（十九）加强党建和精神文明。围绕省厅党建工作重点，积极参与&amp;ldquo;弘扬农业精神、奋力追赶超越&amp;rdquo;主题活动，制定年度学习讲话，落实党课教育，组织开展好主题党日活动等。推进作风建设，落实党风廉政&amp;ldquo;两个责任&amp;rdquo;。加强道德和法制教育，积极参加文体活动，活跃精神文化生活，陶冶情操，增强凝聚力，建设和谐处室，争创&amp;ldquo;五星级&amp;rdquo;党支部。组织开展多种形式活动，持续推动行风建设，进一步弘扬奉献精神，服务&amp;ldquo;三农&amp;rdquo;事业。推行依法行政，加强业务培训，推动服务和管理的科学化、制度化、规范化，切实提高业务水平。（二十）加强工作督查考核。依法依规行政，采取定期检查、不定期抽查和集中检查的方法对各项工作进行督促检查，及时解决工作中存在的困难和问题。按照《陕西省农技推广项目绩效考评办法》、《陕西省新型职业农民培育绩效考评办法》、《陕西省农村能源项目绩效考评办法》、《陕西省农业科技项目管理办法》要求，组织对农技体系建设、职业农民培育、农村能源建设和农业科技项目完成情况考核评价，及时通报，强化整改，对重点项目实行约谈制度，确保项目顺利实施。（二十一）深入开展调查研究。调动全省教育系统、农业科技系统、推广体系、能源环保系统及现代农业产业技术体系专家积极性，开展多范围、多层次的调查研究，重点调查农业供给侧结构性改革形势下的科技教育能源环保工作的焦点、热点、难点问题，总结工作新思路、新理念，提炼工作新模式、新典型，促进全省农业科教工作再上新台阶。（二十二）广泛开展宣传活动。充分发挥电视、广播、报刊、网络等主流媒体的作用，围绕农业科技创新、农技体系建设、职业农民培育、生态环境建设等方面，开展形式多样、生动活泼的宣传活动，继续办好现代农业产业技术体系网络专栏、职业农民培育网络专栏，大力宣传农业科教先进人物和职业农民典型代表，营造良好的工作氛围。\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室印发陕西省2017年农业科教能环工作要点的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-04-21 15:12:08',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕44号各设区市农业局（委），杨凌示范区农业局，韩城市农林局：根据《农业部办公厅关于申报第七批全国一村一品示范村镇的通知》（农办经〔2017〕9号）精神，为做好我省第七批全国一村一品示范村镇申报工作，现就有关事项通知如下：一、申报条件和认定标准示范村镇由县级农业行政主管部门进行申报。村镇主导产业应是特色种植业、养殖业、传统手工业，也可以是休闲农业、文化传承、农村电子商务等行业。具体标准：（一）主导产业突出。专业村主导产业收入占全村农业经济总收入60%以上，从事主导产业生产经营活动农户数占专业村农户总数的50%以上。专业乡镇主导产业收入占全乡镇农业经济总收入30%以上，从事主导产业生产经营活动的农户数占专业乡镇农户总数30%以上。（二）带农致富效果显著。专业村农民人均可支配收入高于所在乡镇农民人均可支配收入10%以上，专业乡镇农民人均可支配收入高于所在县市农民人均可支配收入10%以上。（三）品牌影响力大。专业村镇主导产品必须有注册商标，有通过无公害农产品、绿色食品、有机农产品或农产品地理标志登记保护认证。获得中国地理标志证明商标、国家地理标志保护产品或省级以上名牌认证的专业村镇优先考虑。（四）组织化水平高。专业村镇有成立农民合作社，入社农户数占专业村、专业乡镇从业农户数的比重分别为40%以上和30%以上。专业村镇与龙头企业或专业批发市场有效对接。二、申报数量西安、宝鸡、咸阳、渭南、榆林和汉中市各推荐1个示范乡镇、2 '
               '个示范村，其他市（区）各推荐 1个示范乡镇、1个示范村或只推荐 '
               '2个示范村。三、申报程序全国一村一品示范村镇认定按照自愿申报、专家评审、审核认定的程序进行。各市（区）农业局（委）一村一品主管部门要高度重视本次申报工作，严格按照认定标准做好遴选、初审、推荐等工作，认真组织申报。由县级农业行政主管部门指导符合条件的专业村镇按照要求填写申报书（见附件1、2），初审后填写《审核推荐表》（见附件5），专业村镇主导产品品牌建设情况必须附证明材料（&amp;ldquo;三品一标&amp;rdquo;证书复印件或扫描打印件，不附上一律视为无）。市级农业行政主管部门对县区推荐村镇，依据申报条件进行实地考查，审核通过后，按照示范村、镇分别填写市级汇总表（见附件3、4）上报省发展一村一品指导中心，省厅将组织专家进行评审并公示后，报农业部农业产业化办公室。四、有关要求请各市（区）于5月15日前将申报材料一式六份（A4纸普通装订），以市局正式文件报省发展一村一品指导中心，并附电子版。联系人：李华斌电话：029-87344961E-mail：87318402nyt@163.com附件：1. '
               '全国一村一品示范村镇申报书2. 全国一村一品示范村镇申报表3. 全国一村一品示范村申报市级汇总表4. '
               '全国一村一品示范镇申报市级汇总表5. '
               '审核推荐表\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '2017年4月19日附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于申报第七批全国一村一品示范村镇的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-04-14 09:41:49',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕36号各有关设区市农业局（委），杨凌区农业局，韩城市农林局：受去冬早春气温偏高、田间湿度大等因素影响，今年小麦条锈病在我省陕南及关中的中西部发生较常年明显偏早、程度普遍偏重、蔓延速度异常迅速，大流行态势明显，对小麦生产构成严重威胁。目前，小麦条锈病已在我省7市37县（区）发生，面积已达103万亩，3-4月份我省降雨偏多，田间温、湿度对病害快速传播蔓延十分有利，随着温度稳定回升，小麦条锈病在我省发生范围和程度将进一步扩大和加重，防控形势异常严峻。为切实抓好小麦条锈病等病虫防控工作，确保夏粮生产安全，现紧急通知如下：一、提高认识，加强组织领导小麦是我省主要夏粮作物，做好小麦条锈病防控工作对确保夏粮丰收，实现全年粮食增产目标至关重要。小麦条锈病属跨区域流行性病害，突发性强、流行速度快、危害损失重。现距小麦收获还有两个月的时间，如果不加强防控，在菌源量充足、气候适宜的情况下，极易暴发流行成灾。各地要从讲政治的高度出发，充分认识做好防控工作的重要性，切实增强紧迫感和责任感，坚决克服麻痹侥幸思想，强化对防控工作的组织领导，落实各项防控措施和责任，及时组织、发动群众开展大面积防治。二、密切监测，做好预警指导各地农业植保部门要继续加强病情监测，加密调查频次，加大调查范围。特别是小麦条锈病常发、重发地区，要开展拉网式普查，及时、准确预报病情动态，为指导大面积防治提供依据；要继续做好病虫信息报送工作，及时上报病虫发生防控信息，特殊情况随时汇报，不得迟报、漏报和瞒报。适时组织专家和技术人员深入田间地头，开展技术培训和指导，提高科学防治水平。重发区要建立防控示范样板，组织召开防控现场会，充分利用报纸、广播、电视等新闻媒体，大力开展宣传工作，引导媒体和社会舆论，营造防控氛围，推动大面积群防群控。三、制定方案，科学开展防控各地要依据省上制定的麦油病虫防控技术方案，结合当地病虫发生实际，因地制宜制定防控方案。小麦条锈病防控要坚持&amp;ldquo;科学监测、打点保面、早期封锁中心、流行初期大面积施药&amp;rdquo;的防治策略。当田间发现小麦条锈病少量病叶时，立即摘除并带到田外烧毁或深埋；对出现的发病中心，要立即&amp;ldquo;打点保面&amp;rdquo;，封锁发病中心，防止扩散蔓延。当田间平均病叶率达到0.5%-1%时，要立即组织开展大面积应急防控，重发田块在施药7-10天后再开展第二次药剂防治。防治药剂可选用三唑酮、烯唑醇、戊唑醇、氟环唑、已唑醇、丙环唑、醚菌酯、吡唑醚菌酯、嘧啶核苷类抗菌素、烯肟&amp;bull;戊唑醇等。四、提早准备，开展统防统治为加强我省农作物重大病虫防控，省财政已列支了专项防控经费。各地要在用好省级防控专项资金的同时，克服消极等待思想，多渠道争取资金，要及时将小麦条锈病发生流行的危险性及可能导致的严重后果向当地政府作详细汇报，积极争取地方财政的资金支持，提早做好防控药剂、器械和燃油等物资的购置和储备，确保防控需要。在开展防控时，要继续坚持&amp;ldquo;统防引领，群防群治&amp;rdquo;的防控机制，充分发挥财政资金引导作用，鼓励专业化防治队伍开展统防统治，动员群众开展多种形式的防控，增强对突发性、暴发性、流行性病虫害的应急防控能力，努力提高防治效果和防治效率，及时有效控制危害。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年4月12日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于进一步加强小麦条锈病防控工作的紧急通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-04-14 08:40:51',
 'art_detail': '\n'
               '         '
               '陕农业发〔2017〕34号各设区市农业（畜牧、农机、果业）局（委）、杨凌示范区农业局，韩城市农林局，厅有关处（局），厅属有关单位：为加快我省生态文明建设，贯彻落实中省重大战略部署和要求，增强环保责任意识，切实做好全省农业生态环境保护工作，结合我省农业实际，制定如下意见：一、增强农业生态环境保护工作的责任感和使命感党的十八大以来，高度重视生态文明建设，将生态文明建设纳入&amp;ldquo;五位一体&amp;rdquo;的总体布局。党中央、国务院提出了关于生态文明建设的新理念、新思想、新战略，印发了《中共中央国务院关于加快推进生态文明建设的意见》(中发〔2015〕12号)，国务院先后发布了大气、水、土壤污染防治行动计划，并建立了环境保护督察制度。农业部、国家发改委等部门印发了《全国农业可持续发展规划（2015&amp;mdash;2030年）》（农计发〔2015〕145号）和《关于加快发展农业循环经济的指导意见》（发改环资〔2016〕203号），农业部印发了《关于打好农业面源污染防治攻坚战的实施意见》（农科教发〔2015〕1号）等，为建立健全农业生态环境保护机制、加强农业面源污染防治工作提出了具体目标和任务。省委、省政府高度重视，相继印发了关于加强生态环境保护的指导意见和落实大气、水、土壤污染防治行动的实施方案，进一步强化了各部门工作职责，明确了任务要求，生态文明建设工作已经列入了省委省政府重要议事日程。近年来，由于耕地质量退化、农业环境污染、生态功能递减等不利因素影响，现代农业发展面临生态系统退化与农产品供给要求提升的双重压力。农业投入品过量使用成为农业生态系统破坏的主要原因，农业源与工业源污染迭加成为农产品质量安全的最大隐患，农业生态资源利用率低成为农业可持续发展的重大障碍。深入贯彻执行中省关于加强生态文明建设文件精神要求，抓好农业环境保护工作，完成&amp;ldquo;十三五&amp;rdquo;&amp;ldquo;一控两减三基本&amp;rdquo;总目标，形势紧迫，任务艰巨。二、总体思路和目标任务（一）总体思路：全面贯彻执行党的十八大和十八届三中、四中、五中、六中全会精神，严格落实省委省政府工作部署，以邓小平理论、&amp;ldquo;三个代表&amp;rdquo;重要思想、科学发展观为指导，树立贯彻五大发展理念，以推进农业供给侧结构性改革为主线，以推进农业生态文明建设为中心，以落实&amp;ldquo;一控两减三基本&amp;rdquo;为目标，切实做好农业生态环境保护工作，推动我省特色现代农业发展。（二）主要目标：力争到2020年，农村畜禽粪便基本实现资源化利用，规模畜禽养殖场（小区）配套建设废弃物处理设施比例达75%以上；秸秆综合利用率达到 '
               '85%以上；土壤环境质量总体保持稳定，全省化肥使用量实现零增长，利用率提高到40%以上，测土配方施肥技术推广覆盖率提高到90%以上；农作物病虫害统防统治覆盖率达到40%以上，农药利用率达到40%以上，农药使用量实现零增长；全省农膜回收率达到80%以上；着力推进资源循环利用，农业面源污染势头得到有效扭转，农业生态环境质量持续改善。三、重点任务（一）加强畜禽养殖粪污资源化利用。各级农业（畜牧）行政主管部门要鼓励支持生态化畜禽养殖产业发展，加强畜禽养殖废弃物综合利用与病死畜禽无害化处理。严格规范兽药、饲料添加剂的生产和使用，促进源头减量。统筹考虑环境承载能力及畜禽养殖污染防治要求，按照农牧结合、种养平衡的原则，科学规划布局畜禽养殖。推行标准化规模养殖，配套建设粪便污水贮存、处理、利用设施，改进设施养殖工艺，完善技术装备条件。要鼓励和支持散养密集区场地硬化防渗，实行畜禽粪污分户收集、集中处理。畜牧技术部门要因地制宜推广畜禽粪污综合利用技术模式，规范和引导畜禽养殖场做好养殖废弃物资源化利用,推广干湿分离与雨污分离、大中型和养殖小区沼气工程、有机肥加工等设施设备。要加快推广废弃物循环利用的农业清洁生产和循环经济模式。（二）加强秸秆综合利用。拓宽农作物秸秆开发利用途径，以秸秆肥料化、饲料化、能源化、基料化等主要利用方式，宣传引导农民和多部门协作推进秸秆综合利用。推广秸秆机械化利用和保护性耕作技术，推动秸秆机械化还田、生物腐熟还田、养畜过腹还田，提高肥料化利用率。推广秸秆青贮氨化、微贮、颗粒饲料等，提高饲料化利用率。推广秸秆生物气化、热解气化、固化成型、炭化、直燃发电等技术，因地制宜发展以秸秆能源化、燃料化和基料化利用工作。发展以秸秆为基料的食用菌产业，生产育苗基质、栽培基质，提高基料化利用率。要加快培育发展秸秆收储运等农村社会化服务组织，到2020 '
               '年，全省建立较为完善的秸秆还田、收集、储存、运输等社会化服务体系，基本形成布局合理、多元利用、可持续运行的综合利用格局。（三）加强老旧农机具管理。要强化绿色发展理念、扩大资源节约型环境友好型农机化技术应用。推进农机报废更新，完善农机报废更新补贴政策，加快淘汰能耗高、污染重、性能低的老旧机械，鼓励和引导农业机械以旧换新和升级换代，要积极推广先进绿色环保新机具，促进节能、环保、安全农业机械的推广应用。优化农机装备结构，降低农业机械作业能耗，推进农机农艺融合，推动农机从数量增长向质量和数量效益并重、从资源消耗向创新驱动转变。（四）加强农田土壤污染防治。提升和保护耕地质量，加强农田土壤污染防治，强化农产品产地环境安全管理。2017-2018年全省要开展农田土壤污染状况详查和第二次农业污染源普查；建立国、省监测网点和预警体系，组织农用地类别判定，实施农产品产地分级管理；推进污染耕地安全利用，开展农田土壤污染治理与修复试点示范，严格管控重度污染耕地。要大力发展节水农业，推广保墒固土、生物节水、沟播种植、膜下滴灌等旱作节水技术，提高灌溉水和天然降水利用率；实施机深松，改善耕地质量。要推行休耕制度，解决土壤退化问题，恢复自我调节、自我修复能力，提升耕地质量，实现藏粮于地战略。（五）推行化肥减量使用。分区域、分作物制订科学施肥方案，公布区域施肥&amp;ldquo;大配方&amp;rdquo;，推广高产、高效、环保施肥技术，全面实施测土配方施肥；推广化肥机械深施、种肥同播、水肥一体化等技术，提高肥料利用率，推进施肥方式转变；加快缓释肥料、水溶性肥料、生物肥料等新型肥料研发推广，推进新肥料新技术应用；鼓励农民积造农家肥，施用商品有机肥，推广秸秆粉碎还田、腐熟还田、过腹还田等技术，推广种植绿肥，优化用肥结构，推进有机肥资源利用。（六）推行农药减量使用。坚持&amp;ldquo;预防为主，综合统治&amp;rdquo;的植保方针，按照绿色防控、统防统治的工作要求，落实&amp;ldquo;控、替、精、统&amp;rdquo;技术路线，依托新型经营主体和专业化服务组织，开展农作物病虫害统防统治与绿色防控融合示范，集成推广农药减量增效综合技术模式，加快绿色防控技术推广应用。要严格执行国家有关高毒、高残留农药使用管理规定，推广高效低毒低残留农药及新型高效植保机械，指导农民科学用药，精准施药，提高农药利用率。要建立农药包装容器等废弃物回收制度。（七）积极推进农膜回收利用。建立健全废弃农膜回收储运和综合利用网络，宣传引导农民和农业生产组织树立环保意识，推进农田残膜回收区域性示范，扶持地膜回收网点和废旧地膜加工能力建设，创新地膜回收与再利用机制，落实残膜回收利用补贴政策。要全面推广使用0.01mm以上加厚地膜，加快可降解地膜、地膜残留捡拾及加工机械的研发。各级农业综合执法部门要严厉打击违法生产和销售不合格农膜行为，强化农膜回收利用管理。（八）积极推动流域治理。全面实施&amp;ldquo;五大流域&amp;rdquo;农业面源污染综合防治示范工程，集成推广农业面源污染综合防治技术，分生态流域、生产区域建立综合防治示范样板，大力推广综合清洁生产技术，促进农业面源污染全面治理，凸显农业生产、农民生活、农村生态功能，实现&amp;ldquo;田园清洁&amp;rdquo;、&amp;ldquo;乡村美丽&amp;rdquo;的农业生态文明目标。（九）积极发展生态循环农业。全面推动资源利用节约化、生产过程清洁化、产业链接循环化、废弃物处理资源化，加快转变农业发展方式，全面推进农业转型升级。推动果业生态化和菜茶园清洁化，以绿色生产带动&amp;ldquo;三品一标&amp;rdquo;发展。加强反光膜、残枝、套袋、尾菜、残膜、农资包装物等废弃物资源化利用。抓好现代农业园区提质增效，推行标准化生产，大力推行&amp;ldquo;五治一品&amp;rdquo;，强化园区产地环境治理。推广生物质能、太阳能、风能、电能等清洁可再生能源，加快推进农村居民炊事、采暖设备更新换代。开展生态循环农业技术试验示范，要推广&amp;ldquo;种植业-秸秆-畜禽养殖-粪便-沼肥还田&amp;rdquo;、&amp;ldquo;养殖业-畜禽粪便-沼肥-种植业&amp;rdquo;等循环模式，促进沼气沼肥高值高效利用，促进种养平衡。四、工作措施（一）强化组织领导，加强制度建设。省农业厅成立农业生态环境保护工作领导小组（详见附件1），由分管厅长任组长，厅相关处（局）和厅属单位负责同志为成员，合力抓好农业生态环境保护工作。各级农业（畜牧）部门要切实强化对农业生态环境保护工作的组织领导，成立相应机构，全面落实4项制度（详见附件2）。主要领导实行&amp;ldquo;一岗双责&amp;rdquo;，做到农业生态环境保护工作与业务工作同安排、同部署、同落实。各单位要制定年度工作方案，明确职责、细化任务，落实机构、人员和措施。相关部门要落实年度承诺和报告制度，将工作内容和措施以承诺的方式进行公布，接受公众监督。（二）落实部门责任，加强目标考核。农业环保工作要坚持&amp;ldquo;管行业必须管环保&amp;rdquo;&amp;ldquo;谁决策，谁负责&amp;rdquo;&amp;ldquo;谁监管，谁负责&amp;rdquo;&amp;ldquo;谁污染、谁负责&amp;rdquo;的原则。各单位要按照职责分工（详见附件3）抓好落实，每季度报送一次总结。各级农业（畜牧）部门要参照省厅职责分工，做好部门责任划分工作。全面加强督查考核制度，实行分层考核，省农业厅负责对市级农业（畜牧）行政主管部门和省厅有关单位进行考核，市、县级农业局负责对本行政区域相关部门进行考核。省农业厅每年将组织专项督查组对各地开展不定期专项督查，方式为明察暗访。资料报送及日常工作情况将纳入考核内容。（三）加强应急处置，发挥&amp;ldquo;监督员&amp;rdquo;作用。各级各部门要重视和做好农业污染源和突出环境问题调查，落实好农业环境突发事件应急预案，配合环保部门及时处理。要落实&amp;ldquo;监督员&amp;rdquo;制度，发挥自律监督作用，支持&amp;ldquo;监督员&amp;rdquo;开展工作，充分发挥其在环保知识宣传、信息调查统计、行业自律监督职责作用。（四）统筹多方资源，发挥项目带动作用。各级农业（畜牧）部门要加强与发改、财政、环保等部门协调配合，争取本级财政支持。要严格落实相关法律和政策要求，鼓励社会资本参与农业生态环境保护工作。在各类农业项目的申报、实施、检查中，要充分体现农业生态环境保护的内容、措施、成效。发挥畜牧养殖标准化示范场创建、果业提质增效、化肥农药零增长行动、绿色增产、沼气建设、耕地质量提升等项目的带动支撑作用，大力发展生态循环农业，提升农业废弃物资源化利用水平。（五）做好宣传培训，营造社会氛围。各级农业（畜牧）部门要加大培训力度，开展农业面源污染防治技术专题教育和培训，着力提高种粮大户、家庭农场、专业合作社农业环境保护水平。充分利用报纸、广播、电视、新媒体等，加强农业生态环境保护的科学普及、舆论宣传，推广普及化害为利、变废为宝的清洁生产技术和污染防治措施，让广大群众理解、支持、积极参与农业生态环境保护工作，形成全社会关心支持的发展氛围。事业单位机构改革后，本意见分工职能由改革后的新单位承担。附件：1．陕西省农业厅农业生态环境保护工作领导小组\xa0\xa0\xa0\xa0\xa0 '
               '2．陕西省农业生态环境保护工作4项制度（即：领导小组联席会议制度、&amp;ldquo;监督员&amp;rdquo;制度、年度承诺与报告制度、督查考核制度）\xa0\xa0\xa0\xa0\xa0 '
               '3．2017 2020年陕西省农业生态环境保护工作目标责任分工表\xa0 '
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '2017年4月10日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于加强全省农业生态环境保护工作的意见'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-04-11 10:56:00',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕34号各设区市农业（畜牧、农机）局（委、中心），杨凌示范区农业局，韩城市农林局，厅属有关单位：为贯彻落实2017年中央一号文件和中央农村工作会议精神，加快我省各级农技推广人员观念转变和方式创新，提高农业技术推广人员能力和服务&amp;ldquo;三农&amp;rdquo;本领，深入推进我省农业供给侧结构性改革，促进农业增效、农民增收和农村增绿。根据高校千人培训计划安排，省农业厅决定，委托西北农林科技大学举办全省系列高级职称农技术人员高级研修班。现将有关事项通知下：一、省内（一）班次安排1.农业供给侧改革与转型升级高级研修班第一期：2017年4月17日－22日，4月17日报到。第二期：2017年4月24日－29日，4月24日报到（在宝鸡眉县举办）。2.规模化标准养殖高级研修班第一期：2017年5月15日－20日，5月15日报到。第二期：2017年5月22日－27日，5月22日报到。3.农技推广观念转变与模式创新高级研修班第一期：2017年6月5日－10日，6月5日报到。第二期：2017年6月12日－17日，6月12日报到。4.现代农业产业园建设与发展模式创新高级研修班第一期：2017年6月19日－24日，6月19日报到。第二期：2017年6月26日－7月1日，6月26日报到。5.特色农业发展高级研修班2017年6月26日－7月1日，6月26日报到（在渭南市举办）。（二）研修内容、方法1.研修内容：农业供给侧结构性改革、农业转型升级、农业技术推广方式创新、农业生产方式转变、农业科技创新、农业投入品（农药、化肥）使用降低、提升现代农业科技示范园区功能以及&amp;ldquo;互联网＋农业&amp;rdquo;等。2.研修方法：采用理论讲授、研讨交流、现场教学、成果展示与交流分享&amp;ldquo;四元一体&amp;rdquo;化的方法。（三）研修地点及联系人1.地点：杨凌示范区邰城路南段西北农林科技大学新天地酒店，前台电话029－87071666。在宝鸡眉县、渭南市举办的培训班地点另行通知。2.乘车路线：杨陵火车站、高铁站、汽车站乘1路公交车，至西北农林科技大学新天地酒店。3.联系人：省农业厅科教处联系人：申 '
               '巍 电 话：029－87321775西北农林科技大学联系人：王 强 张继瑄电 话：029－87080221 '
               '029－87080229（四）名额分配及报名方式1.研修对象：省、市农业和畜牧系统具有高级职称农技推广人员每期100名（名额分配见附件1）。2.报名方式：以市为单位，集中确定每期参加人员及带队负责人，在每期培训班开班前10天，将带队负责人及参研人员名单统一汇总，报西北农林科技大学继续教育学院（汇总表见附件2）， '
               '邮箱：1600265258@qq.com。同时抄报省农业厅科教处，邮箱：sxnykj@163.com。二、省外班次安排1.高级职称农技人员研修班研修地点：上海研修对象：正高级职称农技推广人员50名。时间安排：2017年6月12日&amp;mdash;16日，6月12日报到。主要目的：利用东部地区优质科教资源，开拓农技推广人员视野，拓宽思路，转变观念，准确把握现代农业发展的趋势和方向，为陕西特色现代农业提供智力支持。主要内容：围绕农业产业结构调整优化，深化农产品供给侧结构性改革；以绿色种植满足绿色需求为导向，推动陕西农业资源高效利用；提升农业科技园建设水平，扩大科技园引领、示范、服务等功能开展研修。2.培训机构骨干培训班研修地点：上海培训对象：培训机构负责人及骨干共50名。时间安排：2017年5月2日&amp;mdash;6日，5月2日报到。培训目的：通过交流学习，借鉴外省的先进经验和方法，培养培训机构骨干师资和管理人员，提升我省农技人员培训的效果。培训内容：培养他们熟练利用现代信息化手段、现代培训新装备的应用，&amp;ldquo;互联网＋&amp;rdquo;农技人员培训的新思维、新技术、新方法。以上班次名额分配见附件3、汇总表见附件2，报名地点另行通知，报名方式和联系人同省内高级研修班。三、其它事项1.请参加研修的人员提前结合本地实际开展与研修主题相关的调研工作，带着问题参加研修，提升研修成效。每人撰写一篇不少于2000字与研修内容相关并对我省或本区域农业生产具有指导意义的论文或交流材料，培训班结束前提交。2.研修人员修完规定的课程，经考核合格后，颁发培训结业证书，研修学时可记入&amp;ldquo;专业技术人员继续教育&amp;rdquo;。3.本次研修（培训）班不收取任何费用，交通费自理。报到时请交1张1寸近期免冠照片。附件：1. '
               '省内研修班名额分配表\xa0\xa0\xa0\xa0\xa0 2. 研修班人员汇总表\xa0\xa0\xa0\xa0\xa0 '
               '3. '
               '省外研修班名额分配表\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年4月10日\xa0\xa0 附件.docx\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于举办高级职称农技推广人员研修（培训）班的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-04-01 14:31:01',
 'art_detail': '\n'
               '         陕农业发〔2017〕23号\r\n'
               '\r\n'
               '各设区市农业局（委）、发展改革委、财政局、水利（务）局、林业局、工商行政管理局、地方税务局、供销合作社、国家税务局，各银监分局，杨凌示范区农业局、发展改革局、财政局、水务局、工商行政管理局、地方税务局、供销合作社、国家税务局，韩城市农林局、经济发展局、财政局、水务局、工商行政管理局、地方税务局、供销合作社、国家税务局：\r\n'
               '为发挥农民合作社示范社的示范带动作用，提升我省农民合作社发展水平，在各地创建示范社的基础上，按照省农业厅等10部门印发的《陕西省农民合作社示范社评定及监测办法》（陕农业发〔2014〕63号）的规定，在全省开展第二批陕西省农民合作社示范社申报评定和第一批省级示范社监测工作，由合作社申请，市、县农业部门会同同级有关部门审核推荐，省示范社联评小组评审，经公示无异议，决定认定高陵七色彩无公害蔬菜农民专业合作社等421家合作社为陕西省农民合作社示范社，岐山县益店镇冯家山灌区北干七支渠农民用水协会等6家用水合作组织为陕西省农民用水合作组织示范组织，取消西安市阎良区绿丰源科技畜牧养殖专业合作社等30家合作社陕西省农民合作社示范社资格。\r\n'
               '希望认定的省级示范社和省级用水示范组织要珍惜荣誉、再接再厉，始终坚持以服务农民群众为宗旨，规范发展，守法经营，不断提升服务能力，充分发挥示范带动作用，为促进我省农民合作社规范发展和农民增收发挥重要作用。\r\n'
               '各级农业、发改、财政、水利、林业、工商、税务、供销、银监等部门要加强对省级示范社和用水示范组织的指导、扶持和服务，落实和完善扶持政策，引领我省农民合作社做强做大。各级农业行政主管部门要会同水利、林业、供销社等部门和单位做好动态监测，对不合格的应取消其省级示范社资格。\r\n'
               '取消省级示范社资格的合作社，对已接受财政扶持的资金，要按照《农民专业合作社财务会计制度（试行）》（财会〔2007〕15号）等有关规定纳入财务管理与核算，并向全体成员公开、公示资金使用情况，所形成的资产归合作社成员共同所有，并平均量化到成员账户，解散、破产清算时，不得作为可分配剩余资产分配给成员。\r\n'
               '附件：1. 陕西省农民合作社示范社和陕西省农民用水合作组织示范组织名单\r\n'
               '\xa0\xa0\xa0\xa0\xa0 2. 取消监测不合格陕西省农民合作社示范社资格名单\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 陕西省农业厅 '
               '陕西省发展和改革委员会 陕西省财政厅\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 陕西省水利厅 '
               '陕西省林业厅 陕西省工商行政管理局\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 陕西省地方税务局 '
               '陕西省供销合作总社 陕西省国家税务局\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '中国银行业监督管理委员会陕西监管局\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年3月7日\r\n'
               '附件.doc\r\n'
               '\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '关于认定陕西省农民合作社示范社和取消监测不合格陕西省农民合作社示范社资格的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-04-17 17:39:55',
 'art_detail': '\n'
               '         '
               '陕农业会发〔2017〕12号各有关设区市农业局（委），韩城市农林局，厅属有关单位：为贯彻落实农业部小麦重大病虫防控现场会精神，切实做好我省小麦穗期重大病虫防控工作，我厅决定召开全省小麦穗期重大病虫防控现场会，现将有关事宜通知如下：一、会议内容安排部署全省小麦穗期重大病虫防控工作；观摩作业现场。二、时间地点时间：4月20日上午报到，4月20日下午开会，会期半天。地点：三原县三原宾馆（三原县宴友思大街东段35号，联系人：林坤 '
               '029-38910555 '
               '13060350305），三、参加人员（一）西安市、宝鸡市、咸阳市、铜川市、渭南市、汉中市、安康市、商洛市、韩城市农业（林）局分管领导、农技中心负责人或植保站站长。（二）长安区、周至县、蓝田县、高陵县、岐山县、陇县、陈仓区、眉县、兴平市、泾阳县、三原县、武功县、蒲城县、富平县、临渭区、大荔县、勉县、汉滨区、山阳县农业局分管领导、农技中心主任或植保站站长。（三）省农机局法规处、省农技站、省种子站、省植保站、省药检所、省土肥站负责同志。（四）邀请农民日报社、陕西日报社、陕西广播电视台、陕西农业网、陕西农业杂志社等新闻媒体参会并报道。四、有关要求（一）请各市农业局负责通知辖区单位参会，并将会议回执以市为单位汇总，于4月18日18:00前统一报省植保总站（邮箱：sxzbfzk2007@163.com）和三原县植保站（邮箱：syzb2282218@163.com '
               '）。（二）请省植保总站做好会议筹备相关事宜。（三）请省农业宣传信息中心负责邀请有关新闻媒体。（四）由于会议接待能力有限，请勿超员。联系人：省植保总站 '
               '魏会新 029-87321497 13891988501三原县植保站 孙德文 '
               '13259027518\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
               '2017年4月17日报名回执.doc\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '关于召开全省小麦穗期重大病虫防控现场会的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2017-03-21 14:20:21',
 'art_detail': '\n'
               '         '
               '驻陕农纪发〔2017〕4号省农业厅、省扶贫开发办公室、省供销合作总社各处（室、局）各单位，省纪委驻省农业厅纪检组各室：现将《关于建立省纪委驻省农业厅纪检组与省农业厅、省扶贫开发办公室、省供销合作总社等单位工作联系协调机制的实施意见（试行）》印发给你们，请认真遵照执行。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '中共陕西省农业厅党组 '
               '中共陕西省扶贫开发办公室党组\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '中共陕西省供销合作总社党组 '
               '中共陕西省纪委驻省农业厅纪检组\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年3月14日关于建立省纪委驻省农业厅纪检组与省农业厅、省扶贫开发办公室、省供销合作总社等单位工作联系协调机制的实施意见（试行）根据《关于加强省纪委派驻机构建设的意见》和《关于全面落实省纪委向省一级党和国家机关派驻纪检机构的方案》要求，为建立省纪委驻省农业厅纪检组（简称驻厅纪检组）与省农业厅、省扶贫开发办公室、省供销合作总社等三家综合监督单位（简称各单位）之间的工作联系协调机制，进一步推动从严治党&amp;ldquo;两个责任&amp;rdquo;落实，提出如下实施意见。一、建立从严治党主体责任和监督责任落实机制1.驻厅纪检组要认真履行监督职责，督促和协助各单位党组落实从严治党主体责任，督促和指导各单位机关纪委落实从严治党日常监督责任；各单位应围绕贯彻落实中省纪委全会精神，制定年度落实从严治党、加强党风廉政建设和反腐败工作安排意见，并分解任务、落实责任；各单位要结合年度工作重点和领导分工调整情况，及时制定和更新党组及其班子成员年度落实从严治党、加强党风廉政建设主体责任清单。2.党组履行主体责任的主要内容包括：遵守党章和其他党内法规、贯彻执行党的路线方针政策和决议情况；遵守政治纪律和政治规矩情况；贯彻执行民主集中制情况；加强作风建设情况；选好用好干部，防止选人用人上的不正之风和腐败问题情况；强化对权力运行的制约和监督，从源头上防治腐败情况；加强廉政文化和政风行风建设，纠正行业不正之风情况；领导和支持机关纪委查处违纪问题情况；党组主要负责人抓班子带队伍和领导班子成员抓分管范围内&amp;ldquo;两个责任&amp;rdquo;落实情况等。3.机关纪委履行日常监督责任的主要内容包括：对本单位所属各级党组织和党员干部遵守党章和其他党内法规，贯彻执行党的路线方针政策和决议，遵守政治纪律和政治规矩以及贯彻执行民主集中制等进行监督检查情况；对本单位领导干部选拔任用和行使权力进行日常监督情况；对本单位落实中央八项规定精神和纠正&amp;ldquo;四风&amp;rdquo;问题监督检查情况；受理信访举报及处置情况；开展廉政教育和纪律检查工作情况等。4.驻厅纪检组对各单位履行&amp;ldquo;两个责任&amp;rdquo;情况进行监督检查，及时受理各单位各级党组织和党员的检举、控告，认真分析各单位党风廉政建设中存在的问题，并督促整改。对各单位各级领导班子履行主体责任不力、造成严重后果的，提出问责建议。5.驻厅纪检组要主动接受各单位各级党组织和干部群众的监督。二、建立驻厅纪检组与各单位联席会议机制6.驻厅纪检组与各单位党组联席会议。各单位确定一名党组成员为联席会议成员，由驻厅纪检组组长召集，根据工作需要召开联席会议，主要内容是研究和通报党风廉政建设和反腐败工作重大事项、部署重大专项活动、落实省纪委重大决策部署等。涉及各单位自身重大事项需要召开专题联席会议的，由各单位党组书记或驻厅纪检组组长主持召开。7.驻厅纪检组与各单位纪检工作联席会议。由驻厅纪检组组长或副组长召集，各单位机关纪委书记和相关处室人员参加，原则上每季度召开一次联席会议，也可根据工作需要安排召开。主要内容是传达学习贯彻中省纪委有关会议、文件和中省领导同志重要讲话精神；通报重要工作情况；安排检查党风廉政建设工作；研究解决工作中存在的问题；交流工作经验和做法；安排部署纪检专项活动和重要工作；征求对驻厅纪检组工作的意见和建议等。8.联席会议研究确定的有关事项，分别由驻厅纪检组和各单位按照职责分工负责部署落实。三、建立驻厅纪检组参加或列席各单位会议机制9.各单位召开党组会、行政会及其他重要会议，会议通知应提前抄送驻厅纪检组。涉及党风廉政建设、&amp;ldquo;三重一大&amp;rdquo;事项等议题的，须书面商请驻厅纪检组负责人参加或列席；涉及其他内容的重要会议，驻厅纪检组认为有必要参加的，也可提出参加或列席。10.各单位临时召开的重要会议，可提前电话告知驻厅纪检组，驻厅纪检组认为有必要时可以参加或列席。11.各单位印发的会议纪要，一般应在5个工作日内抄送驻厅纪检组。四、建立各单位重大事项事前报备机制12.驻厅纪检组与各单位应加强对&amp;ldquo;三重一大&amp;rdquo;事项的事前监督管理，妥善处置重大事项可能引发的廉政风险问题，力求重大事项公开透明、公正公平、程序合规，将廉政风险降到最低程度。13.各单位研究&amp;ldquo;三重一大&amp;rdquo;事项，应在事前将相关方案资料向驻厅纪检组报备，驻厅纪检组通过廉政风险评估后如有不同意见时，应主动与各单位沟通研究，在提出监督建议并完善方案后方可上会研究和实施。如遇特殊情况事前无法报备的，事后应及时补报并说明原因。14.各单位研究决定重大事项，不按规定履行事前报备程序，又不及时补报并主动说明理由的，驻厅纪检组将函询并约谈相关责任部门和责任人；对违规决策造成不良影响和重大失误的，驻厅纪检组依纪依规启动问责程序。15.涉及&amp;ldquo;三重一大&amp;rdquo;需要事前报备的具体事项，由驻厅纪检组与各单位根据部门工作实际分别商定。五、建立各单位工作报告、信息通报和有关事项报备机制16.建立工作报告机制。各单位应于每年第一季度内向驻厅纪检组报送党组本年度落实全面从严治党、加强党风廉政建设和反腐败工作安排部署情况，党组及其班子成员年度落实从严治党、加强党风廉政建设主体责任清单，以及党组成员、领导班子成员上一年度履行主体责任及廉洁从政情况；各单位应按时报送半年和全年落实党风廉政建设责任制情况，党组落实从严治党主体责任及机关纪委落实从严治党日常监督责任工作情况。17.建立季报工作机制。各单位应在每季度最后一个月20日前，向驻厅纪检组书面通报本季度本单位履行主体责任工作动态、党员和国家工作人员违纪违法情况、问题线索处置及党政纪处分情况、违反中央八项规定精神问题线索处置统计汇总及本单位行政许可事项统计汇总等情况，无数据时要零报告。18.建立工作信息通报机制。驻厅纪检组应及时向各单位通报监督检查中发现的问题，并提出整改意见和建议；各单位处置突发性重大事件或事故情况，包括重大安全事故、涉及领导班子成员的重要舆情、影响社会稳定的群体性事件等事项，应在向上级党委政府报告的同时抄送驻厅纪检组。19.各单位领导班子成员和处级干部涉及婚姻变化、家庭办理婚丧嫁娶事宜、因私出国（境）、配偶和子女移居国（境）外或被追究刑事责任等个人有关事项，应按照规定及时向驻厅纪检组报备。六、建立驻厅纪检组监督配合各单位专项工作机制20.各单位在开展党风廉政建设监督检查、各类审计及财务检查、惠农扶贫项目补贴政策落实监督检查、固定资产核查、年度财政扶贫资金绩效考核、年度目标责任考核等专项工作活动时，应将活动安排部署及时抄送驻厅纪检组，驻厅纪检组要主动监督，积极配合开展工作。21.各单位在各类专项工作活动结束后，应将相关的检查情况、各类审计报告、考核结果等及时抄送驻厅纪检组备案。驻厅纪检组根据督促检查和专项审计中发现的违规违纪问题线索，与各单位共同研究处理意见，及时依纪依规进行处置。22.各单位党组书记应将省委组织部对本单位领导班子成员的年度考核情况与驻厅纪检组组长沟通。各单位在机关年度目标责任考核结束后，应将处级干部的考核结果及时报驻厅纪检组备案。七、建立各单位拟任处级领导干部任前廉政考试和廉政谈话机制23.落实领导干部任前廉政法规考试制度。各单位拟任职的处级领导干部在任前必须参加廉政法规考试，在任职公示期间，各单位应将参加考试人员基本情况书面报送驻厅纪检组，及时通知相关人员参加廉政法规考试，驻厅纪检组向省纪委申领复习资料、申请考试、抽题监考、评判试卷、通报成绩。考试成绩不合格者进行补考，补考不合格者不予任用。由于特殊原因未按时参加考试者，经各单位组织人事部门同意并写出书面说明后，可参加下一次考试。24.开展领导干部任前廉政谈话。在处级领导干部任职通知下发后，由各单位商驻厅纪检组对新任处级领导干部进行集体或个别廉政谈话。谈话对象应结合本职工作实际写出廉政承诺书，并于廉政谈话前分别报送驻厅纪检组和机关纪委存档备案。廉政谈话结束7日内，由谈话对象所在单位和部门负责，将个人廉政承诺书以适当方式进行公示，接受干部群众监督。八、建立各单位处级干部选拔任用等工作征求驻厅纪检组意见机制25.各单位在推荐副厅级干部及后备干部人选、民主推荐处级干部前，应就有关考虑和方案书面征求驻厅纪检组意见；在干部考察阶段应就具体考察人选书面征求驻厅纪检组意见，并附干部任免审批表和个人有关事项报告抽查核实情况；驻厅纪检组一般应在收到书面征求意见函后3个工作日内书面回复意见和建议，作为提交党组会研究的前置条件。26.各单位处级干部拟提拔任用人选，由驻厅纪检组出具廉政鉴定；科级干部拟任副处级干部的廉政鉴定由所在单位机关纪委出具。27.各单位在推荐机关纪委书记和直属单位纪委书记人选时，应当由组织人事部门会同驻厅纪检组联合提名推荐人选并组织考察工作。28.驻厅纪检组对各单位机关和直属单位处级干部因公出国（境）进行事前审查备案，在审查备案无异议并书面反馈意见后，方能办理出国（境）相关手续。29.各单位推荐省级或全国先进集体和先进个人，需要征求驻厅纪检组意见时比照上述规定进行；各单位干部职工住房登记、房屋过户等需纪检部门签署意见的，在经所在单位相关职能部门进行核实并如实填写意见后，由所在单位机关纪委审核签署意见。九、建立驻厅纪检组对各单位问题线索和案件的处置机制30.各单位应畅通信访举报渠道，在本单位门户网站首页的醒目位置公开驻厅纪检组和本单位受理信访举报方式，按规定及时处置问题线索。31.驻厅纪检组一般负责各单位涉及处级及以上干部问题线索的处置，科级及以下干部问题线索一般由所在单位的机关纪委负责。32.各单位对收到反映处级及以上干部的违规违纪问题线索、一般干部的重大问题线索（指反映问题线索比较具体、可能触犯法律的问题线索），应在收到后3个工作日内，由各单位机关纪委将原件报送驻厅纪检组。33.驻厅纪检组调查处级干部违反党纪的案件，在立案前应征求所在单位党组书记的意见，也可根据案情，经省纪委批准，立案后再予以通报。34.驻厅纪检组向各单位交办的问题线索，各单位应按照规定程序认真办理，并按要求时限向驻厅纪检组报送办理结果。35.驻厅纪检组应加强信访举报和纪律审查的统计分析工作，定期向各单位通报统计分析情况，提出意见和建议。十、建立驻厅纪检组对各单位纪检工作指导和监督机制36.驻厅纪检组应及时向各单位传达中省纪委有关会议精神和工作部署，听取各单位落实主体责任、开展党风廉政建设和反腐败工作、处置问题线索和查办违纪案件等方面的情况汇报，通报有关纪检工作情况，研究安排下一阶段工作。37.驻厅纪检组采取专项检查、专题调研、座谈交流等方式，对各单位纪检工作开展业务指导和监督；通过集中培训、抽调人员参加纪律审查工作等形式，不断提高各单位纪检干部的履职能力和业务水平；督促和指导各单位按规定配备专职纪检干部、充实工作人员，加强本单位纪检机构和干部队伍建设。\xa0\n'
               '        ',
 'art_source': '驻省农业厅纪检组',
 'art_title': '印发《关于建立省纪委驻省农业厅纪检组与省农业厅、省扶贫开发办公室、省供销合作总社等单位工作联系协调机制的实施意见（试行）》的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-03-31 16:00:02',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕30号各设区市农业局（委），杨凌示范区农业局，韩城市农林局：近年来，受国内外农产品贸易增加、气候变化等因素影响，苹果蠹蛾、红火蚁、马铃薯甲虫、柑橘黄龙病等全国农业植物检疫性有害生物扩散蔓延速度加快、危害程度加重，境外潜在的检疫性有害生物传入风险不断增加，植物疫情监测阻截防控形势十分严峻。为提升我省农业植物疫情阻截防控能力，保障农业生产和农产品质量安全，现就做好2017年检疫性有害生物防控工作通知如下：一、高度重视植物检疫工作植物检疫是保护农业产业安全的重要措施，是绿色发展的必然要求，可防患于未然，有效遏制检疫性有害生物的传入和扩散蔓延；可确保出口农产品符合进口国家的植物检疫要求，突破进口国的检疫技术壁垒；可避免检疫性有害生物对未发生区的危害，减少农药使用，保护生态环境。植物检疫工作关系着产业的存废，农民的增收致富，农村的发展，必须高度重视。各地要牢固树立风险意识和责任意识，密切关注疫情动态，及早部署疫情普查和监测工作，建立疫情应急处置机制，制定防控预案。在国家取消植物检疫收费的情况下，要按照财政部有关文件精神，落实工作经费，保障植物检疫工作顺利开展。二、切实做好以苹果蠹蛾为重点的疫情防控苹果蠹蛾是威胁我省果业安全的重大植物疫情，新疆、甘肃、宁夏、内蒙等周边省份疫情不断扩展，向我省不断逼近，传入风险加剧。各级农业部门要切实加强对苹果蠹蛾防控工作的组织领导，落实防控责任，重申工作纪律，高度警惕思想麻痹、落实不力等问题，严格按照&amp;ldquo;一堵二控三测&amp;rdquo;的防控策略，严守关键环节，落实关键措施，有效阻截苹果蠹蛾疫情传入。要落实疫情防控属地责任，抓好稻水象甲等已发和突发疫情的防控，压缩发生面积，控制扩散蔓延，确保我省农业生产安全。三、深入开展以提升能力为核心的示范县创建开展植物检疫执法示范县创建，提高检疫人员执法能力，规范检疫执法行为，通过法律手段震慑违法违规调运行为，防止疫情人为传播和扩散蔓延。各地要以提升执法水平为核心，以提高&amp;ldquo;二率&amp;rdquo;（产地检疫覆盖率、调运检疫持证率），推进&amp;ldquo;二化&amp;rdquo;（市场监管常态化、检疫执法规范化）为重点，按照植物检疫执法示范县创建工作规范，全力推进。各设区市要做好安排部署，组织交流学习，开展检查评比，力争整市达标；省上通过联评联查，奖优罚劣，推进创建工作开展，提升我省植物检疫执法工作水平。四、强化植物疫情保密意识根据《农业工作国家秘密范围的规定》和《农业植物疫情报告与发布管理办法》，未公布的重大植物疫情信息属于国家秘密，我省农业植物疫情信息由农业部或省农业厅负责发布，其他单位和个人不得以任何形式公布农业植物疫情。禁止在非疫区开展检疫性有害生物的研究。各地农业植物检疫机构要按照相关规定要求，保存、报送农业植物疫情信息和文件；不得承担其它单位检疫性有害生物监测任务；发现疑似农业植物检疫性有害生物，应送至省植保站指定的科研单位专家进行鉴定，确保无植物疫情泄密事件发生。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '陕西省农业厅办公室\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 '
               '2017年3月28日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅办公室',
 'art_title': '陕西省农业厅办公室关于做好2017年植物检疫工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-04-01 14:34:32',
 'art_detail': '\n'
               '         陕农业发〔2017〕24号\r\n'
               '\r\n'
               '各设区市农业局（委）、发展改革委、财政局、水利（务）局、林业局、工商行政管理局、地方税务局、供销合作社、国家税务局，各银监分局，杨凌示范区农业局、发展改革局、财政局、水务局、工商行政管理局、地方税务局、供销合作社、国家税务局，韩城市农林局、经济发展局、财政局、水务局、工商行政管理局、地方税务局、供销合作社、国家税务局：\r\n'
               '根据农业部、国家发展和改革委员会、财政部、水利部、国家税务总局、国家工商行政管理总局、国家林业局、中国银行业监督管理委员会、中华全国供销合作总社《关于公布2016年国家农民合作社示范社名单的通知》（农经发〔2016〕16号），我省周至县农家乐果蔬专业合作社等29家合作社被认定为国家农民合作社示范社，东六支烽火第六农民用水者协会等2家农民用水合作组织被认定为全国农民用水合作组织示范组织。\r\n'
               '国家示范社和全国用水示范组织作为农民合作社的先进典型，要珍惜荣誉、再接再厉，尽快做优做强；要强化服务成员宗旨，积极提供专业化社会化系列化服务，不断满足成员发展农业生产经营的需求；要健全规章制度，加强民主管理，保障成员各项权利；要大力推行标准化生产，注重农产品品牌建设，提高产品质量安全水平；要坚持守法经营，积极弘扬团结互助、诚信友爱的合作文化，充分发挥表率带头作用，示范引领广大农民合作社提高发展质量和水平。\r\n'
               '各有关部门要按照中央要求，落实和完善扶持政策，强化指导服务，积极支持国家示范社和全国用水示范组织发展。要加强监督管理，实行动态监测，建立淘汰机制，不断提升国家示范社和全国用水示范组织队伍的先进性纯洁性。要引导广大农民合作社向国家示范社和全国用水示范组织学习，建立健全各项规章制度，完善民主管理、资产管理和利益分配机制，不断提高市场竞争能力和服务成员、带动农户能力，为发展现代农业、推进农业供给侧结构改革、促进农民增收、建设社会主义新农村做出贡献。\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅 陕西省发展和改革委员会 陕西省财政厅\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
               '陕西省水利厅 陕西省林业厅 陕西省工商行政管理局\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省地方税务局 陕西省供销合作总社 陕西省国家税务局\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
               '中国银行业监督管理委员会陕西监管局\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
               '2017年2月27日\r\n'
               '附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '关于公布国家农民合作社示范社名单（陕西）的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-03-07 11:30:25',
 'art_detail': '\n'
               '         陕农业发〔2017〕19号\r\n'
               '\r\n'
               '各设区市农业局（委），杨凌示范区农业局，韩城市农林局，厅属各有关单位，各有关科研单位：\r\n'
               '为全面落实《农业部办公厅关于做好2017年农业转基因监管工作的通知》（农办科〔2017〕4号）要求，做好2017年农业转基因监管工作，促进农业转基因研究与应用健康发展，现就有关事项通知如下。\r\n'
               '一、突出重点，杜绝非法转基因试验生产经营行为\r\n'
               '（一）加强试验环节监管。各级农业行政主管部门要按照法律、法规、规章要求，全面加强试验环节属地监管。一是严格执行转基因作物中间试验、环境释放和生产性试验依法报告报批制度，严查有关科研单位和大专院校中间试验是否依法报告、环境释放和生产性试验是否依法报批、安全控制措施是否落实，３月底完成。二是对农业部已经批复的转基因试验全覆盖检查，试验前检查控制措施和制度建设情况，试验中检查安全隔离等措施落实情况，试验结束检查残余物和收获物处理、保存情况，３月底完成。三是对辖区内涉农科研育种单位的玉米、水稻和油菜等农作物试验地，利用快速检测方法开展全覆盖排查，查处转基因作物非法试验，生产试验季节至少检查３次。四是将近年来被处罚、被通报单位作为监管重点，每月检查１次，确保试验各个环节全程监管。\r\n'
               '（二）加强南繁基地监管。省种子管理站要全面加强南繁基地的监管，把我省南繁单位的玉米、水稻试验田作为监管重点，苗期、拔节期和穗期等生产关键时期，利用快速检测方法进行全覆盖检测监测，严查私自开展转基因试验和育繁种行为，对违规试验和育繁种材料坚决铲除，并按规定将相关单位和个人严肃处理，同时要求南繁单位开展自查。\r\n'
               '（三）加强品种审定环节监管。申请品种审定的单位要对参加区域试验的玉米、水稻、大豆、小麦、棉花等品种进行转基因成分检测，试验组织单位要进行复检，发现非法含有转基因成分的立即终止试验并按规定严肃处理。严格落实未获得农业转基因生物生产应用安全证书的品种一律不得进行区域试验和品种审定的要求。\r\n'
               '（四）加强种子生产环节监管。各级种子管理部门要把辖区内种子企业的制种田作为重点，查早查小。播种前，对辖区内的种子生产基地开展拉网式排查，查清亲本来源，防止非法转基因种子播种。在苗期和花期，利用快速检测方法对种子田进行大范围筛查，对发现问题的地块，要严从速查处，并依法严肃处理相关责任人员。\r\n'
               '（五）加强种子经营环节监管。各级种子管理部门要结合春秋冬三季的种子质量抽查活动，组织对抽查的玉米、水稻、大豆和油菜等种子进行转基因成分抽检，严防转基因种子冒充非转基因种子生产经营。\r\n'
               '（六）加强进口加工环节监管。各级农业行政管理部门要严格落实转基因生物进口和加工许可制度，严查国内进口商和加工企业的安全控制措施、档案记录和标识管理，重点核查装卸、储藏、运输、加工过程中安全控制措施落实情况，产品采购、加工、销售等管理档案以及转基因产品标识情况，开展抽样检测，确保进口转基因生物全部用于原料加工，推动境外贸易商、国内进口商、国内加工企业监管工作一体化。\r\n'
               '二、严查严打，持续保持打击违法转基因的高压态势\r\n'
               '（一）加大试验研发环节的查处力度。对违法开展田间试验（中间试验、环境释放、生产性试验）和品种选育的研发者，责令停止试验，停止安全评价申请资格，依法给予行政处罚，情节严重的停止科研项目，追究单位领导责任。\r\n'
               '（二）加大品种审定环节的查处力度。对以转基因品种冒充非转基因品种申请试验审定的，立即停止试验，并停止相关申请者参试资格，并严格按《种子法》及相关法规规章进行处罚。\r\n'
               '（三）加大种子生产经营环节的查处力度。对违法制种、繁种、销售转基因种子（种苗）的生产经营者，要立即停止其生产经营行为，依法没收违法所得和种子，吊销种子生产经营许可证，构成犯罪的依法移送司法机关，追究刑事责任。\r\n'
               '（四）加大对进口加工转基因生物环节的查处力度。对违规进口加工转基因生物，安全管控措施落实不力的进口和加工企业，依法责令其停止进口，停止加工资格，并给予行政处罚。\r\n'
               '三、落实责任，确保监管措施落实到位\r\n'
               '（一）强化责任分工。省农业厅农业转基因监管工作在厅农业转基因生物安全管理领导小组的安排部署下，领导小组办公室要抓好综合协调、归口管理工作，各成员单位要按照《陕西省农业厅农业转基因生物安全管理职责分工意见》各司其职，将责任落实到人到事。厅科教处负责组织实施农业转基因生物安全的监督管理和转基因生物加工审批、科学研究、科普宣传等工作；厅种植业处负责全省转基因农作物种子（苗）的生产、加工和经营管理，并负责全省转基因农作物种子（苗）及含有转基因成分的农药、肥料等在生产、加工、经营、储存、运输、销售流通过程中的安全控制管理；省畜牧局负责转基因畜禽及其相关产品的生产、加工和经营管理以及在生产、加工、经营、储存、运输、销售流通过程中的安全控制管理；省果业局负责转基因果树种苗、水果及其相关产品的生产、加工和经营管理以及在生产、加工、经营、储存、运输、销售流通过程中的安全控制管理；省种子站负责转基因农作物品种区试、审定，种子生产、经营环节的监督检验等技术支撑工作。市县农业行政主管部门负责辖区内转基因安全监管工作，尤其杨凌示范区农业局要全面加强西北农林科技大学等辖区科研单位转基因试验研究监管，制定本辖区农业转基因生物安全监管实施方案，并于３月底前将实施方案报送省农业厅科教处。各级种子管理部门做好品种选育、南繁基地、品种试验审定和种子生产经营等环节转基因管理工作，其他有关机构在职责范围内开展监管工作。通过绩效考核、约谈问责、督导检查等方式，层层传导压力，层层压实责任，坚决落实转基因生物非法扩散执法监管的管理责任，主要领导要亲自抓，分管领导要具体抓，责任要分解到具体部门，落实到人。\r\n'
               '（二）落实主体责任。各级农业行政主管部门是本行政区域内农业转基因监管工作的责任主体，主要领导要负总责。要严格按照《种子法》、《农业转基因生物安全管理条例》要求，认真履行转基因作物监管职责，切实担负属地监管责任，将转基因监管工作制度化，并在人员、经费和装备等方面加大支持力度，确保各项监管措施落到实处。研究试验单位、种子企业、进口加工企业，是“第一责任人”。各设区市农业行政主管部门要督促这些单位和个人健全管理制度，切实担负起主体责任，进一步提高认识、建立制度、落实监管措施。督促种子生产经营者和进口加工企业依法持证经营，健全管理档案，规范标识管理。各级农业部门要在４月前，与转基因研发、生产、加工、经营单位和种子生产经营企业签订《模范遵守转基因法律法规承诺书》（见附件1、2、3），做出不扩散不生产违规转基因材料、种子和产品的承诺。\r\n'
               '（三）加强宣传培训。各地要以《种子法》、《农业转基因生物安全管理条例》等法律法规为重点，充分利用多种途径，分层次开展形式多样的宣传培训活动。一是面向全省农业主管部门以及科研、试验、生产、加工单位的负责人，开展转基因培训，夯实全行业懂法守法、依法从业的基础。二是鼓励社会各界对违规行为进行举报，对于举报的线索，要追根溯源，一查到底，主动接受监督。公开曝光案件查处结果，威慑违法行为，营造严打高压氛围，震慑违法分子。三是利用文化、科技、卫生三下乡及大型会展等活动，面向社会公众开展形式多样、生动活泼、群众喜闻乐见的转基因知识宣传教育活动。尤其要加强制种户的宣传，普及法律到乡村到农户，让广大了解相关法律规定，自觉自愿尊法守法生产良种。\r\n'
               '（四）加强信息上报。各级农业行政主管部门要认真执行转基因监管信息月报制度，落实专人负责，没有案件的零报告。各市区要及时将《农业转基因执法监管查办案件情况统计表》（见附件4、5）报告省农业厅转基因生物安全管理办公室（省农业厅科教处），并于每年11月底以前将辖区内安全监管工作总结及时上报。对已结案的违规违法案件，各地要及时将详细案情和查处情况报告省农业厅。凡出现农业转基因生物安全重大问题的，属地方农业行政部门未主动履行监管职责或未及时报告的，由属地农业行政主管部门承担主要责任。省厅将根据了解和掌握的情况，对不认真履行监管职责的单位给予通报批评。\r\n'
               '附件：1. 研发单位模范遵守转基因法律法规承诺书\r\n'
               '\xa0\xa0\xa0\xa0\xa0 2. 加工企业模范遵守转基因法律法规承诺书\r\n'
               '\xa0\xa0\xa0\xa0\xa0 3. 种子企业模范遵守转基因法律法规承诺书\r\n'
               '\xa0\xa0\xa0\xa0\xa0 4. 农业转基因执法监管查办案件情况统计表\r\n'
               '\xa0\xa0\xa0\xa0\xa0 5. 农业转基因执法监管情况统计表\xa0 附件.docx\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年2月23日\r\n'
               '\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于做好2017年农业转基因监管工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-02-07 09:36:54',
 'art_detail': '\n'
               '         '
               '陕农业人事〔2017〕4号厅机关各处（室、局）、厅属各单位：省农业厅2017年1月22日研究决定，任命：巩彦宏为厅发展计划与财务处副处长，免去其厅离退休人员服务管理处副处长职务。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年1月23日\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于巩彦宏同志任免职的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-02-17 16:20:17',
 'art_detail': '\n'
               '         '
               '陕农业发〔2016〕101号各设区市农业、畜牧、农机、果业局（委、中心），杨凌示范区农业局，韩城市农林局，厅机关各处（室、局）、厅属各单位：新修订的《陕西省家庭农场资格认定办法》和《陕西省示范家庭农场评定及监测办法》经2016年第15次省农业厅行政会议审议通过。现印发给你们，请遵照执行。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '2016年12月27日\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省家庭农场资格认定办法第一条 '
               '为贯彻落实中、省有关文件精神，引导和扶持家庭农场发展，规范我省家庭农场认定工作，根据有关法律法规，制定本办法。第二条 '
               '家庭农场是指以家庭成员为主要劳动力，利用家庭承包土地或流转土地，从事农业规模化、集约化、商品化生产经营，并以农业收入为主要收入来源的新型农业经营主体。第三条 '
               '家庭农场经营范围除从事种植业、养殖业、休闲观光农业外，可兼营与其经营产品相关的研发、加工、销售或服务。第四条 '
               '县级以上农业行政主管部门是家庭农场的业务主管部门和资格认定机关，县级农村经营管理机构具体负责辖区内家庭农场的申报受理、条件审查、实地考查、认定监测和指导服务工作。家庭农场资格认定采取自愿原则，家庭农场资格认定不收取任何费用。第五条 '
               '各级农业行政主管部门负责辖区内家庭农场业务指导、组织培训以及本级示范家庭农场的创建评定和监测管理工作，并对优秀家庭农场、优秀业务辅导员、先进指导服务单位等进行表彰，引导家庭农场健康发展。第六条 '
               '家庭农场资格认定应同时符合以下条件：（一）家庭农场劳动力以家庭成员为主，常年雇工数量不超过家庭务农人员数量。生产经营稳定，拥有一定的基础设施和机械设备，土地流转经营期或承包期在5年以上；（二）家庭农场以农业收入为主，农业收入应占家庭总收入的60%以上，家庭成员人均收入不低于本县区城镇居民人均可支配收入；（三）家庭农场经营者应接受过农业技能培训，掌握相应的农业生产经营技能，有生产经营记录，有会计核算账目；（四）产品必须符合农产品质量安全标准，商品率达到95%以上；（五）生产经营达到一定规模。从事种植业的，粮食耕种面积应在100亩以上，果园、蔬菜、茶园面积20亩以上。从事养殖业的，牛存栏50头以上，猪存栏300头以上，羊存栏100只以上，鸡存栏5000羽以上。从事种养结合、特种种养业和休闲观光农业的，规模可适当放宽条件；对以上未涉及的区域主导产业，各地要结合当地实际，制定切实可行的家庭农场认定标准。第七条 '
               '家庭农场资格认定程序。（一）申报。农户向所在乡镇人民政府（街道办事处）或加入的农民专业合作社提出申请，并提供以下材料原件及复印件：1．陕西省家庭农场资格认定申请表（附件）；2．申请人身份证；3．土地承包、流转合同或承包经营权证书；4．其他有关证明材料。（二）初审。乡镇人民政府（街道办事处）或农民专业合作社负责初审有关材料原件与复印件的真实性，签署意见，报送县级农业行政主管部门。（三）审核。县级农村经营管理机构负责审核申报材料的真实性，组织专业人员进行实地考察，并提出认定意见。（四）公示。对拟认定的家庭农场，在县级农业信息网等公开媒体上进行公示，公示期不少于7天。（五）颁证。公示期满后，如无异议，由县级农业行政主管部门发文公布名单，并颁发证书。（六）存档。县级农业行政主管部门对认定的家庭农场申请、考察、审核等资料存档备查。由农民专业合作社审核申报的家庭农场要到乡镇人民政府（街道办事处）备案。第八条 '
               '县级农业行政主管部门对认定的家庭农场，建立家庭农场名录，每年对经营情况进行监测，实行动态管理，对不符合条件的要及时撤销认定资格。县级农业行政主管部门应建立家庭农场网上认定管理系统，方便农民。第九条 '
               '经资格认定的家庭农场，可以享受相应的涉农建设项目、财政、税收、信贷、担保、保险、设施用地等相关扶持和优惠政策。各级农业部门要对家庭农场予以项目倾斜。第十条 '
               '鼓励家庭农场根据实际需要，自愿到工商部门登记。第十一条 '
               '对出现下列情形之一的家庭农场，由认定机关撤销其资格，收回证书，并向社会公布。（一）取得家庭农场资格认定后，没有家庭成员直接从事农业生产和经营的。（二）因经营不善，资不抵债破产或被兼并、合并的。（三）提供虚假材料获得家庭农场资格的。（四）土地流转到期，没有续签，达不到认定条件的。（五）已不符合本办法对家庭农场认定条件的。第十二条 '
               '县级农业行政主管部门应根据本办法尽快制定当地家庭农场认定办法。第十三条 本办法由陕西省农业厅负责解释。第十四条 '
               '本办法自2017年1月20日起施行，止2022年1月20日。陕西省示范家庭农场评定及监测办法第一条 '
               '为充分发挥示范家庭农场的示范带动作用，规范省级示范家庭农场的创建管理，促进全省家庭农场健康发展，进一步加快构建新型农业经营体系，结合我省实际，现制定本办法。第二条 '
               '家庭农场是以家庭经营为基础，以家庭成员为主要劳动力，以农业收入为家庭主要收入来源，从事农业规模化、集约化、商品化生产经营的新型农业经营主体。陕西省示范家庭农场（简称省级示范家庭农场）是全省优秀家庭农场的代表。第三条 '
               '省级示范家庭农场评定工作坚持公开、公平、公正、公信的原则，自主申报、择优推荐、专家评审、媒体公示、发文认定。第四条 '
               '省级示范家庭农场必须达到以下标准：（一）市级示范家庭农场。家庭农场必须符合《陕西省农业厅家庭农场资格认定办法》的条件要求，经县级农业行政主管部门认定，并被评定为市级示范家庭农场。在工商部门登记的优先。（二）经营者专业素养高。家庭农场经营者以适度规模从事农、林、牧、渔、种养结合和休闲农业等（以下统称农业）生产经营活动3年以上，具备现代农业生产技能和经营管理理念，掌握先进生产经营模式，实践经验丰富，或具备新型职业农民资格。（三）经营规模适度。家庭农场生产经营的土地有规范的土地承包或流转合同，土地租期5年以上。从事种植业的，粮油作物耕种面积200亩以上，果业、蔬菜、茶叶、苗木、花卉等经济作物50亩以上。从事畜牧业的，牛存栏100头以上，生猪存栏500头以上，肉羊存栏400只以上，奶山羊200只以上，家禽存栏1万羽以上，水产养殖面积50亩以上。经济林经营规模100亩以上。从事种养结合或特种种养业、休闲农业的，可适当放宽条件。（四）基础设施完备。拥有一定的生产资料和产品初级加工场所和设施，有与生产经营相适应的水、电、路基础设施条件，机械化程度高于当地相同产业。（五）生产技术标准。采用先进的生产管理标准或技术规范，实行质量安全管理，严格农业投入品使用，生产记录完整，质量可追溯。（六）经营管理规范。建立购销台账，已形成规范实用的经营管理模式。设置会计账簿，财务管理实现科学规范。制定年度生产计划。（七）经济效益较高。土地、劳力、资本要素配置合理，基本实现订单生产，有稳定的销售渠道。农产品年销售总额50万元以上，正常年份农业生产经营年纯收入达到15万元以上，农业收入占家庭纯收入的80%以上。（八）示范带动力强。应加入农民合作社或专业协会员，遵纪守法，诚实守信，无不良记录，能够以先进的生产经营方式和成熟的管理模式带动周边农户发展，在当地有较高的信誉和威望。第五条 '
               '申报省级示范家庭农场必须提供以下材料原件及复印件：（一）省级示范家庭农场申报表（附件）；（二）家庭农场经营管理情况报告；（三）家庭农场经营者身份证明（身份证或户口簿）、农业行政主管部门的家庭农场资格认定证书或批文、市级示范家庭农场的证书或批文、工商部门营业执照等；（四）土地承包、流转合同或承包经营权证书；（五）家庭农场资产负债表；（六）其他优秀或先进的证明材料。第六条 '
               '省级示范家庭农场实行家庭申报、逐级推荐、省级评定、定期监测、动态管理。市、县农业行政主管部门负责审查、推荐和监测工作，省农业厅负责评定管理工作。第七条 '
               '省级示范家庭农场每两年评定一次。由符合条件的县级示范家庭农场向所在县级农业行政主管部门提出申请，并提供相关资料。县级农村经营管理机构负责对申报材料的真实性进行审查，并择优推荐，将审查推荐意见及申报材料以正式文件上报市级农业行政主管部门。市级农业行政主管部门对县级推荐的示范家庭农场择优推荐，以正式文件报省农业厅。第八条 '
               '省农业厅组织农业、畜牧、果业、农机、农产品质量安全、农村经营管理等方面专业人员组成评审小组，对各市申报材料进行审核，形成省级示范家庭农场拟定名单，并通过陕西农业网向社会公示7天。经公示无异议的，由省农业厅命名为&amp;ldquo;陕西省示范家庭农场&amp;rdquo;，发文公布并颁发证书，列入陕西省示范家庭农场名录，纳入家庭农场扶持项目库。第九条 '
               '省级示范家庭农场实行动态监测管理制度。市级农业行政主管部门每年对辖区内省级示范家庭农场生产经营管理情况进行监测审查，并形成专门的监测报告，于当年6月底前报送省农业厅。省农业厅适时组织人员抽查。第十条 '
               '出现下列情况之一的，取消其省级示范家庭农场资格，收回证书，并向社会公布，且在3年内不得申报：（一）在申报、审核和监测过程中提供虚假材料或存在舞弊行为的。（二）生产经营水平下降、资不抵债破产，已达不到省级示范家庭农场标准的。（三）经营中存在违法行为，或发生重大农产品质量安全事故的。（四）监测不合格，或拒绝参加监测，或不按规定要求按时提供监测材料的。（五）发生其他严重问题的。第十一条 '
               '对因遭遇自然灾害等造成经营收入或生产规模骤降，难以达到省级示范家庭农场认定标准的,经市级农业行政主管部门综合评价后仍有恢复能力的，可予以保留一年省级示范家庭农场资格。第十二条 '
               '各市、县区应全面开展示范家庭农场创建活动，评定市、县级示范家庭农场，建立示范家庭农场名录，并纳入扶持项目库。第十三条 '
               '各级农业行政主管部门要为示范家庭农场发展创造条件，全面落实各项优惠扶持政策。凡适合家庭农场实施的农业项目要优先安排示范家庭农场承担，并通过财政奖补、项目扶持、贷款担保和贴息、政策性农业保险等方式支持示范家庭农场发展，充分发挥其示范带动作用。第十四条 '
               '本办法由省农业厅负责解释。第十五条 本办法自2017年1月20日起施行，止2022年1月20日。\xa0附件.doc\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅印发《陕西省家庭农场资格认定办法》和《陕西省示范家庭农场评定及监测办法》的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅文件',
 'art_date': '2017-02-08 14:51:10',
 'art_detail': '\n'
               '         '
               '陕西稼丰农资集团有限责任公司2014年9月5日经省农业厅批准取得《农作物种子经营许可证》〔证号：B（陕）农种经许字（2014）第0021号〕，许可有效期至2019年9月4日。现该企业转型不再从事农作物种子生产经营工作。根据《种子法》及《农作物种子生产经营许可管理办法》的有关规定，省农业厅决定对陕西稼丰农资集团有限责任公司的农作物种子经营许可证予以注销，从通告发布之日起，该公司不再具有农作物种子经营资格。\r\n'
               '特此通告。\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\r\n'
               '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年1月24日\r\n'
               '\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于注销陕西稼丰农资集团有限责任公司农作物种子经营许可证的通告'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅办公室文件',
 'art_date': '2017-02-28 14:59:24',
 'art_detail': '\n'
               '         '
               '陕农业办发〔2017〕17号各设区市农业、畜牧局，杨凌示范区农业局，韩城市农林局，厅机关各有关处（室、局）、厅属有关单位：2月8日，省审改办印发了《关于做好〈国务院关于第三批取消中央指定地方实施行政许可事项和第三批清理规范国务院部门行政审批中介服务事项承接落实工作〉的通知》（陕审改办发〔2017〕2号，以下简称《通知》），《通知》涉及农业部门4项取消中央指定地方实施行政许可事项和2项清理规范行政审批中介服务事项（详见附件）。请各单位按照《通知》要求，根据属地管理和行业负责的原则，逐项制定行政审批事项取消后续监管和衔接措施，确保取消和清理的事项不再在省级进行初审，确保取消和清理事项所涉及的行业和领域管理有序，确保各项工作无缝衔接、平稳过渡。附件：1. '
               '国务院决定第三批取消中央指定地方实施的行政许可事项目录（涉及省农业厅部分）\xa0\xa0\xa0\xa0\xa0 2. '
               '第三批清理规范国务院部门行政审批中介服务事项目录（涉及省农业厅部分）\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅办公室\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年2月17日附件.doc\xa0\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅办公室关于贯彻落实第三批取消中央指定地方实施行政许可事项和第三批清理规范国务院部门行政审批中介服务事项工作的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅函',
 'art_date': '2017-02-28 14:47:35',
 'art_detail': '\n'
               '         '
               '陕农业函〔2017〕61号各设区市农业、畜牧、果业局（委），杨凌示范区农业局，韩城市农林局，厅属有关单位：根据农业部农产品质量安全中心《关于开展2017年无公害农产品和地理标志农产品标志使用专项检查的通知》（农质安函〔2017〕25号）文要求，我厅决定于&amp;ldquo;3.15国际消费者权益日&amp;rdquo;期间在全省范围内组织开展无公害农产品和地理标志农产品标志使用专项检查，现就有关事项通知如下：一、检查内容及重点（一）检查内容：依法开展无公害农产品和地理标志农产品标志使用情况检查，集中查处违法违规使用无公害农产品和地理标志农产品标志、证书的行为。（二）无公害农产品检查重点：用标产品与无公害农产品标志信息是否相符，用标产品与无公害农产品证书信息是否相符，用标产品是否在证书有效期内，是否存在转让、买卖无公害农产品证书和标志的行为，是否存在伪造、冒用无公害农产品标志行为。（三）农产品地理标志检查重点：登记证书持有人授权使用标志情况，标志使用人信息录入&amp;ldquo;农产品地理标志管理系统&amp;rdquo;情况，标志使用人实际标志使用情况，是否存在超范围使用标志行为，是否存在伪造、冒用标志和证书行为。二、工作要求（一）各市（区）农业行政主管部门要组织专门力量，深入开展标志使用专项检查。对检查中发现的问题，要认真核实，留存证据，视不同情况依照相关程序予以处理。请省优质农产品开发服务中心、省畜牧技术推广总站根据各自行业及分管业务做好抽查工作。（二）各市（区）农业行政主管部门及省优质农产品开发服务中心、省畜牧技术推广总站要以此次活动为契机，集中开展无公害农产品和农产品地理标志宣传活动，全面提升无公害农产品和农产品地理标志的公信力和美誉度，强化获证单位依法用标意识，引导广大消费者和市场经营主体正确识别、选购，为无公害农产品和农产品地理标志生产、消费营造良好的市场氛围。（三）各市（区）农业行政主管部门、省优质农产品开发服务中心、省畜牧技术推广总站要通过此次标志专项检查，全面掌握本地区、本行业无公害农产品和地理标志农产品标志使用现状，系统梳理在标志使用和管理中存在的问题和难点，研究提出科学对策，不断完善标志管理制度机制。三、时间安排请各工作机构于3月1日至3月27日期间，组织开展本地区、本行业标志使用专项检查，每个市（区）组织开展批发市场、农贸市场或超市现场检查不少于10家，在检查中发现用标问题的应提供清晰的证明照片，并于4月1日前将专项检查情况总结报送省农业厅农产品质量安全监管局，并抄报省优质农产品开发服务中心。其中，无公害农产品标志专项检查总结、及农产品地理标志专项检查总结及2017年度无公害农产品标志使用专项检查统计表（附件1）、2017年度地理标志农产品标志使用专项检查统计表（附件2）、农产品地理标志授权使用情况统计表（附件3）请报送省优质农产品开发服务中心。相关表格请登录陕西农业网（www.sxny.gov.cn）下载。请省优质农产品开发服务中心将专项检查情况汇总后于4月9日前报厅农产品质量安全监管局。存在违法、违规用标问题的需要提供清晰图片或相关证据。本次标志使用专项检查活动期间，省厅将适时派人对部分市（区）进行跟踪检查，并对相关结果予以通报。在标志使用专项检查工作中有什么意见和建议，请及时与省厅农产品的质量安全监管局及省优质农产品开发服务中心、省畜牧技术推广总站联系联系。省农业厅农产品质量安全监管局联系人：陈瑶，电话：029-87349060省优质农产品开发服务中心联系人：蔡黎明，电话：029-86262751。赵坤，电话：029-86361557省畜牧技术推广总站联系人：李思峰，电话：029-86269956附件：1.2017年度无公害农产品标志使用专项检查统计表\xa0\xa0\xa0\xa0\xa0 '
               '2. 2017年度地理标志农产品标志使用专项检查统计表\xa0\xa0\xa0\xa0\xa0 '
               '3.农产品地理标志授权使用情况统计表\xa0\xa0\xa0\xa0 '
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年2月28日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于开展无公害农产品和地理标志农产品标志使用专项检查的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅其他文件',
 'art_date': '2017-02-15 17:28:54',
 'art_detail': '\n'
               '         '
               '驻陕农纪发〔2017〕1号各室：现将《中共陕西省纪委驻省农业厅纪检组工作制度（试行）》印发给你们，请认真贯彻执行。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '中共陕西省纪委\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '驻省农业厅纪律检查组\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0'
               '2017年2月10日中共陕西省纪委驻省农业厅纪检组工作制度（试行）第一章 总 则第一条 '
               '根据中央纪委《中国共产党纪律检查机关监督执纪工作规则（试行）》，结合工作实际，制定本工作制度。第二条 '
               '监督执纪坚持依规治党、依规执纪，把监督执纪权力关进制度的笼子，落实打铁还需自身硬的要求，建设忠诚干净担当的纪检干部队伍。第三条 '
               '驻省农业厅纪检组（简称纪检组）由省纪委直接领导，协助、配合省纪委职能部门履行相关职责。第四条 '
               '纪检组履行对省农业厅、省扶贫开发办公室、省供销合作总社（简称综合监督单位）党组及其下属单位各级党组织和党员领导干部的监督职责，监督重点是综合监督单位领导班子和处级干部。第二章 '
               '会 议第五条 坚持民主集中制，重大事项、重要工作及问题线索处置执行中的重要问题，应当经集体研究决定。第六条 '
               '纪检组实行组务会议、组长办公会议、专题会议制度。第七条 '
               '组务会议由组长或组长委托副组长召集和主持，纪检组全体人员参加。主要内容是：（一）学习传达和贯彻落实上级党委、纪委有关党风廉政建设的重要决策部署、重要会议精神，研究制定贯彻落实的具体意见和措施；（二）研究部署推动综合监督单位党风廉政建设的重点工作、重要事项和重要安排；（三）研究制定加强自身建设的具体意见和措施；（四）需要研究的其它事项。第八条 '
               '组务会议至少每月召开一次，也可根据工作需要召开。第九条 '
               '组长办公会议由组长召集主持，副组长和具体承办人员参加，主要内容是：（一）研究、决定对问题线索进行调查、初步核实及立案审查；（二）审议、审核纪律审查报告；（三）研究其它重要事项。第十条 '
               '专题会议由组长或分管副组长主持召开，有关人员参加，对综合监督工作中的有关问题进行专题研究。第十一条 '
               '会议指定专人、专用记录本记录，记录必须做到准确、完整，重要会议应形成会议纪要。第三章 线索管理第十二条 '
               '纪检组受理综合监督单位党组及其管理的党组织和党员干部违反党纪的信访举报线索，接收综合监督单位机关纪委报送的处及处以上干部的信访举报线索及科以下干部重大问题线索。统一受理巡视工作机构和审计机关、行政执法机关、司法机关等单位移交的相关问题线索。第十三条 '
               '涉及综合监督单位党组、省管干部的信访举报线索，经纪检组长批阅后按规定上报省纪委信访室；不属本部门受理范围的，经分管副组长审批后按程序转交相关监督执纪部门。第十四条 '
               '纪检信访举报材料统一由专人接收并进行登记，填写信访问题线索处置呈批表，附信访件原件送分管副组长提出拟处置意见后，送纪检组长批阅。第十五条 '
               '按纪检组长批示，及时将信访件或问题线索摘要送承办人办理或转交有关部门办理。涉及多部门承办的信访举报件，应分类摘要后移送相关部门办理。第十六条 '
               '承办人办理完结后，应当做好问题线索处置材料归档工作，建立档案目录，装订成完整档案，交档案管理人员存档。第十七条 '
               '问题线索的管理处置各环节均须由承办人或经手人签名，全程登记备查。第十八条 '
               '严格信访举报内容的保密工作，不准泄露举报人个人信息和检举内容，严禁将举报材料转给被举报单位或被举报人。第十九条 '
               '纪检组根据工作需要，定期召开专题会议，听取问题线索处置综合情况汇报，加强对一个时期内重点对象、热点问题的汇总分析，对重要检举事项和反映问题集中的领域深入研究，作出科学判断，提出处置要求，为领导决策和纪律审查服务。第四章 '
               '谈话函询第二十条 采取谈话函询方式处置问题线索，应当按程序报批，由分管副组长提出拟谈话函询的意见，报纪检组长批准。第二十一条 '
               '谈话由纪检组长或分管副组长进行，可以由被谈话人所在党组织或纪委主要负责人陪同；经批准也可以委托被谈话人所在党组（党委）主要负责人进行。第二十二条 '
               '谈话过程应当形成工作记录，谈话后可视情况由被谈话人写出书面说明。谈话时，谈话人不得少于两人，并填写谈话函询登记表，谈话后需经被谈话人签字确认。第二十三条 '
               '函询应当以纪检组名义发函给被反映人，并抄送其所在单位党组织主要负责人。被函询人应当在收到函件后十五个工作日内写出书面说明材料，由其所在党组织主要负责人签署意见后发函回复。被函询人为党组织主要负责人的，或者被函询人所作说明涉及党组织主要负责人的，应当直接回复发函纪检组。第二十四条 '
               '谈话函询应当在谈话结束或者收到函询回复后三十日内办结，根据不同情形作出相应处理：（一）反映不实，或者没有证据证明存在问题的，予以了结澄清；（二）问题轻微，不需要追究党纪责任的，采取谈话提醒、批评教育、责令检查、诫勉谈话等方式处理；（三）反映问题比较具体，但被反映人予以否认，或者说明存在明显问题的，应当再次谈话函询或者进行初步核实。第二十五条 '
               '谈话函询材料应当整理归档。第五章 初步核实第二十六条 '
               '采取初步核实方式处置问题线索，由分管副组长提出意见，经组长办会会议研究同意，在纪检组长签字批准后实施。第二十七条 '
               '初步核实应明确专人负责，成立核查组，核查组成员不少于两人。第二十八条 '
               '初步核实工作结束后，核查组应当撰写初核情况报告，由核查组全体人员签名备查。第二十九条 '
               '初核情况报告需经组长办公会议研究、纪检组长审批，必要时向综合监督单位党组主要负责人通报。第六章 立案审查第三十条 '
               '经过初步核实，对存在严重违纪需要追究党纪责任的，应当立案审查。凡报请批准立案的，应当已经掌握部分违纪事实和证据，具备进行审查的条件。第三十一条 '
               '对符合立案条件的，应明确审查组成员，起草立案审查呈批报告，经组长办公会议研究同意、纪检组长审批签字后，予以立案审查。在决定立案前，应征求综合监督单位党组主要负责人的意见，经省纪委批准，也可以立案后予以通报。第三十二条 '
               '决定立案审查后，由纪检组长或副组长与被审查人谈话，宣布立案决定，讲明党的政策和纪律，要求被审查人端正态度、配合调查。第三十三条 '
               '外查工作必须严格按照外查方案执行，不得随意扩大调查范围、变更调查对象和事项，重要事项应当及时请示报告。外查工作期间，执纪人员不得个人单独接触任何涉案人员及其特定关系人，不得擅自采取调查措施，不得从事与外查事项无关的活动。第三十四条 '
               '查明违纪事实后，审查组应当撰写违纪事实材料，与被审查人见面，听取意见。要求被审查人在违纪事实材料上签署意见，对签署不同意见或者拒不签署意见的，审查组应当作出说明或者注明情况。第三十五条 '
               '审查工作结束后，审查组应形成审查报告，由审查组组长及成员签名。对执纪审查过程中发现的其他重要问题和意见建议，应当形成专题报告。第三十六条 '
               '审查报告、专题报告、个人检查材料、违纪事实材料等，应当经组长办公会议研究、纪检组长审批签字后，连同全部证据和程序材料，依照规定移送审理。第三十七条 '
               '审查组对审查全过程形成的材料应当案结卷成、事毕归档。第三十八条 '
               '审查时间不得超过九十日。在特殊情况下，经省纪委批准，可以延长一次，延长时间不得超过九十日。第七章 文件管理第三十九条 '
               '组室领导参加重要会议后五个工作日内应写出汇报提纲，并附重要会议文件资料送分管副组长阅后提出拟办意见，再呈组长阅批后送承办人办理或组内人员传阅。第四十条 '
               '机要文件承办借阅要履行签字手续，明确责任，确保文件安全。第四十一条 '
               '文件承办完毕后，将原文件和会议材料及承办结果交文件管理人员归档。第四十二条 未按期办结的，文件管理人员要及时催办。第四十三条 '
               '发文办理包括拟稿、核稿、审核、会签、签发、编号登记、校对印制、签章、分发、归档等程序。第四十四条 '
               '发文要严格按公文要求进行分类编号。（一）印发制度规定、安排部署工作、转发上级机关公文、对下级机关布置工作和有关事项等，以驻陕农纪发编号。（二）同级机关之间商洽工作、询问和答复问题，向无隶属关系的有关主管部门商请有关事项等，以驻陕农纪函编号。（三）用于向上级机关报告工作、请示问题、反映情况、提出建议，答复上级机关的询问或要求，以驻陕农纪字编号。第四十五条 '
               '公文办理按纪检组长或副组长批示意见，指定专人起草，一般性函件由分管副组长签发；文件、报告及其他重要文件、函件，由分管副组长审核，纪检组长签发。第八章 '
               '信息报送第四十六条 及时、准确、全面地向有关新闻媒体网站反映纪检组工作动态、工作特点，新思路、新举措、新经验。第四十七条 '
               '承办人对承办工作中的新闻亮点及时撰写新闻信息稿件，经分管副组长审核、纪检组长审定后向有关新闻媒体网站及上级纪委、综合监督单位内部交流材料投稿。第四十八条 '
               '信息报送列入年度考核内容。第九章 印章管理第四十九条 '
               '印章由专人保管、使用。印章管理人员因休假、请假等原因不在岗时，由分管副组长指定其他人员管理。第五十条 '
               '用印须经纪检组长或副组长批准签字。组领导外出等紧急情况需要用印的，需电话请示后方可用印，事后及时办理补签手续。第五十一条 '
               '不准在空白纸上加盖公章，特殊情况需要提供印模的，经纪检组长批准后方可使用，用完后印模及时销毁。第五十二条 '
               '因印章管理人员工作疏忽，造成印章被乱盖、遗失或印章管理人员违规用印的，严肃追究责任。第十章 保密工作第五十三条 '
               '严格遵守保密法规和省纪委、省监察厅保密工作制度，增强保密观念。第五十四条 '
               '对中纪委监察部、省纪委监察厅及有关部门下发的机密、秘密文件，实行专人、专柜保管，借阅要按规定登记。第五十五条 '
               '严格按照有关保密规定登记、分发、传阅、承办、保管、归档、清退、销毁等。第十一章 请假休假第五十六条 '
               '认真执行公务员请假休假制度。第五十七条 '
               '临时外出办事的，须告知分管领导或本室同事。请假超过半天的需履行请假手续，副组长向组长请假，其他人员向分管副组长请假。副组长连续请假五天以上的，按规定向省纪委组织部报备，其他人员连续请假三天以上的需经纪检组长批准。第五十八条 '
               '副组长出差需经组长批准，其他人员出差由分管副组长批准，连续出差五日以上的需经纪检组长批准。第五十九条 '
               '不遵守工作纪律，迟到、早退、擅自离岗的，对其进行批评教育；造成不良影响的，年度考核不能评为称职以上等次；旷工或者因公外出、请假期满无正当理由逾期不归连续超过十五天，或者一年内累计超过三十天的，按《公务员法》规定处理。第六十条 '
               '认真执行《职工带薪年休假条例》，保证工作人员正常休假。为了不影响工作，公休假时间较长的应分段休假，因工作需要占用节假日的，可申请补休。第十二章 '
               '财务管理第六十一条 认真执行省财政厅、驻在部门财务管理各项规定。第六十二条 '
               '政府统一采购物品，由各室按规定制定计划，报账员汇总，经组务会议研究后上报省农业厅计划财务部门，经财政厅审批后统一采购。购买一般办公用品，由各室根据需要交报账员统一采购。第六十三条 '
               '单张票据报销费用在五千元以下的由分管副组长审签后报销；五千元以上的由分管副组长审核、纪检组长签字报销。由副组长经手，单张票据报销费用在五千元以下的，由另一名副组长签字报销；五千元以上的由另一名副组长审核，纪检组长签字报销。第六十四条 '
               '固定资产由专人负责登记管理，建立固定资产台帐，已到报废年限不能使用的固定资产，要及时联系相关部门报废核销。固定资产使用须签名登记，使用后应及时归还保管人。第十三章 '
               '附 则第六十五条 '
               '违反本制度规定，情节较轻的，由纪检组提出批评或责成本人做出检查；情节严重，违反相关纪律规定的，依纪依规严肃追究相关责任。第六十六条 '
               '本制度自下发之日起施行。\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '关于印发《中共陕西省纪委驻省农业厅纪检组工作制度（试行）》的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-02-07 09:34:39',
 'art_detail': '\n'
               '         '
               '陕农业人事〔2017〕2号厅机关各处（室、局）、厅属各单位：根据《党政领导干部选拔任用工作条例》有关规定，经省农业厅研究决定，免去：白永太同志省农业规划研究院副院长（正处级）职务，退休。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0'
               '2017年1月5日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于白永太同志免职退休的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-03-03 17:33:27',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕11号各设区市农业局（委）、财政局，杨凌示范区农业局、财政局，韩城市农林局、财政局：根据《财政部关于提前下达2017年部分农业专项转移支付预算的通知》（财农〔2016〕222号）精神，结合我省农村土地承包经营权确权登记颁证（以下简称&amp;ldquo;确权登记颁证&amp;rdquo;）工作进展及资金拨付情况，现将确权登记颁证补助资金计划下达你们（详见附件），并就有关事项通知如下：一、此次下达的确权登记颁证补助资金计划是以市（区）（包含省财政管县）应确权登记颁证面积为基数，按照每亩10元补助标准计算，扣除前期已拨付的补助资金，核算拨付剩余资金计划。二、各市（区）农业主管部门要根据此次下达的资金计划，结合辖区内各县（区、市及开发区、高新区等）确权登记颁证工作完成情况，进行分解下达。三、因确权登记颁证补助资金基数由2013年&amp;ldquo;国土二调&amp;rdquo;面积调整为应确权登记颁证面积，各市（区）辖区内县域（含省财政管县）之间形成的差额，由各市（区）农业主管部门按各县（区）实际进行统筹测算分配。四、确权登记颁证补助资金主要用于查田勘界、表册印制、数据库建立、遗留问题化解等与农村土地承包经营权确权登记颁证有关的费用支出，不得用于增加工作人员和机构运转等与确权登记颁证无关的费用支出。五、各市（区）农业、财政部门要做好确权登记颁证补助资金的管理和监督，对项目实施中出现的问题要及时反映和协调，督促做好项目实施工作，按时完成任务；接此通知后，农业部门需会同财政部门尽快拿出资金安排计划，与30个工作日内将资金拨付到位，并加强对资金使用情况的检查和监督，防止资金滞留、挤占和挪用。六、各项目实施单位要将项目完成和资金使用情况于2017年12月底前以书面形式报省农业厅和省财政厅，省农业厅将会同省财政厅对项目完成情况和资金使用情况进行专项检查。附件：1. '
               '农村土地承包经营权确权登记颁证补助资金计划表\xa0\xa0\xa0\xa0\xa0 2. '
               '农村农村土地承包经营权确权登记颁证省财政直管县已拨付补助资金一览表 '
               '附件.docx\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅 '
               '陕西省财政厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年2月27日\xa0\n'
               '        ',
 'art_source': '厅发展计划处',
 'art_title': '陕西省农业厅  陕西省财政厅关于下达农村土地承包经营权确权登记颁证补助资金计划的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅人事文件',
 'art_date': '2017-02-07 09:35:48',
 'art_detail': '\n'
               '         '
               '陕农业人事〔2017〕3号厅机关各处（室、局）、厅属各单位：根据《党政领导干部选拔任用工作条例》有关规定，下列同志任职试用期满，考核合格，经省农业厅2016年12月30日研究决定，任命：伍明祥为厅政策与法规处副处长；吴粉娥为省果业管理局办公室副主任。以上同志任职时间从试用期任职时间算起。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年1月5日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于伍明祥等同志试用期满正式任职的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:21:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'art_category': '省农业厅计财文件',
 'art_date': '2017-02-24 14:43:43',
 'art_detail': '\n'
               '         '
               '陕农业计财〔2017〕10号各设区市农业、畜牧局（委），杨凌示范区农业局，韩城市农林局，厅机关有关处（室、局）、厅属有关单位：按照农业部办公厅《关于印发2017农业国际交流合作项目任务指南的通知》（农办财[2017]6号）要求，为做好我省2017年农业国际交流合作项目申报工作，现就有关事项通知如下：一、各市（区）农业主管部门要按照农业部农业国际交流合作项目任务指南，结合当地实际情况，组织本地区符合相关资质和条件的单位按时申报，并对所报项目进行公示、审核、论证，确保申报项目工作公开、公正。省管县、地方企业、高校和科研机构按照属地管理原则由属地农业主管部门归口申报。二、项目申报按照公开、自下而上、逐级编报的原则，由符合资质和条件的单位按照指南要求，逐级申报，各级主管部门不得代编代报。三、申报单位要按照指南要求,明确项目预期成果及绩效目标，测算所需资金，制定项目实施方案。项目资金不得开支工资福利、物业管理费用，不得开支除农业技术试验示范推广专用设备以外的其他固定资产购置费用，不得开支与实施项目无关的费用。四、项目申报的具体条件、要求及申报材料格式请查看农业部2017年农业国际交流合作项目任务指南（网址http://www.moa.gov.cn）。五、2月28日前，各市（区）农业主管部门统一以计财字号文件将申报材料一式3份报送省农业厅，并抄送厅发展计划与财务处和厅办公室各1份。逾期未报的将视为弃权。\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '陕西省农业厅\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
               '2017年2月23日\n'
               '        ',
 'art_source': '陕西省农业厅',
 'art_title': '陕西省农业厅关于申报2017年农业国际交流合作项目的通知'}}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 73, in process_item
    data_item['art_detail'], '', data_item['art_category'],'',data_item['art_appendix'])
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'art_appendix'
2019-06-10 17:46:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 64, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-10 17:47:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 64, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-10 17:48:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 65, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-10 17:53:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 65, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-10 18:02:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 68, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
2019-06-10 18:14:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nyt.shaanxi.gov.cn//www/snytqtwj4471/20170929/9630139.html> (referer: http://nyt.shaanxi.gov.cn/www/stwj1187/index_5.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Sxnynct_Stwj_Article_Spider.py", line 61, in parse_article
    if not source.strip():
AttributeError: 'NoneType' object has no attribute 'strip'
