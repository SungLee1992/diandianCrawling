2019-05-31 19:32:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16517.html',
 'pub_address': '全国',
 'pub_time': '2019-01-21',
 'pub_title': None,
 'pur_address': '',
 'pur_num': '3万斤',
 'pur_require': '需求数量3万斤,价格全国,长期有效,,',
 'pur_user': '杨志勇'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "d:\code\python3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Code\workspace\Pyspace\diandianCrawling\crawling\crawling\pipelines.py", line 44, in process_item
    print(item["type"] + "-" * 20+item["result_item"]["pub_title"])
TypeError: can only concatenate str (not "NoneType") to str
2019-05-31 19:37:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16574.html',
 'pub_address': '全国',
 'pub_time': '2019-03-23',
 'pub_title': None,
 'pur_address': '',
 'pur_num': '44595',
 'pur_require': '需求数量44595,价格全国,长期有效,,',
 'pur_user': '刘灿'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "d:\code\python3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Code\workspace\Pyspace\diandianCrawling\crawling\crawling\pipelines.py", line 44, in process_item
    print(item["type"] + "-" * 20+item["result_item"]["pub_title"])
TypeError: can only concatenate str (not "NoneType") to str
2019-05-31 19:37:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16535.html',
 'pub_address': '全国',
 'pub_time': '2019-02-21',
 'pub_title': None,
 'pur_address': '',
 'pur_num': '全国',
 'pur_require': '需求数量全国,价格长期有效,,,',
 'pur_user': '刘灿'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "d:\code\python3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Code\workspace\Pyspace\diandianCrawling\crawling\crawling\pipelines.py", line 44, in process_item
    print(item["type"] + "-" * 20+item["result_item"]["pub_title"])
TypeError: can only concatenate str (not "NoneType") to str
2019-05-31 19:37:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16606.html',
 'pub_address': '广东省东莞市',
 'pub_time': '2019-04-20',
 'pub_title': None,
 'pur_address': '',
 'pur_num': '1000',
 'pur_require': '需求数量1000,价格广东省东莞市,长期有效,,',
 'pur_user': '李哲轩'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "d:\code\python3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Code\workspace\Pyspace\diandianCrawling\crawling\crawling\pipelines.py", line 44, in process_item
    print(item["type"] + "-" * 20+item["result_item"]["pub_title"])
TypeError: can only concatenate str (not "NoneType") to str
2019-05-31 19:37:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16517.html',
 'pub_address': '全国',
 'pub_time': '2019-01-21',
 'pub_title': None,
 'pur_address': '',
 'pur_num': '3万斤',
 'pur_require': '需求数量3万斤,价格全国,长期有效,,',
 'pur_user': '杨志勇'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "d:\code\python3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Code\workspace\Pyspace\diandianCrawling\crawling\crawling\pipelines.py", line 44, in process_item
    print(item["type"] + "-" * 20+item["result_item"]["pub_title"])
TypeError: can only concatenate str (not "NoneType") to str
2019-06-02 22:41:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168185> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168186> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168187> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168188> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165984> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166923> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167644> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168151> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158381> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158576> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158659> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158760> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158830> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:41:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=159779> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=160928> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165085> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165124> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165126> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165372> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165934> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166016> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166051> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166675> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167311> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167415> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167848> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168184> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168204> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168207> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168208> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168209> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168210> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168211> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168201> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168203> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168197> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168198> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168199> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168200> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168049> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168051> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168115> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168009> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:42:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168018> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//")
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-02 22:44:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168184> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168185> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168186> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168187> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168188> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165984> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166923> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167644> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168151> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158381> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158576> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158659> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158760> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158830> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=160928> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165085> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165124> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165126> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165372> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165934> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166016> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166051> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166675> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167925> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167945> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167963> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167964> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168020> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168044> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168091> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168092> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168093> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168097> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168103> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168124> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168133> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168134> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168136> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168155> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168159> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168219> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168222> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168225> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167311> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167415> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167848> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168204> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168207> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168208> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168209> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168210> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167531> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167626> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167777> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167841> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167842> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167878> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167879> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167941> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168007> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168037> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168081> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168104> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168105> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168117> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168123> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168130> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168132> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168154> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168156> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168213> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=162050> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163540> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164300> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164508> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166044> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166500> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166817> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:44:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166821> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166874> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=160860> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=161471> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=161762> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=162023> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=162045> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166929> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167294> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167341> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167623> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167624> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=162949> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168051> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168115> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168137> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168191> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168193> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168195> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168197> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168198> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168199> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168009> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168018> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168022> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168039> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168042> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168200> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168201> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168202> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168203> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168049> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168047> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167351> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167478> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167480> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167567> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167589> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167638> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167639> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167640> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167641> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167350> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167792> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167802> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167846> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167930> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167967> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167968> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167981> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167432> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167449> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167476> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167755> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167817> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167893> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167894> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167895> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168026> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168040> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168041> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168043> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168108> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168125> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168129> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168145> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168146> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168170> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168220> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167766> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167815> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167804> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167776> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164225> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166814> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167005> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167150> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167169> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167215> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167216> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167229> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167427> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=161136> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167664> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167716> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167847> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167849> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168221> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=161643> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166050> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=162467> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164737> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=159779> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=162466> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 22:45:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168211> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
    item['sup_description'] = content.xpath(".//p[1]").extract_first()
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 23:09:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168209> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168210> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168211> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168186> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:09:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(type(content.xpath(".//p[1]//text()")).extract_first())
TypeError: get() missing 1 required positional argument: 'self'
2019-06-02 23:14:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168186> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 90, in parse_detail
    item['sup_user'] = content.xpath(".//text()[3]")
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 23:14:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168187> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 90, in parse_detail
    item['sup_user'] = content.xpath(".//text()[3]")
AttributeError: 'str' object has no attribute 'xpath'
2019-06-02 23:43:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167641> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167792> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167802> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167846> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167930> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167967> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167968> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167350> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168184> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168185> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168186> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168187> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168188> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:43:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168204> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    for i in range(1,len(item)):
TypeError: object of type 'Selector' has no len()
2019-06-02 23:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168210> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168211> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:45:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if item.extract_first()!="":
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168207> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168208> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168209> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168210> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168211> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:47:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167531> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167626> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167777> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167841> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167350> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167351> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167432> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167449> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167476> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167478> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167480> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167567> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167589> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167638> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167639> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167640> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167641> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167792> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:53:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167802> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    print(item.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-02 23:56:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165934> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166016> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166051> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:56:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166675> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:56:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167311> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:56:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167415> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:58:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:58:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168204> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:58:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168207> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:58:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168208> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:58:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168209> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-02 23:58:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168210> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    print(content_item['info_from'])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
TypeError: list indices must be integers or slices, not str
2019-06-03 00:01:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168222> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract_first
2019-06-03 00:01:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168225> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract_first
2019-06-03 00:01:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168133> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract_first
2019-06-03 00:01:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168134> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract_first
2019-06-03 00:01:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168136> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract_first
2019-06-03 00:01:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168155> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract_first())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract_first
2019-06-03 00:01:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168209> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168210> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168211> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168184> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:01:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    print(item.extract())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/item.py", line 74, in __getattr__
    raise AttributeError(name)
AttributeError: extract
2019-06-03 00:03:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168204> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168207> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168208> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168209> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165984> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167644> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168151> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158381> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158576> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167925> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167945> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167963> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167964> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168020> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168044> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168091> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168092> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168093> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168097> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168103> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168133> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168134> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:04:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168136> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:04:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168155> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:04:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168219> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:04:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168222> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:04:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168225> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content(content_item))
TypeError: 'SelectorList' object is not callable
2019-06-03 00:04:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158659> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content_item)
TypeError: 'SelectorList' object is not callable
2019-06-03 00:04:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=161136> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content_item)
TypeError: 'SelectorList' object is not callable
2019-06-03 00:04:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=161643> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    type(content_item)
TypeError: 'SelectorList' object is not callable
2019-06-03 11:07:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168288> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168289> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168290> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168291> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168296> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168305> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168306> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 11:07:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    print(type(content.xpath(".//string()")))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 22:59:48 [twisted] CRITICAL: Unhandled error in Deferred:
2019-06-03 22:59:48 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 13, in <module>
    import pymysql
ImportError: No module named 'pymysql'
2019-06-03 23:30:55 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168281',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分以上的红梅10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分以上的红梅10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:30:55 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168282',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径3-4公分以上的红枫10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径3-4公分以上的红枫10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:30:56 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168283',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径2-3公分的桂花10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径2-3公分的桂花10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:30:56 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168284',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的玉兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的玉兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:30:57 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168285',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5公分左右的红叶石兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5公分左右的红叶石兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:30:57 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168286',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的早樱10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的早樱10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:30:58 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168287',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分的嫁接红梅20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分的嫁接红梅20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:30:58 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:30:59 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:34:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168283',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径2-3公分的桂花10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径2-3公分的桂花10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:34:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168284',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的玉兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的玉兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:34:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168285',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5公分左右的红叶石兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5公分左右的红叶石兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:34:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168286',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的早樱10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的早樱10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:31 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168286',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的早樱10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的早樱10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:32 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168287',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分的嫁接红梅20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分的嫁接红梅20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:33 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168288',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-7公分的香花槐20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-7公分的香花槐20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:33 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168289',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高3米以上的油松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高3米以上的油松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:33 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168290',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高1米左右的白皮松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高1米左右的白皮松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:34 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-10-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168291',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售毛竹10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售毛竹10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:34 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168296',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '低价销售直径3-10厘米的樱花树',
 'sup_address': '周至县终南村',
 'sup_description': '低价销售直径3-10厘米的樱花树8亩左右，树形好，价格低，欢迎需求朋友联系。联系：陈女士电话：13119161886地址：周至县终南村',
 'sup_phone': '13119161886',
 'sup_user': '陈女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:35 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:35 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:36 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:36 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:37 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:37 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:38 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:38 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:39 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:39 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:40 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:40 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:41 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165873',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-04-19',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办事处王家湾村',
 'sup_description': '要求玉米颗粒饱满，无腐烂、无虫、无沙粒，有意出售的电话联系。',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:41 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=165984',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '求购红芋苗',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十三组',
 'sup_description': '求购秦薯四号红芋苗15000苗，有出售者请联系。',
 'sup_phone': '15109208586',
 'sup_user': '冯先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:42 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166662',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-30',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有数千斤大米，有合适的价格请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:42 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166923',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市汉台区发布时间：2019-04-04购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:42 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167237',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-14',
 'pub_title': '求购玉米',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '需要购买一批玉米，用作养殖场鸡饲料,电话联系！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:43 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167452',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-17',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米5000公斤，要求干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '15229382221',
 'sup_user': '谭先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:43 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167580',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米3000公斤，要求水份14%以内，干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '18706733154',
 'sup_user': '高先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:44 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167644',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '油菜籽',
 'sup_address': '陕西汉中',
 'sup_description': '大量新鲜油菜籽出售',
 'sup_phone': '18292654661',
 'sup_user': '丁女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:44 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168148',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '15891399228',
 'sup_user': '赵先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:45 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168151',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤.优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:45 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-03-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=158381',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-07',
 'pub_title': '求购野山药',
 'sup_address': '佛坪县陈家坝镇金星村二组',
 'sup_description': '求购野生山药，平均价格10元每斤，量大从优，',
 'sup_phone': '17730778050',
 'sup_user': '刘和秀'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:46 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-02-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=158659',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-11',
 'pub_title': '大量收购乌笋种子',
 'sup_address': '汉中市佛坪县',
 'sup_description': '大量收购乌笋种子，土名：洋嚯。联系电话：13991608711/13892652745',
 'sup_phone': '13991608711',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:47 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158760',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-12',
 'pub_title': '大量求购线辣椒',
 'sup_address': '西安市阎良区关山镇关山村',
 'sup_description': '大量收购线辣椒，红绿均可，价格面议，欢迎联系。',
 'sup_phone': '18392532698',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:47 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158830',
 'pub_address': '汉中市汉台区',
 'pub_time': '2018-12-13',
 'pub_title': '求购洋芋种',
 'sup_address': '汉中市汉台区七里办事处文庙村',
 'sup_description': '黄先生等户求购洋芋种；品种有；荷兰洋芋、早大白洋芋。有货源的客户快来村联系，价格面议，数量不限。联系人；黄先生，地址；汉中市汉台区七里办事处文庙村，电话；13084883593.文庙村信息站发。',
 'sup_phone': '13084883593',
 'sup_user': '黄先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:47 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=159779',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-29',
 'pub_title': '求购200克以上魔芋5000斤',
 'sup_address': '周至县厚畛子镇同力村',
 'sup_description': '求购200克以上魔芋5000斤联系人:黄先生电话：１３４７４１１０２７５地址：周至县厚畛子镇同力村。',
 'sup_phone': '13474110275',
 'sup_user': '黄先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:48 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-02-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=160928',
 'pub_address': '西安市户县',
 'pub_time': '2019-01-24',
 'pub_title': '求购大葱',
 'sup_address': '鄠邑区玉蝉镇新向村',
 'sup_description': '求购大葱100斤，欢迎联系。',
 'sup_phone': '15091671829',
 'sup_user': '王女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:48 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165085',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-08',
 'pub_title': '大量收购甘蓝菜',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购甘蓝菜，要求单重2斤以上，价格随行就市，欢迎联系销售。',
 'sup_phone': '15291452658',
 'sup_user': '刘先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:49 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165124',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜蒜苔',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜蒜苔，日收购5吨，限陕西西安境内，有意者请联系，价格面议。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:49 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165126',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜香椿',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜香椿芽，有意者请联系价格面议，限西安辖区内，',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:50 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=165372',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-11',
 'pub_title': '收购莲花白、螺丝辣椒',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购莲花白、螺丝辣椒，价格面议，欢迎广大菜农联系销售。',
 'sup_phone': '13474363373',
 'sup_user': '王女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:35:50 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:51 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168097',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售西瓜',
 'sup_address': '鄠邑区蒋村镇同兴村',
 'sup_description': '出售甜王西瓜，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15029807630',
 'sup_user': '陈先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:51 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168103',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售杏子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人出售可口香甜的杏子，价格4.5每斤，需求者请联系！',
 'sup_phone': '13892696179',
 'sup_user': '何先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:52 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168124',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '种植露天桃子，味道好，自然熟',
 'sup_address': '汉中市汉台区',
 'sup_description': '自家种植的桃子，口感有清脆和微软两种，味道有纯甜，微酸甜两种，现摘现送无化肥农药，真正绿色无污染，关键是味道好，味道好，味道好！价格面议，欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:52 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168133',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售丰园红杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售丰园红早熟杏，面积2.5亩，价格面议，欢迎联系。',
 'sup_phone': '17719535936',
 'sup_user': '崔先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:53 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168134',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售樱桃',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售樱桃，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15829462025',
 'sup_user': '崔先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:53 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168136',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售金太阳杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售金太阳杏，产量约2500斤，价格随行就市，欢迎联系。',
 'sup_phone': '15353714592',
 'sup_user': '张女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:54 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:54 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:55 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168219',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售大棚西瓜',
 'sup_address': '庆丰村9组',
 'sup_description': '1、汉台区老君镇庆丰村2组即将大量出售新鲜大棚西瓜，有意者请前来现场订购；2、地址：汉武路中段汉中市红旗机械厂对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:55 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168222',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应次杏子丰园红5000斤',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村供应次杏子丰园红5000斤，价钱面议。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:55 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售油桃',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售油桃，个大，味道不错。有意者请与张女士联系。',
 'sup_phone': '18717316979',
 'sup_user': '张女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:56 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '预售沙红桃',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村预售沙红桃，有意者前来订购。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:57 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168233',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应枣花蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应枣花蜜1000斤，一斤20元，价钱面议。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:57 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168234',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应洋槐蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应洋槐蜜1000斤，一斤20元。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:57 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168266',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '桃子',
 'sup_address': '陕西省汉中市汉台区老君镇徐家营村',
 'sup_description': '现有新鲜桃子5亩桃子属于老品种个头大小合适桃子味道浓甜汁多现在正是出售的季节有需要采摘的或者做生意的可以联系我自己下地采摘价格可以看完水果以后商量非诚勿扰谢谢!',
 'sup_phone': '13379360380',
 'sup_user': '张女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:58 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168292',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '供应金太阳杏1万斤',
 'sup_address': '周至县竹峪镇张龙村',
 'sup_description': '供应金太阳杏1万斤，价格电议。',
 'sup_phone': '18092043194',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:58 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=168301',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应阎良优质绿皮甜瓜',
 'sup_address': '西安市阎良区关山街道办界坊村西界组',
 'sup_description': '我家种植的绿皮甜瓜刚上市，单重1-1.5斤，香甜难忘，欢迎你品尝后购买。',
 'sup_phone': '18092295878',
 'sup_user': '郭大英'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:59 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168320',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '杏',
 'sup_address': '陕西省汉中市汉台区',
 'sup_description': '好吃的杏子，有想法联系啊',
 'sup_phone': '18829863123',
 'sup_user': '赵女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:35:59 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168322',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '咸阳甜杏',
 'sup_address': '陕西省汉中市陕西理工大学',
 'sup_description': '45一箱，包邮啊',
 'sup_phone': '18409168137',
 'sup_user': '王斌'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:00 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=165934',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '收购洋槐花',
 'sup_address': '周至县楼观镇团标村',
 'sup_description': '收购洋槐花，有意者电话联系。',
 'sup_phone': '15091527877',
 'sup_user': '谢女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:00 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=166016',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-21',
 'pub_title': '求购紫薯苗',
 'sup_address': '周至县尚村镇新范村',
 'sup_description': '求购紫薯苗两万个，可以电话报价，有货及时联系',
 'sup_phone': '13619226724',
 'sup_user': '孙先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:01 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=166051',
 'pub_address': '西安市户县',
 'pub_time': '2019-04-22',
 'pub_title': '求购小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '求购小葱秧200斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:01 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166675',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-30',
 'pub_title': '求购鲜洋槐花',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜洋槐花，数量不限，限西安境内，有意者请联系，量大可上门取货。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:02 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167311',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购葱秧',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购葱秧30公斤，品种不限，价格面议，欢迎联系。',
 'sup_phone': '18966810872',
 'sup_user': '杨先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:02 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-07-17',
 'info_from': 'http://222.90.83.241/show.aspx?id=167415',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-17',
 'pub_title': '求购藕种',
 'sup_address': '汉台区老君镇付庙村六组',
 'sup_description': '大量求购优质藕种！',
 'sup_phone': '13571611661',
 'sup_user': '张伟'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:03 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167848',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购大蒜5万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购大蒜5万斤，要求个大，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:04 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168275',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高60公分大田侧柏1.5万株',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：高60公分大田侧柏1.5万株，价格面议，欢迎联系。',
 'sup_phone': '15877344352',
 'sup_user': '李先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:04 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168276',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径1公分国槐3000棵',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：胸径1公分国槐3000棵，价格面议，欢迎联系。',
 'sup_phone': '13092046069',
 'sup_user': '何先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:04 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168277',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径15公分龙爪槐20棵',
 'sup_address': '周至县四屯镇联三村',
 'sup_description': '出售：胸径15公分龙爪槐20棵，价格面议，欢迎联系。',
 'sup_phone': '15091151300',
 'sup_user': '李先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:05 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=168278',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高80公分兰天竹营养钵3500株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：高80公分兰天竹营养钵3500株，价格面议，欢迎联系。',
 'sup_phone': '15319458368',
 'sup_user': '张女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:05 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168280',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售直径3公分左右的大叶女贞10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售直径3公分左右的大叶女贞10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:06 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168281',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分以上的红梅10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分以上的红梅10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:06 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168282',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径3-4公分以上的红枫10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径3-4公分以上的红枫10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:07 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168283',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径2-3公分的桂花10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径2-3公分的桂花10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:07 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168284',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的玉兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的玉兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:08 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:08 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=167478',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '土鸡',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡，有意者请与丁先生联系，电话：13689190503。',
 'sup_phone': '13689190503',
 'sup_user': '丁先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:09 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167480',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-18',
 'pub_title': '出售红皮鸡蛋',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售红皮鸡蛋65盘，每盘重约4斤，价格面议，欢迎联系。',
 'sup_phone': '15353526258',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:09 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167567',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-19',
 'pub_title': '高先生长期供应牛奶',
 'sup_address': '周至县尚村镇马村',
 'sup_description': '高先生长期供应牛奶，价格面议。',
 'sup_phone': '15809220930',
 'sup_user': '高先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:09 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167589',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '出售黑狗',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '出售黑色1岁拉布拉多犬1只，价格面议，欢迎联系。',
 'sup_phone': '17791427630',
 'sup_user': '刘先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:10 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167638',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售白鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤白鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:10 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=167639',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售花鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤花鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:11 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167640',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售草鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤草鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:11 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167641',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售鲤鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤鲤鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:12 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167792',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售三元仔猪',
 'sup_address': '鄠邑区玉蝉街办割耳庄村',
 'sup_description': '出售三元仔猪10头，每头体重15公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15229279068',
 'sup_user': '刘先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:12 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167802',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售鹅蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售鹅蛋50枚，价格面议，欢迎联系。',
 'sup_phone': '15229076911',
 'sup_user': '王女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:13 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167846',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '供应羊羔5只',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '供应羊羔5只，单只体重大约25―28公斤，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:13 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-08-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167930',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售草鱼',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售鲜活草鱼500余条，每条重3斤--7斤，欢迎联系。',
 'sup_phone': '13572072008',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:14 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=167967',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '新鲜鸡蛋出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村（工业园区）',
 'sup_description': '本人是养殖专业户，现长期对外出售新鲜鸡蛋，货真价实，量大从优，价格面议！',
 'sup_phone': '18691645043',
 'sup_user': '老徐'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:14 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167968',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '鲜牛奶对外出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村7组',
 'sup_description': '本人饲养奶牛数头，长期对外出售新鲜牛奶，5公里免费送货上门，欢迎订购！',
 'sup_phone': '14791618835',
 'sup_user': '廖宝友'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:15 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167981',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售三元生猪',
 'sup_address': '高新区秦渡镇南焦羊村',
 'sup_description': '出售三元生猪30头，单头体重130公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029033406',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:15 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168239',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售肉猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售三元肉猪50头，体重120公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15829108410',
 'sup_user': '肖女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:16 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168246',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:16 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168261',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '土鸡蛋',
 'sup_address': '汉中市汉台区七里街道办事处染房营村四组',
 'sup_description': '本人在果园有散养蛋鸡，蛋质优良，无毒无公害，真正的绿色产品，价格优惠，欢迎大家选购。',
 'sup_phone': '13992693136',
 'sup_user': '唐世义'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:17 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168311',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜的土鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:17 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168285',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5公分左右的红叶石兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5公分左右的红叶石兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:18 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=168305',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白蜡树',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有直径5公分白蜡树300棵，直径6公分白蜡树100棵，急于出售。欢迎电话联系。',
 'sup_phone': '13484667542',
 'sup_user': '闫兆'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:18 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-19',
 'info_from': 'http://222.90.83.241/show.aspx?id=168306',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白皮松',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有高度1米白皮松300棵，急于出售。欢迎电话联系。',
 'sup_phone': '13032916618',
 'sup_user': '刘展雄'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:20 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168304',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应西红柿',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '本人家有3亩温室西红柿成熟出售，货源、品质保证，价格面议，欢迎各地客商联系收购。',
 'sup_phone': '18092632479',
 'sup_user': '刘文'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:20 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168312',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '出售大蒜',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售红皮大蒜约400斤，价格面议，欢迎联系。',
 'sup_phone': '13571840519',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:21 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168041',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售芥兰',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售芥兰菜6000斤左右，价格面议，欢迎联系。',
 'sup_phone': '18192003238',
 'sup_user': '吴女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:21 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168043',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应西红柿',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应西红柿500斤。',
 'sup_phone': '15829468093',
 'sup_user': '刘女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:22 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168108',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应大蒜100斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '供应大蒜100斤.新蒜。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:22 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168293',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '大量出售架豆王',
 'sup_address': '西安市绿康果蔬苗木专业合作社',
 'sup_description': '出售架豆王60多亩，长度20-30厘米左右，质量好，价格低，欢迎联系。联系：蒲经理电话：13201689888地址：西安市绿康果蔬苗木专业合作社',
 'sup_phone': '13201689888',
 'sup_user': '蒲经理'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:23 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168129',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '供给优质土豆',
 'sup_address': '陕西省汉中市汉台区宗营镇下寨村三组',
 'sup_description': '自家种植一亩品种为早大白的土豆，现已成熟，大约有1500斤需将其出售。有意者请联系本人。',
 'sup_phone': '18829662083',
 'sup_user': '黄玉莲'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:23 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168145',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售韭菜600斤，价格面议，欢迎联系。',
 'sup_phone': '15902991386',
 'sup_user': '马先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:24 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168146',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售小葱秧800斤，价格面议，欢迎联系。',
 'sup_phone': '13772449091',
 'sup_user': '吴女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:24 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167804',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜出售',
 'sup_address': '新校村',
 'sup_description': '现有大量新鲜蔬菜出售，批发零售皆可，主要有辣椒，西红柿，豆角，西蓝花等若有需要的请和我联系。',
 'sup_phone': '15760959624',
 'sup_user': '李先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:25 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167815',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜',
 'sup_address': '汉台区铺镇锦福专业蔬菜合作社',
 'sup_description': '我村锦福蔬菜合作社现有:西葫芦、黄瓜、辣椒、茄子、西红柿对外批发出售；（可组织整车货源）欢迎新老客户前来订购！',
 'sup_phone': '13038477096',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:25 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=167817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-24',
 'pub_title': '魔芋出售',
 'sup_address': '陈家坝镇孔家湾村一组',
 'sup_description': '因土地用作它途，最近亟待出售一批魔芋，价格好商量！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:25 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167893',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菠菜',
 'sup_address': '鄠邑区渭丰镇定五村',
 'sup_description': '出售菠菜4000斤，价格面议，欢迎联系。',
 'sup_phone': '18710978332',
 'sup_user': '赵女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:26 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-10-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167894',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘亭街办南羊村',
 'sup_description': '出售韭菜，面积10亩，价格面议，欢迎联系。',
 'sup_phone': '13572179512',
 'sup_user': '周女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:26 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167895',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售矮青菜',
 'sup_address': '鄠邑区渭丰镇定六村',
 'sup_description': '出售矮青菜3000斤，价格面议，欢迎联系。',
 'sup_phone': '13109617130',
 'sup_user': '赵女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:27 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-07-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168026',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '蔬菜出售',
 'sup_address': '老君镇拐拐村',
 'sup_description': '大量出售西红柿与黄瓜，各3000斤左右。欢迎选购。',
 'sup_phone': '18591612273',
 'sup_user': '秦小强'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:27 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168040',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应架豆王',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应架豆王300斤。',
 'sup_phone': '18092634616',
 'sup_user': '刘女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:28 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168170',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-30',
 'pub_title': '蒲瓜',
 'sup_address': '汉台区铺镇芦坝村一组',
 'sup_description': '我现有蒲瓜4000斤出售，批发价0.8元/每斤。',
 'sup_phone': '13630267456',
 'sup_user': '魏小民'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:28 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168220',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售新鲜大棚秀珍菇',
 'sup_address': '庆丰村1组',
 'sup_description': '1、汉台区老君镇庆丰村1组大量出售新鲜大棚秀珍菇，有意者请面议；2、地址：汉武路中段陕西省汇力园区对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:29 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168125',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '出售土豆，天然产出',
 'sup_address': '汉中市汉台区',
 'sup_description': '出售纯天然土豆，粉糯可口，个头匀称，表面光滑，现挖先发价格面议欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:30 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168197',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购国槐胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购国槐，胸径20至22公分，1.5米土球，数量689颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:31 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168198',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购广玉兰胸径18至20公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购广玉兰胸径18至20公分，1.5米土球，数量，365颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:32 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168199',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购法桐胸径15至17公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购法桐，胸径15至17公分，1.5米土球，数量804颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:32 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168200',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购桂花树胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购桂花树，胸径12至14公分，1.2米土球，数量1568颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:33 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168201',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购字画木槿地径5至7公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购字画木槿地径5至7公分，1米土球，数量1478颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:33 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168018',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购高5.0米以上的白皮松13棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高5.0米以上的白皮松13棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:34 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168022',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购胸径4公分的国槐50棵',
 'sup_address': '周至县翠峰镇农林村四组',
 'sup_description': '求购胸径4公分的国槐50棵。',
 'sup_phone': '15399480380',
 'sup_user': '侯女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:34 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168039',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径14公分银杏350棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径14公分银杏350棵，要求分支点2.8-3.5米，带土球90公分，有货的朋友请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:35 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168042',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径12公分香花槐200棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径12公分香花槐200棵，要求分支点2.8米以上，树杆端直，树冠优美，有货者请尽快联系，看货议价。',
 'sup_phone': '18229025186',
 'sup_user': '毛先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:35 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-02-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=161136',
 'pub_address': '西安市周至县',
 'pub_time': '2019-01-30',
 'pub_title': '求购80-120克秦美猕猴桃30000斤',
 'sup_address': '周至县四屯镇三联村中二屯',
 'sup_description': '求购80-120克库存秦美猕猴桃30000斤，有出售者请联系。',
 'sup_phone': '13572903928',
 'sup_user': '薛智军'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:36 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-03-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=161643',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-17',
 'pub_title': '求购霉烂猕猴桃',
 'sup_address': '周至县二曲镇孟家村',
 'sup_description': '大量求购霉烂猕猴桃。价格面议。',
 'sup_phone': '13659209629',
 'sup_user': '郝先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:36 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-03-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=162466',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-26',
 'pub_title': '求购徐香猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '求购带把徐香猕猴桃200000斤，看货谈价。',
 'sup_phone': '13572526437',
 'sup_user': '吕先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:37 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-03-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=162467',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-26',
 'pub_title': '求购海沃德猕猴桃',
 'sup_address': '周至县楼观镇西会村',
 'sup_description': '求购海沃德猕猴桃买整库或者单车均可，要硬度好，看货谈价。',
 'sup_phone': '13689205889',
 'sup_user': '田先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:37 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=164225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-21',
 'pub_title': '大量求购海沃德猕猴桃次果',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现大量求购海沃德猕猴桃次果，价格面谈。',
 'sup_phone': '18792637406',
 'sup_user': '齐先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:38 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-17',
 'info_from': 'http://222.90.83.241/show.aspx?id=164737',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-29',
 'pub_title': '求购90起步海沃德猕猴桃5万斤',
 'sup_address': '西安市马召镇仁烟村',
 'sup_description': '求购90起步海沃德猕猴桃5万斤，欢迎联系！',
 'sup_phone': '15191915106',
 'sup_user': '陈先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:38 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166050',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-22',
 'pub_title': '大量收购甜瓜',
 'sup_address': '西安市阎良区关山街道办老王村西北组（原老王村小学院内）',
 'sup_description': '大量收购甜瓜，以质论价，欢迎联系销售。',
 'sup_phone': '15094000816',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:39 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=166814',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-05',
 'pub_title': '大量收购“芝麻蜜”甜瓜',
 'sup_address': '西安市阎良区关山街道办北十字口西北角',
 'sup_description': '大量收购阎良“芝麻蜜”、小籽甜瓜，价格随行就市，欢迎广大瓜农联系销售。',
 'sup_phone': '13347409123',
 'sup_user': '冯先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:39 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=167005',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-08',
 'pub_title': '求购猕猴桃公花粉3斤',
 'sup_address': '周至县哑柏镇上阳化村',
 'sup_description': '急求猕猴桃公花粉3斤，价格面议。',
 'sup_phone': '13609203888',
 'sup_user': '陈女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:40 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167150',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '大量收购青李子',
 'sup_address': '陕西周至广济上二屯村',
 'sup_description': '大量收购青李子，每斤0.25元。',
 'sup_phone': '18229042452',
 'sup_user': '刘师傅'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:40 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167169',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '求购青李子',
 'sup_address': '周至县富仁镇永丰村',
 'sup_description': '求购青李子。数量价格面议。',
 'sup_phone': '13201591625',
 'sup_user': '李先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:41 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167215',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '大量求购青李子',
 'sup_address': '周至县马召镇焦家楼村',
 'sup_description': '大量求购青李子,每斤0.25元。',
 'sup_phone': '18229042452',
 'sup_user': '张女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:41 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167216',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '收购李子青果',
 'sup_address': '周至县广济镇南陈村',
 'sup_description': '陈先生大量收购李子青果，不论大小，每斤0.2元，有意者速联系。',
 'sup_phone': '18710430164',
 'sup_user': '陈先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:41 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-24',
 'info_from': 'http://222.90.83.241/show.aspx?id=167229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-14',
 'pub_title': '大量收购青李子',
 'sup_address': '周至县广济镇桑园村',
 'sup_description': '大量收购青李子，每斤0.25元联系人:王女士电话:85121695地址:周至县广济镇桑园村',
 'sup_phone': '85121695',
 'sup_user': '王女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:42 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167427',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-17',
 'pub_title': '求购杏',
 'sup_address': '周至县楼观镇下三清村',
 'sup_description': '求购杏，丰园红，金太阳等，有意向者电话联系。',
 'sup_phone': '15091861572',
 'sup_user': '康先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:42 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167664',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-21',
 'pub_title': '求购青李子',
 'sup_address': '周至县马召镇熨斗村',
 'sup_description': '求购青李子，有意者电话联系。',
 'sup_phone': '18700828599',
 'sup_user': '赵女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:43 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167716',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-22',
 'pub_title': '求购青李子1万斤',
 'sup_address': '周至县广济镇商家磨村',
 'sup_description': '求购青李子1万斤，价格面议',
 'sup_phone': '13700245778',
 'sup_user': '潘女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:43 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167847',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购金太阳杏子1.5万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购金太阳杏子1.5万斤，要求个大，价格面议。',
 'sup_phone': '18710683521',
 'sup_user': '宋先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:44 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167849',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购进口海沃德猕猴桃2万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购进口海沃德猕猴桃2万斤，要求80克起步，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:44 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168221',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '求购油桃5000斤',
 'sup_address': '周至县广济镇南留村',
 'sup_description': '求购油桃5000斤，要求色红脆甜，价格面议，有货的速联系。',
 'sup_phone': '17389206678',
 'sup_user': '刘先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:45 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168047',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径10公分红叶碧桃20棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径10公分红叶碧桃20棵，要求大半冠，树干端直，带土球80公分，有货者请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:45 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168049',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分国槐32棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分国槐32棵，要求分支点2.5-3米，4米原生冠，带常规土球，有货的朋友请尽快联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:46 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168051',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分七叶树42棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分七叶树42棵，要求分支点2.8-3.2米，4米原生冠，带常规土球，有货者请速联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:46 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168115',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购白皮松',
 'sup_address': '周至县二曲街道办事处李家村',
 'sup_description': '本处现急需求购一米起步老芽三级18碗碗白皮松，一车装7000株，有货请电话联系。',
 'sup_phone': '13759925466',
 'sup_user': '李朝辉'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:47 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168137',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购高1.5米以上的塔柏200棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高1.5米以上的塔柏200棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:47 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168191',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购银杏胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购银杏胸径20至22公分，要求，冠副4米，高8米至8米5.1.5米的土球，总数量636颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:48 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168193',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购雪松6至7米',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购雪松6至7米，冠幅2米至2.5，1.2米土球，总数量，235颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:48 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168195',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购七叶树',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购七叶树，胸径15至18公分，要求1.5米土球，数量826颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:36:49 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168247',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大量大米，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:50 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168268',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '现有今年新油菜籽3000斤左右颗粒饱满油菜籽颜色黑已经处理干净小灰尘出油率高油菜籽完全晒干发的有图片但仅为参考还是要看实际货物如有需要者可以和我联系非诚勿扰!',
 'sup_phone': '18700657341',
 'sup_user': '龙女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:50 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168310',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大米，请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:51 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168319',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售油菜籽',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '有2019年出产的油菜籽2000斤欲对外出售，菜籽干度好，出油率高，如有购买者请联系，价格面议。',
 'sup_phone': '18391619491',
 'sup_user': '苟建荣'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:51 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168321',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售小麦',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '本人有2019年出产小麦2000斤现对外出售，麦子干度好，色泽鲜亮。如有需要者请联系。',
 'sup_phone': '13259287568',
 'sup_user': '孙培军'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:52 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168105',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:52 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168117',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-28',
 'pub_title': '出售油菜籽',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售油菜籽约600斤，价格面议，欢迎联系。',
 'sup_phone': '13572583121',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:53 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168123',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '汉台区武乡镇同心村',
 'sup_description': '大量今年新油菜籽出售，地址：汉台区武乡镇同心。联系电话：18710666754张女士',
 'sup_phone': '18710666754',
 'sup_user': '张女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:53 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168130',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有油菜籽出售，无杂质、无霉粒，数吨如有需求者请与我联系，联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:54 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167878',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售土豆',
 'sup_address': '陕西省西安市周至县尚村镇张寨村八组',
 'sup_description': '我处有3亩地土豆出售，有需求者请联系。',
 'sup_phone': '18729974792',
 'sup_user': '张先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:54 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167879',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菜油',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十四组',
 'sup_description': '我处有200斤菜油出售，有需求者电话联系。',
 'sup_phone': '15991614124',
 'sup_user': '闫先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:55 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167941',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售玉米',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售玉米3000斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:55 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168007',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售2019新收小麦',
 'sup_address': '汉台区七里街道马家坝村一组',
 'sup_description': '家有2019年应季新收小麦800斤需出售，有意者请于我联系，电话13891622698',
 'sup_phone': '13891622698',
 'sup_user': '衡正斌'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:56 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168037',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售菜籽、小麦',
 'sup_address': '汉台区老君镇王道池村',
 'sup_description': '现有刚收获的小麦、菜籽。价格随市场。联系电话：18891618650联系人李先生',
 'sup_phone': '18891618650',
 'sup_user': '李新华'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:56 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168081',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '优质菜籽',
 'sup_address': '汉台区武乡镇崔营村',
 'sup_description': '本村大量上市2019年优质油菜籽，量大、质量优，有意者来电咨询洽谈',
 'sup_phone': '18220666628',
 'sup_user': '崔先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:57 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168104',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:57 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168132',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '小麦',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有大量小麦出售，质优无杂质颗粒饱满，如有需求者请与李先生联系。联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇共力村九组。',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:58 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=168154',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '菜籽',
 'sup_address': '汉台区老君镇',
 'sup_description': '菜籽色泽鲜亮.颗粒饱满',
 'sup_phone': '13379361068',
 'sup_user': '黄女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:58 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168156',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，价格随行就市，欢迎联系。',
 'sup_phone': '13991942437',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:36:59 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168213',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售新小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，欢迎联系。',
 'sup_phone': '18792949262',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:37:00 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167624',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购青年母鸡',
 'sup_address': '鄠邑区甘河镇北板村',
 'sup_description': '求购海兰褐青年母鸡1500只，要求日龄60天-100天，价格面议，欢迎联系。',
 'sup_phone': '18629514457',
 'sup_user': '董先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:00 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167623',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购鸡蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购红皮鸡蛋400盘，每盘重1.9公斤左右，价格面议，欢迎联系。',
 'sup_phone': '18392549287',
 'sup_user': '曹先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:01 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-07-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=166821',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '收购群羊',
 'sup_address': '陕西省汉中市',
 'sup_description': '大量收购群羊，价格美丽。联系电话（微信）：18828091357。',
 'sup_phone': '18828091357',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:01 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=166874',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-06',
 'pub_title': '求购母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购经产母猪5头，要求健康无病，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:02 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166929',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋所在地：汉中市汉台区发布时间：2019-04-22求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:02 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=167341',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-16',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '常期收购淘汰母猪，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '吴先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:03 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162045',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购淘汰红毛蛋鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购淘汰红毛蛋鸡800只-均重4.2斤以上，毛色好，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:03 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162050',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购各种狗',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '大量求购各种狗，哈士奇、拉布拉多、金毛、萨摩、阿拉斯加、边牧、马犬、博美、比熊等，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:04 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-03-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=161471',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-14',
 'pub_title': '求购鸭蛋',
 'sup_address': '陕西省西安市周至县集贤镇西村',
 'sup_description': '求购鸭蛋20斤，有货者请联系。',
 'sup_phone': '13519133896',
 'sup_user': '田先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:04 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-03-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=161762',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-19',
 'pub_title': '求购胸径20-22公分银杏55棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购胸径20-22公分银杏，要求高度7-8米，冠幅4米，数量55棵，有货者电话联系，价格面议。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:05 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162023',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购散养100只老母鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购散养老母鸡100只，7--8个月，体重5斤左右，价格合适，欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:05 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=162949',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-03-04',
 'pub_title': '求购羊羔',
 'sup_address': '阎良区关山街道办老王村小马组',
 'sup_description': '上门收购小公羊、母羊羔，价格随行，欢迎联系。',
 'sup_phone': '13759637031',
 'sup_user': '杨先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:06 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=163540',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-14',
 'pub_title': '求购鹅蛋',
 'sup_address': '鄠邑区涝店镇马家堡村',
 'sup_description': '求购鹅蛋100枚，价格面议，欢迎联系。',
 'sup_phone': '13484800110',
 'sup_user': '张女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:06 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=164300',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购地径8公分紫薇20棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购地径8公分紫薇20棵，要求分支点60公分以上，有意者请电话联系。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:07 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168202',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购红宝石海棠胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购红宝石海棠胸径12至14公分，1.2米土球，数量1706颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:07 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166044',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-22',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:07 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166500',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-28',
 'pub_title': '求购土鸡蛋',
 'sup_address': '吴基庄村',
 'sup_description': '需要购买土鸡蛋60个，物美价廉',
 'sup_phone': '13772809382',
 'sup_user': '张女士'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:08 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '求购一批土鸡鸡苗',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '现需要一批鸡苗（200只），适应本地气候，成活率高的！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:08 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=168241',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '大量求购淘汰母猪，价格随行就市，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:09 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167294',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购猪仔',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '求购猪仔10头，要求单头重25斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029246927',
 'sup_user': '刘先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:10 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2018-12-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=158576',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-10',
 'pub_title': '求购魔芋5000斤',
 'sup_address': '西安市周至县楼观镇上三清村',
 'sup_description': '我处急需魔芋，数量5000斤，每个200克以上，有意者，请尽快联系。',
 'sup_phone': '13474110275',
 'sup_user': '刘俊锋'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:10 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-07-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168318',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '小辣子',
 'sup_address': '汉台区七里办事处金江2组',
 'sup_description': '王先生家中种植了各种蔬菜,小辣子已经成熟,正在大量出售,如有需求,请电话联系',
 'sup_phone': '15891461382',
 'sup_user': '王先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:11 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168203',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购大叶女贞胸径10至12公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购大叶女贞，胸径10至12公分，1.2米土球，数量1348颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:11 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=168279',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '求购胸径4公分高杆石楠600棵',
 'sup_address': '周至县马召镇桃李坪村',
 'sup_description': '求购胸径4公分高杆石楠600棵，分枝点1.5米，有货请电话联系。',
 'sup_phone': '13891948456',
 'sup_user': '郭新峰'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:37:12 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'end_time': '2019-03-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=164508',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-25',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉台区汉王镇大兴村',
 'sup_description': '价格1元每枚',
 'sup_phone': '15129581840',
 'sup_user': '胡生'}}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 136, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:38:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168266',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '桃子',
 'sup_address': '陕西省汉中市汉台区老君镇徐家营村',
 'sup_description': '现有新鲜桃子5亩桃子属于老品种个头大小合适桃子味道浓甜汁多现在正是出售的季节有需要采摘的或者做生意的可以联系我自己下地采摘价格可以看完水果以后商量非诚勿扰谢谢!',
 'sup_phone': '13379360380',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 134, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:38:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168292',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '供应金太阳杏1万斤',
 'sup_address': '周至县竹峪镇张龙村',
 'sup_description': '供应金太阳杏1万斤，价格电议。',
 'sup_phone': '18092043194',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 134, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:38:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=168301',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应阎良优质绿皮甜瓜',
 'sup_address': '西安市阎良区关山街道办界坊村西界组',
 'sup_description': '我家种植的绿皮甜瓜刚上市，单重1-1.5斤，香甜难忘，欢迎你品尝后购买。',
 'sup_phone': '18092295878',
 'sup_user': '郭大英'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 134, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:38:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168320',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '杏',
 'sup_address': '陕西省汉中市汉台区',
 'sup_description': '好吃的杏子，有想法联系啊',
 'sup_phone': '18829863123',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 134, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168289',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高3米以上的油松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高3米以上的油松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168290',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高1米左右的白皮松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高1米左右的白皮松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168291',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售毛竹10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售毛竹10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168296',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '低价销售直径3-10厘米的樱花树',
 'sup_address': '周至县终南村',
 'sup_description': '低价销售直径3-10厘米的樱花树8亩左右，树形好，价格低，欢迎需求朋友联系。联系：陈女士电话：13119161886地址：周至县终南村',
 'sup_phone': '13119161886',
 'sup_user': '陈女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=168305',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白蜡树',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有直径5公分白蜡树300棵，直径6公分白蜡树100棵，急于出售。欢迎电话联系。',
 'sup_phone': '13484667542',
 'sup_user': '闫兆'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-19',
 'info_from': 'http://222.90.83.241/show.aspx?id=168306',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白皮松',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有高度1米白皮松300棵，急于出售。欢迎电话联系。',
 'sup_phone': '13032916618',
 'sup_user': '刘展雄'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=168278',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高80公分兰天竹营养钵3500株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：高80公分兰天竹营养钵3500株，价格面议，欢迎联系。',
 'sup_phone': '15319458368',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165873',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-04-19',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办事处王家湾村',
 'sup_description': '要求玉米颗粒饱满，无腐烂、无虫、无沙粒，有意出售的电话联系。',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=165984',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '求购红芋苗',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十三组',
 'sup_description': '求购秦薯四号红芋苗15000苗，有出售者请联系。',
 'sup_phone': '15109208586',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:42:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:42:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168097',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售西瓜',
 'sup_address': '鄠邑区蒋村镇同兴村',
 'sup_description': '出售甜王西瓜，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15029807630',
 'sup_user': '陈先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168022> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168207> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168321> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168282> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168287> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 109, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168132> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168284> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 141, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','需求')
KeyError: 'pub_title'
2019-06-03 23:45:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168103',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售杏子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人出售可口香甜的杏子，价格4.5每斤，需求者请联系！',
 'sup_phone': '13892696179',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:45:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 113, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168306> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168208',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售5—8公分红叶李3000颗'}, 'type': 'supply', 'content': '<div class="show_content" style=" text-align:left;">\r\n                            本人出售5—8公分红叶李3000颗，如有需求者请联系。<br>联系人：朱先生<br>联系电话：18149061125<br>有效期：2019-06-08<br>地址：陕西省周至县翠峰镇史务村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168290> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168288> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 113, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165984> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: get() missing 1 required positional argument: 'self'
2019-06-03 23:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167766> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168305> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168211',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售8—10公分青桐1000颗'}, 'type': 'supply', 'content': '<div class="show_content" style=" text-align:left;">\r\n                            本人出售8—10公分青桐1000颗，如有需求者请联系。<br>联系人：朱先生<br>联系电话：18149061125<br>有效期：2019-06-08<br>地址：陕西省周至县翠峰镇史务村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165984> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167804> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168289> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 113, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: get() missing 1 required positional argument: 'self'
2019-06-03 23:45:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168210',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售5—10公分国槐500颗'}, 'type': 'supply', 'content': '<div class="show_content" style=" text-align:left;">\r\n                            本人出售5—10公分国槐500颗，如有需求者请联系。<br>联系人：朱先生<br>联系电话：18149061125<br>有效期：2019-06-08<br>地址：陕西省周至县翠峰镇史务村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167755> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 113, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: get() missing 1 required positional argument: 'self'
2019-06-03 23:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 110, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168124',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '种植露天桃子，味道好，自然熟',
 'sup_address': '汉中市汉台区',
 'sup_description': '自家种植的桃子，口感有清脆和微软两种，味道有纯甜，微酸甜两种，现摘现送无化肥农药，真正绿色无污染，关键是味道好，味道好，味道好！价格面议，欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:45:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168209',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售3—5米油松80颗'}, 'type': 'supply', 'content': '<div class="show_content" style=" text-align:left;">\r\n                            本人出售3—5米油松80颗，如有需求者请联系。<br>联系人：朱先生<br>联系电话：18149061125<br>有效期：2019-06-08<br>地址：陕西省周至县翠峰镇史务村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168281> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 110, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167776> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166923> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: get() missing 1 required positional argument: 'self'
2019-06-03 23:45:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 113, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168042> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-03 23:45:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168133',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售丰园红杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售丰园红早熟杏，面积2.5亩，价格面议，欢迎联系。',
 'sup_phone': '17719535936',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:45:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168224',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应大叶女贞5000棵'}, 'type': 'supply', 'content': '<div class="show_content" style=" text-align:left;">\r\n                            供应大叶女贞5000棵，米径6——8公分，分支点2.3米，株高5米左右，价格面议，欢迎联系。<br>联系人：刘先生<br>联系电话：17389206678<br>有效期：2019-06-15<br>地址：周至县广济镇南留村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167644> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 110, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167815> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: get() missing 1 required positional argument: 'self'
2019-06-03 23:45:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168195> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-03 23:45:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 113, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    # print(item["result_item"])
OSError: [Errno 5] Input/output error
2019-06-03 23:45:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168134',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售樱桃',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售樱桃，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15829462025',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:45:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 110, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168215',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售白皮松'}, 'type': 'supply', 'content': '<div class="show_content" style=" text-align:left;">\r\n                            <p>\r\n\t出售白皮松30000株，树高约1米，价格面议，欢迎联系。\r\n</p>\r\n<p>\r\n\t\xa0 \xa0\xa0\r\n</p><br>联系人：李先生<br>联系电话：13289803688<br>有效期：2020-05-31<br>地址：鄠邑区渭丰镇定四村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167817> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: get() missing 1 required positional argument: 'self'
2019-06-03 23:45:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168284> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168193> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-03 23:45:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 113, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168186> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168291> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:45:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    # print(item["result_item"])
OSError: [Errno 5] Input/output error
2019-06-03 23:45:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168211> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 110, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166923> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:45:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167893> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: get() missing 1 required positional argument: 'self'
2019-06-03 23:45:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168223',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应红叶李'}, 'type': 'supply', 'content': '<div class="show_content" style=" text-align:left;">\r\n                            我村马先生供应红叶李500棵，胸径4-6公分，分支点1.8米，价钱面议。<br>联系人：马先生<br>联系电话：15902924791<br>有效期：2019-06-30<br>地址：周至县翠峰镇官庄村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 113, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=167478',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '土鸡',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡，有意者请与丁先生联系，电话：13689190503。',
 'sup_phone': '13689190503',
 'sup_user': '丁先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    # print(item["result_item"])
OSError: [Errno 5] Input/output error
2019-06-03 23:45:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168047> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-03 23:45:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:45:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 110, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168219',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售大棚西瓜',
 'sup_address': '庆丰村9组',
 'sup_description': '1、汉台区老君镇庆丰村2组即将大量出售新鲜大棚西瓜，有意者请前来现场订购；2、地址：汉武路中段汉中市红旗机械厂对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:45:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167644> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: get() missing 1 required positional argument: 'self'
2019-06-03 23:45:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:55 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168192',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售冠幅1——3米腊梅150棵'}, 'content': '<div class="show_content" style=" text-align:left;">\r\n                            出售冠幅1——3米腊梅150棵.<br>联系人：罗先生<br>联系电话：13772150239<br>有效期：2020-03-30<br>地址：周至县侯家村镇渭洲村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    # print(item["result_item"])
OSError: [Errno 5] Input/output error
2019-06-03 23:45:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 110, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:45:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168137> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-03 23:45:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168222',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应次杏子丰园红5000斤',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村供应次杏子丰园红5000斤，价钱面议。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:45:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166923> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:45:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167567',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-19',
 'pub_title': '高先生长期供应牛奶',
 'sup_address': '周至县尚村镇马村',
 'sup_description': '高先生长期供应牛奶，价格面议。',
 'sup_phone': '15809220930',
 'sup_user': '高先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    # print(item["result_item"])
OSError: [Errno 5] Input/output error
2019-06-03 23:45:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:59 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168183',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售米径8---10公分七叶树100棵'}, 'content': '<div class="show_content" style=" text-align:left;">\r\n                            <span style="font-size:18px;">出售米径8---10公分七叶树100棵，价格电话联系。</span><br>联系人：王先生<br>联系电话：15934805777<br>有效期：2019-06-15<br>地址：陕西省西安市周至县尚村镇大水屯村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:45:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:45:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 110, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168191> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
AttributeError: 'NoneType' object has no attribute 'xpath'
2019-06-03 23:46:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:46:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167930> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167480',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-18',
 'pub_title': '出售红皮鸡蛋',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售红皮鸡蛋65盘，每盘重约4斤，价格面议，欢迎联系。',
 'sup_phone': '15353526258',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    # print(item["result_item"])
OSError: [Errno 5] Input/output error
2019-06-03 23:46:03 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤'}, 'content': '<div class="show_content" style=" text-align:left;">\r\n                            <p style="text-indent:2em;">\r\n\t求购玉米1000斤。优质。\r\n</p><br>联系人：王先生<br>联系电话：15339152108<br>有效期：2019-04-18<br>地址：周至县广济镇小留村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 28, in process_item
    #     self.sess = self.session()
OSError: [Errno 5] Input/output error
2019-06-03 23:46:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168136',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售金太阳杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售金太阳杏，产量约2500斤，价格随行就市，欢迎联系。',
 'sup_phone': '15353714592',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:46:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167967> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    # print(item["result_item"])
OSError: [Errno 5] Input/output error
2019-06-03 23:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:07 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷'}, 'content': '<div class="show_content" style=" text-align:left;">\r\n                            <span style="color:#666666;font-family:宋体;font-size:21px;background-color:#FFFFFF;">\xa0 \xa0勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。</span><br>联系人：唐老板<br>联系电话：0916-3416161<br>有效期：2019-12-31<br>地址：陕西省汉中市勉县周家山镇明星村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 28, in process_item
    #     self.sess = self.session()
OSError: [Errno 5] Input/output error
2019-06-03 23:46:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 133, in process_item
    sql = 'INSERT INTO no_supply (pro_name,sup_variety,sup_validity,sup_num,sup_phone,sup_user,sup_origin,sup_type) VALUES ("%s","%s","%s","%s","%s","%s","%s","%s")' % (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-03 23:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 132, in process_item
    # print(item["result_item"])
OSError: [Errno 5] Input/output error
2019-06-03 23:46:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:46:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168284> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:11 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=157755',
 'pub_address': '西安市周至县',
 'pub_time': '2018-11-27',
 'pub_title': '大量收购荠菜'}, 'content': '<div class="show_content" style=" text-align:left;">\r\n                            大量收购荠菜，每斤1元\r\n    联系人:何女士\r\n    电话:17791544238\r\n    地址:周至县翠峰镇史务村<br>联系人：何女士<br>联系电话：17791544238<br>有效期：2018-12-17<br>地址：周至县翠峰镇史务村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 28, in process_item
    #     self.sess = self.session()
OSError: [Errno 5] Input/output error
2019-06-03 23:46:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167842> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:15 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168196',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售高度50公分红瑞木2万'}, 'content': '<div class="show_content" style=" text-align:left;">\r\n                            出售高度50公分红瑞木2万。<br>联系人：罗先生<br>联系电话：13772150239<br>有效期：2020-03-30<br>地址：周至县侯家村镇渭洲村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:46:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168151> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:46:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167968> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:19 [scrapy.core.scraper] ERROR: Error processing {'type': 'supply', 'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=168194',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售米径2——6冠幅国槐2万棵'}, 'content': '<div class="show_content" style=" text-align:left;">\r\n                            出售米径2——6冠幅国槐2万棵。<br>联系人：罗先生<br>联系电话：13772150239<br>有效期：2020-03-31<br>地址：周至县侯家村镇渭洲村<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 22, in process_item
OSError: [Errno 5] Input/output error
2019-06-03 23:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:46:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167878> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168188> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168285> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:24 [scrapy.core.scraper] ERROR: Error processing {'type': 'purchase', 'result_item': {'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米'}, 'content': '<div class="show_content" style=" text-align:left;">\r\n                            玉米\r\n<div class="show_datetime">\r\n\t所在地：汉中市汉台区                        发布时间：2019-02-28\r\n\t<div class="show_content" style="text-align:left;">\r\n\t\t现需要玉米一千斤   要求玉米粒饱满   干净   没有发霉   价格按照玉米的质量定价商量   家有玉米的可以和我聊天   非诚勿扰！谢谢 <br>\r\n联系人：姚女士<br>\r\n联系电话：13891631077<br>\r\n有效期：2019-03-08<br>\r\n地址：陕西省汉中市汉台区老君镇\r\n\t</div>\r\n</div><br>联系人：姚女士<br>联系电话：13891631077<br>有效期：2019-04-30<br>地址：陕西省汉中市汉台区老君镇<br>邮箱：\r\n                            <br>\r\n                            \r\n                        </div>'}
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/pipelines.py", line 28, in process_item
    #     self.sess = self.session()
OSError: [Errno 5] Input/output error
2019-06-03 23:46:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:46:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168189> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167941> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:46:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167644> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167981> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168184> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167879> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168192> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 116, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168204> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=160860> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168215> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167777> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:46:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168211> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:46:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167878> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168190> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168151> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:46:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167894> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:46:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167842> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168196> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165984> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:46:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166923> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168223> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:46:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168155> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:46:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 87, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:46:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:46:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167893> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:46:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:46:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167531> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 95, in parse_detail
OSError: [Errno 5] Input/output error
2019-06-03 23:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167644> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168225> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:47:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168208> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167895> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:47:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168194> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167626> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168159> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168210> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:47:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168278> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168207> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 89, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 23:47:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:47:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167841> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168026> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168222> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168209> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:47:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 23:47:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168043> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167879> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168268> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166923> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:47:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168284> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166923> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168282> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
TypeError: object of type 'Selector' has no len()
2019-06-03 23:47:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 23:47:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168041> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168310> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165984> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:47:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168282> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168280> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168187> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=160860> (referer: http://222.90.83.241/List.aspx?cid=120)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 23:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167925> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168319> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168040> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:47:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168281> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 23:47:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167945> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168093> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168108> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168219> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:47:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168285> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168044> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 23:47:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168319> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167432> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168037> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
AttributeError: 'Selector' object has no attribute 'extract_first'
2019-06-03 23:47:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167963> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168296> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 23:47:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167878> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167351> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167878> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168020> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168306> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=157755> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 91, in parse_detail
    str = "".join(ii.split())
OSError: [Errno 5] Input/output error
2019-06-03 23:47:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168284> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168310> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167804> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in xpath
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 84, in <listcomp>
    return self.__class__(flatten([x.xpath(xpath, namespaces=namespaces, **kwargs) for x in self]))
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in .//string()
2019-06-03 23:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167476> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=161136> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168093> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167804> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167449> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168305> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168283> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167815> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167964> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167894> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167968> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167815> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=162467> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
TypeError: 'SelectorList' object is not callable
2019-06-03 23:47:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167350> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168291> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167815> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167925> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168093> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168185> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168039> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
TypeError: 'SelectorList' object is not callable
2019-06-03 23:47:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167478> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167817> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164733> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167817> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167350> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167237> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 94, in parse_detail
    # print(result)
OSError: [Errno 5] Input/output error
2019-06-03 23:47:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168283> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167804> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168042> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
TypeError: 'SelectorList' object is not callable
2019-06-03 23:47:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167878> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167478> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167893> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168305> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164647> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167878> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167644> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 94, in parse_detail
    # print(result)
OSError: [Errno 5] Input/output error
2019-06-03 23:47:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168291> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:47:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164225> (referer: http://222.90.83.241/List.aspx?cid=119)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
TypeError: 'SelectorList' object is not callable
2019-06-03 23:47:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167893> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:47:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168183> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:47:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:47:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164961> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:47:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168290> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:47:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168296> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167895> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 94, in parse_detail
    # print(result)
OSError: [Errno 5] Input/output error
2019-06-03 23:48:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168018> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
TypeError: 'SelectorList' object is not callable
2019-06-03 23:48:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168093> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:48:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:48:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167893> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=166662> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168284> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165984> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167894> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167967> (referer: http://222.90.83.241/List.aspx?cid=90)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168151> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 94, in parse_detail
    # print(result)
OSError: [Errno 5] Input/output error
2019-06-03 23:48:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168047> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
TypeError: 'SelectorList' object is not callable
2019-06-03 23:48:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168148> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168156> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164700> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164603> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168204> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 90, in parse_detail
    for ii in items:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167817> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168184> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167452> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 94, in parse_detail
    # print(result)
OSError: [Errno 5] Input/output error
2019-06-03 23:48:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168009> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
TypeError: 'SelectorList' object is not callable
2019-06-03 23:48:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167879> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:48:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168207> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 90, in parse_detail
    for ii in items:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=163917> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158138> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:48:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167804> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168247> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:48:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168290> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164323> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=165873> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167580> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 94, in parse_detail
    # print(result)
OSError: [Errno 5] Input/output error
2019-06-03 23:48:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168224> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168151> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 97, in parse_detail
    sup_user = result[result.rfind('联系人：')+4:result.rfind('联系电话：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164101> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:48:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164177> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 96, in parse_detail
    sup_description = result[0:result.find('联系人：')]
OSError: [Errno 5] Input/output error
2019-06-03 23:48:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168208> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 90, in parse_detail
    for ii in items:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167941> (referer: http://222.90.83.241/List.aspx?cid=87)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
OSError: [Errno 5] Input/output error
2019-06-03 23:48:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168022> (referer: http://222.90.83.241/List.aspx?cid=121)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 88, in parse_detail
    items = i_content.split('\r')
TypeError: 'SelectorList' object is not callable
2019-06-03 23:48:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168093> (referer: http://222.90.83.241/List.aspx?cid=89)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 92, in parse_detail
    if str:
OSError: [Errno 5] Input/output error
2019-06-03 23:48:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=168274> (referer: http://222.90.83.241/List.aspx?cid=91)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 93, in parse_detail
    result += str
OSError: [Errno 5] Input/output error
2019-06-03 23:48:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=167804> (referer: http://222.90.83.241/List.aspx?cid=88)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 102, in parse_detail
    result = ""
OSError: [Errno 5] Input/output error
2019-06-03 23:48:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=164172> (referer: http://222.90.83.241/List.aspx?cid=117)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 108, in parse_detail
    item['sup_address'] = sup_address
OSError: [Errno 5] Input/output error
2019-06-03 23:48:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://222.90.83.241/show.aspx?id=158576> (referer: http://222.90.83.241/List.aspx?cid=118)
Traceback (most recent call last):
  File "/home/yanxiuhao/.local/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/mnt/d/Documents/Desktop/git/diandianbangnong/diandianCrawling/crawling/crawling/spiders/Sxnynct_SupAndPur_Spider.py", line 94, in parse_detail
    # print(result)
OSError: [Errno 5] Input/output error
2019-06-04 00:03:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168281',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分以上的红梅10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分以上的红梅10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168282',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径3-4公分以上的红枫10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径3-4公分以上的红枫10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168283',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径2-3公分的桂花10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径2-3公分的桂花10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168284',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的玉兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的玉兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168285',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5公分左右的红叶石兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5公分左右的红叶石兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168286',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的早樱10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的早樱10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168287',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分的嫁接红梅20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分的嫁接红梅20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165873',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-04-19',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办事处王家湾村',
 'sup_description': '要求玉米颗粒饱满，无腐烂、无虫、无沙粒，有意出售的电话联系。',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=165984',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '求购红芋苗',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十三组',
 'sup_description': '求购秦薯四号红芋苗15000苗，有出售者请联系。',
 'sup_phone': '15109208586',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166662',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-30',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有数千斤大米，有合适的价格请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166923',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市汉台区发布时间：2019-04-04购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167237',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-14',
 'pub_title': '求购玉米',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '需要购买一批玉米，用作养殖场鸡饲料,电话联系！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167452',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-17',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米5000公斤，要求干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '15229382221',
 'sup_user': '谭先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167580',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米3000公斤，要求水份14%以内，干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '18706733154',
 'sup_user': '高先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167644',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '油菜籽',
 'sup_address': '陕西汉中',
 'sup_description': '大量新鲜油菜籽出售',
 'sup_phone': '18292654661',
 'sup_user': '丁女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168148',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '15891399228',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168151',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤.优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=158381',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-07',
 'pub_title': '求购野山药',
 'sup_address': '佛坪县陈家坝镇金星村二组',
 'sup_description': '求购野生山药，平均价格10元每斤，量大从优，',
 'sup_phone': '17730778050',
 'sup_user': '刘和秀'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=158576',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-10',
 'pub_title': '求购魔芋5000斤',
 'sup_address': '西安市周至县楼观镇上三清村',
 'sup_description': '我处急需魔芋，数量5000斤，每个200克以上，有意者，请尽快联系。',
 'sup_phone': '13474110275',
 'sup_user': '刘俊锋'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=158659',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-11',
 'pub_title': '大量收购乌笋种子',
 'sup_address': '汉中市佛坪县',
 'sup_description': '大量收购乌笋种子，土名：洋嚯。联系电话：13991608711/13892652745',
 'sup_phone': '13991608711',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158760',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-12',
 'pub_title': '大量求购线辣椒',
 'sup_address': '西安市阎良区关山镇关山村',
 'sup_description': '大量收购线辣椒，红绿均可，价格面议，欢迎联系。',
 'sup_phone': '18392532698',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158830',
 'pub_address': '汉中市汉台区',
 'pub_time': '2018-12-13',
 'pub_title': '求购洋芋种',
 'sup_address': '汉中市汉台区七里办事处文庙村',
 'sup_description': '黄先生等户求购洋芋种；品种有；荷兰洋芋、早大白洋芋。有货源的客户快来村联系，价格面议，数量不限。联系人；黄先生，地址；汉中市汉台区七里办事处文庙村，电话；13084883593.文庙村信息站发。',
 'sup_phone': '13084883593',
 'sup_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=159779',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-29',
 'pub_title': '求购200克以上魔芋5000斤',
 'sup_address': '周至县厚畛子镇同力村',
 'sup_description': '求购200克以上魔芋5000斤联系人:黄先生电话：１３４７４１１０２７５地址：周至县厚畛子镇同力村。',
 'sup_phone': '13474110275',
 'sup_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=160928',
 'pub_address': '西安市户县',
 'pub_time': '2019-01-24',
 'pub_title': '求购大葱',
 'sup_address': '鄠邑区玉蝉镇新向村',
 'sup_description': '求购大葱100斤，欢迎联系。',
 'sup_phone': '15091671829',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165085',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-08',
 'pub_title': '大量收购甘蓝菜',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购甘蓝菜，要求单重2斤以上，价格随行就市，欢迎联系销售。',
 'sup_phone': '15291452658',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165124',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜蒜苔',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜蒜苔，日收购5吨，限陕西西安境内，有意者请联系，价格面议。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165126',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜香椿',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜香椿芽，有意者请联系价格面议，限西安辖区内，',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=165372',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-11',
 'pub_title': '收购莲花白、螺丝辣椒',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购莲花白、螺丝辣椒，价格面议，欢迎广大菜农联系销售。',
 'sup_phone': '13474363373',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=165934',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '收购洋槐花',
 'sup_address': '周至县楼观镇团标村',
 'sup_description': '收购洋槐花，有意者电话联系。',
 'sup_phone': '15091527877',
 'sup_user': '谢女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=166016',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-21',
 'pub_title': '求购紫薯苗',
 'sup_address': '周至县尚村镇新范村',
 'sup_description': '求购紫薯苗两万个，可以电话报价，有货及时联系',
 'sup_phone': '13619226724',
 'sup_user': '孙先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=166051',
 'pub_address': '西安市户县',
 'pub_time': '2019-04-22',
 'pub_title': '求购小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '求购小葱秧200斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166675',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-30',
 'pub_title': '求购鲜洋槐花',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜洋槐花，数量不限，限西安境内，有意者请联系，量大可上门取货。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167311',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购葱秧',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购葱秧30公斤，品种不限，价格面议，欢迎联系。',
 'sup_phone': '18966810872',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-17',
 'info_from': 'http://222.90.83.241/show.aspx?id=167415',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-17',
 'pub_title': '求购藕种',
 'sup_address': '汉台区老君镇付庙村六组',
 'sup_description': '大量求购优质藕种！',
 'sup_phone': '13571611661',
 'sup_user': '张伟'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167848',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购大蒜5万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购大蒜5万斤，要求个大，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168318',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '小辣子',
 'sup_address': '汉台区七里办事处金江2组',
 'sup_description': '王先生家中种植了各种蔬菜,小辣子已经成熟,正在大量出售,如有需求,请电话联系',
 'sup_phone': '15891461382',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168275',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高60公分大田侧柏1.5万株',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：高60公分大田侧柏1.5万株，价格面议，欢迎联系。',
 'sup_phone': '15877344352',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168276',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径1公分国槐3000棵',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：胸径1公分国槐3000棵，价格面议，欢迎联系。',
 'sup_phone': '13092046069',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:03:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168277',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径15公分龙爪槐20棵',
 'sup_address': '周至县四屯镇联三村',
 'sup_description': '出售：胸径15公分龙爪槐20棵，价格面议，欢迎联系。',
 'sup_phone': '15091151300',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=168278',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高80公分兰天竹营养钵3500株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：高80公分兰天竹营养钵3500株，价格面议，欢迎联系。',
 'sup_phone': '15319458368',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168280',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售直径3公分左右的大叶女贞10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售直径3公分左右的大叶女贞10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168288',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-7公分的香花槐20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-7公分的香花槐20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168289',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高3米以上的油松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高3米以上的油松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168290',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高1米左右的白皮松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高1米左右的白皮松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168291',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售毛竹10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售毛竹10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168296',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '低价销售直径3-10厘米的樱花树',
 'sup_address': '周至县终南村',
 'sup_description': '低价销售直径3-10厘米的樱花树8亩左右，树形好，价格低，欢迎需求朋友联系。联系：陈女士电话：13119161886地址：周至县终南村',
 'sup_phone': '13119161886',
 'sup_user': '陈女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=168305',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白蜡树',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有直径5公分白蜡树300棵，直径6公分白蜡树100棵，急于出售。欢迎电话联系。',
 'sup_phone': '13484667542',
 'sup_user': '闫兆'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-19',
 'info_from': 'http://222.90.83.241/show.aspx?id=168306',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白皮松',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有高度1米白皮松300棵，急于出售。欢迎电话联系。',
 'sup_phone': '13032916618',
 'sup_user': '刘展雄'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168239',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售肉猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售三元肉猪50头，体重120公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15829108410',
 'sup_user': '肖女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168261',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '土鸡蛋',
 'sup_address': '汉中市汉台区七里街道办事处染房营村四组',
 'sup_description': '本人在果园有散养蛋鸡，蛋质优良，无毒无公害，真正的绿色产品，价格优惠，欢迎大家选购。',
 'sup_phone': '13992693136',
 'sup_user': '唐世义'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168311',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜的土鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167968',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '鲜牛奶对外出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村7组',
 'sup_description': '本人饲养奶牛数头，长期对外出售新鲜牛奶，5公里免费送货上门，欢迎订购！',
 'sup_phone': '14791618835',
 'sup_user': '廖宝友'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167981',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售三元生猪',
 'sup_address': '高新区秦渡镇南焦羊村',
 'sup_description': '出售三元生猪30头，单头体重130公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029033406',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=167478',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '土鸡',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡，有意者请与丁先生联系，电话：13689190503。',
 'sup_phone': '13689190503',
 'sup_user': '丁先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167480',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-18',
 'pub_title': '出售红皮鸡蛋',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售红皮鸡蛋65盘，每盘重约4斤，价格面议，欢迎联系。',
 'sup_phone': '15353526258',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167567',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-19',
 'pub_title': '高先生长期供应牛奶',
 'sup_address': '周至县尚村镇马村',
 'sup_description': '高先生长期供应牛奶，价格面议。',
 'sup_phone': '15809220930',
 'sup_user': '高先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167589',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '出售黑狗',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '出售黑色1岁拉布拉多犬1只，价格面议，欢迎联系。',
 'sup_phone': '17791427630',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167638',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售白鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤白鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=167639',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售花鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤花鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167640',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售草鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤草鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167641',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售鲤鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤鲤鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167802',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售鹅蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售鹅蛋50枚，价格面议，欢迎联系。',
 'sup_phone': '15229076911',
 'sup_user': '王女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167846',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '供应羊羔5只',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '供应羊羔5只，单只体重大约25―28公斤，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167930',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售草鱼',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售鲜活草鱼500余条，每条重3斤--7斤，欢迎联系。',
 'sup_phone': '13572072008',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168246',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168097',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售西瓜',
 'sup_address': '鄠邑区蒋村镇同兴村',
 'sup_description': '出售甜王西瓜，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15029807630',
 'sup_user': '陈先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168103',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售杏子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人出售可口香甜的杏子，价格4.5每斤，需求者请联系！',
 'sup_phone': '13892696179',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168124',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '种植露天桃子，味道好，自然熟',
 'sup_address': '汉中市汉台区',
 'sup_description': '自家种植的桃子，口感有清脆和微软两种，味道有纯甜，微酸甜两种，现摘现送无化肥农药，真正绿色无污染，关键是味道好，味道好，味道好！价格面议，欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168133',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售丰园红杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售丰园红早熟杏，面积2.5亩，价格面议，欢迎联系。',
 'sup_phone': '17719535936',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168134',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售樱桃',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售樱桃，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15829462025',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168136',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售金太阳杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售金太阳杏，产量约2500斤，价格随行就市，欢迎联系。',
 'sup_phone': '15353714592',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168219',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售大棚西瓜',
 'sup_address': '庆丰村9组',
 'sup_description': '1、汉台区老君镇庆丰村2组即将大量出售新鲜大棚西瓜，有意者请前来现场订购；2、地址：汉武路中段汉中市红旗机械厂对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=161471',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-14',
 'pub_title': '求购鸭蛋',
 'sup_address': '陕西省西安市周至县集贤镇西村',
 'sup_description': '求购鸭蛋20斤，有货者请联系。',
 'sup_phone': '13519133896',
 'sup_user': '田先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=161762',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-19',
 'pub_title': '求购胸径20-22公分银杏55棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购胸径20-22公分银杏，要求高度7-8米，冠幅4米，数量55棵，有货者电话联系，价格面议。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162023',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购散养100只老母鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购散养老母鸡100只，7--8个月，体重5斤左右，价格合适，欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162045',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购淘汰红毛蛋鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购淘汰红毛蛋鸡800只-均重4.2斤以上，毛色好，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162050',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购各种狗',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '大量求购各种狗，哈士奇、拉布拉多、金毛、萨摩、阿拉斯加、边牧、马犬、博美、比熊等，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=162949',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-03-04',
 'pub_title': '求购羊羔',
 'sup_address': '阎良区关山街道办老王村小马组',
 'sup_description': '上门收购小公羊、母羊羔，价格随行，欢迎联系。',
 'sup_phone': '13759637031',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=163540',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-14',
 'pub_title': '求购鹅蛋',
 'sup_address': '鄠邑区涝店镇马家堡村',
 'sup_description': '求购鹅蛋100枚，价格面议，欢迎联系。',
 'sup_phone': '13484800110',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=164300',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购地径8公分紫薇20棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购地径8公分紫薇20棵，要求分支点60公分以上，有意者请电话联系。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=167967',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '新鲜鸡蛋出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村（工业园区）',
 'sup_description': '本人是养殖专业户，现长期对外出售新鲜鸡蛋，货真价实，量大从优，价格面议！',
 'sup_phone': '18691645043',
 'sup_user': '老徐'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166044',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-22',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166500',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-28',
 'pub_title': '求购土鸡蛋',
 'sup_address': '吴基庄村',
 'sup_description': '需要购买土鸡蛋60个，物美价廉',
 'sup_phone': '13772809382',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '求购一批土鸡鸡苗',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '现需要一批鸡苗（200只），适应本地气候，成活率高的！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=166821',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '收购群羊',
 'sup_address': '陕西省汉中市',
 'sup_description': '大量收购群羊，价格美丽。联系电话（微信）：18828091357。',
 'sup_phone': '18828091357',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=166874',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-06',
 'pub_title': '求购母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购经产母猪5头，要求健康无病，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166929',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋所在地：汉中市汉台区发布时间：2019-04-22求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167294',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购猪仔',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '求购猪仔10头，要求单头重25斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029246927',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=167341',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-16',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '常期收购淘汰母猪，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '吴先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167623',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购鸡蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购红皮鸡蛋400盘，每盘重1.9公斤左右，价格面议，欢迎联系。',
 'sup_phone': '18392549287',
 'sup_user': '曹先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167624',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购青年母鸡',
 'sup_address': '鄠邑区甘河镇北板村',
 'sup_description': '求购海兰褐青年母鸡1500只，要求日龄60天-100天，价格面议，欢迎联系。',
 'sup_phone': '18629514457',
 'sup_user': '董先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168296',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '低价销售直径3-10厘米的樱花树',
 'sup_address': '周至县终南村',
 'sup_description': '低价销售直径3-10厘米的樱花树8亩左右，树形好，价格低，欢迎需求朋友联系。联系：陈女士电话：13119161886地址：周至县终南村',
 'sup_phone': '13119161886',
 'sup_user': '陈女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=168305',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白蜡树',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有直径5公分白蜡树300棵，直径6公分白蜡树100棵，急于出售。欢迎电话联系。',
 'sup_phone': '13484667542',
 'sup_user': '闫兆'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=168241',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '大量求购淘汰母猪，价格随行就市，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-19',
 'info_from': 'http://222.90.83.241/show.aspx?id=168306',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白皮松',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有高度1米白皮松300棵，急于出售。欢迎电话联系。',
 'sup_phone': '13032916618',
 'sup_user': '刘展雄'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168222',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应次杏子丰园红5000斤',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村供应次杏子丰园红5000斤，价钱面议。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168283',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径2-3公分的桂花10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径2-3公分的桂花10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售油桃',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售油桃，个大，味道不错。有意者请与张女士联系。',
 'sup_phone': '18717316979',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168284',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的玉兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的玉兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '预售沙红桃',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村预售沙红桃，有意者前来订购。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168285',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5公分左右的红叶石兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5公分左右的红叶石兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168286',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的早樱10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的早樱10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168233',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应枣花蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应枣花蜜1000斤，一斤20元，价钱面议。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168234',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应洋槐蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应洋槐蜜1000斤，一斤20元。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168266',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '桃子',
 'sup_address': '陕西省汉中市汉台区老君镇徐家营村',
 'sup_description': '现有新鲜桃子5亩桃子属于老品种个头大小合适桃子味道浓甜汁多现在正是出售的季节有需要采摘的或者做生意的可以联系我自己下地采摘价格可以看完水果以后商量非诚勿扰谢谢!',
 'sup_phone': '13379360380',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168292',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '供应金太阳杏1万斤',
 'sup_address': '周至县竹峪镇张龙村',
 'sup_description': '供应金太阳杏1万斤，价格电议。',
 'sup_phone': '18092043194',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=168301',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应阎良优质绿皮甜瓜',
 'sup_address': '西安市阎良区关山街道办界坊村西界组',
 'sup_description': '我家种植的绿皮甜瓜刚上市，单重1-1.5斤，香甜难忘，欢迎你品尝后购买。',
 'sup_phone': '18092295878',
 'sup_user': '郭大英'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168320',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '杏',
 'sup_address': '陕西省汉中市汉台区',
 'sup_description': '好吃的杏子，有想法联系啊',
 'sup_phone': '18829863123',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168322',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '咸阳甜杏',
 'sup_address': '陕西省汉中市陕西理工大学',
 'sup_description': '45一箱，包邮啊',
 'sup_phone': '18409168137',
 'sup_user': '王斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=164508',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-25',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉台区汉王镇大兴村',
 'sup_description': '价格1元每枚',
 'sup_phone': '15129581840',
 'sup_user': '胡生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167215',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '大量求购青李子',
 'sup_address': '周至县马召镇焦家楼村',
 'sup_description': '大量求购青李子,每斤0.25元。',
 'sup_phone': '18229042452',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165873',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-04-19',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办事处王家湾村',
 'sup_description': '要求玉米颗粒饱满，无腐烂、无虫、无沙粒，有意出售的电话联系。',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167216',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '收购李子青果',
 'sup_address': '周至县广济镇南陈村',
 'sup_description': '陈先生大量收购李子青果，不论大小，每斤0.2元，有意者速联系。',
 'sup_phone': '18710430164',
 'sup_user': '陈先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=165984',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '求购红芋苗',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十三组',
 'sup_description': '求购秦薯四号红芋苗15000苗，有出售者请联系。',
 'sup_phone': '15109208586',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-24',
 'info_from': 'http://222.90.83.241/show.aspx?id=167229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-14',
 'pub_title': '大量收购青李子',
 'sup_address': '周至县广济镇桑园村',
 'sup_description': '大量收购青李子，每斤0.25元联系人:王女士电话:85121695地址:周至县广济镇桑园村',
 'sup_phone': '85121695',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166662',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-30',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有数千斤大米，有合适的价格请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167427',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-17',
 'pub_title': '求购杏',
 'sup_address': '周至县楼观镇下三清村',
 'sup_description': '求购杏，丰园红，金太阳等，有意向者电话联系。',
 'sup_phone': '15091861572',
 'sup_user': '康先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167664',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-21',
 'pub_title': '求购青李子',
 'sup_address': '周至县马召镇熨斗村',
 'sup_description': '求购青李子，有意者电话联系。',
 'sup_phone': '18700828599',
 'sup_user': '赵女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=167478',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '土鸡',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡，有意者请与丁先生联系，电话：13689190503。',
 'sup_phone': '13689190503',
 'sup_user': '丁先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167716',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-22',
 'pub_title': '求购青李子1万斤',
 'sup_address': '周至县广济镇商家磨村',
 'sup_description': '求购青李子1万斤，价格面议',
 'sup_phone': '13700245778',
 'sup_user': '潘女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167480',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-18',
 'pub_title': '出售红皮鸡蛋',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售红皮鸡蛋65盘，每盘重约4斤，价格面议，欢迎联系。',
 'sup_phone': '15353526258',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=161136',
 'pub_address': '西安市周至县',
 'pub_time': '2019-01-30',
 'pub_title': '求购80-120克秦美猕猴桃30000斤',
 'sup_address': '周至县四屯镇三联村中二屯',
 'sup_description': '求购80-120克库存秦美猕猴桃30000斤，有出售者请联系。',
 'sup_phone': '13572903928',
 'sup_user': '薛智军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167567',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-19',
 'pub_title': '高先生长期供应牛奶',
 'sup_address': '周至县尚村镇马村',
 'sup_description': '高先生长期供应牛奶，价格面议。',
 'sup_phone': '15809220930',
 'sup_user': '高先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=161643',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-17',
 'pub_title': '求购霉烂猕猴桃',
 'sup_address': '周至县二曲镇孟家村',
 'sup_description': '大量求购霉烂猕猴桃。价格面议。',
 'sup_phone': '13659209629',
 'sup_user': '郝先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=162466',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-26',
 'pub_title': '求购徐香猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '求购带把徐香猕猴桃200000斤，看货谈价。',
 'sup_phone': '13572526437',
 'sup_user': '吕先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167589',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '出售黑狗',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '出售黑色1岁拉布拉多犬1只，价格面议，欢迎联系。',
 'sup_phone': '17791427630',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167638',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售白鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤白鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168018',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购高5.0米以上的白皮松13棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高5.0米以上的白皮松13棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=167639',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售花鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤花鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168022',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购胸径4公分的国槐50棵',
 'sup_address': '周至县翠峰镇农林村四组',
 'sup_description': '求购胸径4公分的国槐50棵。',
 'sup_phone': '15399480380',
 'sup_user': '侯女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167640',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售草鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤草鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168039',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径14公分银杏350棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径14公分银杏350棵，要求分支点2.8-3.5米，带土球90公分，有货的朋友请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168042',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径12公分香花槐200棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径12公分香花槐200棵，要求分支点2.8米以上，树杆端直，树冠优美，有货者请尽快联系，看货议价。',
 'sup_phone': '18229025186',
 'sup_user': '毛先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167641',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售鲤鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤鲤鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167792',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售三元仔猪',
 'sup_address': '鄠邑区玉蝉街办割耳庄村',
 'sup_description': '出售三元仔猪10头，每头体重15公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15229279068',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168047',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径10公分红叶碧桃20棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径10公分红叶碧桃20棵，要求大半冠，树干端直，带土球80公分，有货者请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167802',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售鹅蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售鹅蛋50枚，价格面议，欢迎联系。',
 'sup_phone': '15229076911',
 'sup_user': '王女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168049',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分国槐32棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分国槐32棵，要求分支点2.5-3米，4米原生冠，带常规土球，有货的朋友请尽快联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:04:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167846',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '供应羊羔5只',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '供应羊羔5只，单只体重大约25―28公斤，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168051',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分七叶树42棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分七叶树42棵，要求分支点2.8-3.2米，4米原生冠，带常规土球，有货者请速联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:04:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167930',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售草鱼',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售鲜活草鱼500余条，每条重3斤--7斤，欢迎联系。',
 'sup_phone': '13572072008',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168115',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购白皮松',
 'sup_address': '周至县二曲街道办事处李家村',
 'sup_description': '本处现急需求购一米起步老芽三级18碗碗白皮松，一车装7000株，有货请电话联系。',
 'sup_phone': '13759925466',
 'sup_user': '李朝辉'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:04:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=167967',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '新鲜鸡蛋出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村（工业园区）',
 'sup_description': '本人是养殖专业户，现长期对外出售新鲜鸡蛋，货真价实，量大从优，价格面议！',
 'sup_phone': '18691645043',
 'sup_user': '老徐'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:04:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168137',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购高1.5米以上的塔柏200棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高1.5米以上的塔柏200棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167968',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '鲜牛奶对外出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村7组',
 'sup_description': '本人饲养奶牛数头，长期对外出售新鲜牛奶，5公里免费送货上门，欢迎订购！',
 'sup_phone': '14791618835',
 'sup_user': '廖宝友'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168191',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购银杏胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购银杏胸径20至22公分，要求，冠副4米，高8米至8米5.1.5米的土球，总数量636颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167981',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售三元生猪',
 'sup_address': '高新区秦渡镇南焦羊村',
 'sup_description': '出售三元生猪30头，单头体重130公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029033406',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168193',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购雪松6至7米',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购雪松6至7米，冠幅2米至2.5，1.2米土球，总数量，235颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168239',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售肉猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售三元肉猪50头，体重120公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15829108410',
 'sup_user': '肖女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168246',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168195',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购七叶树',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购七叶树，胸径15至18公分，要求1.5米土球，数量826颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168261',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '土鸡蛋',
 'sup_address': '汉中市汉台区七里街道办事处染房营村四组',
 'sup_description': '本人在果园有散养蛋鸡，蛋质优良，无毒无公害，真正的绿色产品，价格优惠，欢迎大家选购。',
 'sup_phone': '13992693136',
 'sup_user': '唐世义'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168197',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购国槐胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购国槐，胸径20至22公分，1.5米土球，数量689颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168198',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购广玉兰胸径18至20公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购广玉兰胸径18至20公分，1.5米土球，数量，365颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168311',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜的土鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166923',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市汉台区发布时间：2019-04-04购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168199',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购法桐胸径15至17公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购法桐，胸径15至17公分，1.5米土球，数量804颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167237',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-14',
 'pub_title': '求购玉米',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '需要购买一批玉米，用作养殖场鸡饲料,电话联系！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168200',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购桂花树胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购桂花树，胸径12至14公分，1.2米土球，数量1568颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167452',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-17',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米5000公斤，要求干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '15229382221',
 'sup_user': '谭先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168201',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购字画木槿地径5至7公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购字画木槿地径5至7公分，1米土球，数量1478颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167580',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米3000公斤，要求水份14%以内，干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '18706733154',
 'sup_user': '高先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168202',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购红宝石海棠胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购红宝石海棠胸径12至14公分，1.2米土球，数量1706颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167644',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '油菜籽',
 'sup_address': '陕西汉中',
 'sup_description': '大量新鲜油菜籽出售',
 'sup_phone': '18292654661',
 'sup_user': '丁女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168203',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购大叶女贞胸径10至12公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购大叶女贞，胸径10至12公分，1.2米土球，数量1348颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168148',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '15891399228',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=168279',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '求购胸径4公分高杆石楠600棵',
 'sup_address': '周至县马召镇桃李坪村',
 'sup_description': '求购胸径4公分高杆石楠600棵，分枝点1.5米，有货请电话联系。',
 'sup_phone': '13891948456',
 'sup_user': '郭新峰'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168151',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤.优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=162467',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-26',
 'pub_title': '求购海沃德猕猴桃',
 'sup_address': '周至县楼观镇西会村',
 'sup_description': '求购海沃德猕猴桃买整库或者单车均可，要硬度好，看货谈价。',
 'sup_phone': '13689205889',
 'sup_user': '田先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=158381',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-07',
 'pub_title': '求购野山药',
 'sup_address': '佛坪县陈家坝镇金星村二组',
 'sup_description': '求购野生山药，平均价格10元每斤，量大从优，',
 'sup_phone': '17730778050',
 'sup_user': '刘和秀'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=164225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-21',
 'pub_title': '大量求购海沃德猕猴桃次果',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现大量求购海沃德猕猴桃次果，价格面谈。',
 'sup_phone': '18792637406',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=158576',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-10',
 'pub_title': '求购魔芋5000斤',
 'sup_address': '西安市周至县楼观镇上三清村',
 'sup_description': '我处急需魔芋，数量5000斤，每个200克以上，有意者，请尽快联系。',
 'sup_phone': '13474110275',
 'sup_user': '刘俊锋'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-17',
 'info_from': 'http://222.90.83.241/show.aspx?id=164737',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-29',
 'pub_title': '求购90起步海沃德猕猴桃5万斤',
 'sup_address': '西安市马召镇仁烟村',
 'sup_description': '求购90起步海沃德猕猴桃5万斤，欢迎联系！',
 'sup_phone': '15191915106',
 'sup_user': '陈先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=158659',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-11',
 'pub_title': '大量收购乌笋种子',
 'sup_address': '汉中市佛坪县',
 'sup_description': '大量收购乌笋种子，土名：洋嚯。联系电话：13991608711/13892652745',
 'sup_phone': '13991608711',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166050',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-22',
 'pub_title': '大量收购甜瓜',
 'sup_address': '西安市阎良区关山街道办老王村西北组（原老王村小学院内）',
 'sup_description': '大量收购甜瓜，以质论价，欢迎联系销售。',
 'sup_phone': '15094000816',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158760',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-12',
 'pub_title': '大量求购线辣椒',
 'sup_address': '西安市阎良区关山镇关山村',
 'sup_description': '大量收购线辣椒，红绿均可，价格面议，欢迎联系。',
 'sup_phone': '18392532698',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=166814',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-05',
 'pub_title': '大量收购“芝麻蜜”甜瓜',
 'sup_address': '西安市阎良区关山街道办北十字口西北角',
 'sup_description': '大量收购阎良“芝麻蜜”、小籽甜瓜，价格随行就市，欢迎广大瓜农联系销售。',
 'sup_phone': '13347409123',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158830',
 'pub_address': '汉中市汉台区',
 'pub_time': '2018-12-13',
 'pub_title': '求购洋芋种',
 'sup_address': '汉中市汉台区七里办事处文庙村',
 'sup_description': '黄先生等户求购洋芋种；品种有；荷兰洋芋、早大白洋芋。有货源的客户快来村联系，价格面议，数量不限。联系人；黄先生，地址；汉中市汉台区七里办事处文庙村，电话；13084883593.文庙村信息站发。',
 'sup_phone': '13084883593',
 'sup_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=167005',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-08',
 'pub_title': '求购猕猴桃公花粉3斤',
 'sup_address': '周至县哑柏镇上阳化村',
 'sup_description': '急求猕猴桃公花粉3斤，价格面议。',
 'sup_phone': '13609203888',
 'sup_user': '陈女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=160928',
 'pub_address': '西安市户县',
 'pub_time': '2019-01-24',
 'pub_title': '求购大葱',
 'sup_address': '鄠邑区玉蝉镇新向村',
 'sup_description': '求购大葱100斤，欢迎联系。',
 'sup_phone': '15091671829',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167150',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '大量收购青李子',
 'sup_address': '陕西周至广济上二屯村',
 'sup_description': '大量收购青李子，每斤0.25元。',
 'sup_phone': '18229042452',
 'sup_user': '刘师傅'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165085',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-08',
 'pub_title': '大量收购甘蓝菜',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购甘蓝菜，要求单重2斤以上，价格随行就市，欢迎联系销售。',
 'sup_phone': '15291452658',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167169',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '求购青李子',
 'sup_address': '周至县富仁镇永丰村',
 'sup_description': '求购青李子。数量价格面议。',
 'sup_phone': '13201591625',
 'sup_user': '李先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165124',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜蒜苔',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜蒜苔，日收购5吨，限陕西西安境内，有意者请联系，价格面议。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165126',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜香椿',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜香椿芽，有意者请联系价格面议，限西安辖区内，',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167879',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菜油',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十四组',
 'sup_description': '我处有200斤菜油出售，有需求者电话联系。',
 'sup_phone': '15991614124',
 'sup_user': '闫先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167941',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售玉米',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售玉米3000斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=165934',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '收购洋槐花',
 'sup_address': '周至县楼观镇团标村',
 'sup_description': '收购洋槐花，有意者电话联系。',
 'sup_phone': '15091527877',
 'sup_user': '谢女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168007',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售2019新收小麦',
 'sup_address': '汉台区七里街道马家坝村一组',
 'sup_description': '家有2019年应季新收小麦800斤需出售，有意者请于我联系，电话13891622698',
 'sup_phone': '13891622698',
 'sup_user': '衡正斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=166016',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-21',
 'pub_title': '求购紫薯苗',
 'sup_address': '周至县尚村镇新范村',
 'sup_description': '求购紫薯苗两万个，可以电话报价，有货及时联系',
 'sup_phone': '13619226724',
 'sup_user': '孙先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168037',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售菜籽、小麦',
 'sup_address': '汉台区老君镇王道池村',
 'sup_description': '现有刚收获的小麦、菜籽。价格随市场。联系电话：18891618650联系人李先生',
 'sup_phone': '18891618650',
 'sup_user': '李新华'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=166051',
 'pub_address': '西安市户县',
 'pub_time': '2019-04-22',
 'pub_title': '求购小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '求购小葱秧200斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168081',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '优质菜籽',
 'sup_address': '汉台区武乡镇崔营村',
 'sup_description': '本村大量上市2019年优质油菜籽，量大、质量优，有意者来电咨询洽谈',
 'sup_phone': '18220666628',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166675',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-30',
 'pub_title': '求购鲜洋槐花',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜洋槐花，数量不限，限西安境内，有意者请联系，量大可上门取货。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168104',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=161471',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-14',
 'pub_title': '求购鸭蛋',
 'sup_address': '陕西省西安市周至县集贤镇西村',
 'sup_description': '求购鸭蛋20斤，有货者请联系。',
 'sup_phone': '13519133896',
 'sup_user': '田先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167878',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售土豆',
 'sup_address': '陕西省西安市周至县尚村镇张寨村八组',
 'sup_description': '我处有3亩地土豆出售，有需求者请联系。',
 'sup_phone': '18729974792',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=161762',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-19',
 'pub_title': '求购胸径20-22公分银杏55棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购胸径20-22公分银杏，要求高度7-8米，冠幅4米，数量55棵，有货者电话联系，价格面议。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162023',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购散养100只老母鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购散养老母鸡100只，7--8个月，体重5斤左右，价格合适，欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168117',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-28',
 'pub_title': '出售油菜籽',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售油菜籽约600斤，价格面议，欢迎联系。',
 'sup_phone': '13572583121',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168123',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '汉台区武乡镇同心村',
 'sup_description': '大量今年新油菜籽出售，地址：汉台区武乡镇同心。联系电话：18710666754张女士',
 'sup_phone': '18710666754',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162045',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购淘汰红毛蛋鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购淘汰红毛蛋鸡800只-均重4.2斤以上，毛色好，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168130',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有油菜籽出售，无杂质、无霉粒，数吨如有需求者请与我联系，联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162050',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购各种狗',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '大量求购各种狗，哈士奇、拉布拉多、金毛、萨摩、阿拉斯加、边牧、马犬、博美、比熊等，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168132',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '小麦',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有大量小麦出售，质优无杂质颗粒饱满，如有需求者请与李先生联系。联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇共力村九组。',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=168154',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '菜籽',
 'sup_address': '汉台区老君镇',
 'sup_description': '菜籽色泽鲜亮.颗粒饱满',
 'sup_phone': '13379361068',
 'sup_user': '黄女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168097',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售西瓜',
 'sup_address': '鄠邑区蒋村镇同兴村',
 'sup_description': '出售甜王西瓜，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15029807630',
 'sup_user': '陈先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168103',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售杏子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人出售可口香甜的杏子，价格4.5每斤，需求者请联系！',
 'sup_phone': '13892696179',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168213',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售新小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，欢迎联系。',
 'sup_phone': '18792949262',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168124',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '种植露天桃子，味道好，自然熟',
 'sup_address': '汉中市汉台区',
 'sup_description': '自家种植的桃子，口感有清脆和微软两种，味道有纯甜，微酸甜两种，现摘现送无化肥农药，真正绿色无污染，关键是味道好，味道好，味道好！价格面议，欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168247',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大量大米，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168133',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售丰园红杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售丰园红早熟杏，面积2.5亩，价格面议，欢迎联系。',
 'sup_phone': '17719535936',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168134',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售樱桃',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售樱桃，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15829462025',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168268',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '现有今年新油菜籽3000斤左右颗粒饱满油菜籽颜色黑已经处理干净小灰尘出油率高油菜籽完全晒干发的有图片但仅为参考还是要看实际货物如有需要者可以和我联系非诚勿扰!',
 'sup_phone': '18700657341',
 'sup_user': '龙女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168136',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售金太阳杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售金太阳杏，产量约2500斤，价格随行就市，欢迎联系。',
 'sup_phone': '15353714592',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168310',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大米，请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168319',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售油菜籽',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '有2019年出产的油菜籽2000斤欲对外出售，菜籽干度好，出油率高，如有购买者请联系，价格面议。',
 'sup_phone': '18391619491',
 'sup_user': '苟建荣'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168321',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售小麦',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '本人有2019年出产小麦2000斤现对外出售，麦子干度好，色泽鲜亮。如有需要者请联系。',
 'sup_phone': '13259287568',
 'sup_user': '孙培军'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168219',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售大棚西瓜',
 'sup_address': '庆丰村9组',
 'sup_description': '1、汉台区老君镇庆丰村2组即将大量出售新鲜大棚西瓜，有意者请前来现场订购；2、地址：汉武路中段汉中市红旗机械厂对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168222',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应次杏子丰园红5000斤',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村供应次杏子丰园红5000斤，价钱面议。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售油桃',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售油桃，个大，味道不错。有意者请与张女士联系。',
 'sup_phone': '18717316979',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167792',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售三元仔猪',
 'sup_address': '鄠邑区玉蝉街办割耳庄村',
 'sup_description': '出售三元仔猪10头，每头体重15公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15229279068',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '预售沙红桃',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村预售沙红桃，有意者前来订购。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168304',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应西红柿',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '本人家有3亩温室西红柿成熟出售，货源、品质保证，价格面议，欢迎各地客商联系收购。',
 'sup_phone': '18092632479',
 'sup_user': '刘文'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167847',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购金太阳杏子1.5万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购金太阳杏子1.5万斤，要求个大，价格面议。',
 'sup_phone': '18710683521',
 'sup_user': '宋先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=167817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-24',
 'pub_title': '魔芋出售',
 'sup_address': '陈家坝镇孔家湾村一组',
 'sup_description': '因土地用作它途，最近亟待出售一批魔芋，价格好商量！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168234',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应洋槐蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应洋槐蜜1000斤，一斤20元。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167893',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菠菜',
 'sup_address': '鄠邑区渭丰镇定五村',
 'sup_description': '出售菠菜4000斤，价格面议，欢迎联系。',
 'sup_phone': '18710978332',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168266',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '桃子',
 'sup_address': '陕西省汉中市汉台区老君镇徐家营村',
 'sup_description': '现有新鲜桃子5亩桃子属于老品种个头大小合适桃子味道浓甜汁多现在正是出售的季节有需要采摘的或者做生意的可以联系我自己下地采摘价格可以看完水果以后商量非诚勿扰谢谢!',
 'sup_phone': '13379360380',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167894',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘亭街办南羊村',
 'sup_description': '出售韭菜，面积10亩，价格面议，欢迎联系。',
 'sup_phone': '13572179512',
 'sup_user': '周女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168292',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '供应金太阳杏1万斤',
 'sup_address': '周至县竹峪镇张龙村',
 'sup_description': '供应金太阳杏1万斤，价格电议。',
 'sup_phone': '18092043194',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167895',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售矮青菜',
 'sup_address': '鄠邑区渭丰镇定六村',
 'sup_description': '出售矮青菜3000斤，价格面议，欢迎联系。',
 'sup_phone': '13109617130',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168026',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '蔬菜出售',
 'sup_address': '老君镇拐拐村',
 'sup_description': '大量出售西红柿与黄瓜，各3000斤左右。欢迎选购。',
 'sup_phone': '18591612273',
 'sup_user': '秦小强'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=168301',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应阎良优质绿皮甜瓜',
 'sup_address': '西安市阎良区关山街道办界坊村西界组',
 'sup_description': '我家种植的绿皮甜瓜刚上市，单重1-1.5斤，香甜难忘，欢迎你品尝后购买。',
 'sup_phone': '18092295878',
 'sup_user': '郭大英'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168320',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '杏',
 'sup_address': '陕西省汉中市汉台区',
 'sup_description': '好吃的杏子，有想法联系啊',
 'sup_phone': '18829863123',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168040',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应架豆王',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应架豆王300斤。',
 'sup_phone': '18092634616',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168322',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '咸阳甜杏',
 'sup_address': '陕西省汉中市陕西理工大学',
 'sup_description': '45一箱，包邮啊',
 'sup_phone': '18409168137',
 'sup_user': '王斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167804',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜出售',
 'sup_address': '新校村',
 'sup_description': '现有大量新鲜蔬菜出售，批发零售皆可，主要有辣椒，西红柿，豆角，西蓝花等若有需要的请和我联系。',
 'sup_phone': '15760959624',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167815',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜',
 'sup_address': '汉台区铺镇锦福专业蔬菜合作社',
 'sup_description': '我村锦福蔬菜合作社现有:西葫芦、黄瓜、辣椒、茄子、西红柿对外批发出售；（可组织整车货源）欢迎新老客户前来订购！',
 'sup_phone': '13038477096',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=162949',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-03-04',
 'pub_title': '求购羊羔',
 'sup_address': '阎良区关山街道办老王村小马组',
 'sup_description': '上门收购小公羊、母羊羔，价格随行，欢迎联系。',
 'sup_phone': '13759637031',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=163540',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-14',
 'pub_title': '求购鹅蛋',
 'sup_address': '鄠邑区涝店镇马家堡村',
 'sup_description': '求购鹅蛋100枚，价格面议，欢迎联系。',
 'sup_phone': '13484800110',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168041',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售芥兰',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售芥兰菜6000斤左右，价格面议，欢迎联系。',
 'sup_phone': '18192003238',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168043',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应西红柿',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应西红柿500斤。',
 'sup_phone': '15829468093',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=164300',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购地径8公分紫薇20棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购地径8公分紫薇20棵，要求分支点60公分以上，有意者请电话联系。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168108',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应大蒜100斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '供应大蒜100斤.新蒜。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167804',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜出售',
 'sup_address': '新校村',
 'sup_description': '现有大量新鲜蔬菜出售，批发零售皆可，主要有辣椒，西红柿，豆角，西蓝花等若有需要的请和我联系。',
 'sup_phone': '15760959624',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167815',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜',
 'sup_address': '汉台区铺镇锦福专业蔬菜合作社',
 'sup_description': '我村锦福蔬菜合作社现有:西葫芦、黄瓜、辣椒、茄子、西红柿对外批发出售；（可组织整车货源）欢迎新老客户前来订购！',
 'sup_phone': '13038477096',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168125',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '出售土豆，天然产出',
 'sup_address': '汉中市汉台区',
 'sup_description': '出售纯天然土豆，粉糯可口，个头匀称，表面光滑，现挖先发价格面议欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=167817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-24',
 'pub_title': '魔芋出售',
 'sup_address': '陈家坝镇孔家湾村一组',
 'sup_description': '因土地用作它途，最近亟待出售一批魔芋，价格好商量！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168129',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '供给优质土豆',
 'sup_address': '陕西省汉中市汉台区宗营镇下寨村三组',
 'sup_description': '自家种植一亩品种为早大白的土豆，现已成熟，大约有1500斤需将其出售。有意者请联系本人。',
 'sup_phone': '18829662083',
 'sup_user': '黄玉莲'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168145',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售韭菜600斤，价格面议，欢迎联系。',
 'sup_phone': '15902991386',
 'sup_user': '马先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167893',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菠菜',
 'sup_address': '鄠邑区渭丰镇定五村',
 'sup_description': '出售菠菜4000斤，价格面议，欢迎联系。',
 'sup_phone': '18710978332',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167894',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘亭街办南羊村',
 'sup_description': '出售韭菜，面积10亩，价格面议，欢迎联系。',
 'sup_phone': '13572179512',
 'sup_user': '周女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168146',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售小葱秧800斤，价格面议，欢迎联系。',
 'sup_phone': '13772449091',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168105',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167895',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售矮青菜',
 'sup_address': '鄠邑区渭丰镇定六村',
 'sup_description': '出售矮青菜3000斤，价格面议，欢迎联系。',
 'sup_phone': '13109617130',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168026',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '蔬菜出售',
 'sup_address': '老君镇拐拐村',
 'sup_description': '大量出售西红柿与黄瓜，各3000斤左右。欢迎选购。',
 'sup_phone': '18591612273',
 'sup_user': '秦小强'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167849',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购进口海沃德猕猴桃2万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购进口海沃德猕猴桃2万斤，要求80克起步，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168040',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应架豆王',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应架豆王300斤。',
 'sup_phone': '18092634616',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168221',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '求购油桃5000斤',
 'sup_address': '周至县广济镇南留村',
 'sup_description': '求购油桃5000斤，要求色红脆甜，价格面议，有货的速联系。',
 'sup_phone': '17389206678',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168041',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售芥兰',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售芥兰菜6000斤左右，价格面议，欢迎联系。',
 'sup_phone': '18192003238',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168312',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '出售大蒜',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售红皮大蒜约400斤，价格面议，欢迎联系。',
 'sup_phone': '13571840519',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168043',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应西红柿',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应西红柿500斤。',
 'sup_phone': '15829468093',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168108',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应大蒜100斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '供应大蒜100斤.新蒜。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168293',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '大量出售架豆王',
 'sup_address': '西安市绿康果蔬苗木专业合作社',
 'sup_description': '出售架豆王60多亩，长度20-30厘米左右，质量好，价格低，欢迎联系。联系：蒲经理电话：13201689888地址：西安市绿康果蔬苗木专业合作社',
 'sup_phone': '13201689888',
 'sup_user': '蒲经理'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168125',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '出售土豆，天然产出',
 'sup_address': '汉中市汉台区',
 'sup_description': '出售纯天然土豆，粉糯可口，个头匀称，表面光滑，现挖先发价格面议欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168220',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售新鲜大棚秀珍菇',
 'sup_address': '庆丰村1组',
 'sup_description': '1、汉台区老君镇庆丰村1组大量出售新鲜大棚秀珍菇，有意者请面议；2、地址：汉武路中段陕西省汇力园区对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168129',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '供给优质土豆',
 'sup_address': '陕西省汉中市汉台区宗营镇下寨村三组',
 'sup_description': '自家种植一亩品种为早大白的土豆，现已成熟，大约有1500斤需将其出售。有意者请联系本人。',
 'sup_phone': '18829662083',
 'sup_user': '黄玉莲'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168145',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售韭菜600斤，价格面议，欢迎联系。',
 'sup_phone': '15902991386',
 'sup_user': '马先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
le'
2019-06-04 00:05:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168146',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售小葱秧800斤，价格面议，欢迎联系。',
 'sup_phone': '13772449091',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168170',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-30',
 'pub_title': '蒲瓜',
 'sup_address': '汉台区铺镇芦坝村一组',
 'sup_description': '我现有蒲瓜4000斤出售，批发价0.8元/每斤。',
 'sup_phone': '13630267456',
 'sup_user': '魏小民'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168220',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售新鲜大棚秀珍菇',
 'sup_address': '庆丰村1组',
 'sup_description': '1、汉台区老君镇庆丰村1组大量出售新鲜大棚秀珍菇，有意者请面议；2、地址：汉武路中段陕西省汇力园区对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168293',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '大量出售架豆王',
 'sup_address': '西安市绿康果蔬苗木专业合作社',
 'sup_description': '出售架豆王60多亩，长度20-30厘米左右，质量好，价格低，欢迎联系。联系：蒲经理电话：13201689888地址：西安市绿康果蔬苗木专业合作社',
 'sup_phone': '13201689888',
 'sup_user': '蒲经理'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168304',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应西红柿',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '本人家有3亩温室西红柿成熟出售，货源、品质保证，价格面议，欢迎各地客商联系收购。',
 'sup_phone': '18092632479',
 'sup_user': '刘文'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168312',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '出售大蒜',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售红皮大蒜约400斤，价格面议，欢迎联系。',
 'sup_phone': '13571840519',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:05:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=164508',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-25',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉台区汉王镇大兴村',
 'sup_description': '价格1元每枚',
 'sup_phone': '15129581840',
 'sup_user': '胡生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166044',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-22',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166500',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-28',
 'pub_title': '求购土鸡蛋',
 'sup_address': '吴基庄村',
 'sup_description': '需要购买土鸡蛋60个，物美价廉',
 'sup_phone': '13772809382',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '求购一批土鸡鸡苗',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '现需要一批鸡苗（200只），适应本地气候，成活率高的！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=166821',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '收购群羊',
 'sup_address': '陕西省汉中市',
 'sup_description': '大量收购群羊，价格美丽。联系电话（微信）：18828091357。',
 'sup_phone': '18828091357',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=166874',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-06',
 'pub_title': '求购母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购经产母猪5头，要求健康无病，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166929',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋所在地：汉中市汉台区发布时间：2019-04-22求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167294',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购猪仔',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '求购猪仔10头，要求单头重25斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029246927',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:05:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=167341',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-16',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '常期收购淘汰母猪，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '吴先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167623',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购鸡蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购红皮鸡蛋400盘，每盘重1.9公斤左右，价格面议，欢迎联系。',
 'sup_phone': '18392549287',
 'sup_user': '曹先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167624',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购青年母鸡',
 'sup_address': '鄠邑区甘河镇北板村',
 'sup_description': '求购海兰褐青年母鸡1500只，要求日龄60天-100天，价格面议，欢迎联系。',
 'sup_phone': '18629514457',
 'sup_user': '董先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=168241',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '大量求购淘汰母猪，价格随行就市，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167311',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购葱秧',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购葱秧30公斤，品种不限，价格面议，欢迎联系。',
 'sup_phone': '18966810872',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-17',
 'info_from': 'http://222.90.83.241/show.aspx?id=167415',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-17',
 'pub_title': '求购藕种',
 'sup_address': '汉台区老君镇付庙村六组',
 'sup_description': '大量求购优质藕种！',
 'sup_phone': '13571611661',
 'sup_user': '张伟'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167848',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购大蒜5万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购大蒜5万斤，要求个大，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168318',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '小辣子',
 'sup_address': '汉台区七里办事处金江2组',
 'sup_description': '王先生家中种植了各种蔬菜,小辣子已经成熟,正在大量出售,如有需求,请电话联系',
 'sup_phone': '15891461382',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168275',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高60公分大田侧柏1.5万株',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：高60公分大田侧柏1.5万株，价格面议，欢迎联系。',
 'sup_phone': '15877344352',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168276',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径1公分国槐3000棵',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：胸径1公分国槐3000棵，价格面议，欢迎联系。',
 'sup_phone': '13092046069',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168277',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径15公分龙爪槐20棵',
 'sup_address': '周至县四屯镇联三村',
 'sup_description': '出售：胸径15公分龙爪槐20棵，价格面议，欢迎联系。',
 'sup_phone': '15091151300',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=168278',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高80公分兰天竹营养钵3500株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：高80公分兰天竹营养钵3500株，价格面议，欢迎联系。',
 'sup_phone': '15319458368',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168280',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售直径3公分左右的大叶女贞10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售直径3公分左右的大叶女贞10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168281',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分以上的红梅10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分以上的红梅10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168282',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径3-4公分以上的红枫10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径3-4公分以上的红枫10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168287',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分的嫁接红梅20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分的嫁接红梅20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168288',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-7公分的香花槐20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-7公分的香花槐20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168289',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高3米以上的油松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高3米以上的油松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168290',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高1米左右的白皮松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高1米左右的白皮松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168291',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售毛竹10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售毛竹10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168310',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大米，请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168319',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售油菜籽',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '有2019年出产的油菜籽2000斤欲对外出售，菜籽干度好，出油率高，如有购买者请联系，价格面议。',
 'sup_phone': '18391619491',
 'sup_user': '苟建荣'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168321',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售小麦',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '本人有2019年出产小麦2000斤现对外出售，麦子干度好，色泽鲜亮。如有需要者请联系。',
 'sup_phone': '13259287568',
 'sup_user': '孙培军'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168117',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-28',
 'pub_title': '出售油菜籽',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售油菜籽约600斤，价格面议，欢迎联系。',
 'sup_phone': '13572583121',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168123',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '汉台区武乡镇同心村',
 'sup_description': '大量今年新油菜籽出售，地址：汉台区武乡镇同心。联系电话：18710666754张女士',
 'sup_phone': '18710666754',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168130',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有油菜籽出售，无杂质、无霉粒，数吨如有需求者请与我联系，联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168132',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '小麦',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有大量小麦出售，质优无杂质颗粒饱满，如有需求者请与李先生联系。联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇共力村九组。',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=168154',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '菜籽',
 'sup_address': '汉台区老君镇',
 'sup_description': '菜籽色泽鲜亮.颗粒饱满',
 'sup_phone': '13379361068',
 'sup_user': '黄女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168156',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，价格随行就市，欢迎联系。',
 'sup_phone': '13991942437',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167878',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售土豆',
 'sup_address': '陕西省西安市周至县尚村镇张寨村八组',
 'sup_description': '我处有3亩地土豆出售，有需求者请联系。',
 'sup_phone': '18729974792',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167879',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菜油',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十四组',
 'sup_description': '我处有200斤菜油出售，有需求者电话联系。',
 'sup_phone': '15991614124',
 'sup_user': '闫先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168268',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '现有今年新油菜籽3000斤左右颗粒饱满油菜籽颜色黑已经处理干净小灰尘出油率高油菜籽完全晒干发的有图片但仅为参考还是要看实际货物如有需要者可以和我联系非诚勿扰!',
 'sup_phone': '18700657341',
 'sup_user': '龙女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=159779',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-29',
 'pub_title': '求购200克以上魔芋5000斤',
 'sup_address': '周至县厚畛子镇同力村',
 'sup_description': '求购200克以上魔芋5000斤联系人:黄先生电话：１３４７４１１０２７５地址：周至县厚畛子镇同力村。',
 'sup_phone': '13474110275',
 'sup_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:06:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168233',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应枣花蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应枣花蜜1000斤，一斤20元，价钱面议。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    data = (item['pub_title'],item['sup_description'],item['end_time'],'',item['sup_phone'],item['sup_user'],'陕西省农村信息站监管系统','供应')
KeyError: 'pub_title'
2019-06-04 00:06:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=165372',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-11',
 'pub_title': '收购莲花白、螺丝辣椒',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购莲花白、螺丝辣椒，价格面议，欢迎广大菜农联系销售。',
 'sup_phone': '13474363373',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 144, in process_item
KeyError: 'pub_title'
2019-06-04 00:44:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168284',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的玉兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的玉兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168285',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5公分左右的红叶石兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5公分左右的红叶石兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168286',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的早樱10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的早樱10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168287',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分的嫁接红梅20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分的嫁接红梅20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168288',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-7公分的香花槐20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-7公分的香花槐20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168289',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高3米以上的油松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高3米以上的油松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168290',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高1米左右的白皮松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高1米左右的白皮松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165873',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-04-19',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办事处王家湾村',
 'sup_description': '要求玉米颗粒饱满，无腐烂、无虫、无沙粒，有意出售的电话联系。',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=165984',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '求购红芋苗',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十三组',
 'sup_description': '求购秦薯四号红芋苗15000苗，有出售者请联系。',
 'sup_phone': '15109208586',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166662',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-30',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有数千斤大米，有合适的价格请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166923',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市汉台区发布时间：2019-04-04购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167237',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-14',
 'pub_title': '求购玉米',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '需要购买一批玉米，用作养殖场鸡饲料,电话联系！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167580',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米3000公斤，要求水份14%以内，干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '18706733154',
 'sup_user': '高先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167644',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '油菜籽',
 'sup_address': '陕西汉中',
 'sup_description': '大量新鲜油菜籽出售',
 'sup_phone': '18292654661',
 'sup_user': '丁女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168148',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '15891399228',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168151',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤.优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=158381',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-07',
 'pub_title': '求购野山药',
 'sup_address': '佛坪县陈家坝镇金星村二组',
 'sup_description': '求购野生山药，平均价格10元每斤，量大从优，',
 'sup_phone': '17730778050',
 'sup_user': '刘和秀'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=158576',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-10',
 'pub_title': '求购魔芋5000斤',
 'sup_address': '西安市周至县楼观镇上三清村',
 'sup_description': '我处急需魔芋，数量5000斤，每个200克以上，有意者，请尽快联系。',
 'sup_phone': '13474110275',
 'sup_user': '刘俊锋'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158760',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-12',
 'pub_title': '大量求购线辣椒',
 'sup_address': '西安市阎良区关山镇关山村',
 'sup_description': '大量收购线辣椒，红绿均可，价格面议，欢迎联系。',
 'sup_phone': '18392532698',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158830',
 'pub_address': '汉中市汉台区',
 'pub_time': '2018-12-13',
 'pub_title': '求购洋芋种',
 'sup_address': '汉中市汉台区七里办事处文庙村',
 'sup_description': '黄先生等户求购洋芋种；品种有；荷兰洋芋、早大白洋芋。有货源的客户快来村联系，价格面议，数量不限。联系人；黄先生，地址；汉中市汉台区七里办事处文庙村，电话；13084883593.文庙村信息站发。',
 'sup_phone': '13084883593',
 'sup_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=167478',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '土鸡',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡，有意者请与丁先生联系，电话：13689190503。',
 'sup_phone': '13689190503',
 'sup_user': '丁先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167480',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-18',
 'pub_title': '出售红皮鸡蛋',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售红皮鸡蛋65盘，每盘重约4斤，价格面议，欢迎联系。',
 'sup_phone': '15353526258',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167567',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-19',
 'pub_title': '高先生长期供应牛奶',
 'sup_address': '周至县尚村镇马村',
 'sup_description': '高先生长期供应牛奶，价格面议。',
 'sup_phone': '15809220930',
 'sup_user': '高先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167589',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '出售黑狗',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '出售黑色1岁拉布拉多犬1只，价格面议，欢迎联系。',
 'sup_phone': '17791427630',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167638',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售白鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤白鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=167639',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售花鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤花鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168097',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售西瓜',
 'sup_address': '鄠邑区蒋村镇同兴村',
 'sup_description': '出售甜王西瓜，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15029807630',
 'sup_user': '陈先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168103',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售杏子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人出售可口香甜的杏子，价格4.5每斤，需求者请联系！',
 'sup_phone': '13892696179',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168124',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '种植露天桃子，味道好，自然熟',
 'sup_address': '汉中市汉台区',
 'sup_description': '自家种植的桃子，口感有清脆和微软两种，味道有纯甜，微酸甜两种，现摘现送无化肥农药，真正绿色无污染，关键是味道好，味道好，味道好！价格面议，欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168133',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售丰园红杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售丰园红早熟杏，面积2.5亩，价格面议，欢迎联系。',
 'sup_phone': '17719535936',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168134',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售樱桃',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售樱桃，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15829462025',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168136',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售金太阳杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售金太阳杏，产量约2500斤，价格随行就市，欢迎联系。',
 'sup_phone': '15353714592',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168219',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售大棚西瓜',
 'sup_address': '庆丰村9组',
 'sup_description': '1、汉台区老君镇庆丰村2组即将大量出售新鲜大棚西瓜，有意者请前来现场订购；2、地址：汉武路中段汉中市红旗机械厂对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168222',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应次杏子丰园红5000斤',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村供应次杏子丰园红5000斤，价钱面议。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售油桃',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售油桃，个大，味道不错。有意者请与张女士联系。',
 'sup_phone': '18717316979',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '预售沙红桃',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村预售沙红桃，有意者前来订购。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168233',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应枣花蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应枣花蜜1000斤，一斤20元，价钱面议。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168234',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应洋槐蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应洋槐蜜1000斤，一斤20元。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168266',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '桃子',
 'sup_address': '陕西省汉中市汉台区老君镇徐家营村',
 'sup_description': '现有新鲜桃子5亩桃子属于老品种个头大小合适桃子味道浓甜汁多现在正是出售的季节有需要采摘的或者做生意的可以联系我自己下地采摘价格可以看完水果以后商量非诚勿扰谢谢!',
 'sup_phone': '13379360380',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168292',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '供应金太阳杏1万斤',
 'sup_address': '周至县竹峪镇张龙村',
 'sup_description': '供应金太阳杏1万斤，价格电议。',
 'sup_phone': '18092043194',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=168301',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应阎良优质绿皮甜瓜',
 'sup_address': '西安市阎良区关山街道办界坊村西界组',
 'sup_description': '我家种植的绿皮甜瓜刚上市，单重1-1.5斤，香甜难忘，欢迎你品尝后购买。',
 'sup_phone': '18092295878',
 'sup_user': '郭大英'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168320',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '杏',
 'sup_address': '陕西省汉中市汉台区',
 'sup_description': '好吃的杏子，有想法联系啊',
 'sup_phone': '18829863123',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168322',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '咸阳甜杏',
 'sup_address': '陕西省汉中市陕西理工大学',
 'sup_description': '45一箱，包邮啊',
 'sup_phone': '18409168137',
 'sup_user': '王斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167640',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售草鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤草鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167641',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售鲤鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤鲤鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167792',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售三元仔猪',
 'sup_address': '鄠邑区玉蝉街办割耳庄村',
 'sup_description': '出售三元仔猪10头，每头体重15公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15229279068',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167802',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售鹅蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售鹅蛋50枚，价格面议，欢迎联系。',
 'sup_phone': '15229076911',
 'sup_user': '王女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167846',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '供应羊羔5只',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '供应羊羔5只，单只体重大约25―28公斤，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167930',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售草鱼',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售鲜活草鱼500余条，每条重3斤--7斤，欢迎联系。',
 'sup_phone': '13572072008',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=167967',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '新鲜鸡蛋出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村（工业园区）',
 'sup_description': '本人是养殖专业户，现长期对外出售新鲜鸡蛋，货真价实，量大从优，价格面议！',
 'sup_phone': '18691645043',
 'sup_user': '老徐'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167968',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '鲜牛奶对外出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村7组',
 'sup_description': '本人饲养奶牛数头，长期对外出售新鲜牛奶，5公里免费送货上门，欢迎订购！',
 'sup_phone': '14791618835',
 'sup_user': '廖宝友'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167981',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售三元生猪',
 'sup_address': '高新区秦渡镇南焦羊村',
 'sup_description': '出售三元生猪30头，单头体重130公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029033406',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168239',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售肉猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售三元肉猪50头，体重120公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15829108410',
 'sup_user': '肖女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168246',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168261',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '土鸡蛋',
 'sup_address': '汉中市汉台区七里街道办事处染房营村四组',
 'sup_description': '本人在果园有散养蛋鸡，蛋质优良，无毒无公害，真正的绿色产品，价格优惠，欢迎大家选购。',
 'sup_phone': '13992693136',
 'sup_user': '唐世义'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168311',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜的土鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=159779',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-29',
 'pub_title': '求购200克以上魔芋5000斤',
 'sup_address': '周至县厚畛子镇同力村',
 'sup_description': '求购200克以上魔芋5000斤联系人:黄先生电话：１３４７４１１０２７５地址：周至县厚畛子镇同力村。',
 'sup_phone': '13474110275',
 'sup_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=160928',
 'pub_address': '西安市户县',
 'pub_time': '2019-01-24',
 'pub_title': '求购大葱',
 'sup_address': '鄠邑区玉蝉镇新向村',
 'sup_description': '求购大葱100斤，欢迎联系。',
 'sup_phone': '15091671829',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165085',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-08',
 'pub_title': '大量收购甘蓝菜',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购甘蓝菜，要求单重2斤以上，价格随行就市，欢迎联系销售。',
 'sup_phone': '15291452658',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165124',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜蒜苔',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜蒜苔，日收购5吨，限陕西西安境内，有意者请联系，价格面议。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165126',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜香椿',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜香椿芽，有意者请联系价格面议，限西安辖区内，',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=165372',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-11',
 'pub_title': '收购莲花白、螺丝辣椒',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购莲花白、螺丝辣椒，价格面议，欢迎广大菜农联系销售。',
 'sup_phone': '13474363373',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=165934',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '收购洋槐花',
 'sup_address': '周至县楼观镇团标村',
 'sup_description': '收购洋槐花，有意者电话联系。',
 'sup_phone': '15091527877',
 'sup_user': '谢女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=166016',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-21',
 'pub_title': '求购紫薯苗',
 'sup_address': '周至县尚村镇新范村',
 'sup_description': '求购紫薯苗两万个，可以电话报价，有货及时联系',
 'sup_phone': '13619226724',
 'sup_user': '孙先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=166051',
 'pub_address': '西安市户县',
 'pub_time': '2019-04-22',
 'pub_title': '求购小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '求购小葱秧200斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166675',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-30',
 'pub_title': '求购鲜洋槐花',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜洋槐花，数量不限，限西安境内，有意者请联系，量大可上门取货。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167311',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购葱秧',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购葱秧30公斤，品种不限，价格面议，欢迎联系。',
 'sup_phone': '18966810872',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-17',
 'info_from': 'http://222.90.83.241/show.aspx?id=167415',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-17',
 'pub_title': '求购藕种',
 'sup_address': '汉台区老君镇付庙村六组',
 'sup_description': '大量求购优质藕种！',
 'sup_phone': '13571611661',
 'sup_user': '张伟'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167848',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购大蒜5万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购大蒜5万斤，要求个大，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168318',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '小辣子',
 'sup_address': '汉台区七里办事处金江2组',
 'sup_description': '王先生家中种植了各种蔬菜,小辣子已经成熟,正在大量出售,如有需求,请电话联系',
 'sup_phone': '15891461382',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168275',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高60公分大田侧柏1.5万株',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：高60公分大田侧柏1.5万株，价格面议，欢迎联系。',
 'sup_phone': '15877344352',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168276',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径1公分国槐3000棵',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：胸径1公分国槐3000棵，价格面议，欢迎联系。',
 'sup_phone': '13092046069',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168277',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径15公分龙爪槐20棵',
 'sup_address': '周至县四屯镇联三村',
 'sup_description': '出售：胸径15公分龙爪槐20棵，价格面议，欢迎联系。',
 'sup_phone': '15091151300',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=168278',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高80公分兰天竹营养钵3500株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：高80公分兰天竹营养钵3500株，价格面议，欢迎联系。',
 'sup_phone': '15319458368',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168280',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售直径3公分左右的大叶女贞10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售直径3公分左右的大叶女贞10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168281',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分以上的红梅10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分以上的红梅10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168282',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径3-4公分以上的红枫10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径3-4公分以上的红枫10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168283',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径2-3公分的桂花10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径2-3公分的桂花10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168291',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售毛竹10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售毛竹10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168296',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '低价销售直径3-10厘米的樱花树',
 'sup_address': '周至县终南村',
 'sup_description': '低价销售直径3-10厘米的樱花树8亩左右，树形好，价格低，欢迎需求朋友联系。联系：陈女士电话：13119161886地址：周至县终南村',
 'sup_phone': '13119161886',
 'sup_user': '陈女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=168305',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白蜡树',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有直径5公分白蜡树300棵，直径6公分白蜡树100棵，急于出售。欢迎电话联系。',
 'sup_phone': '13484667542',
 'sup_user': '闫兆'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-19',
 'info_from': 'http://222.90.83.241/show.aspx?id=168306',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白皮松',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有高度1米白皮松300棵，急于出售。欢迎电话联系。',
 'sup_phone': '13032916618',
 'sup_user': '刘展雄'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168170',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-30',
 'pub_title': '蒲瓜',
 'sup_address': '汉台区铺镇芦坝村一组',
 'sup_description': '我现有蒲瓜4000斤出售，批发价0.8元/每斤。',
 'sup_phone': '13630267456',
 'sup_user': '魏小民'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168220',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售新鲜大棚秀珍菇',
 'sup_address': '庆丰村1组',
 'sup_description': '1、汉台区老君镇庆丰村1组大量出售新鲜大棚秀珍菇，有意者请面议；2、地址：汉武路中段陕西省汇力园区对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168293',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '大量出售架豆王',
 'sup_address': '西安市绿康果蔬苗木专业合作社',
 'sup_description': '出售架豆王60多亩，长度20-30厘米左右，质量好，价格低，欢迎联系。联系：蒲经理电话：13201689888地址：西安市绿康果蔬苗木专业合作社',
 'sup_phone': '13201689888',
 'sup_user': '蒲经理'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168304',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应西红柿',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '本人家有3亩温室西红柿成熟出售，货源、品质保证，价格面议，欢迎各地客商联系收购。',
 'sup_phone': '18092632479',
 'sup_user': '刘文'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168312',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '出售大蒜',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售红皮大蒜约400斤，价格面议，欢迎联系。',
 'sup_phone': '13571840519',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167895',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售矮青菜',
 'sup_address': '鄠邑区渭丰镇定六村',
 'sup_description': '出售矮青菜3000斤，价格面议，欢迎联系。',
 'sup_phone': '13109617130',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168026',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '蔬菜出售',
 'sup_address': '老君镇拐拐村',
 'sup_description': '大量出售西红柿与黄瓜，各3000斤左右。欢迎选购。',
 'sup_phone': '18591612273',
 'sup_user': '秦小强'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168040',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应架豆王',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应架豆王300斤。',
 'sup_phone': '18092634616',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168041',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售芥兰',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售芥兰菜6000斤左右，价格面议，欢迎联系。',
 'sup_phone': '18192003238',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167804',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜出售',
 'sup_address': '新校村',
 'sup_description': '现有大量新鲜蔬菜出售，批发零售皆可，主要有辣椒，西红柿，豆角，西蓝花等若有需要的请和我联系。',
 'sup_phone': '15760959624',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167815',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜',
 'sup_address': '汉台区铺镇锦福专业蔬菜合作社',
 'sup_description': '我村锦福蔬菜合作社现有:西葫芦、黄瓜、辣椒、茄子、西红柿对外批发出售；（可组织整车货源）欢迎新老客户前来订购！',
 'sup_phone': '13038477096',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=167817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-24',
 'pub_title': '魔芋出售',
 'sup_address': '陈家坝镇孔家湾村一组',
 'sup_description': '因土地用作它途，最近亟待出售一批魔芋，价格好商量！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167893',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菠菜',
 'sup_address': '鄠邑区渭丰镇定五村',
 'sup_description': '出售菠菜4000斤，价格面议，欢迎联系。',
 'sup_phone': '18710978332',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167894',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘亭街办南羊村',
 'sup_description': '出售韭菜，面积10亩，价格面议，欢迎联系。',
 'sup_phone': '13572179512',
 'sup_user': '周女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168043',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应西红柿',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应西红柿500斤。',
 'sup_phone': '15829468093',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:44:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168108',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应大蒜100斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '供应大蒜100斤.新蒜。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168125',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '出售土豆，天然产出',
 'sup_address': '汉中市汉台区',
 'sup_description': '出售纯天然土豆，粉糯可口，个头匀称，表面光滑，现挖先发价格面议欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168129',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '供给优质土豆',
 'sup_address': '陕西省汉中市汉台区宗营镇下寨村三组',
 'sup_description': '自家种植一亩品种为早大白的土豆，现已成熟，大约有1500斤需将其出售。有意者请联系本人。',
 'sup_phone': '18829662083',
 'sup_user': '黄玉莲'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168145',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售韭菜600斤，价格面议，欢迎联系。',
 'sup_phone': '15902991386',
 'sup_user': '马先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168198',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购广玉兰胸径18至20公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购广玉兰胸径18至20公分，1.5米土球，数量，365颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168199',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购法桐胸径15至17公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购法桐，胸径15至17公分，1.5米土球，数量804颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=158659',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-11',
 'pub_title': '大量收购乌笋种子',
 'sup_address': '汉中市佛坪县',
 'sup_description': '大量收购乌笋种子，土名：洋嚯。联系电话：13991608711/13892652745',
 'sup_phone': '13991608711',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168201',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购字画木槿地径5至7公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购字画木槿地径5至7公分，1米土球，数量1478颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168202',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购红宝石海棠胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购红宝石海棠胸径12至14公分，1.2米土球，数量1706颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168018',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购高5.0米以上的白皮松13棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高5.0米以上的白皮松13棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168022',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购胸径4公分的国槐50棵',
 'sup_address': '周至县翠峰镇农林村四组',
 'sup_description': '求购胸径4公分的国槐50棵。',
 'sup_phone': '15399480380',
 'sup_user': '侯女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168039',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径14公分银杏350棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径14公分银杏350棵，要求分支点2.8-3.5米，带土球90公分，有货的朋友请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168042',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径12公分香花槐200棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径12公分香花槐200棵，要求分支点2.8米以上，树杆端直，树冠优美，有货者请尽快联系，看货议价。',
 'sup_phone': '18229025186',
 'sup_user': '毛先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167452',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-17',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米5000公斤，要求干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '15229382221',
 'sup_user': '谭先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=161762',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-19',
 'pub_title': '求购胸径20-22公分银杏55棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购胸径20-22公分银杏，要求高度7-8米，冠幅4米，数量55棵，有货者电话联系，价格面议。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162023',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购散养100只老母鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购散养老母鸡100只，7--8个月，体重5斤左右，价格合适，欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162045',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购淘汰红毛蛋鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购淘汰红毛蛋鸡800只-均重4.2斤以上，毛色好，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162050',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购各种狗',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '大量求购各种狗，哈士奇、拉布拉多、金毛、萨摩、阿拉斯加、边牧、马犬、博美、比熊等，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=162949',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-03-04',
 'pub_title': '求购羊羔',
 'sup_address': '阎良区关山街道办老王村小马组',
 'sup_description': '上门收购小公羊、母羊羔，价格随行，欢迎联系。',
 'sup_phone': '13759637031',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=163540',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-14',
 'pub_title': '求购鹅蛋',
 'sup_address': '鄠邑区涝店镇马家堡村',
 'sup_description': '求购鹅蛋100枚，价格面议，欢迎联系。',
 'sup_phone': '13484800110',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=164300',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购地径8公分紫薇20棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购地径8公分紫薇20棵，要求分支点60公分以上，有意者请电话联系。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166044',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-22',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166500',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-28',
 'pub_title': '求购土鸡蛋',
 'sup_address': '吴基庄村',
 'sup_description': '需要购买土鸡蛋60个，物美价廉',
 'sup_phone': '13772809382',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '求购一批土鸡鸡苗',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '现需要一批鸡苗（200只），适应本地气候，成活率高的！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=166821',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '收购群羊',
 'sup_address': '陕西省汉中市',
 'sup_description': '大量收购群羊，价格美丽。联系电话（微信）：18828091357。',
 'sup_phone': '18828091357',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=166874',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-06',
 'pub_title': '求购母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购经产母猪5头，要求健康无病，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166929',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋所在地：汉中市汉台区发布时间：2019-04-22求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167294',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购猪仔',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '求购猪仔10头，要求单头重25斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029246927',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=167341',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-16',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '常期收购淘汰母猪，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '吴先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167623',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购鸡蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购红皮鸡蛋400盘，每盘重1.9公斤左右，价格面议，欢迎联系。',
 'sup_phone': '18392549287',
 'sup_user': '曹先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=161136',
 'pub_address': '西安市周至县',
 'pub_time': '2019-01-30',
 'pub_title': '求购80-120克秦美猕猴桃30000斤',
 'sup_address': '周至县四屯镇三联村中二屯',
 'sup_description': '求购80-120克库存秦美猕猴桃30000斤，有出售者请联系。',
 'sup_phone': '13572903928',
 'sup_user': '薛智军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=161643',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-17',
 'pub_title': '求购霉烂猕猴桃',
 'sup_address': '周至县二曲镇孟家村',
 'sup_description': '大量求购霉烂猕猴桃。价格面议。',
 'sup_phone': '13659209629',
 'sup_user': '郝先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=162466',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-26',
 'pub_title': '求购徐香猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '求购带把徐香猕猴桃200000斤，看货谈价。',
 'sup_phone': '13572526437',
 'sup_user': '吕先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=162467',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-26',
 'pub_title': '求购海沃德猕猴桃',
 'sup_address': '周至县楼观镇西会村',
 'sup_description': '求购海沃德猕猴桃买整库或者单车均可，要硬度好，看货谈价。',
 'sup_phone': '13689205889',
 'sup_user': '田先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=164225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-21',
 'pub_title': '大量求购海沃德猕猴桃次果',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现大量求购海沃德猕猴桃次果，价格面谈。',
 'sup_phone': '18792637406',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-17',
 'info_from': 'http://222.90.83.241/show.aspx?id=164737',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-29',
 'pub_title': '求购90起步海沃德猕猴桃5万斤',
 'sup_address': '西安市马召镇仁烟村',
 'sup_description': '求购90起步海沃德猕猴桃5万斤，欢迎联系！',
 'sup_phone': '15191915106',
 'sup_user': '陈先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166050',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-22',
 'pub_title': '大量收购甜瓜',
 'sup_address': '西安市阎良区关山街道办老王村西北组（原老王村小学院内）',
 'sup_description': '大量收购甜瓜，以质论价，欢迎联系销售。',
 'sup_phone': '15094000816',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=166814',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-05',
 'pub_title': '大量收购“芝麻蜜”甜瓜',
 'sup_address': '西安市阎良区关山街道办北十字口西北角',
 'sup_description': '大量收购阎良“芝麻蜜”、小籽甜瓜，价格随行就市，欢迎广大瓜农联系销售。',
 'sup_phone': '13347409123',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=167005',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-08',
 'pub_title': '求购猕猴桃公花粉3斤',
 'sup_address': '周至县哑柏镇上阳化村',
 'sup_description': '急求猕猴桃公花粉3斤，价格面议。',
 'sup_phone': '13609203888',
 'sup_user': '陈女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167169',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '求购青李子',
 'sup_address': '周至县富仁镇永丰村',
 'sup_description': '求购青李子。数量价格面议。',
 'sup_phone': '13201591625',
 'sup_user': '李先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167215',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '大量求购青李子',
 'sup_address': '周至县马召镇焦家楼村',
 'sup_description': '大量求购青李子,每斤0.25元。',
 'sup_phone': '18229042452',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167216',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '收购李子青果',
 'sup_address': '周至县广济镇南陈村',
 'sup_description': '陈先生大量收购李子青果，不论大小，每斤0.2元，有意者速联系。',
 'sup_phone': '18710430164',
 'sup_user': '陈先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-24',
 'info_from': 'http://222.90.83.241/show.aspx?id=167229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-14',
 'pub_title': '大量收购青李子',
 'sup_address': '周至县广济镇桑园村',
 'sup_description': '大量收购青李子，每斤0.25元联系人:王女士电话:85121695地址:周至县广济镇桑园村',
 'sup_phone': '85121695',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167427',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-17',
 'pub_title': '求购杏',
 'sup_address': '周至县楼观镇下三清村',
 'sup_description': '求购杏，丰园红，金太阳等，有意向者电话联系。',
 'sup_phone': '15091861572',
 'sup_user': '康先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167664',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-21',
 'pub_title': '求购青李子',
 'sup_address': '周至县马召镇熨斗村',
 'sup_description': '求购青李子，有意者电话联系。',
 'sup_phone': '18700828599',
 'sup_user': '赵女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167716',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-22',
 'pub_title': '求购青李子1万斤',
 'sup_address': '周至县广济镇商家磨村',
 'sup_description': '求购青李子1万斤，价格面议',
 'sup_phone': '13700245778',
 'sup_user': '潘女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167847',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购金太阳杏子1.5万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购金太阳杏子1.5万斤，要求个大，价格面议。',
 'sup_phone': '18710683521',
 'sup_user': '宋先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167849',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购进口海沃德猕猴桃2万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购进口海沃德猕猴桃2万斤，要求80克起步，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167878',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售土豆',
 'sup_address': '陕西省西安市周至县尚村镇张寨村八组',
 'sup_description': '我处有3亩地土豆出售，有需求者请联系。',
 'sup_phone': '18729974792',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167879',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菜油',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十四组',
 'sup_description': '我处有200斤菜油出售，有需求者电话联系。',
 'sup_phone': '15991614124',
 'sup_user': '闫先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167941',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售玉米',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售玉米3000斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168007',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售2019新收小麦',
 'sup_address': '汉台区七里街道马家坝村一组',
 'sup_description': '家有2019年应季新收小麦800斤需出售，有意者请于我联系，电话13891622698',
 'sup_phone': '13891622698',
 'sup_user': '衡正斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168037',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售菜籽、小麦',
 'sup_address': '汉台区老君镇王道池村',
 'sup_description': '现有刚收获的小麦、菜籽。价格随市场。联系电话：18891618650联系人李先生',
 'sup_phone': '18891618650',
 'sup_user': '李新华'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168081',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '优质菜籽',
 'sup_address': '汉台区武乡镇崔营村',
 'sup_description': '本村大量上市2019年优质油菜籽，量大、质量优，有意者来电咨询洽谈',
 'sup_phone': '18220666628',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168104',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168105',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168117',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-28',
 'pub_title': '出售油菜籽',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售油菜籽约600斤，价格面议，欢迎联系。',
 'sup_phone': '13572583121',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168123',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '汉台区武乡镇同心村',
 'sup_description': '大量今年新油菜籽出售，地址：汉台区武乡镇同心。联系电话：18710666754张女士',
 'sup_phone': '18710666754',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168130',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有油菜籽出售，无杂质、无霉粒，数吨如有需求者请与我联系，联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168132',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '小麦',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有大量小麦出售，质优无杂质颗粒饱满，如有需求者请与李先生联系。联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇共力村九组。',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=168154',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '菜籽',
 'sup_address': '汉台区老君镇',
 'sup_description': '菜籽色泽鲜亮.颗粒饱满',
 'sup_phone': '13379361068',
 'sup_user': '黄女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168156',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，价格随行就市，欢迎联系。',
 'sup_phone': '13991942437',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168213',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售新小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，欢迎联系。',
 'sup_phone': '18792949262',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168247',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大量大米，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168268',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '现有今年新油菜籽3000斤左右颗粒饱满油菜籽颜色黑已经处理干净小灰尘出油率高油菜籽完全晒干发的有图片但仅为参考还是要看实际货物如有需要者可以和我联系非诚勿扰!',
 'sup_phone': '18700657341',
 'sup_user': '龙女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168310',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大米，请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168319',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售油菜籽',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '有2019年出产的油菜籽2000斤欲对外出售，菜籽干度好，出油率高，如有购买者请联系，价格面议。',
 'sup_phone': '18391619491',
 'sup_user': '苟建荣'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168321',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售小麦',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '本人有2019年出产小麦2000斤现对外出售，麦子干度好，色泽鲜亮。如有需要者请联系。',
 'sup_phone': '13259287568',
 'sup_user': '孙培军'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168221',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '求购油桃5000斤',
 'sup_address': '周至县广济镇南留村',
 'sup_description': '求购油桃5000斤，要求色红脆甜，价格面议，有货的速联系。',
 'sup_phone': '17389206678',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167624',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购青年母鸡',
 'sup_address': '鄠邑区甘河镇北板村',
 'sup_description': '求购海兰褐青年母鸡1500只，要求日龄60天-100天，价格面议，欢迎联系。',
 'sup_phone': '18629514457',
 'sup_user': '董先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=168241',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '大量求购淘汰母猪，价格随行就市，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168047',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径10公分红叶碧桃20棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径10公分红叶碧桃20棵，要求大半冠，树干端直，带土球80公分，有货者请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168049',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分国槐32棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分国槐32棵，要求分支点2.5-3米，4米原生冠，带常规土球，有货的朋友请尽快联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168051',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分七叶树42棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分七叶树42棵，要求分支点2.8-3.2米，4米原生冠，带常规土球，有货者请速联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168115',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购白皮松',
 'sup_address': '周至县二曲街道办事处李家村',
 'sup_description': '本处现急需求购一米起步老芽三级18碗碗白皮松，一车装7000株，有货请电话联系。',
 'sup_phone': '13759925466',
 'sup_user': '李朝辉'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168137',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购高1.5米以上的塔柏200棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高1.5米以上的塔柏200棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168191',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购银杏胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购银杏胸径20至22公分，要求，冠副4米，高8米至8米5.1.5米的土球，总数量636颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168193',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购雪松6至7米',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购雪松6至7米，冠幅2米至2.5，1.2米土球，总数量，235颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168195',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购七叶树',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购七叶树，胸径15至18公分，要求1.5米土球，数量826颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168197',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购国槐胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购国槐，胸径20至22公分，1.5米土球，数量689颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168146',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售小葱秧800斤，价格面议，欢迎联系。',
 'sup_phone': '13772449091',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print(type(item['pub_title']) + item['pub_title'])
KeyError: 'pub_title'
2019-06-04 00:45:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=168279',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '求购胸径4公分高杆石楠600棵',
 'sup_address': '周至县马召镇桃李坪村',
 'sup_description': '求购胸径4公分高杆石楠600棵，分枝点1.5米，有货请电话联系。',
 'sup_phone': '13891948456',
 'sup_user': '郭新峰'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168203',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购大叶女贞胸径10至12公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购大叶女贞，胸径10至12公分，1.2米土球，数量1348颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=161471',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-14',
 'pub_title': '求购鸭蛋',
 'sup_address': '陕西省西安市周至县集贤镇西村',
 'sup_description': '求购鸭蛋20斤，有货者请联系。',
 'sup_phone': '13519133896',
 'sup_user': '田先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=164508',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-25',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉台区汉王镇大兴村',
 'sup_description': '价格1元每枚',
 'sup_phone': '15129581840',
 'sup_user': '胡生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167150',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-13',
 'pub_title': '大量收购青李子',
 'sup_address': '陕西周至广济上二屯村',
 'sup_description': '大量收购青李子，每斤0.25元。',
 'sup_phone': '18229042452',
 'sup_user': '刘师傅'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:45:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168200',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购桂花树胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购桂花树，胸径12至14公分，1.2米土球，数量1568颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 145, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'pub_title'
2019-06-04 00:47:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168105',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168117',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-28',
 'pub_title': '出售油菜籽',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售油菜籽约600斤，价格面议，欢迎联系。',
 'sup_phone': '13572583121',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168123',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '汉台区武乡镇同心村',
 'sup_description': '大量今年新油菜籽出售，地址：汉台区武乡镇同心。联系电话：18710666754张女士',
 'sup_phone': '18710666754',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168130',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有油菜籽出售，无杂质、无霉粒，数吨如有需求者请与我联系，联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168132',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '小麦',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有大量小麦出售，质优无杂质颗粒饱满，如有需求者请与李先生联系。联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇共力村九组。',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=168154',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '菜籽',
 'sup_address': '汉台区老君镇',
 'sup_description': '菜籽色泽鲜亮.颗粒饱满',
 'sup_phone': '13379361068',
 'sup_user': '黄女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168156',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，价格随行就市，欢迎联系。',
 'sup_phone': '13991942437',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167878',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售土豆',
 'sup_address': '陕西省西安市周至县尚村镇张寨村八组',
 'sup_description': '我处有3亩地土豆出售，有需求者请联系。',
 'sup_phone': '18729974792',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167804',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜出售',
 'sup_address': '新校村',
 'sup_description': '现有大量新鲜蔬菜出售，批发零售皆可，主要有辣椒，西红柿，豆角，西蓝花等若有需要的请和我联系。',
 'sup_phone': '15760959624',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167815',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜',
 'sup_address': '汉台区铺镇锦福专业蔬菜合作社',
 'sup_description': '我村锦福蔬菜合作社现有:西葫芦、黄瓜、辣椒、茄子、西红柿对外批发出售；（可组织整车货源）欢迎新老客户前来订购！',
 'sup_phone': '13038477096',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=167817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-24',
 'pub_title': '魔芋出售',
 'sup_address': '陈家坝镇孔家湾村一组',
 'sup_description': '因土地用作它途，最近亟待出售一批魔芋，价格好商量！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167893',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菠菜',
 'sup_address': '鄠邑区渭丰镇定五村',
 'sup_description': '出售菠菜4000斤，价格面议，欢迎联系。',
 'sup_phone': '18710978332',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167894',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘亭街办南羊村',
 'sup_description': '出售韭菜，面积10亩，价格面议，欢迎联系。',
 'sup_phone': '13572179512',
 'sup_user': '周女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167895',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售矮青菜',
 'sup_address': '鄠邑区渭丰镇定六村',
 'sup_description': '出售矮青菜3000斤，价格面议，欢迎联系。',
 'sup_phone': '13109617130',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168026',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '蔬菜出售',
 'sup_address': '老君镇拐拐村',
 'sup_description': '大量出售西红柿与黄瓜，各3000斤左右。欢迎选购。',
 'sup_phone': '18591612273',
 'sup_user': '秦小强'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168040',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应架豆王',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应架豆王300斤。',
 'sup_phone': '18092634616',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168041',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售芥兰',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售芥兰菜6000斤左右，价格面议，欢迎联系。',
 'sup_phone': '18192003238',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168043',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应西红柿',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应西红柿500斤。',
 'sup_phone': '15829468093',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168108',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应大蒜100斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '供应大蒜100斤.新蒜。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168125',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '出售土豆，天然产出',
 'sup_address': '汉中市汉台区',
 'sup_description': '出售纯天然土豆，粉糯可口，个头匀称，表面光滑，现挖先发价格面议欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168129',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '供给优质土豆',
 'sup_address': '陕西省汉中市汉台区宗营镇下寨村三组',
 'sup_description': '自家种植一亩品种为早大白的土豆，现已成熟，大约有1500斤需将其出售。有意者请联系本人。',
 'sup_phone': '18829662083',
 'sup_user': '黄玉莲'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168145',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售韭菜600斤，价格面议，欢迎联系。',
 'sup_phone': '15902991386',
 'sup_user': '马先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168146',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售小葱秧800斤，价格面议，欢迎联系。',
 'sup_phone': '13772449091',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:47:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168170',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-30',
 'pub_title': '蒲瓜',
 'sup_address': '汉台区铺镇芦坝村一组',
 'sup_description': '我现有蒲瓜4000斤出售，批发价0.8元/每斤。',
 'sup_phone': '13630267456',
 'sup_user': '魏小民'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168220',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售新鲜大棚秀珍菇',
 'sup_address': '庆丰村1组',
 'sup_description': '1、汉台区老君镇庆丰村1组大量出售新鲜大棚秀珍菇，有意者请面议；2、地址：汉武路中段陕西省汇力园区对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168293',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '大量出售架豆王',
 'sup_address': '西安市绿康果蔬苗木专业合作社',
 'sup_description': '出售架豆王60多亩，长度20-30厘米左右，质量好，价格低，欢迎联系。联系：蒲经理电话：13201689888地址：西安市绿康果蔬苗木专业合作社',
 'sup_phone': '13201689888',
 'sup_user': '蒲经理'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168304',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应西红柿',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '本人家有3亩温室西红柿成熟出售，货源、品质保证，价格面议，欢迎各地客商联系收购。',
 'sup_phone': '18092632479',
 'sup_user': '刘文'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168312',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '出售大蒜',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售红皮大蒜约400斤，价格面议，欢迎联系。',
 'sup_phone': '13571840519',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168097',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售西瓜',
 'sup_address': '鄠邑区蒋村镇同兴村',
 'sup_description': '出售甜王西瓜，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15029807630',
 'sup_user': '陈先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168103',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售杏子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人出售可口香甜的杏子，价格4.5每斤，需求者请联系！',
 'sup_phone': '13892696179',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168124',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '种植露天桃子，味道好，自然熟',
 'sup_address': '汉中市汉台区',
 'sup_description': '自家种植的桃子，口感有清脆和微软两种，味道有纯甜，微酸甜两种，现摘现送无化肥农药，真正绿色无污染，关键是味道好，味道好，味道好！价格面议，欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168133',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售丰园红杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售丰园红早熟杏，面积2.5亩，价格面议，欢迎联系。',
 'sup_phone': '17719535936',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168134',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售樱桃',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售樱桃，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15829462025',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168136',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售金太阳杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售金太阳杏，产量约2500斤，价格随行就市，欢迎联系。',
 'sup_phone': '15353714592',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168219',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售大棚西瓜',
 'sup_address': '庆丰村9组',
 'sup_description': '1、汉台区老君镇庆丰村2组即将大量出售新鲜大棚西瓜，有意者请前来现场订购；2、地址：汉武路中段汉中市红旗机械厂对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168222',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应次杏子丰园红5000斤',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村供应次杏子丰园红5000斤，价钱面议。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售油桃',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售油桃，个大，味道不错。有意者请与张女士联系。',
 'sup_phone': '18717316979',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '预售沙红桃',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村预售沙红桃，有意者前来订购。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168233',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应枣花蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应枣花蜜1000斤，一斤20元，价钱面议。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168234',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应洋槐蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应洋槐蜜1000斤，一斤20元。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168266',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '桃子',
 'sup_address': '陕西省汉中市汉台区老君镇徐家营村',
 'sup_description': '现有新鲜桃子5亩桃子属于老品种个头大小合适桃子味道浓甜汁多现在正是出售的季节有需要采摘的或者做生意的可以联系我自己下地采摘价格可以看完水果以后商量非诚勿扰谢谢!',
 'sup_phone': '13379360380',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168292',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '供应金太阳杏1万斤',
 'sup_address': '周至县竹峪镇张龙村',
 'sup_description': '供应金太阳杏1万斤，价格电议。',
 'sup_phone': '18092043194',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=168301',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应阎良优质绿皮甜瓜',
 'sup_address': '西安市阎良区关山街道办界坊村西界组',
 'sup_description': '我家种植的绿皮甜瓜刚上市，单重1-1.5斤，香甜难忘，欢迎你品尝后购买。',
 'sup_phone': '18092295878',
 'sup_user': '郭大英'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168320',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '杏',
 'sup_address': '陕西省汉中市汉台区',
 'sup_description': '好吃的杏子，有想法联系啊',
 'sup_phone': '18829863123',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168322',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '咸阳甜杏',
 'sup_address': '陕西省汉中市陕西理工大学',
 'sup_description': '45一箱，包邮啊',
 'sup_phone': '18409168137',
 'sup_user': '王斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167879',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菜油',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十四组',
 'sup_description': '我处有200斤菜油出售，有需求者电话联系。',
 'sup_phone': '15991614124',
 'sup_user': '闫先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167941',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售玉米',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售玉米3000斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168007',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售2019新收小麦',
 'sup_address': '汉台区七里街道马家坝村一组',
 'sup_description': '家有2019年应季新收小麦800斤需出售，有意者请于我联系，电话13891622698',
 'sup_phone': '13891622698',
 'sup_user': '衡正斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168037',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售菜籽、小麦',
 'sup_address': '汉台区老君镇王道池村',
 'sup_description': '现有刚收获的小麦、菜籽。价格随市场。联系电话：18891618650联系人李先生',
 'sup_phone': '18891618650',
 'sup_user': '李新华'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168081',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '优质菜籽',
 'sup_address': '汉台区武乡镇崔营村',
 'sup_description': '本村大量上市2019年优质油菜籽，量大、质量优，有意者来电咨询洽谈',
 'sup_phone': '18220666628',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168104',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168213',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售新小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，欢迎联系。',
 'sup_phone': '18792949262',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168247',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大量大米，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168268',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '现有今年新油菜籽3000斤左右颗粒饱满油菜籽颜色黑已经处理干净小灰尘出油率高油菜籽完全晒干发的有图片但仅为参考还是要看实际货物如有需要者可以和我联系非诚勿扰!',
 'sup_phone': '18700657341',
 'sup_user': '龙女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168310',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大米，请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168319',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售油菜籽',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '有2019年出产的油菜籽2000斤欲对外出售，菜籽干度好，出油率高，如有购买者请联系，价格面议。',
 'sup_phone': '18391619491',
 'sup_user': '苟建荣'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168321',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售小麦',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '本人有2019年出产小麦2000斤现对外出售，麦子干度好，色泽鲜亮。如有需要者请联系。',
 'sup_phone': '13259287568',
 'sup_user': '孙培军'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168007',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售2019新收小麦',
 'sup_address': '汉台区七里街道马家坝村一组',
 'sup_description': '家有2019年应季新收小麦800斤需出售，有意者请于我联系，电话13891622698',
 'sup_phone': '13891622698',
 'sup_user': '衡正斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168037',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售菜籽、小麦',
 'sup_address': '汉台区老君镇王道池村',
 'sup_description': '现有刚收获的小麦、菜籽。价格随市场。联系电话：18891618650联系人李先生',
 'sup_phone': '18891618650',
 'sup_user': '李新华'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168081',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '优质菜籽',
 'sup_address': '汉台区武乡镇崔营村',
 'sup_description': '本村大量上市2019年优质油菜籽，量大、质量优，有意者来电咨询洽谈',
 'sup_phone': '18220666628',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168104',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168105',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168117',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-05-28',
 'pub_title': '出售油菜籽',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售油菜籽约600斤，价格面议，欢迎联系。',
 'sup_phone': '13572583121',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167878',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售土豆',
 'sup_address': '陕西省西安市周至县尚村镇张寨村八组',
 'sup_description': '我处有3亩地土豆出售，有需求者请联系。',
 'sup_phone': '18729974792',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167804',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜出售',
 'sup_address': '新校村',
 'sup_description': '现有大量新鲜蔬菜出售，批发零售皆可，主要有辣椒，西红柿，豆角，西蓝花等若有需要的请和我联系。',
 'sup_phone': '15760959624',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167815',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜',
 'sup_address': '汉台区铺镇锦福专业蔬菜合作社',
 'sup_description': '我村锦福蔬菜合作社现有:西葫芦、黄瓜、辣椒、茄子、西红柿对外批发出售；（可组织整车货源）欢迎新老客户前来订购！',
 'sup_phone': '13038477096',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=167817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-24',
 'pub_title': '魔芋出售',
 'sup_address': '陈家坝镇孔家湾村一组',
 'sup_description': '因土地用作它途，最近亟待出售一批魔芋，价格好商量！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167893',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菠菜',
 'sup_address': '鄠邑区渭丰镇定五村',
 'sup_description': '出售菠菜4000斤，价格面议，欢迎联系。',
 'sup_phone': '18710978332',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167894',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘亭街办南羊村',
 'sup_description': '出售韭菜，面积10亩，价格面议，欢迎联系。',
 'sup_phone': '13572179512',
 'sup_user': '周女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167895',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售矮青菜',
 'sup_address': '鄠邑区渭丰镇定六村',
 'sup_description': '出售矮青菜3000斤，价格面议，欢迎联系。',
 'sup_phone': '13109617130',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168026',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '蔬菜出售',
 'sup_address': '老君镇拐拐村',
 'sup_description': '大量出售西红柿与黄瓜，各3000斤左右。欢迎选购。',
 'sup_phone': '18591612273',
 'sup_user': '秦小强'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168018',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购高5.0米以上的白皮松13棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高5.0米以上的白皮松13棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168022',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购胸径4公分的国槐50棵',
 'sup_address': '周至县翠峰镇农林村四组',
 'sup_description': '求购胸径4公分的国槐50棵。',
 'sup_phone': '15399480380',
 'sup_user': '侯女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168039',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径14公分银杏350棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径14公分银杏350棵，要求分支点2.8-3.5米，带土球90公分，有货的朋友请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168042',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径12公分香花槐200棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径12公分香花槐200棵，要求分支点2.8米以上，树杆端直，树冠优美，有货者请尽快联系，看货议价。',
 'sup_phone': '18229025186',
 'sup_user': '毛先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168047',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径10公分红叶碧桃20棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径10公分红叶碧桃20棵，要求大半冠，树干端直，带土球80公分，有货者请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168049',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分国槐32棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分国槐32棵，要求分支点2.5-3米，4米原生冠，带常规土球，有货的朋友请尽快联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168051',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分七叶树42棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分七叶树42棵，要求分支点2.8-3.2米，4米原生冠，带常规土球，有货者请速联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168137',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购高1.5米以上的塔柏200棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高1.5米以上的塔柏200棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168191',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购银杏胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购银杏胸径20至22公分，要求，冠副4米，高8米至8米5.1.5米的土球，总数量636颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168193',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购雪松6至7米',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购雪松6至7米，冠幅2米至2.5，1.2米土球，总数量，235颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168195',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购七叶树',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购七叶树，胸径15至18公分，要求1.5米土球，数量826颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168197',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购国槐胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购国槐，胸径20至22公分，1.5米土球，数量689颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168198',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购广玉兰胸径18至20公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购广玉兰胸径18至20公分，1.5米土球，数量，365颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168199',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购法桐胸径15至17公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购法桐，胸径15至17公分，1.5米土球，数量804颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168200',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购桂花树胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购桂花树，胸径12至14公分，1.2米土球，数量1568颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168201',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购字画木槿地径5至7公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购字画木槿地径5至7公分，1米土球，数量1478颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165873',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-04-19',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办事处王家湾村',
 'sup_description': '要求玉米颗粒饱满，无腐烂、无虫、无沙粒，有意出售的电话联系。',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=165984',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '求购红芋苗',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十三组',
 'sup_description': '求购秦薯四号红芋苗15000苗，有出售者请联系。',
 'sup_phone': '15109208586',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166662',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-30',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有数千斤大米，有合适的价格请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166923',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市汉台区发布时间：2019-04-04购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167237',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-14',
 'pub_title': '求购玉米',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '需要购买一批玉米，用作养殖场鸡饲料,电话联系！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167452',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-17',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米5000公斤，要求干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '15229382221',
 'sup_user': '谭先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167580',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米3000公斤，要求水份14%以内，干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '18706733154',
 'sup_user': '高先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167644',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '油菜籽',
 'sup_address': '陕西汉中',
 'sup_description': '大量新鲜油菜籽出售',
 'sup_phone': '18292654661',
 'sup_user': '丁女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168148',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '15891399228',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168151',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤.优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168202',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购红宝石海棠胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购红宝石海棠胸径12至14公分，1.2米土球，数量1706颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168203',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购大叶女贞胸径10至12公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购大叶女贞，胸径10至12公分，1.2米土球，数量1348颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=168279',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '求购胸径4公分高杆石楠600棵',
 'sup_address': '周至县马召镇桃李坪村',
 'sup_description': '求购胸径4公分高杆石楠600棵，分枝点1.5米，有货请电话联系。',
 'sup_phone': '13891948456',
 'sup_user': '郭新峰'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 146, in process_item
    print(type(item['sup_description']) + item['sup_description'])
KeyError: 'sup_description'
2019-06-04 00:48:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168040',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应架豆王',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应架豆王300斤。',
 'sup_phone': '18092634616',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168041',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售芥兰',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售芥兰菜6000斤左右，价格面议，欢迎联系。',
 'sup_phone': '18192003238',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168043',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应西红柿',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应西红柿500斤。',
 'sup_phone': '15829468093',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168108',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应大蒜100斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '供应大蒜100斤.新蒜。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168125',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '出售土豆，天然产出',
 'sup_address': '汉中市汉台区',
 'sup_description': '出售纯天然土豆，粉糯可口，个头匀称，表面光滑，现挖先发价格面议欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168129',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '供给优质土豆',
 'sup_address': '陕西省汉中市汉台区宗营镇下寨村三组',
 'sup_description': '自家种植一亩品种为早大白的土豆，现已成熟，大约有1500斤需将其出售。有意者请联系本人。',
 'sup_phone': '18829662083',
 'sup_user': '黄玉莲'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168145',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售韭菜600斤，价格面议，欢迎联系。',
 'sup_phone': '15902991386',
 'sup_user': '马先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:48:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168146',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售小葱秧800斤，价格面议，欢迎联系。',
 'sup_phone': '13772449091',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 135, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 00:49:24 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://222.90.83.241/show.aspx?id=167476. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 00:58:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168296',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '低价销售直径3-10厘米的樱花树',
 'sup_address': '周至县终南村',
 'sup_description': '低价销售直径3-10厘米的樱花树8亩左右，树形好，价格低，欢迎需求朋友联系。联系：陈女士电话：13119161886地址：周至县终南村',
 'sup_phone': '13119161886',
 'sup_user': '陈女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=168305',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白蜡树',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有直径5公分白蜡树300棵，直径6公分白蜡树100棵，急于出售。欢迎电话联系。',
 'sup_phone': '13484667542',
 'sup_user': '闫兆'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-19',
 'info_from': 'http://222.90.83.241/show.aspx?id=168306',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白皮松',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有高度1米白皮松300棵，急于出售。欢迎电话联系。',
 'sup_phone': '13032916618',
 'sup_user': '刘展雄'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168288',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-7公分的香花槐20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-7公分的香花槐20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168289',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高3米以上的油松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高3米以上的油松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168290',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高1米左右的白皮松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高1米左右的白皮松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=167478',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '土鸡',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡，有意者请与丁先生联系，电话：13689190503。',
 'sup_phone': '13689190503',
 'sup_user': '丁先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167480',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-18',
 'pub_title': '出售红皮鸡蛋',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售红皮鸡蛋65盘，每盘重约4斤，价格面议，欢迎联系。',
 'sup_phone': '15353526258',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167567',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-19',
 'pub_title': '高先生长期供应牛奶',
 'sup_address': '周至县尚村镇马村',
 'sup_description': '高先生长期供应牛奶，价格面议。',
 'sup_phone': '15809220930',
 'sup_user': '高先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167589',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '出售黑狗',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '出售黑色1岁拉布拉多犬1只，价格面议，欢迎联系。',
 'sup_phone': '17791427630',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167638',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售白鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤白鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=167639',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售花鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤花鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167640',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售草鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤草鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167641',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售鲤鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤鲤鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167792',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售三元仔猪',
 'sup_address': '鄠邑区玉蝉街办割耳庄村',
 'sup_description': '出售三元仔猪10头，每头体重15公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15229279068',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167802',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售鹅蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售鹅蛋50枚，价格面议，欢迎联系。',
 'sup_phone': '15229076911',
 'sup_user': '王女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167846',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '供应羊羔5只',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '供应羊羔5只，单只体重大约25―28公斤，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167930',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售草鱼',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售鲜活草鱼500余条，每条重3斤--7斤，欢迎联系。',
 'sup_phone': '13572072008',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=167967',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '新鲜鸡蛋出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村（工业园区）',
 'sup_description': '本人是养殖专业户，现长期对外出售新鲜鸡蛋，货真价实，量大从优，价格面议！',
 'sup_phone': '18691645043',
 'sup_user': '老徐'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167968',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '鲜牛奶对外出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村7组',
 'sup_description': '本人饲养奶牛数头，长期对外出售新鲜牛奶，5公里免费送货上门，欢迎订购！',
 'sup_phone': '14791618835',
 'sup_user': '廖宝友'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167981',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售三元生猪',
 'sup_address': '高新区秦渡镇南焦羊村',
 'sup_description': '出售三元生猪30头，单头体重130公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029033406',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168239',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售肉猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售三元肉猪50头，体重120公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15829108410',
 'sup_user': '肖女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168246',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168261',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '土鸡蛋',
 'sup_address': '汉中市汉台区七里街道办事处染房营村四组',
 'sup_description': '本人在果园有散养蛋鸡，蛋质优良，无毒无公害，真正的绿色产品，价格优惠，欢迎大家选购。',
 'sup_phone': '13992693136',
 'sup_user': '唐世义'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168311',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜的土鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165873',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-04-19',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办事处王家湾村',
 'sup_description': '要求玉米颗粒饱满，无腐烂、无虫、无沙粒，有意出售的电话联系。',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=165984',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '求购红芋苗',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十三组',
 'sup_description': '求购秦薯四号红芋苗15000苗，有出售者请联系。',
 'sup_phone': '15109208586',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166662',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-30',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有数千斤大米，有合适的价格请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166923',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市汉台区发布时间：2019-04-04购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167237',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-14',
 'pub_title': '求购玉米',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '需要购买一批玉米，用作养殖场鸡饲料,电话联系！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167452',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-17',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米5000公斤，要求干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '15229382221',
 'sup_user': '谭先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167580',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米3000公斤，要求水份14%以内，干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '18706733154',
 'sup_user': '高先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167644',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '油菜籽',
 'sup_address': '陕西汉中',
 'sup_description': '大量新鲜油菜籽出售',
 'sup_phone': '18292654661',
 'sup_user': '丁女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168148',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '15891399228',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168151',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤.优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:58:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=158381',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-07',
 'pub_title': '求购野山药',
 'sup_address': '佛坪县陈家坝镇金星村二组',
 'sup_description': '求购野生山药，平均价格10元每斤，量大从优，',
 'sup_phone': '17730778050',
 'sup_user': '刘和秀'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=168305',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白蜡树',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有直径5公分白蜡树300棵，直径6公分白蜡树100棵，急于出售。欢迎电话联系。',
 'sup_phone': '13484667542',
 'sup_user': '闫兆'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-19',
 'info_from': 'http://222.90.83.241/show.aspx?id=168306',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白皮松',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有高度1米白皮松300棵，急于出售。欢迎电话联系。',
 'sup_phone': '13032916618',
 'sup_user': '刘展雄'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168286',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的早樱10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的早樱10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168287',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分的嫁接红梅20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分的嫁接红梅20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168288',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-7公分的香花槐20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-7公分的香花槐20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168289',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高3米以上的油松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高3米以上的油松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168290',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售高1米左右的白皮松10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售高1米左右的白皮松10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165873',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-04-19',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办事处王家湾村',
 'sup_description': '要求玉米颗粒饱满，无腐烂、无虫、无沙粒，有意出售的电话联系。',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=165984',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '求购红芋苗',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十三组',
 'sup_description': '求购秦薯四号红芋苗15000苗，有出售者请联系。',
 'sup_phone': '15109208586',
 'sup_user': '冯先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166662',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-30',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有数千斤大米，有合适的价格请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166923',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市汉台区发布时间：2019-04-04购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167237',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-14',
 'pub_title': '求购玉米',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '需要购买一批玉米，用作养殖场鸡饲料,电话联系！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167452',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-17',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米5000公斤，要求干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '15229382221',
 'sup_user': '谭先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167580',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购玉米',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购玉米3000公斤，要求水份14%以内，干净无霉变，价格面议，欢迎联系。',
 'sup_phone': '18706733154',
 'sup_user': '高先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167644',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '油菜籽',
 'sup_address': '陕西汉中',
 'sup_description': '大量新鲜油菜籽出售',
 'sup_phone': '18292654661',
 'sup_user': '丁女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168148',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '15891399228',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168151',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤.优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=158381',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-07',
 'pub_title': '求购野山药',
 'sup_address': '佛坪县陈家坝镇金星村二组',
 'sup_description': '求购野生山药，平均价格10元每斤，量大从优，',
 'sup_phone': '17730778050',
 'sup_user': '刘和秀'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=158576',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-10',
 'pub_title': '求购魔芋5000斤',
 'sup_address': '西安市周至县楼观镇上三清村',
 'sup_description': '我处急需魔芋，数量5000斤，每个200克以上，有意者，请尽快联系。',
 'sup_phone': '13474110275',
 'sup_user': '刘俊锋'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=158659',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2018-12-11',
 'pub_title': '大量收购乌笋种子',
 'sup_address': '汉中市佛坪县',
 'sup_description': '大量收购乌笋种子，土名：洋嚯。联系电话：13991608711/13892652745',
 'sup_phone': '13991608711',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158760',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-12',
 'pub_title': '大量求购线辣椒',
 'sup_address': '西安市阎良区关山镇关山村',
 'sup_description': '大量收购线辣椒，红绿均可，价格面议，欢迎联系。',
 'sup_phone': '18392532698',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158830',
 'pub_address': '汉中市汉台区',
 'pub_time': '2018-12-13',
 'pub_title': '求购洋芋种',
 'sup_address': '汉中市汉台区七里办事处文庙村',
 'sup_description': '黄先生等户求购洋芋种；品种有；荷兰洋芋、早大白洋芋。有货源的客户快来村联系，价格面议，数量不限。联系人；黄先生，地址；汉中市汉台区七里办事处文庙村，电话；13084883593.文庙村信息站发。',
 'sup_phone': '13084883593',
 'sup_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=159779',
 'pub_address': '西安市周至县',
 'pub_time': '2018-12-29',
 'pub_title': '求购200克以上魔芋5000斤',
 'sup_address': '周至县厚畛子镇同力村',
 'sup_description': '求购200克以上魔芋5000斤联系人:黄先生电话：１３４７４１１０２７５地址：周至县厚畛子镇同力村。',
 'sup_phone': '13474110275',
 'sup_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=160928',
 'pub_address': '西安市户县',
 'pub_time': '2019-01-24',
 'pub_title': '求购大葱',
 'sup_address': '鄠邑区玉蝉镇新向村',
 'sup_description': '求购大葱100斤，欢迎联系。',
 'sup_phone': '15091671829',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=165085',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-08',
 'pub_title': '大量收购甘蓝菜',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购甘蓝菜，要求单重2斤以上，价格随行就市，欢迎联系销售。',
 'sup_phone': '15291452658',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165124',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜蒜苔',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜蒜苔，日收购5吨，限陕西西安境内，有意者请联系，价格面议。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=165126',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-08',
 'pub_title': '求购鲜香椿',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜香椿芽，有意者请联系价格面议，限西安辖区内，',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=165372',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-04-11',
 'pub_title': '收购莲花白、螺丝辣椒',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '大量收购莲花白、螺丝辣椒，价格面议，欢迎广大菜农联系销售。',
 'sup_phone': '13474363373',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=165934',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-20',
 'pub_title': '收购洋槐花',
 'sup_address': '周至县楼观镇团标村',
 'sup_description': '收购洋槐花，有意者电话联系。',
 'sup_phone': '15091527877',
 'sup_user': '谢女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=166016',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-21',
 'pub_title': '求购紫薯苗',
 'sup_address': '周至县尚村镇新范村',
 'sup_description': '求购紫薯苗两万个，可以电话报价，有货及时联系',
 'sup_phone': '13619226724',
 'sup_user': '孙先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=166051',
 'pub_address': '西安市户县',
 'pub_time': '2019-04-22',
 'pub_title': '求购小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '求购小葱秧200斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166675',
 'pub_address': '西安市周至县',
 'pub_time': '2019-04-30',
 'pub_title': '求购鲜洋槐花',
 'sup_address': '周至县司竹镇北淇水村',
 'sup_description': '求购鲜洋槐花，数量不限，限西安境内，有意者请联系，量大可上门取货。',
 'sup_phone': '13571863504',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167311',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购葱秧',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购葱秧30公斤，品种不限，价格面议，欢迎联系。',
 'sup_phone': '18966810872',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-17',
 'info_from': 'http://222.90.83.241/show.aspx?id=167415',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-17',
 'pub_title': '求购藕种',
 'sup_address': '汉台区老君镇付庙村六组',
 'sup_description': '大量求购优质藕种！',
 'sup_phone': '13571611661',
 'sup_user': '张伟'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167848',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '求购大蒜5万斤',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '求购大蒜5万斤，要求个大，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168318',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '小辣子',
 'sup_address': '汉台区七里办事处金江2组',
 'sup_description': '王先生家中种植了各种蔬菜,小辣子已经成熟,正在大量出售,如有需求,请电话联系',
 'sup_phone': '15891461382',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168275',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高60公分大田侧柏1.5万株',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：高60公分大田侧柏1.5万株，价格面议，欢迎联系。',
 'sup_phone': '15877344352',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168276',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径1公分国槐3000棵',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：胸径1公分国槐3000棵，价格面议，欢迎联系。',
 'sup_phone': '13092046069',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:41 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168277',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径15公分龙爪槐20棵',
 'sup_address': '周至县四屯镇联三村',
 'sup_description': '出售：胸径15公分龙爪槐20棵，价格面议，欢迎联系。',
 'sup_phone': '15091151300',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168280',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售直径3公分左右的大叶女贞10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售直径3公分左右的大叶女贞10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168281',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分以上的红梅10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分以上的红梅10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168282',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径3-4公分以上的红枫10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径3-4公分以上的红枫10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168283',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径2-3公分的桂花10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径2-3公分的桂花10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168284',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的玉兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的玉兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168285',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5公分左右的红叶石兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5公分左右的红叶石兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168291',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售毛竹10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售毛竹10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168296',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '低价销售直径3-10厘米的樱花树',
 'sup_address': '周至县终南村',
 'sup_description': '低价销售直径3-10厘米的樱花树8亩左右，树形好，价格低，欢迎需求朋友联系。联系：陈女士电话：13119161886地址：周至县终南村',
 'sup_phone': '13119161886',
 'sup_user': '陈女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168220',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售新鲜大棚秀珍菇',
 'sup_address': '庆丰村1组',
 'sup_description': '1、汉台区老君镇庆丰村1组大量出售新鲜大棚秀珍菇，有意者请面议；2、地址：汉武路中段陕西省汇力园区对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167804',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜出售',
 'sup_address': '新校村',
 'sup_description': '现有大量新鲜蔬菜出售，批发零售皆可，主要有辣椒，西红柿，豆角，西蓝花等若有需要的请和我联系。',
 'sup_phone': '15760959624',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167815',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜',
 'sup_address': '汉台区铺镇锦福专业蔬菜合作社',
 'sup_description': '我村锦福蔬菜合作社现有:西葫芦、黄瓜、辣椒、茄子、西红柿对外批发出售；（可组织整车货源）欢迎新老客户前来订购！',
 'sup_phone': '13038477096',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=167817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-24',
 'pub_title': '魔芋出售',
 'sup_address': '陈家坝镇孔家湾村一组',
 'sup_description': '因土地用作它途，最近亟待出售一批魔芋，价格好商量！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167893',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菠菜',
 'sup_address': '鄠邑区渭丰镇定五村',
 'sup_description': '出售菠菜4000斤，价格面议，欢迎联系。',
 'sup_phone': '18710978332',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167894',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘亭街办南羊村',
 'sup_description': '出售韭菜，面积10亩，价格面议，欢迎联系。',
 'sup_phone': '13572179512',
 'sup_user': '周女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167895',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售矮青菜',
 'sup_address': '鄠邑区渭丰镇定六村',
 'sup_description': '出售矮青菜3000斤，价格面议，欢迎联系。',
 'sup_phone': '13109617130',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168026',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '蔬菜出售',
 'sup_address': '老君镇拐拐村',
 'sup_description': '大量出售西红柿与黄瓜，各3000斤左右。欢迎选购。',
 'sup_phone': '18591612273',
 'sup_user': '秦小强'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168040',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应架豆王',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应架豆王300斤。',
 'sup_phone': '18092634616',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168041',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售芥兰',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售芥兰菜6000斤左右，价格面议，欢迎联系。',
 'sup_phone': '18192003238',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168043',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应西红柿',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应西红柿500斤。',
 'sup_phone': '15829468093',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168108',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应大蒜100斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '供应大蒜100斤.新蒜。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168125',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '出售土豆，天然产出',
 'sup_address': '汉中市汉台区',
 'sup_description': '出售纯天然土豆，粉糯可口，个头匀称，表面光滑，现挖先发价格面议欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168129',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '供给优质土豆',
 'sup_address': '陕西省汉中市汉台区宗营镇下寨村三组',
 'sup_description': '自家种植一亩品种为早大白的土豆，现已成熟，大约有1500斤需将其出售。有意者请联系本人。',
 'sup_phone': '18829662083',
 'sup_user': '黄玉莲'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168145',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售韭菜600斤，价格面议，欢迎联系。',
 'sup_phone': '15902991386',
 'sup_user': '马先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168146',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售小葱秧800斤，价格面议，欢迎联系。',
 'sup_phone': '13772449091',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168170',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-30',
 'pub_title': '蒲瓜',
 'sup_address': '汉台区铺镇芦坝村一组',
 'sup_description': '我现有蒲瓜4000斤出售，批发价0.8元/每斤。',
 'sup_phone': '13630267456',
 'sup_user': '魏小民'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168293',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '大量出售架豆王',
 'sup_address': '西安市绿康果蔬苗木专业合作社',
 'sup_description': '出售架豆王60多亩，长度20-30厘米左右，质量好，价格低，欢迎联系。联系：蒲经理电话：13201689888地址：西安市绿康果蔬苗木专业合作社',
 'sup_phone': '13201689888',
 'sup_user': '蒲经理'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168304',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应西红柿',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '本人家有3亩温室西红柿成熟出售，货源、品质保证，价格面议，欢迎各地客商联系收购。',
 'sup_phone': '18092632479',
 'sup_user': '刘文'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168312',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '出售大蒜',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售红皮大蒜约400斤，价格面议，欢迎联系。',
 'sup_phone': '13571840519',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168261',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '土鸡蛋',
 'sup_address': '汉中市汉台区七里街道办事处染房营村四组',
 'sup_description': '本人在果园有散养蛋鸡，蛋质优良，无毒无公害，真正的绿色产品，价格优惠，欢迎大家选购。',
 'sup_phone': '13992693136',
 'sup_user': '唐世义'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168311',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜的土鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=167967',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '新鲜鸡蛋出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村（工业园区）',
 'sup_description': '本人是养殖专业户，现长期对外出售新鲜鸡蛋，货真价实，量大从优，价格面议！',
 'sup_phone': '18691645043',
 'sup_user': '老徐'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167968',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '鲜牛奶对外出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村7组',
 'sup_description': '本人饲养奶牛数头，长期对外出售新鲜牛奶，5公里免费送货上门，欢迎订购！',
 'sup_phone': '14791618835',
 'sup_user': '廖宝友'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167981',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售三元生猪',
 'sup_address': '高新区秦渡镇南焦羊村',
 'sup_description': '出售三元生猪30头，单头体重130公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029033406',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168239',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售肉猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售三元肉猪50头，体重120公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15829108410',
 'sup_user': '肖女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=167478',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '土鸡',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡，有意者请与丁先生联系，电话：13689190503。',
 'sup_phone': '13689190503',
 'sup_user': '丁先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 00:59:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167480',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-18',
 'pub_title': '出售红皮鸡蛋',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售红皮鸡蛋65盘，每盘重约4斤，价格面议，欢迎联系。',
 'sup_phone': '15353526258',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167567',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-19',
 'pub_title': '高先生长期供应牛奶',
 'sup_address': '周至县尚村镇马村',
 'sup_description': '高先生长期供应牛奶，价格面议。',
 'sup_phone': '15809220930',
 'sup_user': '高先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167589',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '出售黑狗',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '出售黑色1岁拉布拉多犬1只，价格面议，欢迎联系。',
 'sup_phone': '17791427630',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167638',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售白鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤白鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=167639',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售花鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤花鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167640',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售草鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤草鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167641',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售鲤鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤鲤鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167792',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售三元仔猪',
 'sup_address': '鄠邑区玉蝉街办割耳庄村',
 'sup_description': '出售三元仔猪10头，每头体重15公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15229279068',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167802',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售鹅蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售鹅蛋50枚，价格面议，欢迎联系。',
 'sup_phone': '15229076911',
 'sup_user': '王女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167846',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '供应羊羔5只',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '供应羊羔5只，单只体重大约25―28公斤，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167930',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售草鱼',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售鲜活草鱼500余条，每条重3斤--7斤，欢迎联系。',
 'sup_phone': '13572072008',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168246',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168022',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购胸径4公分的国槐50棵',
 'sup_address': '周至县翠峰镇农林村四组',
 'sup_description': '求购胸径4公分的国槐50棵。',
 'sup_phone': '15399480380',
 'sup_user': '侯女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168042',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径12公分香花槐200棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径12公分香花槐200棵，要求分支点2.8米以上，树杆端直，树冠优美，有货者请尽快联系，看货议价。',
 'sup_phone': '18229025186',
 'sup_user': '毛先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168047',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径10公分红叶碧桃20棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径10公分红叶碧桃20棵，要求大半冠，树干端直，带土球80公分，有货者请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168049',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分国槐32棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分国槐32棵，要求分支点2.5-3米，4米原生冠，带常规土球，有货的朋友请尽快联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168051',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分七叶树42棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分七叶树42棵，要求分支点2.8-3.2米，4米原生冠，带常规土球，有货者请速联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168115',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购白皮松',
 'sup_address': '周至县二曲街道办事处李家村',
 'sup_description': '本处现急需求购一米起步老芽三级18碗碗白皮松，一车装7000株，有货请电话联系。',
 'sup_phone': '13759925466',
 'sup_user': '李朝辉'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=168137',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-29',
 'pub_title': '求购高1.5米以上的塔柏200棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高1.5米以上的塔柏200棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168193',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购雪松6至7米',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购雪松6至7米，冠幅2米至2.5，1.2米土球，总数量，235颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168195',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购七叶树',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购七叶树，胸径15至18公分，要求1.5米土球，数量826颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168197',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购国槐胸径20至22公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购国槐，胸径20至22公分，1.5米土球，数量689颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168198',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购广玉兰胸径18至20公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购广玉兰胸径18至20公分，1.5米土球，数量，365颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168199',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购法桐胸径15至17公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购法桐，胸径15至17公分，1.5米土球，数量804颗。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168200',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购桂花树胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购桂花树，胸径12至14公分，1.2米土球，数量1568颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:12 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168201',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购字画木槿地径5至7公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购字画木槿地径5至7公分，1米土球，数量1478颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168202',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购红宝石海棠胸径12至14公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购红宝石海棠胸径12至14公分，1.2米土球，数量1706颗，有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:13 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168203',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '求购大叶女贞胸径10至12公分',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '求购大叶女贞，胸径10至12公分，1.2米土球，数量1348颗。有意者请与谢先生联系。',
 'sup_phone': '13572024234',
 'sup_user': '谢先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=161471',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-14',
 'pub_title': '求购鸭蛋',
 'sup_address': '陕西省西安市周至县集贤镇西村',
 'sup_description': '求购鸭蛋20斤，有货者请联系。',
 'sup_phone': '13519133896',
 'sup_user': '田先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:14 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168018',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购高5.0米以上的白皮松13棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高5.0米以上的白皮松13棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162023',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购散养100只老母鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购散养老母鸡100只，7--8个月，体重5斤左右，价格合适，欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162045',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购淘汰红毛蛋鸡',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '求购淘汰红毛蛋鸡800只-均重4.2斤以上，毛色好，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:15 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-02-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=162050',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-22',
 'pub_title': '求购各种狗',
 'sup_address': '陕西省西安市周至县尚村镇南寨村',
 'sup_description': '大量求购各种狗，哈士奇、拉布拉多、金毛、萨摩、阿拉斯加、边牧、马犬、博美、比熊等，价格面议欢迎联系。',
 'sup_phone': '13572999802',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=162949',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-03-04',
 'pub_title': '求购羊羔',
 'sup_address': '阎良区关山街道办老王村小马组',
 'sup_description': '上门收购小公羊、母羊羔，价格随行，欢迎联系。',
 'sup_phone': '13759637031',
 'sup_user': '杨先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:16 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=163540',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-14',
 'pub_title': '求购鹅蛋',
 'sup_address': '鄠邑区涝店镇马家堡村',
 'sup_description': '求购鹅蛋100枚，价格面议，欢迎联系。',
 'sup_phone': '13484800110',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-29',
 'info_from': 'http://222.90.83.241/show.aspx?id=164300',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购地径8公分紫薇20棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购地径8公分紫薇20棵，要求分支点60公分以上，有意者请电话联系。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:17 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=164508',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-25',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉台区汉王镇大兴村',
 'sup_description': '价格1元每枚',
 'sup_phone': '15129581840',
 'sup_user': '胡生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166044',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-22',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:18 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166500',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-28',
 'pub_title': '求购土鸡蛋',
 'sup_address': '吴基庄村',
 'sup_description': '需要购买土鸡蛋60个，物美价廉',
 'sup_phone': '13772809382',
 'sup_user': '张女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '求购一批土鸡鸡苗',
 'sup_address': '陈家坝镇孔家湾村',
 'sup_description': '现需要一批鸡苗（200只），适应本地气候，成活率高的！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:19 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=166821',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-05',
 'pub_title': '收购群羊',
 'sup_address': '陕西省汉中市',
 'sup_description': '大量收购群羊，价格美丽。联系电话（微信）：18828091357。',
 'sup_phone': '18828091357',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=166874',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-06',
 'pub_title': '求购母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购经产母猪5头，要求健康无病，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:20 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=166929',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-07',
 'pub_title': '求购土鸡蛋',
 'sup_address': '汉中市汉台区',
 'sup_description': '求购土鸡蛋所在地：汉中市汉台区发布时间：2019-04-22求购土鸡蛋，数量不多，自己吃',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167294',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-15',
 'pub_title': '求购猪仔',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '求购猪仔10头，要求单头重25斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029246927',
 'sup_user': '刘先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=167341',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-16',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '常期收购淘汰母猪，价格面议，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '吴先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167623',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购鸡蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '求购红皮鸡蛋400盘，每盘重1.9公斤左右，价格面议，欢迎联系。',
 'sup_phone': '18392549287',
 'sup_user': '曹先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167624',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '求购青年母鸡',
 'sup_address': '鄠邑区甘河镇北板村',
 'sup_description': '求购海兰褐青年母鸡1500只，要求日龄60天-100天，价格面议，欢迎联系。',
 'sup_phone': '18629514457',
 'sup_user': '董先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=168241',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '求购淘汰母猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '大量求购淘汰母猪，价格随行就市，欢迎联系。',
 'sup_phone': '18082209962',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=168279',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '求购胸径4公分高杆石楠600棵',
 'sup_address': '周至县马召镇桃李坪村',
 'sup_description': '求购胸径4公分高杆石楠600棵，分枝点1.5米，有货请电话联系。',
 'sup_phone': '13891948456',
 'sup_user': '郭新峰'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168039',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径14公分银杏350棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径14公分银杏350棵，要求分支点2.8-3.5米，带土球90公分，有货的朋友请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=161762',
 'pub_address': '西安市周至县',
 'pub_time': '2019-02-19',
 'pub_title': '求购胸径20-22公分银杏55棵',
 'sup_address': '周至县广济镇东欢乐村',
 'sup_description': '求购胸径20-22公分银杏，要求高度7-8米，冠幅4米，数量55棵，有货者电话联系，价格面议。',
 'sup_phone': '13630220567',
 'sup_user': '朱先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168213',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售新小麦',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售新小麦3000余斤，欢迎联系。',
 'sup_phone': '18792949262',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168247',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大量大米，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=168268',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '现有今年新油菜籽3000斤左右颗粒饱满油菜籽颜色黑已经处理干净小灰尘出油率高油菜籽完全晒干发的有图片但仅为参考还是要看实际货物如有需要者可以和我联系非诚勿扰!',
 'sup_phone': '18700657341',
 'sup_user': '龙女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168310',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '大米',
 'sup_address': '叶家岭',
 'sup_description': '有大米，请联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168319',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售油菜籽',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '有2019年出产的油菜籽2000斤欲对外出售，菜籽干度好，出油率高，如有购买者请联系，价格面议。',
 'sup_phone': '18391619491',
 'sup_user': '苟建荣'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168321',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '出售小麦',
 'sup_address': '陕西省汉中市汉台区七里办事处田家庙村',
 'sup_description': '本人有2019年出产小麦2000斤现对外出售，麦子干度好，色泽鲜亮。如有需要者请联系。',
 'sup_phone': '13259287568',
 'sup_user': '孙培军'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168081',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '优质菜籽',
 'sup_address': '汉台区武乡镇崔营村',
 'sup_description': '本村大量上市2019年优质油菜籽，量大、质量优，有意者来电咨询洽谈',
 'sup_phone': '18220666628',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168104',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168105',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售谷子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人有几千斤稻谷需出售，米质香糯，欢迎联系洽谈！',
 'sup_phone': '13992662014',
 'sup_user': '武先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167878',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售土豆',
 'sup_address': '陕西省西安市周至县尚村镇张寨村八组',
 'sup_description': '我处有3亩地土豆出售，有需求者请联系。',
 'sup_phone': '18729974792',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167879',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菜油',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十四组',
 'sup_description': '我处有200斤菜油出售，有需求者电话联系。',
 'sup_phone': '15991614124',
 'sup_user': '闫先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167941',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售玉米',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售玉米3000斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168007',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售2019新收小麦',
 'sup_address': '汉台区七里街道马家坝村一组',
 'sup_description': '家有2019年应季新收小麦800斤需出售，有意者请于我联系，电话13891622698',
 'sup_phone': '13891622698',
 'sup_user': '衡正斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168037',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售菜籽、小麦',
 'sup_address': '汉台区老君镇王道池村',
 'sup_description': '现有刚收获的小麦、菜籽。价格随市场。联系电话：18891618650联系人李先生',
 'sup_phone': '18891618650',
 'sup_user': '李新华'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168123',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '汉台区武乡镇同心村',
 'sup_description': '大量今年新油菜籽出售，地址：汉台区武乡镇同心。联系电话：18710666754张女士',
 'sup_phone': '18710666754',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168130',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '油菜籽',
 'sup_address': '陕西省汉中市汉台区武乡镇共力村',
 'sup_description': '我店现有油菜籽出售，无杂质、无霉粒，数吨如有需求者请与我联系，联系电话：13571681271联系地址：陕西省汉中市汉台区武乡镇',
 'sup_phone': '13571681271',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168097',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售西瓜',
 'sup_address': '鄠邑区蒋村镇同兴村',
 'sup_description': '出售甜王西瓜，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15029807630',
 'sup_user': '陈先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168103',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售杏子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人出售可口香甜的杏子，价格4.5每斤，需求者请联系！',
 'sup_phone': '13892696179',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168124',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '种植露天桃子，味道好，自然熟',
 'sup_address': '汉中市汉台区',
 'sup_description': '自家种植的桃子，口感有清脆和微软两种，味道有纯甜，微酸甜两种，现摘现送无化肥农药，真正绿色无污染，关键是味道好，味道好，味道好！价格面议，欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168133',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售丰园红杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售丰园红早熟杏，面积2.5亩，价格面议，欢迎联系。',
 'sup_phone': '17719535936',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168134',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售樱桃',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售樱桃，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15829462025',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168136',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售金太阳杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售金太阳杏，产量约2500斤，价格随行就市，欢迎联系。',
 'sup_phone': '15353714592',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168222',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应次杏子丰园红5000斤',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村供应次杏子丰园红5000斤，价钱面议。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售油桃',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售油桃，个大，味道不错。有意者请与张女士联系。',
 'sup_phone': '18717316979',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '预售沙红桃',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村预售沙红桃，有意者前来订购。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168233',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应枣花蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应枣花蜜1000斤，一斤20元，价钱面议。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168234',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应洋槐蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应洋槐蜜1000斤，一斤20元。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168266',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '桃子',
 'sup_address': '陕西省汉中市汉台区老君镇徐家营村',
 'sup_description': '现有新鲜桃子5亩桃子属于老品种个头大小合适桃子味道浓甜汁多现在正是出售的季节有需要采摘的或者做生意的可以联系我自己下地采摘价格可以看完水果以后商量非诚勿扰谢谢!',
 'sup_phone': '13379360380',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168292',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '供应金太阳杏1万斤',
 'sup_address': '周至县竹峪镇张龙村',
 'sup_description': '供应金太阳杏1万斤，价格电议。',
 'sup_phone': '18092043194',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:00:40 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=168301',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应阎良优质绿皮甜瓜',
 'sup_address': '西安市阎良区关山街道办界坊村西界组',
 'sup_description': '我家种植的绿皮甜瓜刚上市，单重1-1.5斤，香甜难忘，欢迎你品尝后购买。',
 'sup_phone': '18092295878',
 'sup_user': '郭大英'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item['result_item']))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168291',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售毛竹10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售毛竹10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168296',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '低价销售直径3-10厘米的樱花树',
 'sup_address': '周至县终南村',
 'sup_description': '低价销售直径3-10厘米的樱花树8亩左右，树形好，价格低，欢迎需求朋友联系。联系：陈女士电话：13119161886地址：周至县终南村',
 'sup_phone': '13119161886',
 'sup_user': '陈女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-20',
 'info_from': 'http://222.90.83.241/show.aspx?id=168305',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白蜡树',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有直径5公分白蜡树300棵，直径6公分白蜡树100棵，急于出售。欢迎电话联系。',
 'sup_phone': '13484667542',
 'sup_user': '闫兆'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-19',
 'info_from': 'http://222.90.83.241/show.aspx?id=168306',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售白皮松',
 'sup_address': '西安市周至县集贤镇刘家堡村',
 'sup_description': '我地现有高度1米白皮松300棵，急于出售。欢迎电话联系。',
 'sup_phone': '13032916618',
 'sup_user': '刘展雄'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:34 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168275',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高60公分大田侧柏1.5万株',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：高60公分大田侧柏1.5万株，价格面议，欢迎联系。',
 'sup_phone': '15877344352',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168276',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径1公分国槐3000棵',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：胸径1公分国槐3000棵，价格面议，欢迎联系。',
 'sup_phone': '13092046069',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:35 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168277',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径15公分龙爪槐20棵',
 'sup_address': '周至县四屯镇联三村',
 'sup_description': '出售：胸径15公分龙爪槐20棵，价格面议，欢迎联系。',
 'sup_phone': '15091151300',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:36 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:37 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:38 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:01:39 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-03-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164647',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-03-27',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item["result_item"]))
TypeError: can only concatenate str (not "ItemMeta") to str
2019-06-04 01:02:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167641',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售鲤鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤鲤鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:21 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167792',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售三元仔猪',
 'sup_address': '鄠邑区玉蝉街办割耳庄村',
 'sup_description': '出售三元仔猪10头，每头体重15公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15229279068',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167802',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售鹅蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售鹅蛋50枚，价格面议，欢迎联系。',
 'sup_phone': '15229076911',
 'sup_user': '王女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:22 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167846',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '供应羊羔5只',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '供应羊羔5只，单只体重大约25―28公斤，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167930',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售草鱼',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售鲜活草鱼500余条，每条重3斤--7斤，欢迎联系。',
 'sup_phone': '13572072008',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:23 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=167967',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '新鲜鸡蛋出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村（工业园区）',
 'sup_description': '本人是养殖专业户，现长期对外出售新鲜鸡蛋，货真价实，量大从优，价格面议！',
 'sup_phone': '18691645043',
 'sup_user': '老徐'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167968',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '鲜牛奶对外出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村7组',
 'sup_description': '本人饲养奶牛数头，长期对外出售新鲜牛奶，5公里免费送货上门，欢迎订购！',
 'sup_phone': '14791618835',
 'sup_user': '廖宝友'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:24 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:25 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168275',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高60公分大田侧柏1.5万株',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：高60公分大田侧柏1.5万株，价格面议，欢迎联系。',
 'sup_phone': '15877344352',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:26 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168276',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径1公分国槐3000棵',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：胸径1公分国槐3000棵，价格面议，欢迎联系。',
 'sup_phone': '13092046069',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=168278',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高80公分兰天竹营养钵3500株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：高80公分兰天竹营养钵3500株，价格面议，欢迎联系。',
 'sup_phone': '15319458368',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168280',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售直径3公分左右的大叶女贞10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售直径3公分左右的大叶女贞10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:27 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168281',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分以上的红梅10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分以上的红梅10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168282',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径3-4公分以上的红枫10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径3-4公分以上的红枫10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:28 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168283',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径2-3公分的桂花10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径2-3公分的桂花10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168284',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的玉兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的玉兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:29 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168285',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5公分左右的红叶石兰10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5公分左右的红叶石兰10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168286',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径5-6公分的早樱10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径5-6公分的早樱10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168287',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分的嫁接红梅20亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分的嫁接红梅20亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:30 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168018',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购高5.0米以上的白皮松13棵',
 'sup_address': '周至县辛家寨金家庄村',
 'sup_description': '求购高5.0米以上的白皮松13棵，价格电话联系。',
 'sup_phone': '15389454558',
 'sup_user': '金成岐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168022',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '求购胸径4公分的国槐50棵',
 'sup_address': '周至县翠峰镇农林村四组',
 'sup_description': '求购胸径4公分的国槐50棵。',
 'sup_phone': '15399480380',
 'sup_user': '侯女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:31 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168039',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径14公分银杏350棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径14公分银杏350棵，要求分支点2.8-3.5米，带土球90公分，有货的朋友请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168042',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径12公分香花槐200棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径12公分香花槐200棵，要求分支点2.8米以上，树杆端直，树冠优美，有货者请尽快联系，看货议价。',
 'sup_phone': '18229025186',
 'sup_user': '毛先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:32 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168047',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径10公分红叶碧桃20棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径10公分红叶碧桃20棵，要求大半冠，树干端直，带土球80公分，有货者请速联系，看货议价。',
 'sup_phone': '18091297700',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:33 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-04',
 'info_from': 'http://222.90.83.241/show.aspx?id=168049',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '急购胸径18公分国槐32棵',
 'sup_address': '西安市周至县竹峪镇南西沟村',
 'sup_description': '急购胸径18公分国槐32棵，要求分支点2.5-3米，4米原生冠，带常规土球，有货的朋友请尽快联系，看货议价。',
 'sup_phone': '15596469111',
 'sup_user': '赵先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:42 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168304',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应西红柿',
 'sup_address': '西安市阎良区关山街道办南房村刘东组',
 'sup_description': '本人家有3亩温室西红柿成熟出售，货源、品质保证，价格面议，欢迎各地客商联系收购。',
 'sup_phone': '18092632479',
 'sup_user': '刘文'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168312',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '出售大蒜',
 'sup_address': '西安市阎良区关山街道办老王村西北组',
 'sup_description': '出售红皮大蒜约400斤，价格面议，欢迎联系。',
 'sup_phone': '13571840519',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:43 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168125',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '出售土豆，天然产出',
 'sup_address': '汉中市汉台区',
 'sup_description': '出售纯天然土豆，粉糯可口，个头匀称，表面光滑，现挖先发价格面议欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168129',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '供给优质土豆',
 'sup_address': '陕西省汉中市汉台区宗营镇下寨村三组',
 'sup_description': '自家种植一亩品种为早大白的土豆，现已成熟，大约有1500斤需将其出售。有意者请联系本人。',
 'sup_phone': '18829662083',
 'sup_user': '黄玉莲'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:44 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168145',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售韭菜600斤，价格面议，欢迎联系。',
 'sup_phone': '15902991386',
 'sup_user': '马先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168146',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售小葱秧',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售小葱秧800斤，价格面议，欢迎联系。',
 'sup_phone': '13772449091',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:45 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168170',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-30',
 'pub_title': '蒲瓜',
 'sup_address': '汉台区铺镇芦坝村一组',
 'sup_description': '我现有蒲瓜4000斤出售，批发价0.8元/每斤。',
 'sup_phone': '13630267456',
 'sup_user': '魏小民'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167804',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-24',
 'pub_title': '蔬菜出售',
 'sup_address': '新校村',
 'sup_description': '现有大量新鲜蔬菜出售，批发零售皆可，主要有辣椒，西红柿，豆角，西蓝花等若有需要的请和我联系。',
 'sup_phone': '15760959624',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167476',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '出售土鸡蛋',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡蛋，有意者请与吴先生联系，电话：18792776716',
 'sup_phone': '18792776716',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:46 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168093',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '出售手感猕猴桃',
 'sup_address': '周至县楼观镇焦镇村',
 'sup_description': '出售分拣出来手感海沃德猕猴桃1000多斤，看货谈价。',
 'sup_phone': '13119165333',
 'sup_user': '菜先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168097',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售西瓜',
 'sup_address': '鄠邑区蒋村镇同兴村',
 'sup_description': '出售甜王西瓜，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15029807630',
 'sup_user': '陈先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:47 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168103',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售杏子',
 'sup_address': '汉中市汉台区河东店镇张宅村',
 'sup_description': '本人出售可口香甜的杏子，价格4.5每斤，需求者请联系！',
 'sup_phone': '13892696179',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168124',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '种植露天桃子，味道好，自然熟',
 'sup_address': '汉中市汉台区',
 'sup_description': '自家种植的桃子，口感有清脆和微软两种，味道有纯甜，微酸甜两种，现摘现送无化肥农药，真正绿色无污染，关键是味道好，味道好，味道好！价格面议，欢迎订购',
 'sup_phone': '13892601254',
 'sup_user': '陈雨萱'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:48 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168133',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售丰园红杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售丰园红早熟杏，面积2.5亩，价格面议，欢迎联系。',
 'sup_phone': '17719535936',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168134',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售樱桃',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售樱桃，面积3亩，价格面议，欢迎联系。',
 'sup_phone': '15829462025',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:49 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-09',
 'info_from': 'http://222.90.83.241/show.aspx?id=168136',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-29',
 'pub_title': '出售金太阳杏',
 'sup_address': '鄠邑区石井镇栗园坡村',
 'sup_description': '出售金太阳杏，产量约2500斤，价格随行就市，欢迎联系。',
 'sup_phone': '15353714592',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168155',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-29',
 'pub_title': '桃子',
 'sup_address': '汉台区老君镇',
 'sup_description': '个大皮薄.果实色鲜味美',
 'sup_phone': '15771866677',
 'sup_user': '胡先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168159',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-30',
 'pub_title': '出售秦岭板房子土蜂蜜1000斤',
 'sup_address': '周至县板房子镇齐心村',
 'sup_description': '出售秦岭板房子土蜂蜜1000斤，物美价廉，需要请电话联系。',
 'sup_phone': '15829622566',
 'sup_user': '李女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168219',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '大量出售大棚西瓜',
 'sup_address': '庆丰村9组',
 'sup_description': '1、汉台区老君镇庆丰村2组即将大量出售新鲜大棚西瓜，有意者请前来现场订购；2、地址：汉武路中段汉中市红旗机械厂对面；3、',
 'sup_phone': '13892621626',
 'sup_user': '刘慧慧'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168222',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应次杏子丰园红5000斤',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村供应次杏子丰园红5000斤，价钱面议。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168225',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '出售油桃',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售油桃，个大，味道不错。有意者请与张女士联系。',
 'sup_phone': '18717316979',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168229',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '预售沙红桃',
 'sup_address': '周至县翠峰镇官庄村',
 'sup_description': '我村预售沙红桃，有意者前来订购。',
 'sup_phone': '15319451189',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168233',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应枣花蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应枣花蜜1000斤，一斤20元，价钱面议。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168234',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-31',
 'pub_title': '供应洋槐蜜',
 'sup_address': '周至县翠峰镇官村',
 'sup_description': '田女士供应洋槐蜜1000斤，一斤20元。',
 'sup_phone': '13649282312',
 'sup_user': '田女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168266',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '桃子',
 'sup_address': '陕西省汉中市汉台区老君镇徐家营村',
 'sup_description': '现有新鲜桃子5亩桃子属于老品种个头大小合适桃子味道浓甜汁多现在正是出售的季节有需要采摘的或者做生意的可以联系我自己下地采摘价格可以看完水果以后商量非诚勿扰谢谢!',
 'sup_phone': '13379360380',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-15',
 'info_from': 'http://222.90.83.241/show.aspx?id=168292',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '供应金太阳杏1万斤',
 'sup_address': '周至县竹峪镇张龙村',
 'sup_description': '供应金太阳杏1万斤，价格电议。',
 'sup_phone': '18092043194',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=168301',
 'pub_address': '西安市阎良区',
 'pub_time': '2019-06-02',
 'pub_title': '供应阎良优质绿皮甜瓜',
 'sup_address': '西安市阎良区关山街道办界坊村西界组',
 'sup_description': '我家种植的绿皮甜瓜刚上市，单重1-1.5斤，香甜难忘，欢迎你品尝后购买。',
 'sup_phone': '18092295878',
 'sup_user': '郭大英'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168320',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '杏',
 'sup_address': '陕西省汉中市汉台区',
 'sup_description': '好吃的杏子，有想法联系啊',
 'sup_phone': '18829863123',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=168322',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-03',
 'pub_title': '咸阳甜杏',
 'sup_address': '陕西省汉中市陕西理工大学',
 'sup_description': '45一箱，包邮啊',
 'sup_phone': '18409168137',
 'sup_user': '王斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=167478',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-18',
 'pub_title': '土鸡',
 'sup_address': '西安市周至县骆峪镇西沟村',
 'sup_description': '出售土鸡，有意者请与丁先生联系，电话：13689190503。',
 'sup_phone': '13689190503',
 'sup_user': '丁先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167480',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-18',
 'pub_title': '出售红皮鸡蛋',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售红皮鸡蛋65盘，每盘重约4斤，价格面议，欢迎联系。',
 'sup_phone': '15353526258',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167567',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-19',
 'pub_title': '高先生长期供应牛奶',
 'sup_address': '周至县尚村镇马村',
 'sup_description': '高先生长期供应牛奶，价格面议。',
 'sup_phone': '15809220930',
 'sup_user': '高先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=167589',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-20',
 'pub_title': '出售黑狗',
 'sup_address': '鄠邑区甘亭街办洪洞庵村',
 'sup_description': '出售黑色1岁拉布拉多犬1只，价格面议，欢迎联系。',
 'sup_phone': '17791427630',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-13',
 'info_from': 'http://222.90.83.241/show.aspx?id=167638',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售白鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤白鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-14',
 'info_from': 'http://222.90.83.241/show.aspx?id=167639',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售花鲢',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤花鲢出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-22',
 'info_from': 'http://222.90.83.241/show.aspx?id=167640',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售草鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤草鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-21',
 'info_from': 'http://222.90.83.241/show.aspx?id=167641',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-20',
 'pub_title': '出售鲤鱼',
 'sup_address': '武乡镇吴庄村',
 'sup_description': '我库现有8000斤鲤鱼出售鱼均2斤左右，交通便利，价格面议，有意者请提前一天联系。',
 'sup_phone': '13892625622',
 'sup_user': '吴先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:02:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167792',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售三元仔猪',
 'sup_address': '鄠邑区玉蝉街办割耳庄村',
 'sup_description': '出售三元仔猪10头，每头体重15公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15229279068',
 'sup_user': '刘先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-03',
 'info_from': 'http://222.90.83.241/show.aspx?id=167802',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-23',
 'pub_title': '出售鹅蛋',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售鹅蛋50枚，价格面议，欢迎联系。',
 'sup_phone': '15229076911',
 'sup_user': '王女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-25',
 'info_from': 'http://222.90.83.241/show.aspx?id=167846',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-25',
 'pub_title': '供应羊羔5只',
 'sup_address': '周至县司竹镇红丰村',
 'sup_description': '供应羊羔5只，单只体重大约25―28公斤，价格面议。',
 'sup_phone': '13572087795',
 'sup_user': '姚先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-27',
 'info_from': 'http://222.90.83.241/show.aspx?id=167930',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售草鱼',
 'sup_address': '鄠邑区石井镇柿园村',
 'sup_description': '出售鲜活草鱼500余条，每条重3斤--7斤，欢迎联系。',
 'sup_phone': '13572072008',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=167967',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '新鲜鸡蛋出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村（工业园区）',
 'sup_description': '本人是养殖专业户，现长期对外出售新鲜鸡蛋，货真价实，量大从优，价格面议！',
 'sup_phone': '18691645043',
 'sup_user': '老徐'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=167968',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-27',
 'pub_title': '鲜牛奶对外出售',
 'sup_address': '陕西省汉中市汉台区铺镇杨庵村7组',
 'sup_description': '本人饲养奶牛数头，长期对外出售新鲜牛奶，5公里免费送货上门，欢迎订购！',
 'sup_phone': '14791618835',
 'sup_user': '廖宝友'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167981',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售三元生猪',
 'sup_address': '高新区秦渡镇南焦羊村',
 'sup_description': '出售三元生猪30头，单头体重130公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15029033406',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168239',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-31',
 'pub_title': '出售肉猪',
 'sup_address': '鄠邑区玉蝉街办新兴村',
 'sup_description': '出售三元肉猪50头，体重120公斤左右，价格面议，欢迎联系。',
 'sup_phone': '15829108410',
 'sup_user': '肖女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168246',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168261',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-31',
 'pub_title': '土鸡蛋',
 'sup_address': '汉中市汉台区七里街道办事处染房营村四组',
 'sup_description': '本人在果园有散养蛋鸡，蛋质优良，无毒无公害，真正的绿色产品，价格优惠，欢迎大家选购。',
 'sup_phone': '13992693136',
 'sup_user': '唐世义'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=168311',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-06-02',
 'pub_title': '鸡蛋',
 'sup_address': '叶家岭',
 'sup_description': '有新鲜的土鸡蛋，有意者联系',
 'sup_phone': '13772805171',
 'sup_user': '叶女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=167817',
 'pub_address': '汉中市佛坪县',
 'pub_time': '2019-05-24',
 'pub_title': '魔芋出售',
 'sup_address': '陈家坝镇孔家湾村一组',
 'sup_description': '因土地用作它途，最近亟待出售一批魔芋，价格好商量！',
 'sup_phone': '13892647822',
 'sup_user': '杨东'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167893',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菠菜',
 'sup_address': '鄠邑区渭丰镇定五村',
 'sup_description': '出售菠菜4000斤，价格面议，欢迎联系。',
 'sup_phone': '18710978332',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-10-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167894',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售韭菜',
 'sup_address': '鄠邑区甘亭街办南羊村',
 'sup_description': '出售韭菜，面积10亩，价格面议，欢迎联系。',
 'sup_phone': '13572179512',
 'sup_user': '周女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167895',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-26',
 'pub_title': '出售矮青菜',
 'sup_address': '鄠邑区渭丰镇定六村',
 'sup_description': '出售矮青菜3000斤，价格面议，欢迎联系。',
 'sup_phone': '13109617130',
 'sup_user': '赵女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:06 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168026',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '蔬菜出售',
 'sup_address': '老君镇拐拐村',
 'sup_description': '大量出售西红柿与黄瓜，各3000斤左右。欢迎选购。',
 'sup_phone': '18591612273',
 'sup_user': '秦小强'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168040',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应架豆王',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应架豆王300斤。',
 'sup_phone': '18092634616',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:07 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168041',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-28',
 'pub_title': '出售芥兰',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售芥兰菜6000斤左右，价格面议，欢迎联系。',
 'sup_phone': '18192003238',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168043',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应西红柿',
 'sup_address': '周至县富仁镇富仁村',
 'sup_description': '供应西红柿500斤。',
 'sup_phone': '15829468093',
 'sup_user': '刘女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=168108',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-28',
 'pub_title': '供应大蒜100斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '供应大蒜100斤.新蒜。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:08 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-16',
 'info_from': 'http://222.90.83.241/show.aspx?id=167878',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售土豆',
 'sup_address': '陕西省西安市周至县尚村镇张寨村八组',
 'sup_description': '我处有3亩地土豆出售，有需求者请联系。',
 'sup_phone': '18729974792',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=167879',
 'pub_address': '西安市周至县',
 'pub_time': '2019-05-26',
 'pub_title': '出售菜油',
 'sup_address': '陕西省西安市周至县尚村镇张寨村十四组',
 'sup_description': '我处有200斤菜油出售，有需求者电话联系。',
 'sup_phone': '15991614124',
 'sup_user': '闫先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:09 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=167941',
 'pub_address': '西安市户县',
 'pub_time': '2019-05-27',
 'pub_title': '出售玉米',
 'sup_address': '鄠邑区甘河镇元驾村',
 'sup_description': '出售玉米3000斤，价格面议，欢迎联系。',
 'sup_phone': '18729230557',
 'sup_user': '马女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=168007',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售2019新收小麦',
 'sup_address': '汉台区七里街道马家坝村一组',
 'sup_description': '家有2019年应季新收小麦800斤需出售，有意者请于我联系，电话13891622698',
 'sup_phone': '13891622698',
 'sup_user': '衡正斌'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:10 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=168037',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '出售菜籽、小麦',
 'sup_address': '汉台区老君镇王道池村',
 'sup_description': '现有刚收获的小麦、菜籽。价格随市场。联系电话：18891618650联系人李先生',
 'sup_phone': '18891618650',
 'sup_user': '李新华'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:11 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-07',
 'info_from': 'http://222.90.83.241/show.aspx?id=168081',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-05-28',
 'pub_title': '优质菜籽',
 'sup_address': '汉台区武乡镇崔营村',
 'sup_description': '本村大量上市2019年优质油菜籽，量大、质量优，有意者来电咨询洽谈',
 'sup_phone': '18220666628',
 'sup_user': '崔先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print('item type:'+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:11 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://222.90.83.241/show.aspx?id=168104. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:03:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-08',
 'info_from': 'http://222.90.83.241/show.aspx?id=168274',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：燕尾苗3万株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：燕尾苗3万株，价格面议，欢迎联系。',
 'sup_phone': '15191460244',
 'sup_user': '吴女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168275',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高60公分大田侧柏1.5万株',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：高60公分大田侧柏1.5万株，价格面议，欢迎联系。',
 'sup_phone': '15877344352',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168276',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径1公分国槐3000棵',
 'sup_address': '周至县四屯镇新亚村',
 'sup_description': '出售：胸径1公分国槐3000棵，价格面议，欢迎联系。',
 'sup_phone': '13092046069',
 'sup_user': '何先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-10',
 'info_from': 'http://222.90.83.241/show.aspx?id=168277',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：胸径15公分龙爪槐20棵',
 'sup_address': '周至县四屯镇联三村',
 'sup_description': '出售：胸径15公分龙爪槐20棵，价格面议，欢迎联系。',
 'sup_phone': '15091151300',
 'sup_user': '李先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-06-11',
 'info_from': 'http://222.90.83.241/show.aspx?id=168278',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-01',
 'pub_title': '出售：高80公分兰天竹营养钵3500株',
 'sup_address': '周至县四屯镇联二村',
 'sup_description': '出售：高80公分兰天竹营养钵3500株，价格面议，欢迎联系。',
 'sup_phone': '15319458368',
 'sup_user': '张女士'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-08-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168280',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售直径3公分左右的大叶女贞10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售直径3公分左右的大叶女贞10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:03:59 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168281',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径4-5公分以上的红梅10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径4-5公分以上的红梅10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-07-02',
 'info_from': 'http://222.90.83.241/show.aspx?id=168282',
 'pub_address': '西安市周至县',
 'pub_time': '2019-06-02',
 'pub_title': '出售胸径3-4公分以上的红枫10亩',
 'sup_address': '周至县竹峪镇张龙村周至县龙茂苗木专业合作社',
 'sup_description': '出售胸径3-4公分以上的红枫10亩，价格电议。',
 'sup_phone': '13991373863',
 'sup_user': '张先生'}, 'type': 'supply'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 137, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:00 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=158138',
 'pub_address': '西安市阎良区',
 'pub_time': '2018-12-04',
 'pub_title': '收购莲花白大白菜',
 'sup_address': '西安市阎良区关山镇关山街道北十字东50米',
 'sup_description': '收购莲花白、大白菜，现场验货、按质论价，欢迎联系销售。',
 'sup_phone': '13519163465',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-18',
 'info_from': 'http://222.90.83.241/show.aspx?id=163917',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-18',
 'pub_title': '求购玉米1000斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购玉米1000斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:01 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-30',
 'info_from': 'http://222.90.83.241/show.aspx?id=164101',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-20',
 'pub_title': '求购玉米',
 'sup_address': '陕西省汉中市汉台区老君镇',
 'sup_description': '玉米所在地：汉中市汉台区发布时间：2019-02-28现需要玉米一千斤要求玉米粒饱满干净没有发霉价格按照玉米的质量定价商量家有玉米的可以和我聊天非诚勿扰！谢谢',
 'sup_phone': '13891631077',
 'sup_user': '姚女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-12-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164172',
 'pub_address': '陕西省汉中市',
 'pub_time': '2019-03-21',
 'pub_title': '收购黄华占稻谷',
 'sup_address': '陕西省汉中市勉县周家山镇明星村',
 'sup_description': '勉县定军米业发展有限责任公司现大量收购黄华占稻谷，一等每斤1.40元、二等每斤1.38元、三等每斤1.37元；普通稻谷每斤1.30元。',
 'sup_phone': '0916-3416161',
 'sup_user': '唐老板'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-06',
 'info_from': 'http://222.90.83.241/show.aspx?id=164177',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-21',
 'pub_title': '求购小麦',
 'sup_address': '鄠邑区甘河镇胜利村',
 'sup_description': '大量求购小麦，价格面议，欢迎联系。',
 'sup_phone': '13909282750',
 'sup_user': '杜先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:02 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-05',
 'info_from': 'http://222.90.83.241/show.aspx?id=164323',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-22',
 'pub_title': '求购玉米5000-10000斤',
 'sup_address': '陕西省西安市周至县司竹镇马坊村',
 'sup_description': '本人现求购玉米5000-10000斤，如有货的朋友请联系。',
 'sup_phone': '15769188775',
 'sup_user': '齐先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:03 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-26',
 'info_from': 'http://222.90.83.241/show.aspx?id=164603',
 'pub_address': '西安市周至县',
 'pub_time': '2019-03-26',
 'pub_title': '求购黄豆500斤',
 'sup_address': '周至县广济镇小留村',
 'sup_description': '求购黄豆500斤。优质。',
 'sup_phone': '15339152108',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2020-03-28',
 'info_from': 'http://222.90.83.241/show.aspx?id=164700',
 'pub_address': '西安市户县',
 'pub_time': '2019-03-28',
 'pub_title': '求购玉米、小麦',
 'sup_address': '鄠邑区玉蝉街办南斑村',
 'sup_description': '大量收购玉米、小麦，就质论价，欢迎联系。',
 'sup_phone': '15809209688',
 'sup_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:04 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-04-01',
 'info_from': 'http://222.90.83.241/show.aspx?id=164733',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-03-29',
 'pub_title': '需要购买莲藕种',
 'sup_address': '汉中市汉台区七里办事处吴基庄村',
 'sup_description': '需要帮舅舅家购买莲藕种，物美价廉的',
 'sup_phone': '13772809382',
 'sup_user': '张香军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:04:05 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2019-05-31',
 'info_from': 'http://222.90.83.241/show.aspx?id=164961',
 'pub_address': '汉中市汉台区',
 'pub_time': '2019-04-04',
 'pub_title': '购买玉米',
 'sup_address': '佛坪县袁家庄街道办王家湾村',
 'sup_description': '购买玉米所在地：汉中市佛坪县发布时间：2019-03-27要求玉米无沙粒、无腐烂、颗粒饱满',
 'sup_phone': '13992619954',
 'sup_user': '张三香'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 156, in process_item
    print("item type:"+type(item))
TypeError: can only concatenate str (not "type") to str
2019-06-04 01:10:21 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://222.90.83.241/show.aspx?id=168274. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:12:45 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://222.90.83.241/show.aspx?id=168274. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:30:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/show-3536.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:30:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/show-3614.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:30:17 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/show-3537.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:30:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '江苏省宿迁市',
 'info_from': 'http://www.zgncpw.com/buy/show-2907.html',
 'pub_address': '江苏省宿迁市',
 'pub_time': '2018-08-06',
 'pub_title': '求生猪养猪户卖三元苗猪',
 'pur_address': '1',
 'pur_num': '1',
 'pur_require': '需求数量1,价格1,1,1,江苏省宿迁市',
 'pur_user': '董旺'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '大小齐全',
 'info_from': 'http://www.zgncpw.com/buy/show-11506.html',
 'pub_address': '北京市市辖区顺义区杨镇地区.',
 'pub_time': '2018-08-06',
 'pub_title': '河北廊坊鱼苗批发市场在哪里 ？鲤鱼苗多少钱一条',
 'pur_address': '大小齐全',
 'pur_num': '10000',
 'pur_require': '需求数量10000,价格4,大小齐全,大小齐全,大小齐全',
 'pur_user': '李伟'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '1两到1斤左右',
 'info_from': 'http://www.zgncpw.com/buy/show-15601.html',
 'pub_address': '北京市市辖区顺义区杨镇地区.',
 'pub_time': '2018-08-06',
 'pub_title': '求购河北天津山西内蒙鱼苗请联北京鱼苗场淡',
 'pur_address': '1两到1斤左右',
 'pur_num': '协定',
 'pur_require': '需求数量协定,价格面议,1两到1斤左右,1两到1斤左右,1两到1斤左右',
 'pur_user': '李伟'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:50 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16406.html',
 'pub_address': '江苏省镇江市润州区宝塔路街.',
 'pub_time': '2018-10-08',
 'pub_title': '求购各种干货鱼干虾米',
 'pur_address': '',
 'pur_num': '江苏省镇江市润州区宝塔路街.',
 'pur_require': '需求数量江苏省镇江市润州区宝塔路街.,价格2019-10-08,,,',
 'pur_user': '陈经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-12149.html',
 'pub_address': '江苏省宿迁市',
 'pub_time': '2018-08-06',
 'pub_title': '江苏地区仔猪市场价格报价',
 'pur_address': '长期有效',
 'pur_num': '500',
 'pur_require': '需求数量500,价格300,江苏省宿迁市,长期有效,',
 'pur_user': '董旺'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16444.html',
 'pub_address': '浙江省宁波市',
 'pub_time': '2018-10-27',
 'pub_title': '寻求土鸡牛羊合作伙伴',
 'pur_address': '浙江省宁波市',
 'pur_num': '月供4吨左右',
 'pur_require': '需求数量月供4吨左右,价格羊120一公斤牛13,真空包装2.5公斤,浙江省宁波市,长期有效',
 'pur_user': '古艳'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16458.html',
 'pub_address': '浙江省',
 'pub_time': '2018-12-17',
 'pub_title': '有牛羊的联系我 大量要',
 'pur_address': '2019-11-08',
 'pur_num': '10000',
 'pur_require': '需求数量10000,价格白条,浙江省,2019-11-08,',
 'pur_user': '赵小姐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16511.html',
 'pub_address': '河南省周口市项城市范集镇',
 'pub_time': '2019-01-09',
 'pub_title': '求购山羊种羊',
 'pur_address': '2019-07-10',
 'pur_num': '10-12只',
 'pur_require': '需求数量10-12只,价格最好是小羊或已孕的母羊,河南省周口市项城市范集镇,2019-07-10,',
 'pur_user': '赵东阳'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16514.html',
 'pub_address': '安徽省芜湖市',
 'pub_time': '2019-01-17',
 'pub_title': '出售螃蟹',
 'pur_address': '',
 'pur_num': '安徽省芜湖市',
 'pur_require': '需求数量安徽省芜湖市,价格长期有效,,,',
 'pur_user': '程阿林'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16552.html',
 'pub_address': '浙江省',
 'pub_time': '2019-03-07',
 'pub_title': '大量收购土鸡牛羊肉',
 'pur_address': '',
 'pur_num': '浙江省',
 'pur_require': '需求数量浙江省,价格长期有效,,,',
 'pur_user': '常'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16533.html',
 'pub_address': '浙江省宁波市鄞州区',
 'pub_time': '2019-02-20',
 'pub_title': '大量要牛羊土鸡 有货的联系我长期要',
 'pur_address': '',
 'pur_num': '50000',
 'pur_require': '需求数量50000,价格浙江省宁波市鄞州区,长期有效,,',
 'pur_user': '赵小姐'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:51 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16535.html',
 'pub_address': '全国',
 'pub_time': '2019-02-21',
 'pub_title': None,
 'pur_address': '',
 'pur_num': '全国',
 'pur_require': '需求数量全国,价格长期有效,,,',
 'pur_user': '刘灿'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-12176.html',
 'pub_address': '江苏省宿迁市',
 'pub_time': '2018-08-06',
 'pub_title': '江苏今日仔猪市场价格行情',
 'pur_address': '长期有效',
 'pur_num': '500',
 'pur_require': '需求数量500,价格300,江苏省宿迁市,长期有效,',
 'pur_user': '董旺'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16569.html',
 'pub_address': '安徽省蚌埠市',
 'pub_time': '2019-03-21',
 'pub_title': '求购香菇.黑木耳.银耳.松茸.羊肚菌.竹荪.猴头菇.灵芝',
 'pur_address': '安徽省蚌埠市',
 'pur_num': '不限',
 'pur_require': '需求数量不限,价格面议,中性包装,安徽省蚌埠市,长期有效',
 'pur_user': '朱经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16662.html',
 'pub_address': '河北省保定市',
 'pub_time': '2019-05-14',
 'pub_title': '大量求购洋葱',
 'pur_address': '河北省保定市',
 'pur_num': '50吨一单',
 'pur_require': '需求数量50吨一单,价格以质论价,按需包装,河北省保定市,长期有效',
 'pur_user': '李先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '19',
 'info_from': 'http://www.zgncpw.com/buy/show-16655.html',
 'pub_address': '浙江省杭州市江干区闸弄口街.',
 'pub_time': '2019-05-13',
 'pub_title': '缅甸鼎盛国际18469640680求购',
 'pur_address': '17',
 'pur_num': '100',
 'pur_require': '需求数量100,价格58,15,17,19',
 'pur_user': '小吴少'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16665.html',
 'pub_address': '河北省保定市',
 'pub_time': '2019-05-14',
 'pub_title': '大量求购马铃薯',
 'pur_address': '河北省保定市',
 'pur_num': '50吨一单',
 'pur_require': '需求数量50吨一单,价格以质论价,按需包装,河北省保定市,长期有效',
 'pur_user': '李先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16734.html',
 'pub_address': '河北省保定市',
 'pub_time': '2019-05-23',
 'pub_title': '大量求购洋葱',
 'pur_address': '长期有效',
 'pur_num': '50吨一单',
 'pur_require': '需求数量50吨一单,价格以质论价,河北省保定市,长期有效,',
 'pur_user': '李先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16741.html',
 'pub_address': '安徽省蚌埠市蚌山区',
 'pub_time': '2019-05-24',
 'pub_title': '求购竹笋干,黄秋葵,黄花菜,梅干菜,干豆角,各种咸菜',
 'pur_address': '安徽省蚌埠市蚌山区',
 'pur_num': '见详细说明',
 'pur_require': '需求数量见详细说明,价格面议,中性包装,安徽省蚌埠市蚌山区,长期有效',
 'pur_user': '朱经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16764.html',
 'pub_address': '江苏省宿迁市',
 'pub_time': '2019-05-30',
 'pub_title': '新办脱水加工厂需求订单及代加工合作',
 'pur_address': '',
 'pur_num': '江苏省宿迁市',
 'pur_require': '需求数量江苏省宿迁市,价格2020-05-31,,,',
 'pur_user': '周鑫'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16781.html',
 'pub_address': '江苏省徐州市泉山区',
 'pub_time': '2019-06-01',
 'pub_title': '求购一批红薯',
 'pur_address': '',
 'pur_num': '江苏省徐州市泉山区',
 'pur_require': '需求数量江苏省徐州市泉山区,价格长期有效,,,',
 'pur_user': '郭经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16732.html',
 'pub_address': '河北省保定市',
 'pub_time': '2019-05-23',
 'pub_title': '大量求购马铃薯',
 'pur_address': '长期有效',
 'pur_num': '50吨一单',
 'pur_require': '需求数量50吨一单,价格以质论价,河北省保定市,长期有效,',
 'pur_user': '李先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:52 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16782.html',
 'pub_address': '江苏省徐州市泉山区',
 'pub_time': '2019-06-01',
 'pub_title': '求购一批西红柿',
 'pur_address': '',
 'pur_num': '江苏省徐州市泉山区',
 'pur_require': '需求数量江苏省徐州市泉山区,价格长期有效,,,',
 'pur_user': '郭经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16783.html',
 'pub_address': '江苏省徐州市泉山区',
 'pub_time': '2019-06-01',
 'pub_title': '求购一批土豆',
 'pur_address': '',
 'pur_num': '江苏省徐州市泉山区',
 'pur_require': '需求数量江苏省徐州市泉山区,价格长期有效,,,',
 'pur_user': '郭经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16780.html',
 'pub_address': '江苏省徐州市泉山区',
 'pub_time': '2019-06-01',
 'pub_title': '求购一批香菇',
 'pur_address': '',
 'pur_num': '江苏省徐州市泉山区',
 'pur_require': '需求数量江苏省徐州市泉山区,价格长期有效,,,',
 'pur_user': '郭经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16784.html',
 'pub_address': '江苏省徐州市泉山区',
 'pub_time': '2019-06-01',
 'pub_title': '求购一批南瓜',
 'pur_address': '',
 'pur_num': '江苏省徐州市泉山区',
 'pur_require': '需求数量江苏省徐州市泉山区,价格长期有效,,,',
 'pur_user': '郭经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16785.html',
 'pub_address': '江苏省徐州市泉山区',
 'pub_time': '2019-06-01',
 'pub_title': '求购一批猴头菇',
 'pur_address': '',
 'pur_num': '江苏省徐州市泉山区',
 'pur_require': '需求数量江苏省徐州市泉山区,价格长期有效,,,',
 'pur_user': '郭经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-8081.html',
 'pub_address': '河北省保定市',
 'pub_time': '2017-09-11',
 'pub_title': '求购海带紫菜',
 'pur_address': '',
 'pur_num': '河北省保定市',
 'pur_require': '需求数量河北省保定市,价格长期有效,,,',
 'pur_user': '刘女士'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-9947.html',
 'pub_address': '安徽省亳州市蒙城县楚村镇',
 'pub_time': '2017-09-21',
 'pub_title': '求购黄粉虫壁虎麻蜥蜴活体',
 'pur_address': '',
 'pur_num': '安徽省亳州市蒙城县楚村镇',
 'pur_require': '需求数量安徽省亳州市蒙城县楚村镇,价格长期有效,,,',
 'pur_user': ' 张保'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '1000000000',
 'info_from': 'http://www.zgncpw.com/buy/show-12985.html',
 'pub_address': '广东省佛山市南海区里水镇',
 'pub_time': '2017-09-27',
 'pub_title': '长年收购成品草鱼.鲫鱼.大头鱼.鲤鱼.锦鲤.青鱼.黄骨鱼',
 'pur_address': '4斤以上',
 'pur_num': '10000000',
 'pur_require': '需求数量10000000,价格电联,2斤以上,4斤以上,1000000000',
 'pur_user': '林福培'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-10089.html',
 'pub_address': '河南省新乡市原阳县城关镇',
 'pub_time': '2018-08-06',
 'pub_title': '求购马铃薯',
 'pur_address': '河南省新乡市原阳县城关镇',
 'pur_num': '1000吨',
 'pur_require': '需求数量1000吨,价格协商,中性包装,河南省新乡市原阳县城关镇,长期有效',
 'pur_user': '刘静'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16354.html',
 'pub_address': '山东省潍坊市安丘市吾山镇',
 'pub_time': '2018-08-11',
 'pub_title': '20亩20万斤大葱求购！',
 'pur_address': '',
 'pur_num': '山东省潍坊市安丘市吾山镇',
 'pur_require': '需求数量山东省潍坊市安丘市吾山镇,价格长期有效,,,',
 'pur_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市',
 'info_from': 'http://www.zgncpw.com/buy/show-16355.html',
 'pub_address': '河北省保定市',
 'pub_time': '2018-08-13',
 'pub_title': '求购蜂蜜',
 'pur_address': '纸箱',
 'pur_num': '20吨',
 'pur_require': '需求数量20吨,价格38---88元/斤,以质论价,纸箱,河北省保定市',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:53 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区南关街.',
 'info_from': 'http://www.zgncpw.com/buy/show-16382.html',
 'pub_address': '河北省保定市南市区南关街.',
 'pub_time': '2018-09-03',
 'pub_title': '求购洋葱，大蒜，鲜姜',
 'pur_address': '协商',
 'pur_num': '60吨',
 'pur_require': '需求数量60吨,价格1.6----3.8,以质论价,协商,河北省保定市南市区南关街.',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16393.html',
 'pub_address': '河南省南阳市新野县上庄乡',
 'pub_time': '2018-09-14',
 'pub_title': '出售钢葱',
 'pur_address': '',
 'pur_num': '河南省南阳市新野县上庄乡',
 'pur_require': '需求数量河南省南阳市新野县上庄乡,价格长期有效,,,',
 'pur_user': '王建军'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16396.html',
 'pub_address': '湖南省株洲市茶陵县火田镇',
 'pub_time': '2018-09-25',
 'pub_title': '大量农田闲置，可根据各位老板需求进行种植',
 'pur_address': '',
 'pur_num': '湖南省株洲市茶陵县火田镇',
 'pur_require': '需求数量湖南省株洲市茶陵县火田镇,价格2019-01-01 ,,,',
 'pur_user': '周先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16399.html',
 'pub_address': '辽宁省沈阳市',
 'pub_time': '2018-09-30',
 'pub_title': '大量收购青红萝卜',
 'pur_address': '辽宁省沈阳市',
 'pur_num': '不限',
 'pur_require': '需求数量不限,价格详谈,不限,辽宁省沈阳市,长期有效',
 'pur_user': '董胜利'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16391.html',
 'pub_address': '甘肃省白银市白银区',
 'pub_time': '2018-09-12',
 'pub_title': '大量红葱炖羊肉葱出售',
 'pur_address': '',
 'pur_num': '100亩',
 'pur_require': '需求数量100亩,价格甘肃省白银市白银区,长期有效,,',
 'pur_user': '高月琴'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16400.html',
 'pub_address': '河北省保定市北市区',
 'pub_time': '2018-10-03',
 'pub_title': '求购优至土豆',
 'pur_address': '',
 'pur_num': '河北省保定市北市区',
 'pur_require': '需求数量河北省保定市北市区,价格长期有效,,,',
 'pur_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16452.html',
 'pub_address': '安徽省蚌埠市蚌山区',
 'pub_time': '2018-10-31',
 'pub_title': '求购干辣椒.八角.花椒.丁香,草果,香菇,黑木耳',
 'pur_address': '安徽省蚌埠市蚌山区',
 'pur_num': '不限',
 'pur_require': '需求数量不限,价格面议,中性包装,安徽省蚌埠市蚌山区,长期有效',
 'pur_user': '朱经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16478.html',
 'pub_address': '山东省青岛市李沧区',
 'pub_time': '2018-12-17',
 'pub_title': '寻求果蔬及农副产品供货商',
 'pur_address': '',
 'pur_num': '山东省青岛市李沧区',
 'pur_require': '需求数量山东省青岛市李沧区,价格长期有效,,,',
 'pur_user': '马英超'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16440.html',
 'pub_address': '河南省新乡市原阳县城关镇',
 'pub_time': '2018-10-23',
 'pub_title': '求购干洋葱粒、萝卜干丝、西红柿、笋干、山楂等',
 'pur_address': '长期有效',
 'pur_num': '1000吨',
 'pur_require': '需求数量1000吨,价格商议,河南省新乡市原阳县城关镇,长期有效,',
 'pur_user': '张佳'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16434.html',
 'pub_address': '安徽省蚌埠市蚌山区',
 'pub_time': '2018-12-17',
 'pub_title': '求购香菇.黑木耳.银耳.干辣椒.八角.花椒.丁香.草果',
 'pur_address': '安徽省蚌埠市蚌山区',
 'pur_num': '不限',
 'pur_require': '需求数量不限,价格面议,中性包装,安徽省蚌埠市蚌山区,长期有效',
 'pur_user': '朱经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:54 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16425.html',
 'pub_address': '河南省新乡市原阳县城关镇',
 'pub_time': '2018-12-17',
 'pub_title': '求购土豆，红萝卜，白萝卜，红薯生姜等',
 'pur_address': '长期有效',
 'pur_num': '1000吨',
 'pur_require': '需求数量1000吨,价格商议,河南省新乡市原阳县城关镇,长期有效,',
 'pur_user': '张佳'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16424.html',
 'pub_address': '河南省新乡市原阳县城关镇',
 'pub_time': '2018-12-17',
 'pub_title': '求购八角，花椒，洋葱，生姜红辣椒等',
 'pur_address': '长期有效',
 'pur_num': '1000吨',
 'pur_require': '需求数量1000吨,价格商议,河南省新乡市原阳县城关镇,长期有效,',
 'pur_user': '张佳'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-11729.html',
 'pub_address': '全国',
 'pub_time': '2017-04-19',
 'pub_title': '求购三元仔猪',
 'pur_address': '长期有效',
 'pur_num': '30头',
 'pur_require': '需求数量30头,价格详谈,全国,长期有效,',
 'pur_user': '赵景峰'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '2018-04-24 ',
 'info_from': 'http://www.zgncpw.com/buy/show-11796.html',
 'pub_address': '浙江省宁波市鄞州区梅墟街.',
 'pub_time': '2017-04-24',
 'pub_title': '求购大批量乌骨鸡',
 'pur_address': '浙江省宁波市鄞州区梅墟街.',
 'pur_num': '1800',
 'pur_require': '需求数量1800,价格156,真空包装,浙江省宁波市鄞州区梅墟街.,2018-04-24 ',
 'pur_user': '代玉波'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-11897.html',
 'pub_address': '山东省',
 'pub_time': '2017-05-02',
 'pub_title': '4-6钱小龙虾',
 'pur_address': '',
 'pur_num': '山东省',
 'pur_require': '需求数量山东省,价格长期有效,,,',
 'pur_user': '王利菊'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-12109.html',
 'pub_address': '山东省济宁市梁山县梁山街.',
 'pub_time': '2017-06-15',
 'pub_title': '内蒙纯种杜泊羊繁育基地内蒙杜泊羊种羊价格杜泊羊杂交技术',
 'pur_address': '',
 'pur_num': '山东省济宁市梁山县梁山街.',
 'pur_require': '需求数量山东省济宁市梁山县梁山街.,价格长期有效,,,',
 'pur_user': '陈建成'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:55 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-11878.html',
 'pub_address': '辽宁省大连市',
 'pub_time': '2017-04-30',
 'pub_title': '大量需求全品类农副产品',
 'pur_address': '',
 'pur_num': '辽宁省大连市',
 'pur_require': '需求数量辽宁省大连市,价格长期有效,,,',
 'pur_user': '曲路'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-14862.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-07-18',
 'pub_title': '求购白萝卜，红萝卜',
 'pur_address': '',
 'pur_num': '江苏省徐州市鼓楼区黄楼街.',
 'pur_require': '需求数量江苏省徐州市鼓楼区黄楼街.,价格长期有效,,,',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16313.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-07-18',
 'pub_title': '求购香菇',
 'pur_address': '江苏省徐州市鼓楼区黄楼街.',
 'pur_num': '200吨',
 'pur_require': '需求数量200吨,价格面议,中性,江苏省徐州市鼓楼区黄楼街.,长期有效',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16315.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-07-18',
 'pub_title': '求购银耳',
 'pur_address': '江苏省徐州市鼓楼区黄楼街.',
 'pur_num': '100吨',
 'pur_require': '需求数量100吨,价格面议,中性,江苏省徐州市鼓楼区黄楼街.,长期有效',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16314.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-07-18',
 'pub_title': '求购木耳',
 'pur_address': '江苏省徐州市鼓楼区黄楼街.',
 'pur_num': '200吨',
 'pur_require': '需求数量200吨,价格面议,中性,江苏省徐州市鼓楼区黄楼街.,长期有效',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16317.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-07-18',
 'pub_title': '求购松茸',
 'pur_address': '江苏省徐州市鼓楼区黄楼街.',
 'pur_num': '50吨',
 'pur_require': '需求数量50吨,价格面议,中性,江苏省徐州市鼓楼区黄楼街.,长期有效',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16316.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-07-18',
 'pub_title': '求购笋干',
 'pur_address': '江苏省徐州市鼓楼区黄楼街.',
 'pur_num': '300吨',
 'pur_require': '需求数量300吨,价格面议,中性,江苏省徐州市鼓楼区黄楼街.,长期有效',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-13975.html',
 'pub_address': '河北省保定市北市区',
 'pub_time': '2018-07-26',
 'pub_title': '求购优质萝卜',
 'pur_address': '',
 'pur_num': '河北省保定市北市区',
 'pur_require': '需求数量河北省保定市北市区,价格长期有效,,,',
 'pur_user': '黄先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-16320.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-07-18',
 'pub_title': '求购猴头菇',
 'pur_address': '江苏省徐州市鼓楼区黄楼街.',
 'pur_num': '50吨',
 'pur_require': '需求数量50吨,价格面议,中性,江苏省徐州市鼓楼区黄楼街.,长期有效',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16352.html',
 'pub_address': '江西省赣州市安远县凤山乡',
 'pub_time': '2018-07-21',
 'pub_title': '1500亩紫山药上市中',
 'pur_address': '长期有效',
 'pur_num': '3cm*4cm',
 'pur_require': '需求数量3cm*4cm,价格25cm*30cm,江西省赣州市安远县凤山乡,长期有效,',
 'pur_user': '钟喜春'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:56 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-4781.html',
 'pub_address': '广东省茂名市',
 'pub_time': '2017-01-05',
 'pub_title': '高价收购黑颈龟（臭龟）',
 'pur_address': '',
 'pur_num': '广东省茂名市',
 'pur_require': '需求数量广东省茂名市,价格长期有效,,,',
 'pur_user': '黄修斌'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-4348.html',
 'pub_address': '广东省茂名市',
 'pub_time': '2017-01-05',
 'pub_title': '长期高价收购金钱龟',
 'pur_address': '',
 'pur_num': '广东省茂名市',
 'pur_require': '需求数量广东省茂名市,价格长期有效,,,',
 'pur_user': '黄修斌'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-3561.html',
 'pub_address': '山东省济宁市',
 'pub_time': '2017-01-05',
 'pub_title': '2013年鲁西黄牛价格',
 'pur_address': '',
 'pur_num': '山东省济宁市',
 'pur_require': '需求数量山东省济宁市,价格长期有效,,,',
 'pur_user': '赵舰'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-11019.html',
 'pub_address': '河北省保定市北市区',
 'pub_time': '2018-07-26',
 'pub_title': '求购鲜姜大姜',
 'pur_address': '',
 'pur_num': '河北省保定市北市区',
 'pur_require': '需求数量河北省保定市北市区,价格长期有效,,,',
 'pur_user': '王先生'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '山东省济宁市',
 'info_from': 'http://www.zgncpw.com/buy/show-4264.html',
 'pub_address': '山东省济宁市',
 'pub_time': '2017-01-05',
 'pub_title': '广东肉牛价格广东肉牛养殖场肉牛交易市场',
 'pur_address': '免费送货',
 'pur_num': '10000',
 'pur_require': '需求数量10000,价格3000,300斤,免费送货,山东省济宁市',
 'pur_user': '高强'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '长期有效',
 'info_from': 'http://www.zgncpw.com/buy/show-1958.html',
 'pub_address': '江苏省宿迁市',
 'pub_time': '2017-01-05',
 'pub_title': '出售鹅苗鸭苗蛋鸭苗麻鸭苗苏阳鹅苗种鹅孵化基地',
 'pur_address': '江苏省宿迁市',
 'pur_num': '10000',
 'pur_require': '需求数量10000,价格4,良种,江苏省宿迁市,长期有效',
 'pur_user': '徐长城'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16032.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-06-04',
 'pub_title': '木耳',
 'pur_address': '',
 'pur_num': '江苏省徐州市鼓楼区黄楼街.',
 'pur_require': '需求数量江苏省徐州市鼓楼区黄楼街.,价格长期有效,,,',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16100.html',
 'pub_address': '山东省',
 'pub_time': '2018-06-06',
 'pub_title': '长期求购蔬菜水果',
 'pur_address': '',
 'pur_num': '500吨',
 'pur_require': '需求数量500吨,价格山东省,长期有效,,',
 'pur_user': '张经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区',
 'info_from': 'http://www.zgncpw.com/buy/show-16218.html',
 'pub_address': '河北省保定市南市区',
 'pub_time': '2018-06-17',
 'pub_title': '求购白萝卜，胡萝卜',
 'pur_address': '纸箱',
 'pur_num': '160吨',
 'pur_require': '需求数量160吨,价格1----1.8元/,品种不限,纸箱,河北省保定市南市区',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-15786.html',
 'pub_address': '安徽省合肥市瑶海区红光街.',
 'pub_time': '2018-06-11',
 'pub_title': '采购大蒜',
 'pur_address': '',
 'pur_num': '安徽省合肥市瑶海区红光街.',
 'pur_require': '需求数量安徽省合肥市瑶海区红光街.,价格长期有效,,,',
 'pur_user': '刘菲'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区',
 'info_from': 'http://www.zgncpw.com/buy/show-16222.html',
 'pub_address': '河北省保定市南市区',
 'pub_time': '2018-06-18',
 'pub_title': '求购马铃薯',
 'pur_address': '纸箱',
 'pur_num': '300吨',
 'pur_require': '需求数量300吨,价格1.6---2.6元,品种不限,纸箱,河北省保定市南市区',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:57 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区',
 'info_from': 'http://www.zgncpw.com/buy/show-16224.html',
 'pub_address': '河北省保定市南市区',
 'pub_time': '2018-06-18',
 'pub_title': '求购洋葱，大蒜',
 'pur_address': '纸箱',
 'pur_num': '160吨',
 'pur_require': '需求数量160吨,价格1.6---2.6元,品种不限,纸箱,河北省保定市南市区',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区',
 'info_from': 'http://www.zgncpw.com/buy/show-16226.html',
 'pub_address': '河北省保定市南市区',
 'pub_time': '2018-06-18',
 'pub_title': '求购干辣椒',
 'pur_address': '纸箱',
 'pur_num': '20吨',
 'pur_require': '需求数量20吨,价格16---28元/斤,品种不限,纸箱,河北省保定市南市区',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区',
 'info_from': 'http://www.zgncpw.com/buy/show-16235.html',
 'pub_address': '河北省保定市南市区',
 'pub_time': '2018-06-19',
 'pub_title': '求购洋葱，大蒜',
 'pur_address': '纸箱',
 'pur_num': '160吨',
 'pur_require': '需求数量160吨,价格1----3.8元/,品种不限,纸箱,河北省保定市南市区',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区',
 'info_from': 'http://www.zgncpw.com/buy/show-16250.html',
 'pub_address': '河北省保定市南市区',
 'pub_time': '2018-06-20',
 'pub_title': '求购洋葱，大蒜',
 'pur_address': '纸箱',
 'pur_num': '160吨',
 'pur_require': '需求数量160吨,价格1.6----2.6,品种不限,纸箱,河北省保定市南市区',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区',
 'info_from': 'http://www.zgncpw.com/buy/show-16227.html',
 'pub_address': '河北省保定市南市区',
 'pub_time': '2018-06-18',
 'pub_title': '求购白萝卜，胡萝卜',
 'pur_address': '纸箱',
 'pur_num': '160吨',
 'pur_require': '需求数量160吨,价格1.2---2.6元,品种不限,纸箱,河北省保定市南市区',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-16035.html',
 'pub_address': '江苏省徐州市鼓楼区黄楼街.',
 'pub_time': '2018-06-04',
 'pub_title': '山药',
 'pur_address': '',
 'pur_num': '江苏省徐州市鼓楼区黄楼街.',
 'pur_require': '需求数量江苏省徐州市鼓楼区黄楼街.,价格长期有效,,,',
 'pur_user': '李经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '河北省保定市南市区',
 'info_from': 'http://www.zgncpw.com/buy/show-16255.html',
 'pub_address': '河北省保定市南市区',
 'pub_time': '2018-06-20',
 'pub_title': '求狗红薯，紫薯',
 'pur_address': '纸箱',
 'pur_num': '80吨',
 'pur_require': '需求数量80吨,价格1----2.6元/,品种不限,纸箱,河北省保定市南市区',
 'pur_user': '石经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:58 [scrapy.core.scraper] ERROR: Error processing {'result_item': {'end_time': '',
 'info_from': 'http://www.zgncpw.com/buy/show-8585.html',
 'pub_address': '吉林省四平市伊通满族自治县营城子镇',
 'pub_time': '2016-08-10',
 'pub_title': '+【兴牛养殖】吉林省夏洛莱牛养殖基地|夏洛莱牛繁育基地',
 'pur_address': '',
 'pur_num': '吉林省四平市伊通满族自治县营城子镇',
 'pur_require': '需求数量吉林省四平市伊通满族自治县营城子镇,价格长期有效,,,',
 'pur_user': '汪经理'}, 'type': 'purchase'}
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\pipelines.py", line 184, in process_item
    # data = (supply_item['pub_title'],supply_item['sup_description'],supply_item['end_time'],'',supply_item['sup_phone'],supply_item['sup_user'],'中国农产品网','需求')
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'sup_description'
2019-06-04 01:30:58 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/show-9096.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:30:58 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/show-8922.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:30:58 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/show-9033.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:31:07 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/list-18476-3.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:31:07 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/buy/show-12985.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-06-04 01:38:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zgncpw.com/sell/list-1003.html> (referer: http://www.zgncpw.com/sell/list-16.html)
Traceback (most recent call last):
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Documents\Desktop\git\diandianbangnong\diandianCrawling\crawling\crawling\spiders\Zgncpw_Sup_Spider.py", line 68, in parse_pro
    meta={"item": deepcopy(item), "type": "supply"}
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\request\__init__.py", line 25, in __init__
    self._set_url(url)
  File "c:\users\严修灏\appdata\local\programs\python\python37\lib\site-packages\scrapy\http\request\__init__.py", line 62, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: 
2019-06-04 01:38:11 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://www.zgncpw.com/sell/show/48715/. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
